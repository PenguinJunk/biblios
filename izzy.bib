@String { ao        = {Applied Optics} }
@String { csr       = {Continental Shelf Research} }
@String { cvgip     = {Computing Vision Graphics Image Processing} }
@String { iefuzzy   = {IEEE Transactions on Fuzzy Systems} }
@String { iegrs     = {IEEE Transactions on Geoscience and Remote Sensing} }
@String { ieip      = {IEEE Transactions on Image Processing} }
@String { ieit      = {IEEE Transactions on Information Theory} }
@String { iepami    = {IEEE Transactions on Pattern Analysis and Machine Intelligence} }
@String { iesmc     = {IEEE Transactions on Systems Man and Cybernetics} }
@String { iesp      = {IEEE Transactions on Signal Processing} }
@String { ijprs     = {International Journal of Photogrammetry and Remote Sensing} }
@String { ijrs      = {International Journal of Remote Sensing} }
@String { jgr       = {Journal of Geophysical Research} }
@String { jmr       = {Journal of Marine Research} }
@String { joptsocam = {Journal of the Optical Society of America} }
@String { jpr       = {Journal of Plankton Research} }
@String { lo        = {Limnology and Oceanography} }
@String { pers      = {Photogrammetric Engineering and Remote Sensing} }
@String { rse       = {Remote Sensing of Environment} }

@Book{SperberM2017,
  author       = {Dan Sperber and Hugo Mercier},
  title        = {The Enigma of Reason: A New Theory of Human Understanding},
  publisher    = {Harvard University Press},
  comment      = {Discusses reason, its purpose and evolution and how it manifests in human societies. Find that it is a ``tool to convince others and not less importantly a tool for evaluating the arguments others produce to convince us'': p331-332. Reason has evolved to benefit individuals - either by convincing and influencing others and also by evaluating the justifications and arguments given by others: p333. However, much like other evolved features can manifest outside of this proper _domain_, manifesting in the _actual_ domain. ``The proper domain of reasoning is disagreements between oneself and others - clashes of ideas...The actual domain of reasoning, the kind of input that triggers its operations, is. we have argued, the detection of a clash of ideas'': p289-290.  

Reason has been the focus of philosophy and psychology for millennia. Most works argues that reason has an intellectual purpose - to weigh up justifications and produced good, unbiased decisions making. However, the evidence from studies is that reasoning is ``biased - people overwhelmingly find reasons that support their previous beliefs - and it is lazy - people do not carefully scrutinize their own reasons'': p247. When people make choices based on reasons, the results can be worse than using intuition p216-218 ``when people have weak or conflicting intuitions, reason drives them towards the decision for which it is easiest to find reason - the decisions that they can best justify'': p255. 

Starts with introduction of representations and of modules that enable cognition and reasoning. ``Representations are material things, such as activation of groups of neurons in a brain, magnetic patterns in an electronic storage medium, or ink patterns in a piece of paper. They can be inside an organism or in its environment. What makes such a material thing a representation is not its location, its shape, or its structure it is its function. A representation has the function of providing an organisation (or, more generally, any information-processing device) with information about some state of affairs'' p81 

''Metarepresentational modules provide information not only about the representations metarepresented but also, indirectly, these modules have very specific domains, namely, specific aspects of specific kinds of representations... `` p 104  

''The main role of reasons is not to motivate or guide us in reaching conclusions but to explain and justify after the fact the conclusions we have reached'' p112 ``[a review of] a rich range of evidence showing that we have little or no introspective access to our own mental processes and that our verbal reports of these processes are often confabulations'' p114-115 

Inference is deeply linked to reason, in fact reason cannot be achieved without inference at some level - all reasons are inferred, or the reason for these reasons are inferred: p132. ``One of the main claims of this book is that reasoning is not an alternative to intuitive inference; reasoning is use of intuitive inferences about reasons'': p133. ``We infer what our reasons much have been from the conclusions we intuitively arrived at'': p141. 

There have been many different views of reasoning, including probabilistic - and more specifically Bayesian - form of thinking (Oaksford and Chater): p165. Discusses the purpose of reason from an evolutionary perspective. Whilst ancient philosophers would see reason as distinguishing humans from animals, ``The functional effects of reason are roughly the same for Darwin as they were for Aristotle. What is new with Darwin, however, is the use of the effects to explain why reason should have evolved'': p179.  

There's quite a bit of discussion of this including those who believe that reason is a flawed feature. But the book draws the conclusion that ``Reason fulfils two main functions. One function helps solve a major problem of coordination by producing justifications. The other function helps solve a major problem of communication by producing arguments'' (argumentative theory of reasoning): p183. ``The ability to produce and evaluate reasons has not evolved in order to improve psychological insight but as a tool for defending or criticising thoughts and actions, for expressing commitments and for creating mutual expectations. The main function of attributing reasons is to justify oneself and to evaluate the justification of others'': p186. 

The development of idea of the lone reasoner has ``obscured the degree to which reasoning (including scientific reasoning) is a social activity, and the degree to which it is based on intuitions'': p198. 

From studies ``intuitions aimed at gathering the most useful information while reasoning aimed at confirming the participants' stereotypes'': p218. However, this is not so much confirmation bias as ``myside bias''. ``people have no general preference for confirmation. What they find difficult is not looking for counterevidence or counterarguments in general, but only when what is being challenged is their own opinion'': p218. 

The interactionist view of reason explains that better reasons are obtained by argumentation. Weak justifications and arguments, which require less energy to come by, are soon rejected by both sides and the arguers develop better reasons to support their ideas (or their minds are changed) p228. This approach takes less effort and is much more effective than trying to obtain all the arguments alone. Also, people are not good at evaluating the value of their own reasons. However, ``The fact that people are good at evaluating others; reasons is the nail in the coffin of the intellectualist approach. It means that people have the ability to reason objectively, rejecting weak arguments and accepting strong ones but that they do not use these skills on the reasons they produce'': p235. Being biased and lazy, spells disaster for the lone reasoner ... lead to extreme positions'': p247. 

However, ``groups can have disappointing performance not only when pooling physical force but also in a variety of cognitive problems. Brainstorming is a typical example. By and large, group brainstorming doesn't work. In a typical brainstorming session, participants are told not to voice their criticisms, so that they feel free to suggest even wild ideas. This doesn't work: a brainstorming group typically generates fewer and worse ideas then if the ideas of each individual working in isolation had been gathered. By contrast, telling people that 'most studies suggest that you should debate and even criticise each other's ideas' allows them ot produce more ideas'': p266.  

Groups work best when debate is permitted even difficult problems such as predicting geopolitics - groups in which individuals saw the average of their peer's predictions worked better than those who made predictions alone, but those who were allowed to debate rather than just see an average were better still: p270. 

There is even evidence that children who are reasoned with, rather than persuaded using authority, have better outcomes (this could be correlation and not necessarily causation): p291. Also, students who spent time in debate did better than those spending equivalent time essay-writing, even though their writing style was poorer: p298. Also, good evidence that involving citizens in debates about issues that matter results in people who are not only ``better informed and more articulate, but also have a deeper understanding of other people's point of view'': p309-310 [citizens assemblies] (Fishkin 2009, Landemore 2013, Mercier and Landemore 2012). 

Reasoning on the abolition of slavery is given special scrutiny, noting that the anti-abolitionists strongest arguments weren't moral but economic [as with today's anti-environment arguments]. 

The good and the bad of reasoning even applies to scientists, who will find arguments to explain away weak results p318 but will also change their minds when presented with good arguments p319. Looking at so-called solitary geniuses reveals that they were far from solitary and developed their ideas in collaboration with others either by direct discussion or correspondence or by reading their work p322.},
  creationdate = {2022-01-06T13:54:20},
  owner        = {ISargent},
  year         = {2017},
}

@Article{RodriguezVM2020,
  author           = {Carlos Garc\'{\i}a Rodr√≠guez and Jordi Vitri\`{a} and Oscar Mora},
  date             = {2020-11-23},
  title            = {Uncertainty-Based Human-in-the-Loop Deep Learning for Land Cover Segmentation},
  issue            = {22},
  url              = {https://www.mdpi.com/2072-4292/12/22/3836/htm},
  volume           = {12},
  comment          = {Train two neural nets. The first (segmentation) is a u-net that is trained to predict the pixel class. The second (uncertainty detection) takes the outputs of this trained network as inputs and, with a single convolution layer and a softmax output is trained on whether the segmentation output is correct or not.

Given a threshold of confidence (decided by a expert committee) the most uncertain pixels, as predicted by the uncertainty detection network are sent to photo interpreters for revision if needed.},
  creationdate     = {2022-01-24T20:23:35},
  journal          = {Remote Sensing},
  modificationdate = {2023-01-19T08:26:11},
  owner            = {ISargent},
}

@Article{ChengYYGH2018,
  author           = {Cheng, Gong and Yang, Ceyuan and Yao, Xiwen and Guo, Lei and Han, Junwei},
  title            = {When Deep Learning Meets Metric Learning: Remote Sensing Image Scene Classification via Learning Discriminative CNNs},
  doi              = {10.1109/TGRS.2017.2783902},
  number           = {5},
  pages            = {2811-2821},
  volume           = {56},
  comment          = {Simultaneously train a CNN with two objectives - to reduce the scene classification error and to increase the discrimination between inputs of dissimilar classes.

''To this end, apart from minimizing the cross entropy loss (i.e., the softmax classification error from the final FC layer used for the traditional CNN models), we also impose a metric learning regularization term on the CNN features to enforce the D-CNN models to be more discriminative.''

''To this end, we propose the following new objective function, which consists of three terms including a cross-entropy loss term, a metric learning regularization term, and a weight decay term''

''To this end, given each paired training samples, their pair-wise feature distance metric can be measured by computing the Euclidean distance between the D-CNN feature representations''

''To this end, if xi and xj are from the same scene class, their feature distance D(xi , xj ) should be smaller than an up-margin 1; if xi and x j are from different scene classes, their feature distance D(xi , xj ) should be bigger than an down-margin''},
  creationdate     = {2022-01-25T16:04:30},
  journal          = {IEEE Transactions on Geoscience and Remote Sensing},
  modificationdate = {2022-01-25T16:11:37},
  owner            = {ISargent},
  year             = {2018},
}

@Article{AylingC2021,
  author           = {Jacqui Ayling and Adriane Chapman},
  date             = {2020-09-12},
  journaltitle     = {AI and Ethics},
  title            = {Putting AI ethics to work: are the tools ft for purpose?},
  doi              = {https://doi.org/10.1007/s43681-021-00084-x},
  url              = {https://link.springer.com/content/pdf/10.1007/s43681-021-00084-x.pdf},
  comment          = {''Addressing ethical issues systematically requires resource and time, familiarity with assessment/audit regimes and the ability to use the outputs of these tools to make judgements''

AI concerns are
- epistemic - the probabilistic nature of insights, the inherent inscrutability of `black box' algorithms, and the fallibility of the data used for training and input
- normative - fairness of decisional outcomes, erosion of informational privacy, and increasing surveillance and profling of individuals

Phases of AI ethics
 - 2016 to 2019 - high-level ethical principles for AI published such as catalogues of ethical principles and frameworks for ethical, trustworthy responsible AI. These might best address the impacts of AI and data-driven systems framed as applied ethics. Dominated by a philosophical approach as opposed to legal or technical approach.
- A second phase saw a more technical approach from the computer science community. Focus on fairness, accountability and transparency, `ethical-by-design'
- current phase is a move `from what to how', proposals for governance mechanisms, regulation, impact assessment, auditing tools and standards leading to the ability to assure and ultimately, insure AI systems
- latterly a shift towards acknowledgement of political, social and justice issues `beyond the principled and the technical, to practical mechanisms for rectifying power imbalances'

This paper uses audit and assurance practises from other sectors, like financial services, to identify gaps in current ethical impact assessment and audit practises.

''Risks in AI can manifest as either underusing the technology and missing out on value creation and innovation, or overusing/misusing the technology''

First identified 169 ethics documents.
Reduced these to only those ``that s that would give an organisation or practitioner a concrete tool to apply to AI production or deployment'' resulting in a set of 39 documents.

Created some useful typologies:
- stakeholder types
- tool types for impact assessment
- tool types for audits
- processes that were inspected internally vs those that allowed for external inspection
- technical design tools (workshop materials, documentation or technical tools)
- when tool used and if applied to data and/or model

Key fndings:
- The focus has moved from data to models from 2017 to 2020
- Stakeholder types using the tools are limited to those closely related to doing the work
- There is little participation in the assessment or audit process by certain stakeholder groups 
- Only one tool requires external assessment (IEEE)
- Techniques and practices deployed by other forms of Impact Assessment (like EIAs) are not present or rarely suggested in ethical AI impact assessments
- Checklists/questionnaires are ubiquitous across Impact Assessment tools

References https://dl.acm.org/doi/10.1145/3306618.3314289 WhittlestoneNAC2019 for a discussion of why principles are not enough on their own, and how we need to bridge to gap between principles and practice.

''there is no regulatory requirement for any utilization of impact assessments or audits within this feld at the moment, minimizing likely adoption and true application of them''},
  creationdate     = {2022-01-26T12:50:47},
  keywords         = {ethics, corporate culture, AI, EthicsWS},
  modificationdate = {2022-07-05T14:16:20},
  owner            = {ISargent},
}

@Article{ZhuQHSWST2022,
  author           = {Xiao Xiang Zhu and Chunping Qiu and Jingliang Hu and Yilei Shi and Yuanyuan Wang and Michael Schmitt and Hannes Taubenb√∂ck},
  date             = {2022},
  journaltitle     = {Remote Sensing of Environment},
  title            = {The urban morphology on our planet - Global perspectives from space},
  doi              = {https://doi.org/10.1016/j.rse.2021.112794},
  issn             = {0034-4257},
  pages            = {112794},
  url              = {https://www.sciencedirect.com/science/article/pii/S0034425721005149},
  volume           = {269},
  abstract         = {Urbanization is the second largest mega-trend right after climate change. Accurate measurements of urban morphological and demographic figures are at the core of many international endeavors to address issues of urbanization, such as the United Nations' call for ‚ÄúSustainable Cities and Communities‚Äù. In many countries - particularly developing countries -, however, this database does not yet exist. Here, we demonstrate a novel deep learning and big data analytics approach to fuse freely available global radar and multi-spectral satellite data, acquired by the Sentinel-1 and Sentinel-2 satellites. Via this approach, we created the first-ever global and quality controlled urban local climate zones classification covering all cities across the globe with a population greater than 300,000 and made it available to the community (https://doi.org/10.14459/2021mp1633461). Statistical analysis of the data quantifies a global inequality problem: approximately 40\% of the area defined as compact or light/large low-rise accommodates about 60\% of the total population, whereas approximately 30\% of the area defined as sparsely built accommodates only about 10\% of the total population. Beyond, patterns of urban morphology were discovered from the global classification map, confirming a morphologic relationship to the geographical region and related cultural heritage. We expect the open access of our dataset to encourage research on the global change process of urbanization, as a multidisciplinary crowd of researchers will use this baseline for spatial perspective in their work. In addition, it can serve as a unique dataset for stakeholders such as the United Nations to improve their spatial assessments of urbanization.},
  comment          = {Perform ``urban local climate zones classification'' (LCZ) on Sentinel-1 (SAR) and Sentinel-2 data using deep CNN.

The So2Sat LCZ42 benchmark dataset has 17 classes describing largely the building character (compact high-rise, open mid-rise, lightweight low-raise (favela?), etc plus non urban - dense trees, bare rock/paved, etc) labelled manually - with rigorous QA - for 42 urban agglomerations and other areas.

Model is two residual CNNs, one for sentinel-2 input including up to 4 seasons and the other for sentinel-1, 1 season input. Each CNNs produces a 17 vector preduction for which the mean across the predictions is input to the softmax.

Evidence is that sentinel-1 adds very little (but something) to classification. Probably would be better if it were higher spatial resolution.

Assessment is performed using 3 different splits of the data:
random-split - the data were split into train-test using random function across all examples - this would be the upper bound of achievable classification accuracy - this would give a representative measure of accuracy for unseen cities whose data distribution is similar to the training cities
block-split - urban agglomerations were split into non-overlapping train-test areas
held-out cultural-10 split - some agglomerations were entirely withheld - this would be the lower bound of the achievable accuracy by evaluating completely held-out data in a cross-validation scheme

Urban morphology is analysed by viewing the classified images for different urban regions.

Found very different proportions of people live in different population densities: ``60\% of the population live in compact and lightweight/large low-rise areas, occupying 40\% of the built up area. Another 35\% of the population lives in open or sparsely built areas, occupying 55\% of the areas. The remaining 5\% of the population is distributed in the non-built-up LCZ classes. This huge difference in population density reflects a possible inequality in living conditions''.

A clustering is performed on cities based on the quantity and spatial location of LCZs across all cities and identify some characteristics patterns which given the following labels:
European Cities
Cities of the Islamic world
Predominantly Chinese cities
Predominantly African cities
European-African-Asian cities
Very large cities

They do talk a bit about urban heat islands and the climatic impact of urban areas but I don't really understand why these particular classes are referred to as local climate zones.},
  creationdate     = {2022-02-02T15:53:46},
  keywords         = {Remote sensing, Sentinels, Big data, Data fusion, Deep learning, Local climate zones, Urban morphology, Global urban LCZ dataset, Global inequality},
  modificationdate = {2022-02-02T16:19:08},
  owner            = {ISargent},
}

@Article{HasaniLARG2020,
  author           = {Ramin Hasani and Mathias Lechner and Alexander Amini and Daniela Rus and Radu Grosu},
  title            = {Liquid Time-constant Networks},
  eprint           = {2006.04439},
  url              = {https://arxiv.org/abs/2006.04439},
  archiveprefix    = {arXiv},
  comment          = {Use recurrent networks to create networks that continuously learn.
Non-tech article here: https://news.mit.edu/2021/machine-learning-adapts-0128
https://arxiv.org/abs/2110.00476},
  creationdate     = {2022-02-02T16:26:50},
  keywords         = {recurrent neural network, time series},
  modificationdate = {2022-02-03T15:01:51},
  owner            = {ISargent},
  primaryclass     = {cs.LG},
  year             = {2020},
}

@Article{McCuchanCGC2021,
  author           = {Mc Cutchan, Marvin and Comber, Alexis J. and Giannopoulos, Ioannis and Canestrini, Manuela},
  date             = {2021},
  journaltitle     = {Remote Sensing},
  title            = {Semantic Boosting: Enhancing Deep Learning Based LULC Classification},
  doi              = {10.3390/rs13163197},
  issn             = {2072-4292},
  number           = {16},
  url              = {https://www.mdpi.com/2072-4292/13/16/3197},
  volume           = {13},
  abstract         = {The classification of land use and land cover (LULC) is a well-studied task within the domain of remote sensing and geographic information science. It traditionally relies on remotely sensed imagery and therefore models land cover classes with respect to their electromagnetic reflectances, aggregated in pixels. This paper introduces a methodology which enables the inclusion of geographical object semantics (from vector data) into the LULC classification procedure. As such, information on the types of geographic objects (e.g., Shop, Church, Peak, etc.) can improve LULC classification accuracy. In this paper, we demonstrate how semantics can be fused with imagery to classify LULC. Three experiments were performed to explore and highlight the impact and potential of semantics for this task. In each experiment CORINE LULC data was used as a ground truth and predicted using imagery from Sentinel-2 and semantics from LinkedGeoData using deep learning. Our results reveal that LULC can be classified from semantics only and that fusing semantics with imagery‚ÄîSemantic Boosting‚Äîimproved the classification with significantly higher LULC accuracies. The results show that some LULC classes are better predicted using only semantics, others with just imagery, and importantly much of the improvement was due to the ability to separate similar land use classes. A number of key considerations are discussed.},
  article-number   = {3197},
  comment          = {Trained deep network with (1) CORINE land cover (Level 2) data from 2018 for training and validating the models, (2) Sentinel-2 remotely sensed imagery, and (3) vector data obtained from LinkedGeoData, which contains geospatial semantics for its geo-objects - semantic information from OSM. and obtained better LULC classification than using semantics only or imagery only.},
  creationdate     = {2022-02-02T16:38:48},
  keywords         = {remote sensing, deep learning},
  modificationdate = {2022-02-03T15:01:32},
  owner            = {ISargent},
}

@Article{GuoCKCSSRF2020,
  author           = {Yunhui Guo and Noel C. Codella and Leonid Karlinsky and James V. Codella and John R. Smith and Kate Saenko and Tajana Rosing and Rogerio Feris},
  title            = {A Broader Study of Cross-Domain Few-Shot Learning},
  eprint           = {1912.07200},
  url              = {https://arxiv.org/abs/1912.07200},
  archiveprefix    = {arXiv},
  comment          = {What the title says!
Consider learning across domains that include:
ImageNet
CropDisease
EuroSAT
ISIC (medical imagery)
ChestX (x-rays)

Measure similarity of domains using criteria:
1) existence of perspective distortion
2) the semantic content
3) color depth

The datasets include agriculture images (natural images, but specific to agriculture industry), satellite (loses perspective distortion), dermatology (loses perspective distortion, and contains different semantic content), and radiological images (different according to all 3 criteria).

Evaluate several few-shot learning approaches:
- Meta-learning (e.g. MatchingNet and MAML for single-domain cases and Feature-wise transform and Adversarial Domain Adaptation with Reinforced Sample Selection in cross-domain cases) are approaches for which the aim of training is to learn how to learn a new task easily
- transfer learning, from a single model includes: fixed feature extractor, fine-tuning all layers, fine-tuning last-k layers, transductive fine-tuning
- Transfer from Multiple Pre-trained Models, includes methods to select the most useful features from a library of pre-trained models for each task

Best results are for IMS-f which is a method of transferring from multiple pre-trained models and involves fine-tuning each pretrained model before applying model selection. The other fine-tuning methods also work well. Fixed feature extractor works little better than a random embedding (and MatchingNet performs less well than random embedding). Results are better for those target domains that are more similar to the source domain.},
  creationdate     = {2022-02-03T14:32:21},
  keywords         = {transfer learning, Toponet, deep learning},
  modificationdate = {2022-02-03T15:02:38},
  owner            = {ISargent},
  primaryclass     = {cs.CV},
  year             = {2020},
}

@Article{VazeHVZ2022,
  author           = {Sagar Vaze and Kai Han and Andrea Vedaldi and Andrew Zisserman},
  title            = {Generalized Category Discovery},
  eprint           = {2201.02609},
  url              = {https://arxiv.org/abs/2201.02609},
  archiveprefix    = {arXiv},
  comment          = {The aim is to discover new sets within an image dataset for which some examples of some sets are provided. 

Use a vision transformer (ViT, DosovitskiyEtAl2021), pretrained with DINO self-supervision on ImageNet as a backbone. This is then finetuned using contrastive learning. 

Label assignment is achieved using a modification of k-means to assign data to classes or clusters (based on learned representations). This modification ensures that those inputs with a known class are assigned to the same cluster but those without a label can be assigned to any cluster (based on distance from the centroid). The number of clusters is optimised by optimising the accuracy of class assignment of the labelled data points.

Find that the ViT is better than ResNet as a backbone and contrastive fine-tuning is better than the raw DINO representations when it comes to class separation.},
  creationdate     = {2022-02-03T15:02:35},
  keywords         = {discovery, machine learning, vision transformer, unsupervised, self-supervised},
  modificationdate = {2022-02-03T15:48:26},
  owner            = {ISargent},
  primaryclass     = {cs.CV},
  year             = {2022},
}

@Book{WilkinsonP2009,
  author           = {Richard Wilkinson and Kate Pickett},
  date             = {2009},
  title            = {The Spirit Level},
  publisher        = {Penguin},
  subtitle         = {Why Equality is Better for Everyone},
  comment          = {Demostrates masses of evidence that, once societies have reached a level of prosperity, it is not wealth that influences good outcomes (good health, low violence, ...) but the level of equality. Also, draws on other research to provide clear explanation of why this is.

After the first edition was published, there were a number of criticisms, each of which is addressed in a new chapter. At the end of this, comments on the rise of neo-liberal political and economic thinking which pushed out egalitarian ideas in the 1980 and 1990s. However, demonstrates how the content of The Spirit Level is now influencing politics: ``In a major speech a the end of 2009, David Cameron said The Spirit Level showed 'that among the richest countries, it's the more unequal ones that do worse according to almost every life indicator''. ``In September 2010 ... Ed Miliband said ' I do believe this country is too unequal and the gap between rich and poor doesn't just harm the poor, it harms us all'' p298

Uses the same set of the worlds richest countries, as well as US states, and looks at relationship between income inequality (there are many possible measures of inequality, but they don't make much difference p17) and an index of health and social problems, which combined:
- level of trust
- mental illness (inc drug and alcohol addiction)
- life expectancy and infant mortality
- obesity
- children's educational performance
- teenage births
- homicides
- imprisonment rates
- social mobility (not available for US states)
p19

Also, UNICEF index of child wellbeing (for which UK scores bottom out of this set of wealth countries)

Health and social problems occur in individuals and the book describes how it is the individual's response to the social inequality that is the cause. People always have a sense of their rank within society. Anxiety has been rising over time. So has self-esteem. However, there seem to be two groups of people with high self-esteem. One group has positive outcomes, but another ``showed tendencies to violence, racism, who were insensitive to others and were bad a personal relationships'' p37. This second group are the self-promoters p44. The rise in anxiety has been accompanied with rising narcissism, both having roots in 'social evaluative threat' p37. A study of experiments into effects of stress on individuals have found that the most consistent stressors are threats to self-esteem and social status p38. 

Later in the book, it links these responses to inequality with our genetic make up. Psychology/economics experiments show how people will choose to gain nothing rather than accept an unfair offer p202. Chimps and Bonobos are our genetically closest species and yet they have different social structures ``The chimpanzee resolves secual issues with power; the bonobo resolves power issues with sex''. In the section of DNA that regulates these characteristics, humans are closer to the bonobo p205. Humans are preoccupied by social interaction because this is of paramount importance p206. Mirror neurons trigger small muscle responses to what we see others do (and thus we can empathise) p213. Social exclusion results in the same response as physical pain p214.

Looks at the different health and social indicators, each of which has a strong relationship to inequality:

Level of trust - different Inequality also correlates levels of distrust, with resulting poor outcomes for communities. Probably distrust is an outcome of inequality but also this may lead to feedback that further decreases equality p62.

Mental illness - this is affected by our judgement of ourselves and how we believe others view us and levels of trust

Physical health and life expectancy - social status, social networks and stress in early childhood are the psychosocial factors in determining the health of a population, in wealthy countries p77 There is no relationship between the amount of spending on healthcare per person and life expectancy p81

Obesity - its not just about calories and the amount of exercise, stress also seems to cause the body to metabolise differently p95 ``The Thrifty Phenotype'', triggered by stressed conditions pre-birth, has lower metabolic rate p100

Educational performance - more family conflict and disruption in low-income families (due to the reasons above i.e. trust, health) can affect learning p111 but also children are acutely aware of social status and this directly affects outcomes p113

Teenage pregnancy - one factor is that parenthood is the way that young women join the adult world and gain a status, when educational outcomes are poorer

Violence - interestingly, in US states, the relationship between homicide rates and inequality was greater if the rate of gun owndership was factored in (i.e. access to a gun has a relationship to homicide rate too)

Imprisonment - more unequal societies have longer sentences but these do not deter people from crime p153. More equal societies tend to design their criminal justice systems with consultation from experts - criminalogists, lawyers, prison psychiatrists and psychologists p155. Media and political pressure have a greater influence in more unequal societies p156.

The different ways that countries achieve equality of income - scandinavian countries tend to redistribute using taxes and benefits whereas Japan  has a greater equality of market incomes but the health and social outcomes are the same p184

Social status and friendship are linked to health outcomes, strength of community life and violence. Social status and friendship are two opposite ways that humans come together - either by stratification with privileged access to resources, regardless of need or by reciprocity, mutuality, sharing, social obligations, co-operations and recognitions of each others' needs  p199-200

Inequality and the environment: Simple view of development demonstrates that above a certain level of CO2 emissions there is no improvement in life expectancy p219 A great deal of what drives consumption is status competition p226.

''It is often suggested that invention and innovation go with inequality and depend on the promise of individual financial incentives. However, Figure 15.3 suggests the contrary - that more equal societies ten to be more creative'' p225

consumption is a substitute for status, growth is a substitute for equality, more equality makes growth less necessary p226

The things that matter are health, happiness, friendship, community life. But cutting carbon emissions, limiting economic growth in rich countries, is not just having fewer luxuries, inequality has to be reduced simultaneously p231.

More equal societies more public spirited  p232

''to give ourselves the best chance of making the necessary transformation of society we need to remember that the aim is to make a more sociable society, which means avoiding the disruption and dislocation which increase insecurity and fear and so often end in a disastrous backlash'' p237.

''A study which analysed trends in inequality during the 1980s and 1990s ... found that the most important single factor was trade union membership'' p245.

''Although some profit-making businesses have high ethical standards, the institutional framework, seem to invite them to an exploitative relationship with society'' p254.

''To make a reliable difference to company performance, share-ownership has to be combined with more participative management methods'' p256

Inequality, a sense of unfairness and having less control at work has detrimental impact on health outcomes p256

''If Britain became as equal as [the average of Japan, Norway, Sweden and Finland], levels of trust might be expected to be two-thirds as high again as they are now, mental illness might be more than halved, everyone would get an addition year of life, teenage birth rates could fall to one-third of what they are now, homicide rates could fall by 75 per cent, everyone could ge thte equivalent of almost seven weeks extra holiday a year and the government could b closing prisons all over the country'' p268-269.},
  creationdate     = {2022-02-27T09:46:07},
  keywords         = {sociology, economics},
  modificationdate = {2022-11-25T21:56:52},
  owner            = {ISargent},
}

@Misc{Russell2021d,
  author           = {Stuart Russell},
  date             = {2021-12-22},year=2021,
  title            = {AI: A Future for Humans},
  howpublished     = {Radio Lecture, transcript available},
  subtitle         = {Living With Artificial Intelligence},
  url              = {https://www.bbc.co.uk/programmes/m0012q21},
  comment          = {Stuart Russell on corporations as machines, albeit with a bad optimisation function:
''... some people have written articles saying ... that corporations function as machines. They optimise a misspecified objective which is, let's say, quarterly profit, ignoring the externalities, ignoring all the problems that they cause for the rest of the world, and the fossil fuel industry has outwitted the human race. We have lost. I'm sorry. We have lost. Even though we all know what needs to be done, we have lost because they figured this out 50 years ago and have developed a strategy that has outwitted the rest of us''.},
  creationdate     = {2022-02-27T09:49:04},
  episode          = {4},
  keywords         = {AI, business},
  modificationdate = {2022-02-27T09:54:52},
  organisation     = {BBC},
  owner            = {ISargent},
  series           = {The Reith Lectures},
}

@Book{Mazzucato2021,
  author           = {Mariana Mazzucato},
  date             = {2021},
  title            = {Mission Economy},
  subtitle         = {A Moonshot Guide to Changing Capitalism},
  comment          = {Uses the mission to land a Man on the Moon as a model for how purpose-driven innovation can be used to create a better future.
Interesting and galvanising, with a lot of practical 'how to'.
The one aspect that I didn't quite follow was that it talk about long-run growth (e.g. p 164) without saying what that is or what happens when it ultimately ceases. 

Contents gives a lot away:

Capitalism is in crisis:
- Finance is financing FIRE (finance, insurance and real estate)
- Business is focussing on quarterly returns
- The planet is warming
- Governments are tinkering, not leading

Five myths that impeded progress:
- Businesses create value and take risks; governments only de-risk and facilitate
- The purpose of government is to fix market failures
- Government needs to un like a business
- Outsourcing saves taxpayer money and lowers risk
- Governments shouldn't pick winners

Lessons from Apollo
- Leadership: vision and purpose
- Innovation: risk-taking and experimentation
- Organisational change: agility and flexibility
- Spillovers: serendipity and collaboration
- Finance: outcomes-based budgeting
- Business and the state: partnership with a common purpose

Mission-oriented Policies on Earth
- Selecting a mission
- Implementing a mission
- Engaging citizens in a mission
- Mission: a Green New Deal
- Mission: innovating for accessible health
- Mission: narrowing the digital divide

Seven principles for a new political economy
- Value: collectively created
- Markets: shaping not fixing
- Organisations: dynamic capabilities
- Finance: outcomes-based budgeting
- Distribution: sharing risks and rewards
- Partnership: purpose and stakeholder value
- Participation: open systems to co-design our future

a mission-oriented approach ``means choosing directions for the economy and then putting the problems that need solving to get there at the centre of how we design our economic systems'' p8 (this seems analogous to me to the optimisation function alluded to in Stuart Russell's 4th Reith Lecture Russell2021d)

only about a fifth of finance goes into the productive economy p16

Much of current economic thinking is based on Market Failure Theory, which states that markets are the most efficient allocators of resources under three specific  conditions:
1. there is a complete set of markets
2. all consumers and producers behave competitively
3. equilibrium exists (e.g. supply exactly matches demand)
and the only role of government to correct for external positive or negative externalities or information asymmetries
In addition to this, Public Choice Theory, assumes that agents, including government agents, are also self-interested. This means that policy-making is subject to capture by interest groups (because collective action by voters tends to be weak and voters are not very interested) resulting in
- neopotism
- cronyism
- corruption
- rent-seeking
- misallocation of resources
- unfair and damaging competition (crowding out)
Therefore, the conditions that indicate a government should intervene need to outweigh losses of government failure.
Yet there is no empirical evidence for this, even though these theories are used to prevent government taking amitious steps.
p 31 - 33

New Public Management theory is used to justify government being run like a business such as by having cost-benefit analysis of any allocation of funding p25-37

This is why we should have research functions in public sector: ``The key role of NASA is to define the mission, plan the programme, be clear on the guidelines, set the parameters and then allow as much innovation as possible to create the product or service required. None of this could ave been done without the NASA staff themselves having experience of the underlying science and technology; In fact, it would have been impossible to choose contrator intelligently without that knowledge. Additionally, by developing internal expertise, contracts with the private sector would be better managed because those writing them would know just as much about the technology as the contractors'' p 95

''having a vision is not enough, it is essential to engage with citizens about it'' p109

The Sustainable Development Goals SDGs make good missions because they require work over many domains: social, political, technological, behavioural and feedback processes. They also are broken down in to 169 targets. p110

Often innovation policy is focussed on outcomes, such as support for a particular technology. Instead, focus should be on the problem to be solved - the technology and start-ups will follow p111

Describes how to build a mission-map
Grand challenge - what needs solving - e.g. climate change
Mission - what the solution looks like - e.g. 100 carbon neutral European cities by 2030
Sectors - the difficult sectors that needs to be engaged - e.g. real estate, energy, mobility, ...
Mission projects - breaking down the mission to components - e.g. building with carbon neutral components, clean urban electric mobility, ...
p112-114

Mazzucato advised UK Government on how to apply a mission-oriented approach, leading to 2017 Industrial Strategy: Building a Britain fit for the future p117

A mission needs to:
- be bold and inspirational, with societal relevance
- set goals for investment in innovation
- encourage mutltiple solutions
p121-124

Mission implementation requires:
- policy instruments that focus on outcomes and foster innovation
- new approach to governance to includes public finance as investor of first resort
- Appropriate indicators and monitoring frameworks
- A change in how private and public sectors work together
''It is not about government bringing in the private sector to show how public research leads to commercialisation. Most commercialisation opportunities from public research - such as development of the software industry following Appollo - occurred precisely when government kept its eye on the prize and did not worry about the economic value or commercialisation what would result''
p124-130

Citizens need to be engaged not just in the ideas but the design and assessment of the mission. This is collaborative participatory and may require frank debates. But it also must avoid the capture by vested interests. It may not be harmonious but it must represent all perspectives, not just those of the 'elite' experts. p132-137

''Mainstream economic prescriptions of simply solving climate change with a carbon tax and some R\&D subsidies (to let the markest find the optimal pathway), combined with political conomic impediments to carbon taxes, have left us with negligent carbon tax systems and a worryingly slow green transition'' p142

''As behavioural science has shown (and the rader knows from everyday life), real persons do not normally optimally react to price incentives, and they tend to 'satisfice' rather than maximise profits or measures of happiness at every step of the way'' p142

In mainstream economic approaches, the costs are socialised (government funds the research and shoulders the risk) while the profits are privatised (shareholders receive the rewards) p147

''Scientific and medical innovation thrives and progress is made when knowledge is exchanged openly, building upon shared successes and failures. But proprietary science does not follow that logic: it promote secretive competition, prioritises crossing regulatory finishing lines in wealthy countries over wide availability ... and erects barriers to technological diffusion'' p150

'''Wicked' problems cannot be solved in a linear way, and there is no tech solution to social problems'' p154

BBC Computer Literacy Project as an example of a public-led mission (computer literacy) that resulted in spin-outs most notably ARM Holdings and Raspberry Pi p158

''The mission attitude is not about picking individual sectors to support but about identifying problems that can catalyse collaboration beween many different sectors'' p159

On outsourcing during Covid-19 pandemic: ``By relying on consultancy firms to manage the test-and-trace system, the government has not only deprived our brilliant civil servants of an opprtunity to demosntrate and develop their knowledge, but in doing so undermined the possiblity of organisation learning through the crisis'' p177

The 5 capabilities required by government organisations to manage complex and 'wicked' problems:
- Leadership and engagement
- Co-ordination
- Administration
- Risk-taking and experimentation
- Dynamic evaluation

In terms of finance, takes a good deal from The Deficit Myth p182-188

Regarding distribution, advises for predistribution, and only correcting using redistribution (taxes and benefits) p189 

''A stakeholder view needs instaed to reward all stakeholders, not only shareholders: workers, the communities and the environment. This concept recognises that value is collectively created...'' p194

Defending the underlying public interest can be in terms of the approach to the 'commons' - such as data commons'' - take from Elinor Omstrom here p197

Much of the chapter on principles draws from many women scholars - these are listed p 211},
  creationdate     = {2022-02-27T09:51:36},
  keywords         = {economics, business},
  modificationdate = {2022-10-23T12:23:35},
  owner            = {ISargent},
}

@InProceedings{PowerBEBM2021,
  author           = {Alethea Power and Yuri Burda and Harri Edwards and Igor Babuschkin and Vedant Misra},
  booktitle        = {1st Mathematical Reasoning in General Artificial Intelligence Workshop, ICLR 2021},
  date             = {2021-05-07},
  title            = {Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets},
  url              = {https://mathai-iclr.github.io/papers/papers/MATHAI_29_paper.pdf},
  comment          = {Using a small dataset and model, this study found that after a long training, in which the model had apparently overfit to the data (the training accuracy was ~100\% but the validation accuracy had dropped off) the model's validation accuracy begins to ascend - in one case to nearly 100\%. They call this phenomena ``grokking''. More work is needed to understand if/how this plays out with larger problems.},
  creationdate     = {2022-04-28T11:33:38},
  keywords         = {machine learning, training},
  modificationdate = {2022-04-29T12:28:03},
  owner            = {ISargent},
}

@InProceedings{Ghorbani2019,
  author           = {Amirata Ghorbani and James Wexler and James Zou and Been Kim},
  booktitle        = {33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada},
  date             = {2019-12-08},
  title            = {Towards Automatic Concept-based Explanations},
  comment          = {''In conclusion, we introduces ACE , a post-training explanation method that automatically groups
input features into high-level concepts; meaningful concepts that appear as coherent examples and are important for correct prediction of the images they are present in. We verified the meaningfulness and coherency through human experiments and further validated that they indeed carry salient signals for prediction''

Pass images through trained network for a single class and identify the parts of those images that are most salient to that class. Then, to determine meaningfulness:

''We asked 30 participants to perform two tasks: As a baseline test of meaningfulness, first we ask them to choose the more meaningful of two options. One being four segments of the same concept (along with the image they were segmented from) and the other being four random segments of images in the same class. the right option was chosen 95.6\% (14.3/15)(¬±1.0). To further query the meaningfulness of the concepts, participants were asked to describe their chosen option with one word. As a result, for each question, a set of words (e.g. bike, wheel, motorbike) are provided and we tally how many individuals use the same word to describe each set of image. F''},
  creationdate     = {2022-04-29T12:22:51},
  keywords         = {deep learning, meaningfulness, visualisation, IncisiveTagging},
  modificationdate = {2022-06-27T15:14:44},
  owner            = {ISargent},
}

@InProceedings{YehKALPR2020,
  author           = {Yeh, Chih-Kuan and Kim, Been and Arik, Sercan and Li, Chun-Liang and Pfister, Tomas and Ravikumar, Pradeep},
  booktitle        = {Advances in Neural Information Processing Systems},
  date             = {2020},
  title            = {On Completeness-aware Concept-Based Explanations in Deep Neural Networks},
  editor           = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages            = {20554--20565},
  publisher        = {Curran Associates, Inc.},
  url              = {https://proceedings.neurips.cc/paper/2020/file/ecb287ff763c169694f682af52c1f309-Paper.pdf},
  volume           = {33},
  comment          = {Video: \url{https://crossminds.ai/video/on-completeness-aware-concept-based-explanations-in-deep-neural-networks-606fe654f43a7f2f827c06f1}

Evaluation criteria to determine if a set of concepts is sufficient to explain a model

Also design a concept discovery method that does not rely on human labelling (I'd like to try this!!)},
  creationdate     = {2022-04-29T12:32:54},
  keywords         = {machine learning, meaningfulness, visualisation},
  modificationdate = {2023-01-25T11:10:40},
  owner            = {ISargent},
}

@Article{GrillEtAl2020,
  author           = {Jean-Bastien Grill and Florian Strub and Florent Altch\`{e} and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Avila Pires, Bernardo and Zhaohan Daniel Guo and Gheshlaghi Azar, Mohammad and Bilal Piot and Koray Kavukcuoglu and R\`{e}mi Munos and Michal Valko},
  title            = {Bootstrap your own latent-a new approach to self-supervised learning},
  url              = {https://arxiv.org/abs/2006.07733},
  booktitle        = {Advances in Neural Information Processing Systems},
  comment          = {The BYOL paper},
  creationdate     = {2022-05-03T05:56:35},
  modificationdate = {2022-05-03T06:00:25},
  owner            = {ISargent},
  year             = {2020},
}

@Article{HeFWXG219,
  author           = {Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},
  title            = {Momentum contrast for unsupervised visual representation learning},
  comment          = {The MoCo paper},
  creationdate     = {2022-05-03T06:52:00},
  journal          = {arXiv preprint arXiv:1911.05722},
  modificationdate = {2023-01-19T08:35:27},
  owner            = {ISargent},
  year             = {2019},
}

@Article{KimWGCWVS2017,
  author           = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
  title            = {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)},
  doi              = {10.48550/ARXIV.1711.11279},
  url              = {https://arxiv.org/abs/1711.11279},
  comment          = {TCAV is a method of quantifying how sensitive a classification result is to a human-defined concept using  directional derivatives

Choose examples of chosen concept and then determine the vector orthogonal to the boundary between a layer's reponse to this and non-concept examples - this is the Concept Activation Vector},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-05-07T12:28:57},
  keywords         = {Machine Learning (stat.ML), FOS: Computer and information sciences},
  modificationdate = {2022-05-07T12:35:47},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2017},
}

@InProceedings{AbnarDNS2022,
  author           = {Samira Abnar and Mostafa Dehghani and Behnam Neyshabur and Hanie Sedghi},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Exploring the Limits of Large Scale Pre-training},
  url              = {https://openreview.net/forum?id=V3C8p78sDa},
  comment          = {I thought this was a really excellent paper that explored the impact of pretraining (the upstream task) to the accuracy of the downstream tasks. They performed a large empirical study looking at a range of different algorithms, datasets and downstream tasks they identify that there appears to be an upper limit of accuracy on the downstream (DS) task. Find upstream accuracy is not a predictor of downstream accuracy and that optimal parameters for the upstream task may be at odds with those for the downstream tasks. Specifically, it may be necessary to hurt the accuracy of the upstream model to gain better downstream results or to select the upstream model for the specific downstream tasks. This behaviour is closely related to the usefulness of representations in higher layers of the upstream model. Say that ``ultimately the problem is down to data diversity''and so I presume this means that the problem is that the downstream task is out-of-distribution.

Again this is relevant to \os's work pretraining models and emphasises that striving for a highly accurate backbone model is probably unnecessary. Rather, it may be worth building multiple benchmark problems to test different backbones and transfer learning approach against will help us establish what are the best approaches to upstream and downstream training. 

From The Batch:

The authors re-examined 4,800 experiments performed on diverse architectures: Vision Transformers, MLP-Mixers, and ResNets. The models had been pretrained to classify labeled images in JFT or ImageNet 21K. They were tested on 25 tasks, including classifying objects, classifying the orientation of objects, and diagnosing diabetic retinopathy, after fine-tuning via few-shot learning or transfer learning. In few-shot learning, the last layer was replaced and trained on 25 examples. In transfer learning, the whole network was fine-tuned on 1,000 examples.

For each model and fine-tuned task, the authors plotted pretrained accuracy on the horizontal axis and fine-tuned accuracy on the vertical axis. The resulting swaths of clustered dots generally rose nonlinearly until they reached a plateau. 
The authors calculated a curve to match the best results in each task. Then they extended that line to extrapolate fine-tuned accuracy if pretrained accuracy were 100 percent.
In their own experiments, they varied the size of the pretraining set (JFT), number of parameters in the model (Vision Transformer), and number of epochs in pretraining. Then they repeated the steps above. 
Results: Higher pretrained accuracy generally yielded higher fine-tuned accuracy ‚Äî but it reached a point of diminishing returns. In some cases, higher pretrained accuracy yielded worse fine-tuned accuracy. Moreover, pretrained models of equal accuracy didn't necessarily perform equally well on different fine-tuned tasks. The authors' own experiments matched the curves they derived from earlier work, leading them to conclude that dataset size, number of parameters in a model, and length of training don't significantly influence the relationship between pretrained and fine-tuned accuracy.

Why it matters: More pretraining doesn't necessarily result in a better fine-tuned model.

We're thinking: One limiting factor in the value of pretraining accuracy may be the relevance of the pretrained task to the fine-tuned task. No matter how well a model classifies ImageNet, it may not easily learn how to diagnose medical images. A rigorous framework for managing the tradeoff between pretraining and fine-tuning would be useful.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6232> I think this is an excellent paper. Looking at the impact of pretraining (upstream (US) task) on the accuracy of the downstream task. There appears to be an upper limit of accuracy on the downstream (DS) task, over many models/data/downstream tasks/parameters for image recognition tasks Models - Transformer, MLP mixer and ResNet models Data - JFT, ImageNet21k Downstream tasks - VTAB, MetaDataset, Wilds and medical imaging Convex hull of all experiments shows saturation of performance of downstream tasks Model selection should be done for each DS task so several models with similar US accuracy have different impacts on DS accuracy Behaviour is captured in usefulness of representations in higher layers of US model Optimal hyperparameters for US task may be at odds with optimal hyperparameters for DS task Ultimately the problem is down to data diversity for downstream tasks I can't tell if pretraining using same data domain avoids some of this or not},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {pretraining, deep learning, transfer learning},
  modificationdate = {2022-06-28T21:02:42},
  owner            = {ISargent},
}


@InProceedings{Amuasi2022,
  author           = {John Amuasi},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Representation Learning in the Global South: Societal Considerations-Fairness, Safety and Privacy},
  url              = {https://iclr.cc/virtual/2022/invited-talk/7235},
  comment          = {Focussing on Africa, John Amuasi argues for more work into representation learning in the Global South, where there are many AI applications to be addressed and a highly heterogeneous population, data on which would enrich many models. Poorly resourced governments mean that most AI is privately owned, which raises ethical concerns about who is accessing, using and sharing the data.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7235> John Amuasi argues for more work into representation learning in Global South, with focus on Africa, where there are many AI applications. Highly heterogeneous population and thus data and so we should not leave Africa behind when it comes to representation learning Mainly privately owned startups because governments don't have resources to get involved, which raises ethical issues - who is accessing, using and sharing the data, bias and inequalities in data, etc. Identifies steps to balance scales: - Diverse data - Diverse teams - Targetted AI training - Stakeholder engagement},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {representation learning, AI, inclusion, ethics},
  modificationdate = {2022-12-12T19:56:08},
  owner            = {ISargent},
}


@InProceedings{BahriJTM2022,
  author           = {Dara Bahri and Heinrich Jiang and Yi Tay and Donald Metzler},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption},
  url              = {https://openreview.net/forum?id=CuV_qYkmKb3},
  comment          = {This is SimCLR (\cite{ChenKNH2020}) but for tabular data
This work goes back to the earlier contrastive approaches, whereby the machine needs to learn to detect the correct pair of inputs from a large set of negative examples. It applies it to tabular data and outperforms autoencoder approaches.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6297> Like SimCLR but for tabular data For each input, corrupt data by replacing with values taken from distribution of that feature Train, using InfoNCE, to encourage representations that are from the same input to be more similar and those from different inputs to be more dissimilar After early stopping, replace training head with a classification head and fine tune encoder with labelled examples Trained over lots of datasets and combinations Outperforms autoencoders},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {contrastive learning},
  modificationdate = {2022-06-28T20:55:19},
  owner            = {ISargent},
}


@InProceedings{BaoDPW2022,
  author           = {Hangbo Bao and Li Dong and Songhao Piao and Furu Wei},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{BEiT}: {BERT} Pre-Training of Image Transformers},
  url              = {https://openreview.net/forum?id=p-BhZSz59o4},
  comment          = {Masked Language Modelling (MLM) is self-supervised approach used in language transformers. This paper suggests an image equivalent Masked Image Modelling (MIM) to create self-supervised ViTs.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6323> ViTs need more training data than CNNs. So propose Masked Image Modelling (MIM) based on Masked Language Modelling (MLM). Break image up into patches and visual tokens. Randomly mask image patches and corresponding tokens. Corrupted patches are passed into ViT and the goal is to recover the correct visual tokens given the corrupted images. After this, fine tune parameters on downstream tasks. Looking at the self-attention map shows that individual objects are separated off.},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {vision transformers, pretraining, transfer learning},
  modificationdate = {2022-06-28T21:06:41},
  owner            = {ISargent},
}


@InProceedings{BardesPL2022,
  author           = {Adrien Bardes and Jean Ponce and Yann LeCun},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{VICReg}: Variance-Invariance-Covariance Regularization for Self-Supervised Learning},
  url              = {https://openreview.net/forum?id=xm6YD62D1Ub},
  comment          = {This paper as preprinted on arXiv last year and builds on recent siamese network approaches, such as Barlow Twins, which passes two differently augmented versions of the same image through a network and attempts to update the weights (embeddings) to maximise the similarity of the outputs. VICReg constrains the network to ensure that\begin{enumerate}
\item the \emph{variance} of the embeddings along each dimension is independent
\item learn \emph{invariance} to multiple views of an image
\item maximise the \emph{covariance} between embeddings of different views of an image
\end{enumerate}
Unlike earlier siamese approaches using contrastive learning, siamese approaches like this one don't require lots of negative examples which means training is more efficient. See Figure~\ref{fig:vicreg}.

These approaches are really promising for pretraining backbone networks and are being specifically considered in the \os GlobeNet research.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6481> The official VICReg paper. See BardesPL2021.},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {self-supervised, siamese},
  modificationdate = {2022-06-28T20:52:41},
  owner            = {ISargent},
}

@InProceedings{CarliniT2022,
  author           = {Nicholas Carlini and Andreas Terzis},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Poisoning and Backdooring Contrastive Learning},
  url              = {https://openreview.net/forum?id=iC4UHbQ01Mp},
  comment          = {Main problems with self-supervised learning are due to attacks. This paper demonstrates how easy it is to run these attacks by placing backdoored or poisoned image on internet. Tiny percent need to be poisoned or backdoored to ruin the model.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/6317> Main problems with self-supervised learning are due to attacks This paper demonstrates how easy it is to run these attacks by placing backdoored or poisoned image on internet. Tiny percent need to be poisoned or backdoored to ruin the model},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {contrastive learning, attacks},
  modificationdate = {2022-06-28T20:46:40},
  owner            = {ISargent},
}

@InProceedings{ChenHG2022,
  author           = {Xiangning Chen and Cho-Jui Hsieh and Boqing Gong},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {When Vision Transformers Outperform {ResNets} without Pre-training or Strong Data Augmentations},
  url              = {https://openreview.net/forum?id=LtKcMgGOeLt},
  comment          = {There are different levels of inductive bias (the learner's assumptions) in MLP-models, ViTs and convolutional models - with the first having the fewest and the last having the most. This analysis compares all these models and finds that the decision surface of MLP-mixers and ViTs is much sharper than for ResNets (in contrast to the work presented by ~\cite{ParkK2022}, Section~\ref{sss:convmsa}), which can lead sub-optimal solutions. They therefore apply sharpness aware minimisation (SAM), from ~\cite{ForetKMN2021} from last year's conference, which enforces the smoothness by reducing the worst case curvature.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6358> Considering the inductive bias of different types of models - MLP-mixers have the fewest, and ResNets (conv models) have the most, with vision transformers between the two and ResNets generally outperform (at least a little in the case of ViT) the two This work studies conv-free architectures ViT and MLP-mixers and finds that these have a much sharper decision surface than ResNets (c.f. ParkK2022 How Do Vision Transformers Work?) Therefore, use the work of ForetKMN2021 - sharpness aware minimisation, SAM Using the Hessian to identify the number of activated neurons in the layers of the resulting networks and find that early layers are much more sparse with SAM and attention maps are also much for precise Show that stacking strong augmentations have a similar effect on loss landscape: SAM enforces the smoothness by reducing the worst case curvature Augmentation smooths over the directions concerning the inserted inductive biases Should we consider SAM for training conv-free approaches?},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {vision transformers, training, generalisation, error surface, machine learning},
  modificationdate = {2022-06-28T21:06:28},
  owner            = {ISargent},
}


 
@InProceedings{ChenXGCLL2022,
  author           = {Shoufa Chen and Enze Xie and Chongjian GE and Runjian Chen and Ding Liang and Ping Luo},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{CycleMLP}: A {MLP}-like Architecture for Dense Prediction},
  url              = {https://openreview.net/forum?id=NMEceG4v69Y},
  comment          = {Whilst the other papers in this section have all used convolutional approaches, in line with one of the themes this year, which is to train without convolutions (see Section~\ref{ss:vit}), this work looks at using a Multilayer Perceptron (MLP)-based model for dense prediction. In many ways, there's logic in this because Semantic Segmentation using convolutions has had to overcome the problem that convolutions reduce the resolution of the output. However, convoutions address the limitations of dense predictors such as MLPs (and transformers) by reducing the number of learnable parameters and allowing flexibility in the input data size and spatial scale (because they don't need to learn a set of weights for each input pixel position). This method overcomes these limitations of MLP by performing some sort of cycling over the sampling space. I confess I couldn't really understand what they were doing and wonder if it will turn out to be analogous to passing a kernel across the data...},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/6274> Dense prediction (semantic segmentation) from MLP-based model. The proposed method of cycling through sampling that allows images of varying sizes and spatial scales. I don't really understand what they are doing other than 'fixing' non-convolutional MLP-based models for their limitations with images making them a more usable backbone. Say the results are better than MLP-based models and even transformers with fewer parameters and FLOPS.},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {segmentation, pretraining, transfer learning},
  modificationdate = {2022-06-28T21:01:41},
  owner            = {ISargent},
}


@InProceedings{ChenDLYYSRR2022,
  author           = {Beidi Chen and Tri Dao and Kaizhao Liang and Jiaming Yang and Zhao Song and Atri Rudra and Christopher Re},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models},
  url              = {https://openreview.net/forum?id=Nfl-iXa-y7R},
  comment          = {There are moves towards more sparse training in the ML community. However, GPUs are optimised for dense computation meaning sparse training can be inefficient and inaccurate. This paper proposes the Pixelated Butterfly, a variation on the Butterfly matrices from linear algebra which can align with hardware blocks, allowing efficient sparse training.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6571> GPUs are optimised for dense computation. Sparse training cab be inefficient and inaccurate. Butterfly + low rank shows a lot of promise but not hardware efficient. Address this with flat and block butterfly. Block butterfly matrices align with hardware blocks. Flat butterfly replaces product of matrices with a sum (like residual connection) which is easier to parallelise. First trials have demonstrated that this approach maintains accuracy with 2x training speedup.},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {processors, sparsity, deep learning},
  modificationdate = {2022-06-28T20:47:19},
  owner            = {ISargent},
}

@InProceedings{CorbettK2022,
  author           = {Andrew Corbett and Dmitry Kangin},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Imbedding Deep Neural Networks},
  url              = {https://openreview.net/forum?id=yKIAXjkJc2F},
  comment          = {An interesting development in machine learning in the last few years have been continuous depth networks - networks without layers that allow depth to be learned implicitly (e.g. ~\cite{BaiKK2020}). This paper builds on Neural ODE (Neural Ordinary Differential Equations) approach ~\cite{ChenRBD2019} to create InImNets (Invariant Imbedding Networks). The conceptualisation of this architecture is a family of increasingly deep neural networks with the input being passed into each. The overall model output is based on both the output for each neural network \emph{and} the network that output it. The \github repo: \url{https://github.com/andrw3000/inimnet}. See Figure~\ref{fig:inimnet}.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6531> Building on Neural ODE (Neural Ordinary Differential Equations) approaches to continuous-depth neural networks to create InImNets (Invariant Imbedding Networks). ``following the advent of residual neural networks (He et al., 2015) which use `Euler-step` internal updates between layers, DNN evolution is seen to emulate a continuous dynamical system (Lu et al., 2018; Ruthotto \& Haber, 2020). Thus was formed the notion of a `Neural ODE' (Chen et al., 2018)'' Conceptualisation of the architecture is a family of increasingly deep neural networks. The input is passed into each and the output is modelled for each neural network. Invariant Imbedding Method which is a ``reformulation of a two-point boundary value problem as a system of initial value problems, given as functions of initial value x and input location p alone'' - the location being which depth network we have input the data to. https://github.com/andrw3000/inimnet},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {continious depth, implicit models},
  modificationdate = {2022-06-28T20:45:51},
  owner            = {ISargent},
}

@InProceedings{Davis2022,
  author           = {Jenny Davis},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {`Affordances' for Machine Learning},
  comment          = {Talking about how we may intervene in AI to prevent it from amplifying inequality, Jenny Davis described systemic frameworks that specify how technical features and outcomes intertwine. These frameworks can be use to scrutinise and reimagine systems in. In particular, the Mechanisms and Conditions framework asks how technologies afford, for whom and under what circumstances. Mechanisms are Request, Demand, Encourage, Discourage, Refuse, Allow and Conditions are Perception, Dexterity, and Cultural and Institutional Legitimacy. It seems to me this framework could be applied to absolutely anything.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7236> We know that technologies are social, political and power-infused and they affect norms, values and structures We also know that machine learning amplifies inequality This talk is about how we may intervene ML can be better when scrutinised by, and built through, systemic frameworks that specify how technical features and outcomes intertwine Introduces the Mechanisms and Conditions framework for this purpose Identifying affordances as they are, in analysis, and how they could be, in design is essential in AI. Analysis and design are inextricable What something affords is what is allows humans to do but it is not deterministic, humans may also do other things with it Basic affordance frameworks can be binary - a technology does or does not afford something - and assume all subjects are the same. This is corrected for by Mechanisms and Conditions framework which asks (not what technologies afford but) how technologies afford, for whome and under what circumstances Mechanisms of affordance: - Request - Demand - Encourage - Discourage - Refuse - Allow Conditions of Affordance: - Perception - Dexterity - Cultural and Institutional Legitimacy Can use this to scrutinise and reimagine systems In analysis: What does the system request and from whom does it demand? In design: How do we make systems that encourage dignity, refuse exploitation, discourage power asymmetries?},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {ethics, accessibility, affordances, AI},
  modificationdate = {2022-06-28T20:48:45},
  owner            = {ISargent},
}


@InProceedings{DeeckeHB2022,
  author           = {Lucas Deecke and Timothy Hospedales and Hakan Bilen},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Visual Representation Learning over Latent Domains},
  url              = {https://openreview.net/forum?id=kG0AtPi6JI1},
  comment          = {This paper covers how to learn over different domains with data that have similar/same (?) labels. Usually the label (e.g. horse) and the domain (sketch) are learned but this paper proposes latent domain learning with no domain labels. Thus the same representations are learned for a given label, no matter what the input domain. 

This may be relevant to training at \os if we were to try to learn real world features (building, city) in different domains (aerial, satellite).},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/5897> Learning over different domains e.g. photo, sketch, cartoon, painting. Usually the label AND the domain are learned but this paper proposes latent domain learning with no domain labels (but same labels apply within most domains?). This means that there is sharing between different domains. Propose Sparse Latent Adaptation. This is interesting because domains may be considered as different data sources - different sensors, platforms, geographic regions},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {multimodal, machine learning},
  modificationdate = {2022-06-28T21:03:16},
  owner            = {ISargent},
}


@InProceedings{DengRZZ2022,
  author           = {Huiqi Deng and Qihan Ren and Hao Zhang and Quanshi Zhang},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Discovering and Explaining the Representation Bottleneck of {DNN}s},
  url              = {https://openreview.net/forum?id=iRCUlgmdfHJ},
  comment          = {Having observed, by masking out different numbers of patches from images, that trained DNNs tend to classify using simple concepts (presumed to be represented by a few patches) and complex concepts but not middle-complex concepts. They say this is in contrast to humans and so propose L+ and L- losses to encourage learning of middle-complex concepts.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/6623> Really interesting study. By looking at how good trained DNNs are at classification given masked data they find that DNNs tend to be good at classifying using simple concepts and complex concepts, but not middle-complex concepts. This was determined by measuring the interactions between different parts of the images (ideally pixels, but patches meant it was computationally feasible) such that a strong interaction between parts resulted in greater classification success. Strong interactions (better classification success) occurred with a small number of patches (simple concepts) and a large number of patches (complex concepts) but not a middle number of patches (middle-complex concepts). They call this the Representation Bottleneck and it is in contrast to humans who are less unable to extract much information from few patches (simple concepts) and (according to the paper, but I'm not sure I agree) large numbers of patches but much more from a middle number of patches. Propose L+ and L- losses to encourage interactions of different orders and learn more middle-order concepts and demonstrate that DNNs that have encoded high-order representations are more vulnerable to loss of structural information and therefore attacks(?).},
  creationdate     = {2022-05-08T15:25:19},
  keywords         = {explanation, visualisation, deep learning},
  modificationdate = {2022-06-28T20:57:40},
  owner            = {ISargent},
}


@InProceedings{ErgunFLWZ2022,
  author           = {Jon Ergun and Zhili Feng and Sandeep Silwal and David Woodruff and Samson Zhou},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Learning-Augmented k-means Clustering},
  url              = {https://openreview.net/forum?id=X8cLTHexYyY},
  comment          = {With the strapline ``We avoid the worst case if we take advice``, this paper proposes an improvement to k-means (sacrilege!) by adding a model that learns to noisily predict the cluster label of any point.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/7144> We avoid the worst case if we take advice: A noisy ML predictor guides clustering.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {clustering, machine learning},
  modificationdate = {2022-06-28T20:56:05},
  owner            = {ISargent},
}



@InProceedings{FlennerhagSZVSS2022,
  author           = {Sebastian Flennerhag and Yannick Schroecker and Tom Zahavy and van Hasselt, Hado and David Silver and Satinder Singh},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Bootstrapped Meta-Learning},
  url              = {https://openreview.net/forum?id=b-ny3x071E5},
  comment          = {A paper from DeepMind that observes that during optimisation the algorithm doesn't have sight of future directions over the loss function. Therefore, they propose Bootstrapped Meta-Learning in which the the current gradient is bootstrapped to the gradient towards the position several iterations ahead.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6252> A DeepMind paper about learning to learn (particularly for reinforcement learning problems?). Ensure better learning performance over longer term by bootstrapping a target to the current iteration by finding a target that is several iterations ahead and then matching the current direction to the direction of this target. So the current gradient is bootstrapped to the gradient towards the position several iterations ahead. I can't really visualise this although they use lots of diagrams to explain.},
  creationdate     = {2022-05-08T15:25:20},
  modificationdate = {2022-06-28T20:58:09},
  owner            = {ISargent},
}



@InProceedings{GeertsR2022,
  author           = {Floris Geerts and Juan L. Reutter},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Expressiveness and Approximation Properties of Graph Neural Networks},
  url              = {https://openreview.net/forum?id=wIzUeM3TAU},
  comment          = {Proposes a unified model for graph neural networks (GNNs) to allow their distinguishing power to be analysed no matter what type of GNN is being used. It is an analogue of the Message Passing Neural Networks (MPNNs): k-MPNN.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6804> Analysis of Graph Neural Networks (GNNs). Some are Message Passing Neural Networks (MPNNs) which can be analysed for their distinguishing power but many are not and need to be individual specialised proofs for each type. This paper proposes k-MPNNs, an analogue of MPNNs for more complex GNNs to expose the distinguishing power of any GNN.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {graph networks},
  modificationdate = {2022-06-28T20:46:58},
  owner            = {ISargent},
}

@InProceedings{GeigerSMD2022,
  author           = {Franziska Geiger and Martin Schrimpf and Tiago Marques and James DiCarlo},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream},
  url              = {https://openreview.net/forum?id=g1SzIRLQXMM},
  comment          = {This work used data ``brain predictivity'', how well the model predicted what a brain would produce from an input, as a metric for the goodness of a trained model. They identified different methods of reducing the number of synaptic updates. One interesting discovery was that initialising the network with weights extracted from the distribution of weights of a previously trained networks massively reduces the number of required updates over initialising with standard Kaiming Normal. They suggest that this is analogous to evolution choosing better initial brain conditions.

It could be worth us at \os looking at weight distributions in our trained networks and seeing if this is useful for prescribing a weight initialiser for our networks.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6891> Trying to model primate ventral stream which is part of brain that does core object recognition using ANNs. Training to maintain high brain predictivity using Brain-Score as benchmark for this. 4 sub units of brain models in the model, CORnet-S: V1_COR, V1_COR, V4_COR and IT_COR. Aim to reduce the number of synaptic updates whilst maintaining high brain predictivity. Find that initialising brain with ``artificial genome'' by compressing trained weights to distribution which proved much better ``at birth'' than Kaiming Normal weight initialisation (54\% initial predictivity without training). Reduce synaptic updates by freezing earlier brain units - downstream training - or even by freezing all but the final layer of brain units - critical training. Downstream training reduces score but critical training is nearly as good as full training but only requires 5\% of parameters. Final score is 79\% brain predictivity but with only .5\% of the updates. The ``at birth'' initialisation is especially interesting as it may be analogous to brain pre-wiring in primates - and could be something we apply for weight init.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {neuroscience, machine learning, initialisation},
  modificationdate = {2022-06-28T20:49:48},
  owner            = {ISargent},
}


@InProceedings{GhaffariSFW2022,
  author           = {Saba Ghaffari and Ehsan Saleh and David Forsyth and Yu-Xiong Wang},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {On the Importance of Firth Bias Reduction in Few-Shot Classification},
  url              = {https://openreview.net/forum?id=DNRADop4ksB},
  comment          = {When training a network with many examples, a good estimate of the best value of the parameters (weights) are their expected value (the average over the whole dataset). However, when there are fewer examples, for example when a pretrained network is being finetuned for redeployment on a new tasks with very few training examples, their is a bias from the parameters' expected values and the actual optimal values. This was apparently addressed by Firth and this paper proposed to add Firth Bias Reduction to the loss when transferring to a new task with few examples. They demonstrate that it improves results when there are few training examples and the results are not harmed when there are many training examples.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6222> When tuning a pretrained network for few-shot learning (adapting to a new task with very few training examples) there is a bias in the parameter estimation because there are only a few examples. Intuition of this bias is that, with many example, the expectation of the parameters is close to the actual optimisation of the parameters, but with fewer examples the expectation is likely to be further from the optical parameter set. This paper proposes to add Firth Bias Reduction to the loss and demonstrates that it improves results with fewer examples and also never hurts even when there are lots of examples.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {pretraining, finetuning, few-shot, transfer learning},
  modificationdate = {2022-06-28T21:04:10},
  owner            = {ISargent},
}

@InProceedings{HamiltonLFZF2022,
  author           = {Mark Hamilton and Scott Lundberg and Stephanie Fu and Lei Zhang and William Freeman},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning},
  url              = {https://openreview.net/forum?id=TqNsv1TuCX9},
  comment          = {Shapley Values are considered to be that fairest way to attribute contributions to a varied set of actors (such as workers of different abilities, different units of a trained network). This paper gives a nice explanation of these and describes using the Shapley-Taylor index to identify where one image is similar to another. Despite being pressed by the reviewers, the authors refuse to go as far as using human explanation of the different regions highlighted my heatmaps  ``Because human evaluations introduce biases such as preference for compact or smoothness explanations'', a point worth considering in relation to \os's node-labelling work.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6983> This paper provides a really nice explanation of Shapley Values as the fair way to reward contributions https://mmlsparkdemo.blob.core.windows.net/iclr22/Axiomatic%20Search%202.mp4 Looking at systems that compare pairs of images using a similarity function Aim to understand what motivates their behaviour even when we don't have underlying code or value functions Use Shapley values, co-operative game theory, fair way to compare different things Produce heatmaps to compare images. Can use Shapley-Taylor index to generalise and query where in one image is similar to another They refuse to use human evaluations of the derived explanations ``Because human evaluations introduce biases such as preference for compact or smoothness explanations''},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {explanation, visualisation, algorithm analysis, machine learning},
  modificationdate = {2022-06-28T20:57:04},
  owner            = {ISargent},
}

@InProceedings{HamiltonZHSF2022,
  author           = {Mark Hamilton and Zhoutong Zhang and Bharath Hariharan and Noah Snavely and William Freeman},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Unsupervised Semantic Segmentation by Distilling Feature Correspondences},
  url              = {https://openreview.net/forum?id=SaKO6z6Hl0c},
  comment          = {Based on the work in ~\cite{HamiltonLFZF2022} (see Section~\ref{ss:meaningful}), this group propose ``STEGO'' which performs unsupervised segmentation using pretrained networks with good results, including on remote sensing (Potsdam 3 Aerial Segmentation) data. They achieve this my finding the correspondences between the responses of the pretrained network to different inputs and cluster these to produce `labels'. The results are then refined with Conditional Random Field (pixel labels are conditioned on their neighbours removing `salt and pepper' type noise). This means that if your pretrained network is unsupervised/self-supervised you can potentially arrive at a good initial Basemap without any initial labels.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6068> The STEGO paper - this is work OS/Harry B looking at. Follows on from HamiltonLFZF2022 and by exploiting the correspondences between features in different images when they are processed by self-supervised model. Features that are highly correspondent are amplified and clustered to identify regions in segmentation. Trained SSL backbone is frozen to become the ``visual transformer''. Data are passed from here into a segmentation head that learns segmentation correspondences using the correspondence distillation loss. At prediction time, this segmentation correspondence is clustered and then refine with conditional random field (usually this removes high frequency noise). Results are very good even on very cluttered scenes and including on Potsdam 3 aerial segmentation challenge remote sensing dataset.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {semantic segmentation, self-supervised},
  modificationdate = {2022-06-28T21:01:08},
  owner            = {ISargent},
}

@InProceedings{HepburnLSBM2022,
  author           = {Alexander Hepburn and Valero Laparra and Raul Santos-Rodriguez and Johannes Ball\`{e} and Jesus Malo},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {On the relation between statistical learning and perceptual distances},
  url              = {https://openreview.net/forum?id=zXM0b4hi5_B},
  comment          = {Better generated images are achieved by regularising generated image statistics to align to visual perception. I'm not sure how new this is, because it seems very similar to what was discovered in ~\cite{SimoncelliO01} (which they do cite) and ~\cite{MordvintsevOT2015} (which they don't).},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6766> Intersection between perception (of distances) statistics (of natural images) and machine learning (and what the models learn) Paper looks at behaviour of human visual system and its interaction with statistics of natural images. For example, demonstrate how perceptual metrics allow reconstruction of natural images from models that have only been trained on random noise Find that perceptual distances provide regularisation and are especially useful if data are scarce},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {psychophysics, image statistics, machine learning},
  modificationdate = {2022-06-28T20:51:25},
  owner            = {ISargent},
}

@InProceedings{JahanianPTI2022,
  author           = {Ali Jahanian and Xavier Puig and Yonglong Tian and Phillip Isola},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Generative Models as a Data Source for Multiview Representation Learning},
  url              = {https://openreview.net/forum?id=qhAeZjs7dCL},
  comment          = {A cool thing about GANs is that they can be steered - different meanings emerge along different directions of the learned latent space. This means that different versions of the same thing, such as different rotations of an object, or an object appearing under different conditions, can be generated by the model. This paper exploited this to produce synthetic data - much like a new augmentation of a real image - with which they used contrastive learning to train a model.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6339> Paper looking at using Implicit Generative Models IGM such as StyleGAN, GPT-3, etc for contrastive learning These models are steerable, in the latent space there is positional, environmental or other information and so they are dynamic So use this steerability to create different views of the same object and perform contrastive learning with these (and real data)},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {GANs, self-supervised, contrastive learning},
  modificationdate = {2022-06-28T20:55:37},
  owner            = {ISargent},
}


@InProceedings{JingVLT2022,
  author           = {Li Jing and Pascal Vincent and Yann LeCun and Yuandong Tian},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Understanding Dimensional Collapse in Contrastive Self-supervised Learning},
  url              = {https://openreview.net/forum?id=YevsQ05DEN7},
  comment          = {Apparently, dimensional collapse can also happen if the augmentations used (to alter the input in ways that shouldn't affect the meaning of the image) have a variation that is greater than the original data variation. They propose DirectCLR which directly optimises representation space without relying on a trainable projector.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6792> In contrastive learning approaches, dimensional collapse can occur when augmentations are greater than data variation and due to implicit regularisation. Is this clue that we shouldn't apply certain augmentations designed for natural imagery to our remote sensing imagery? Also, more layers can lead to more collapse. Propose DirectCLR which directly optimises representation space without relying on a trainable projector.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {contrastive learning, self-supervised, regularisation, algorithm analysis},
  modificationdate = {2022-06-28T20:54:32},
  owner            = {ISargent},
}

@InProceedings{JoySTRSN2022,
  author           = {Tom Joy and Yuge Shi and Philip Torr and Tom Rainforth and Sebastian Schmon and Siddharth N},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Learning Multimodal {VAEs} through Mutual Supervision},
  url              = {https://openreview.net/forum?id=1xXvPrAshao},
  comment          = {Proposes MEME, a variation of Variational Autoencoders (probabilistic enconders), which improves the learning of representations shared between images and text.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6308> Learning using heterogeneous data such as images and text in a way that learns a shared representation using VAEs. This allows cross-generation - going from image to text or vice versa. The method proposed here, MEME (probably some combination of ``modality'' and ``encoder''), can cope with missing modalities during training.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {multimodal, self-supervised},
  modificationdate = {2022-06-28T20:50:46},
  owner            = {ISargent},
}

@InProceedings{Kim2022,
  author           = {Been Kim},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Beyond interpretability: developing a language to shape our relationships with AI},
  url              = {https://www.youtube.com/watch?v=Ub45cGEcTB0},
  comment          = {Been Kim's invited talk was one of my favourites from ICLR 2021 and so it was good to see her invited back to talk through her group's progress. The underlying theme of this talk was that the AI is a, somewhat alien, co-worker that we need to get to know and learn how to dialogue with. In particular, she talked through work understanding what a model is using to in the input data when it makes decisions. Kim highlighted her TCAV work (\cite{KimWGCWVS2017}), in which the contribution of human-defined concepts (e.g. stripes) to classification (e.g. zebra) is quantified, and the ConceptShap work ~\cite{YehKALPR2020}, which is a method of discovering the concepts in a trained model and then determines how much these contribute to the final result. It would certainly be useful to explore what concepts make up \os's remote sensing data.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7237> Through out the talk, machines are represented as a co-worker, sometimes quite alien, but needing ways to understand and hold dialogue with. Explanation of TCAV - label human concepts and see how they are represented in machine. I think this is the second stage to labelling nodes - take node labels and see how model responds to these? Or maybe the later work automatic concept-based explanations (ACE) Ghorbani2019 and ConceptSHAP YehKALPR2020 https://proceedings.neurips.cc/paper/2020/hash/ecb287ff763c169694f682af52c1f309-Abstract.html. ``Choosing elements of language that best serves humans'' Or attached generative model to a trained model to recreate machine's concepts.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {deep learning, visualisation, explanation},
  modificationdate = {2023-01-25T10:00:59},
  owner            = {ISargent},
}

@InProceedings{Kohli2022,
  author           = {Pushmeet Kohli},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Leveraging {AI} for Science},
  comment          = {DeepMind outlined their approach to science for which they build large multidisciplinary teams with the domain experts embedded. The selection of problems is based on meeting three criteria:\begin{itemize}
\item Potential for high scientific significance and impact
\item Availability of data/simulation for learning
\item A clear objective function
\end{itemize}
(which possibly excludes some of the more important questions of our time).

They demonstrated their protein structure prediction work, which included confidence measures by replacing the prediction head with a regression against confidence, which may be an alternative to network calibration to try at \os.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7238> DeepMind's approach to science - High scientific significance and impact - Availability of data/simulation for learning - Clear objective function Work in collaboration with scientists Needs to be: - able to generalise (nature has general laws) - able to predict uncertainty (confidence of system/prediction) - explainable/interpretable Protein structure prediction Included confidence measures - replaced the prediction head with a regression against confidence Many years, large multi-disciplinary team to achieve AlphaFold2, very accurate, very fast prediction of proteins and led to human and other organism's proteome prediction},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {AI, biology},
  modificationdate = {2022-06-28T20:46:20},
  owner            = {ISargent},
}

@InProceedings{KumarRJML2022,
  author           = {Ananya Kumar and Aditi Raghunathan and Robbie Jones and Tengyu Ma and Percy Liang},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution},
  url              = {https://openreview.net/forum?id=UYneFzXSJWh},
  comment          = {Times have changed since the early days of suggesting we pretrain deep networks to overcome the lack of training data related to our specific task. Now \textbf{``Pretraining is the defacto standard in modern machine learning''}. However, how we then use this pretrained model is still up for grabs. Most popular approaches are finetuning (retrain whole model) or linear probing (only tune the new head). It seems that when the downstream tasks uses data that are in-distribution case, fine tuning works best. However, linear probing works better for out-of-distribution (OOD) data. One reason for this is the new head is initialised with random weights which cause too much adjustment to the pretrained weights. They therefore suggest Linear Probing - Fine Tuning (LP-FT), a hybrid approach which tunes the new head first before finetuning the backbone so that the weights in the head are more attuned to the pretrained weights.

This is relevant to \os should we be using pretraining more to create backbones that are then deployed for data from different sensors or platforms. What we don't know is when data fall out of distribution - for example is a new version of an aerial camera out of distribution, or even a different flying year when seasonal conditions have changed?},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/5945> Very relevant to OS, with respect to Toponet approach. ``Pretraining is the defacto standard in modern machine learning''. But, how should we properly use pretrained models? Most popular approaches are finetuning (retrain whole model) or linear probing (only tune the new head). With the in-distribution case (e.g. same data) case fine tuning is best but it under performs in out-of-distribution (OOD) cases, in which linear probing works. One problem is that new head with fine-tuning is randomly initialised so features change too much which these are being adjusted. Suggest Linear Probing - Fine Tuning (LP-FT) alternative to fine tuning which is a two-step approach - tuning the head first, before tuning the model - is an improvement on this which improves on OOD cases - features are changed much less using this approach.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {pretraining, fine-tuning, transfer learning},
  modificationdate = {2022-06-28T21:02:08},
  owner            = {ISargent},
}

@InProceedings{LeeCJZTL2022,
  author           = {Kwonjoon Lee and Huiwen Chang and Lu Jiang and Han Zhang and Zhuowen Tu and Ce Liu},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{ViTGAN}: Training GANs with Vision Transformers},
  url              = {https://openreview.net/forum?id=dwg5rXg1WS_},
  comment          = {Training ViTs adversarially to produce generative networks.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6288> Had to do a number of tweaks to get ViTs to train as GANs},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {vision transformers},
  modificationdate = {2022-06-28T21:07:54},
  owner            = {ISargent},
}

@InProceedings{LiangGTSWX2022,
  author           = {Youwei Liang and Chongjian GE and Zhan Tong and Yibing Song and Jue Wang and Pengtao Xie},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{EViT}: Expediting Vision Transformers via Token Reorganizations},
  url              = {https://openreview.net/forum?id=BjyvwnXXVn_},
  comment          = {Work to make training ViTs more efficient by preserving the attentive tokens (which may be concepts or background) and fusing the inattentive ones.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6169> Can we make ViTs more efficient. Tokens may be on concept or background. Propose to reorganise the tokens by preserving attentive tokens and fusing inattentive ones.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {vision transformers, training},
  modificationdate = {2022-06-28T21:07:14},
  owner            = {ISargent},
}


@InProceedings{LiWA2022,
  author           = {Zhiyuan Li and Tianhao Wang and Sanjeev Arora},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {What Happens after {SGD} Reaches Zero Loss? --A Mathematical Framework},
  url              = {https://openreview.net/forum?id=siCt4xZn5Ve},
  comment          = {In contrast, this paper questions the assumption that a larger learning rate flattens the minima and proposes that instead stochastic gradient descent has two phases: in the first it follows the gradient flow of the loss surface, but in the second noise causes it to bounce in and out of the local minima. This would explain why a small learning rate can be as good as a large one, if given longer to train.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/7049> My very simple interpretation: Previous paper found that smaller learning rate can generalise as well as large learning rate if trained for longer so assumptions about larger learning rate flattening the minima may not be reasonable. Main result is that learning with SGD has two phases. In the first, as expected, SGD follows gradient flow. In the second phase, SGD bounces in and out of the manifold of the local minima because of noise.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {algorithm analysis, optimisation},
  modificationdate = {2022-06-28T20:43:40},
  owner            = {ISargent},
}

@InProceedings{LiEtAl2022,
  author           = {Yangguang Li and Feng Liang and Lichen Zhao and Yufeng Cui and Wanli Ouyang and Jing Shao and fengwei yu and Junjie Yan},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm},
  url              = {https://openreview.net/forum?id=zq1iJkNk3uN},
  comment          = {Based on CLIP, a vision-language model, ``DeCLIP''pretrains a image-text model using self-supervised SimSiam (see Section~\ref{ss:unsupervised}) with the image data and Masked Language Modelling (MLM) (see Section~\ref{ss:vit}) for text data, to reduce the requirement for labels.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6406> Training CLIP with fewer labels. CLIP is a vision-language model that is trained using supervision and by maximising the similarities between paired images and text. Apply SimSiam for image data and Masked Language Modelling for text data to reduce the requirement for labels. Further methods applied. Call resulting method ``DeCLIP''.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {contrastive learning, pretraining, self-supervised, multimodal model, siamese, transfer learning},
  modificationdate = {2022-06-28T21:03:38},
  owner            = {ISargent},
}


@InProceedings{LiuZJD2022,
  author           = {Shikun Liu and Shuaifeng Zhi and Edward Johns and Andrew Davison},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Bootstrapping Semantic Segmentation with Regional Contrast},
  url              = {https://openreview.net/forum?id=6u6N8WWwYSM},
  comment          = {The authors that most current existing approaches to image segmentation on use local context (e.g. with convolutional layers) and say that cross-entropy loss doesn't provide meaningful information to allow training to focus on the more confusing classes. They propose using regional contrast loss function - ReCo - which should encourage representations to be more similar within-class and more dissimilar between classes. Using a confidence map they are able to select training examples that focus on more difficult problems. Indicate that this approach is more useful when only a few well-labelled examples, or many incompletely labelled examples, are available. Could some of these approaches be interesting in an \os context?},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6375> Segmentation when either only a few completely labelled images or many images but labels are incomplete Current segmentation methods only use local context Cross-entropy loss doesn't provide enough meaningful information to focus on the more confusing classes Propose regional contrast loss function - ReCo - representations within classes should be more similar and between classes should be more dissimilar Select examples that are easy and difficult given a confidence map},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {semantic segmentation, limted data},
  modificationdate = {2022-06-28T20:59:57},
  owner            = {ISargent},
}


@InProceedings{LyuFWT2022,
  author           = {Qi Lyu and Xiao Fu and Weiran Wang and Songtao Lu},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective},
  url              = {https://openreview.net/forum?id=5FUq05QRc5b},
  comment          = {Whilst this paper is aiming to train networks to be deployed onto identifying different views of the same thing (multiview learning), it seems more generally applicable to me for improving results for downstream tasks which may be somewhat out of domain. Often, classifiers misclassify images because they have learned some spurious aspect of the context, e.g. they use snow in the image to label the dog as a husky. This can mean they fail when the context is unusual, such as classifying a cow when it appears on a beach. To address this, this paper proposes a training approach that maximises that correlation been images of the same class (husky, cow) which then encourages the shared information between examples to be more relevant to the class. This approach also provides the ability to extract the `private`/background, uncorrelated information.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6062> This paper looks at multiview learning (and possibly improving OOD results? - izzy) by decomposing latent representations to shared (e.g. content, what the label refers to) and private (e.g. context or style) components. Intuition is given with classification of an image of a cow (content) on the beach (context), which can fail because cows in the training data are usually on grass. Using this approach they maximise correlation in similar way to DeepCC and Barlow Twins and find that this is a good objective. This means the shared information can be learned and the private information extracted.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {siamese, self-supervised, multiview learning, training},
  modificationdate = {2022-06-28T21:03:56},
  owner            = {ISargent},
}

@InProceedings{MadaanYLLH2022,
  author           = {Divyam Madaan and Jaehong Yoon and Yuanchun Li and Yunxin Liu and Sung Ju Hwang},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Representational Continuity for Unsupervised Continual Learning},
  url              = {https://openreview.net/forum?id=9Hrka5PA7LW},
  comment          = {In a production set-up, ideally a backbone network would be learning continually as new data come in. However, if learning is supervised this requires continuously labelling data. Further, as the domain drifts, ``catastrophic forgetting'' can lead to a model that can no longer perform tasks it was previously good at. This paper looks at solutions to both these and finds that Lifelong Unsupervised Mixup (LUMP) (they also tried Dark Experience Replay) in combination with Barlow Twins (they also tried SimSiam) produces a backbone that responses well over time to a range of downstream tasks. 

I think this paper is very relevant to \os's future use of machine learning for image interpretation. It addresses sets out an approach to continually updating backbone networks, as new data are acquired, which doesn't require new labels to be produced. Here's the \github repo: \url{https://github.com/divyam3897/UCL}.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/7120> I think this paper is very relevant to OS's use of machine learning for image interpretation. It addresses the issue of continual learning in the case from visual data posted on the web which is unlabelled and for which new problems need to be addressed (e.g. finding real world features for which previous model have not been created). I see that as how we should ultimately be working at OS, we have data continually coming in from different platforms and we want to be able to address new customer problems as they arise. The problem is, to learn for one problem can require a lot of labelled data and can also not help future problems. And as we move onto future problems, ``catastrophic forgetting'' may occur which means that our models stop being able to solve for earlier problems. This paper addresses this using Unsupervised Continual Learning (UCL). They take self-supervised models SimSiam and Barlow Twins (yay, we know about those :-) ) to address the labelling problem - learning representations that can then be used to solve problems as they arise (e.g. as a backbone network). Investigate solutions to catastrophic forgetting by revisiting representations learned on previous tasks: - structural regularization (encourage current task parameters to stay close to previous parameters) - unsupervised replay using Dark Experience Replay (DER) to minimise the Euclidian distance between projected output of current unlabelled task and replay buffer (earlier inputs) task - and propose Lifelong Unsupervised Mixup (LUMP) which interpolates between the examples in the current task and random examples from the replay buffer Using CIFAR-10, CIFAR-100 and Split Tiny-ImageNet problems they assess accuracy and forgetting over successive problems for different approaches against a baseline of finetuning the backbone Find that unsupervised approaches perform better than supervised approaches for accuracy and forgetting. The use of LUMP also results in better performance over all other methods. Barlow Twins with LUMP appears to be the best combination for forgetting and is fairly equivalent for accuracy. Evidence that UCL, especially with LUMP, learning more distinctive features (by visual inspection) and also has a loss landscape that is stable and robust (remains consistent over subsequent tasks). Here's the repo: https://github.com/divyam3897/UCL},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {siamese, self-supervised, online learning, continual learning},
  modificationdate = {2022-12-03T19:15:10},
  owner            = {ISargent},
}

@InProceedings{MaNYJXZZA2022,
  author           = {Xiaojian Ma and Weili Nie and Zhiding Yu and Huaizu Jiang and Chaowei Xiao and Yuke Zhu and Song-Chun Zhu and Anima Anandkumar},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{RelViT}: Concept-guided Vision Transformer for Visual Relational Reasoning},
  url              = {https://openreview.net/forum?id=afoV8W3-IYp},
  comment          = {The ``surfing the zeitgeist''award must surely go to this paper for including pretty much all the representation learning trends into one approach: global and local contrastive learning  in vision transformers for visual reasoning.},
  comments         = {From <https://iclr.cc/virtual/2022/poster/6087> This paper does it all: global and local contrastive learning in vision transformers for visual reasoning},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {vision transformers, contrastive learning, visual reasoning},
  modificationdate = {2022-06-28T21:10:08},
  owner            = {ISargent},
}


@InProceedings{MelasKyriaziRLV2022,
  author           = {Luke Melas-Kyriazi and Christian Rupprecht and Iro Laina and Andrea Vedaldi},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Finding an Unsupervised Image Segmenter in each of your Deep Generative Models},
  url              = {https://openreview.net/forum?id=Ug-bgjgSlKV},
  comment          = {This is another approach using a pretrained network, this time specifically a GAN. This work finds that if one optimises for the transform of the data that increases the contrast in the generated image, a foreground-background mask is produced - such as a mask that outlines where a horse is and blocks out the fields and sky. They then use these masks as segmentation labels for the generated data for training a segmenter. Despite being trained only on synthetic data, the results on real data are very good. I am not sure that this would work out of the box for remote sensing data which tends not to have a foreground-background character.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6368> Latent spaces of GANs contain human-interpretable directions. Use these for downstream tasks! Find a latent direction in pretrained generator Optimise direction that increases the contrast in generated images whilst keeping edges the same - turns foreground light or dark and background in the opposite direction and thus construct foreground-background segmentation masks Use these directions to create a large synthetic dataset of masks and train segmenter on these Only trained on synthetic data and yet performs very well Would this work on OS data with no foreground-background characteristic? https://github.com/lukemelas/pytorch-pretrained-gans},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {GANs, semantic segmentation, pretraining, transfer learning},
  modificationdate = {2022-06-28T21:01:25},
  owner            = {ISargent},
}

@InProceedings{MillerCM2022,
  author           = {Michelle Miller and SueYeon Chung and Ken Miller},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Divisive Feature Normalization Improves Image Recognition Performance in AlexNet},
  url              = {https://openreview.net/forum?id=aOX3a9q3RVV},
  comment          = {In neuroscience, it is know that neurons can be inhibited by more active neurons nearby, known as Divisive Normalization. This paper investigates their application in improving training of AlexNets although I'm unconvinced by the results which seem to show that Batch Normalization has the greater impact. However, possibly more interesting and relevant to this section, is that this paper also looks at how well the manifold of each network node separates the classes (its capacity). They find that this varies through the depth with a steep increase at final layers, which may be expected, but is a result of highly varying changes in dimensionality of manifolds and the correlation between manifolds. They also measure the sparsity of the model using the Gini index, finding all models are sparse in the final layer.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6633> Divisive Normalisation is when the response of one neuron is reduced or inhibited by more active nearby neurons and is important in neuroscience Applied DN by scaling neuronal response by exponentially weighted sum of its neighbours after ReLU on all conv layers of AlexNet in various combinations and found that DN followed by Batch Normalisation had the best accuracy performance (CFIAR-100) >10\% than with no normalisation (but not much different to BN alone, looking at the graphs). Look at capacity of manifolds for each neuron - the number of separable categories per neuron. This shows that capacity is low for early and intermediate layers but rises steeply in the final layers. This breaks down to high dimensionality (less easy to distinguish) at low at early layer, which increases in intermediate layers and then rapidly drops in final layers. The correlation between manifolds drops to very low (manifolds are farther from each other) at early layers, increases in intermediate layers and then drops off for final layers. Sparsity - measure using Gini index (inequality of income). DN increases sparsity (a bit) through network but at the final layer all models are as sparse.},
  creationdate     = {2022-05-08T15:25:20},
  keywords         = {training, algorithm analysis},
  modificationdate = {2022-06-28T20:45:14},
  owner            = {ISargent},
}


@InProceedings{MouselinosMM2022,
  author           = {Spyridon Mouselinos and Henryk Michalewski and Mateusz Malinowski},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Measuring {CLEVR}ness: Black-box Testing of Visual Reasoning Models},
  url              = {https://openreview.net/forum?id=UtGtoS4CYU},
  comment          = {This paper notes that visual reasoning models are easily fooled and so introduce an adversarial component to training (the approach where a part of the algorithm tries to fool the training model and the model therefore learns to spot adversarial input, like growing up with an older sibling). This makes the final model much more robust (like growing up with an older sibling).},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6011> Demonstrate that visual reasoning models (e.g. models that answer questions about images) are easily fooled (overfit to the training data?) and introduce an adversarial component into training to makes models much more robust.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {visual reasoning},
  modificationdate = {2022-06-28T21:09:31},
  owner            = {ISargent},
}

@InProceedings{Olukotun2022,
  author           = {Kunle Olukotun},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Accelerating {AI} Systems: Let the Data Flow!},
  comment          = {With reference to the Pixelated Butterfly ~\cite{ChenDLYYSRR2022}, Kunle Olukotun's invited talk delves into redesigning processing units to work better with the flow of data during training. Whilst Moore's law is slowing down, computation is now limited by power. Processors are bottlenecked by the flow of data on and off the chip. Research at Stanford has developed the Plasticine Architecture leading to the SambaNova Cardinal reconfigurable dataflow unit (RDU) chip which is designed as a lattice of compute and memory units so that data are held with the processing units rather than on separate memory units. This spatial dataflow approach results in $3\times$ - $20\times$ performance improvement.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7239> Moore's law is slowing down and computation is now limited by power. But ML is demanding ever more performance (in ``post-Moore's Law era''). Sparse models, e.g. Pixelated butterfly is a solution (lottery ticket hypothesis says sparse models should be as accurate as dense models). Convergence of inference and training, on same platform (rather than inference on CPU, which requires requalifying model). Also allows continuous learning or incremental re-training (very relevant to OS). Can decompose architectural components (conv, pools, etc) to optimise them for different hardware patterns to work better in parallel. Dataflow is the natural ML execution model, thus: Plasticine: a reconfigurable dataflow architecture (RDA) to efficiently accelerate ML applications resulted in SambaNova Cardinal reconfigurable dataflow unit (RDU) chip. Made up of - Pattern Compute Unit (PCU) - Pattern Memory Unit (PMU) Traditional ML processors are bottlenecked by memory and lots of bandwidth between moving data back and forth Instead, spatial dataflow allows for ``metapipelining'' - more parallelism. Communication is direct on the chip so not having to push data back and forth to memory. 3x to 20x performance (large to small batch sizes).},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {processors, sparsity, deep learning},
  modificationdate = {2022-06-28T20:47:37},
  owner            = {ISargent},
}

@InProceedings{ParkK2022,
  author           = {Namuk Park and Songkuk Kim},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {How Do Vision Transformers Work?},
  url              = {https://openreview.net/forum?id=D78Go4hVcxO},
  comment          = {The loss landscape (see also Section~\ref{ss:algorithmanalysis}) of ViTs are apparently flatter than ResNets (c.f. \cite{ChenHG2022}, Section~\ref{sss:chenhg}), which should lead to better optimisation. However, it is also non-convex (there are potentially more than one local minimum). This work looks at how the components of ViTs, multi-head self-attentions (MSA) process the images and find that they are low-pass filters, smoothing the input. This is in contrast to convolutions, which are high-pass filters (I don't think they have to be - Izzy). The conclusion is that MSAs are shape-based and convolution filters are texture based. The resulting proposal is to put MSA blocks into ResNets to make the most of their complementary nature. This may be am interesting architecture to try at \os some time.},
  comments         = {From <https://iclr.cc/virtual/2022/spotlight/6018> Multi-head self-attentions (MSAs) mean that ViT have a flatter loss landscape than ResNet (c.f. ChenHG2022). But loss landscape is non-convex. MSAs are low-pass filters, convolutions are high-pass filters. Therefore, MSA are shape-biased, and convolutions are texture biased - they are complementary. Propose to combine the two by placing MSA blocks into ResNet.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {vision transformers, CNNs, algorithm analysis},
  modificationdate = {2022-06-28T21:06:07},
  owner            = {ISargent},
}

@InProceedings{Precup2022,
  author           = {Doina Precup},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {From Reinforcement Learning to {AI}},
  comment          = {The invited talk from Doina Precup developed the hypothesis that ``Reward is enough''to learn all behaviours required by an agent. More complex behaviours are learned in more complex environments and this could be the key to general AI.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7240> The ``reward is enough'' hypothesis: that individuals/agents develop complex behaviours purely in response to reward. The secret ingredient is a complex environment. Propose that reinforcement learning can be used as core component of general AI agents - rewards will enable the complex behaviours to emerge. Need to build knowledge - procedural and predictive/empirical (in the form of general value functions). These must be: - Expressive, to represent many things, including abstract things - Learnable, from data without labels or supervision - Composable, can be reconfigured to create solutions to knew problems Hierarchical knowledge learned using reinforcement learning by giving agent access to gestures to interact with the AndroidEnv, Android emulator for which emulated apps each have their own rewards. Agent needs to learn how to gain rewards from this interface (see https://arxiv.org/abs/2204.10374). Imagine an agent in a vast, open-ended environment‚Ä¶},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {reinforcement learning, general AI},
  modificationdate = {2022-06-28T20:47:48},
  owner            = {ISargent},
}

@InProceedings{RakotoarisonMRSS2022,
  author           = {Herilalaina Rakotoarison and Louisot Milijaona and Andry RASOANAIVO and Michele Sebag and Marc Schoenauer},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Learning meta-features for {AutoML}},
  url              = {https://openreview.net/forum?id=DTkEfj0Ygb8},
  comment          = {Proposes an approach, MetaBu, for meta-learning over tabular data. This approach hand-crafted meta features to the topology of some optimal projection of the data.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6789> Learning to learn (meta-learning) with tabular data. Propose MetaBu which aligns hand-crafted meta features to the topology of a 'top configuration', which I can only understand as some ideal projection of the data.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {meta-learning},
  modificationdate = {2022-06-28T20:59:00},
  owner            = {ISargent},
}


@InProceedings{RiadTGZ2022,
  author           = {Rachid Riad and Olivier Teboul and David Grangier and Neil Zeghidour},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Learning Strides in Convolutional Neural Networks},
  url              = {https://openreview.net/forum?id=M752z9FKJP},
  comment          = {Strides (the distance between one sample and the next when applying convolutional, pooling and other filters over an image) are normally a fixed distance. This paper proposes DiffStride, a way of optimising stride length.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/7069> This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Convergence is not always on same strides - depends on initialisation? But performance is almost always good?},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {training, CNNs},
  modificationdate = {2022-06-28T20:50:06},
  owner            = {ISargent},
}

@InProceedings{SagawaEtAl2022,
  author           = {Shiori Sagawa and Pang Wei Koh and Tony Lee and Irena Gao and Sang Michael Xie and Kendrick Shen and Ananya Kumar and Weihua Hu and Michihiro Yasunaga and Henrik Marklund and Sara Beery and Etienne David and Ian Stavness and Wei Guo and Jure Leskovec and Kate Saenko and Tatsunori Hashimoto and Sergey Levine and Chelsea Finn and Percy Liang},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Extending the {WILDS} Benchmark for Unsupervised Adaptation},
  url              = {https://openreview.net/forum?id=z7p2V6KROOV},
  comment          = {Benchmark datasets are useful for testing approaches to machine learning. Last year this group introduced the WILDS benchmark for testing methods of adapting to new domain. This year, they are introducing WILDS 2.0 which is the original data with labels and a new set of unlabelled data for testing unsupervised approaches to adapting to new domains, see \url{https://wilds.stanford.edu/get_started/}.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6963> Out-of-distribution (OOD) performance is considerably lower than performance witin the distribution of the training data. Introduced the WILDS benchmark last year to test methods of adapting to new domain. This paper introduces WILDS 2.0 which is the original data with labels and a new set of unlabelled data for testing unsupervised approaches to adapting to new domains. Could be really useful for testing approaches, especially as it contains satellite imagery. https://wilds.stanford.edu/get_started/},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {benchmark data, transfer learning},
  modificationdate = {2022-06-28T21:04:29},
  owner            = {ISargent},
}

@InProceedings{Schmid2022,
  author           = {Cordelia Schmid},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Do you see what I see? Large-scale learning from multimodal videos},
  comment          = {This invited talk gave an overview of the visual reasoning task when applied to videos and how it is being addressed. I note that the video equivalent of an image patch is a few seconds of video. An example task is ``what is the largest object to the right of the man{?}''. An example algorithm is VideoBERT, which is a transformer language model approach that learns the correlation between video and text annotation.},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7241> Learning from videos with sound/speech. E.g. VideoBERT is a pretrained backbone which will learn correlation between text and video information. Use it to create question answering model for answering questions about videos. Look at data cleaning etc. Video version of patches is clips, e.g. 10 seconds long. Good zero shot results on questions like ``what is the largest object to the right of the man'' (except the wheelbarrow is actually on the man's left) and on video captioning.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {multimodal, video, visual reasoning},
  modificationdate = {2022-06-28T21:08:54},
  owner            = {ISargent},
}


@InProceedings{SchmidtEtAl2022,
  author           = {Victor Schmidt and Alexandra Luccioni and M\`{e}lisande Teng and Tianyu Zhang and Alexia Reynaud and Sunand Raghupathi and Gautier Cosne and Adrien Juraver and Vahe Vardanyan and Alex Hernandez-Garcia and Yoshua Bengio},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{ClimateGAN}: Raising Climate Change Awareness by Generating Images of Floods},
  url              = {https://openreview.net/forum?id=EZNOb_uNpJk},
  comment          = {I saw this work prensented by Joshua Bengio at an online talk a couple of years ago. It can now be accessed at \url{https://thisclimatedoesnotexist.com/}
 (give it a go). The GAN model uses image segmentation, masking and generation of flood effect to give a view of a familiar place impacted by climate change. See a rendering of Explorer House under floodwater in Figure~\ref{fig:climategan} and also at \url{https://thisclimatedoesnotexist.com/en/share/dcfac8ef-5cef-43c5-8e7b-d73abf7780a5}.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6224> https://thisclimatedoesnotexist.com/ First publication of work Bengio spoke about a while ago creating images of what climate _looks_ like at a human scale. Perform pixel-wise classification to produce depth map and from this segmentation image. Then GAN for unsupervised domain adaptation to determine where the flood _would_ be. Finally painter renders flooding.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {environment, GANs, segmentation},
  modificationdate = {2022-06-28T20:49:12},
  owner            = {ISargent},
}

@InProceedings{SchottEtAl2022,
  author           = {Lukas Schott and von Kuegelgen, Julius and Frederik Tr\''{a}uble and Peter Gehler and Chris Russell and Matthias Bethge and Bernhard Schoelkopf and Francesco Locatello and Wieland Brendel},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Visual Representation Learning Does Not Generalize Strongly Within the Same Domain},
  url              = {https://openreview.net/forum?id=9RUHPlladgh},
  comment          = {Looks at the impact of different ways of splitting datasets given the known variation of different scene characteristics (brown to blonde hair and frown to smile). Finds that those methods that leave part of the range outside of the training data, requiring the model to extrapolate, are the worst. This remains the case when the training data contain blonde hair or smiling people but not blonde smiling people, indicating that models do not learn the underlying structure of the dataset.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6276> Analyse generalisation of many different visual representation learning approaches. Given known factors of variation (e.g. hair colour from brown to blonde, frown to smile) there are different options for performing train test split: - Random split, which means that network is mostly interpolating between training samples - Extrapolation split, which tests how well the model extrapolates over one factor of variation - Composition split, which tests how well the model extrapolates over two or more factors (e.g. train data does not contain blonde smiling people) Looking at different inductive biases: - un-/weakly supervised (mainly AEs) - fully supervised - transfer models (from e.g. ImageNet) Models are almost perfect with random split, but bad for composition and interpolation and most severe for extrapolation case and conclude that models don't learn underlying structure in dataset - models are fairly modular and so can model in-distribution factors but not out of distribution factors},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {algorithm analysis, machine learning, supervised, unsupervised, transfer learning},
  modificationdate = {2022-06-28T20:50:25},
  owner            = {ISargent},
}

@InProceedings{SellamEtAl2022,
  author           = {Thibault Sellam and Steve Yadlowsky and Ian Tenney and Jason Wei and Naomi Saphra and Alexander D'Amour and Tal Linzen and Jasmijn Bastings and Iulia Turc and Jacob Eisenstein and Dipanjan Das and Ellie Pavlick},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {The {MultiBERTs}: {BERT} Reproductions for Robustness Analysis},
  url              = {https://openreview.net/forum?id=K0E_F0gFDgA},
  comment          = {Often claims are made about what models `understand` or what their biases are. However, there is rarely understanding about whether these are a result of the training parameters or an artifact of the family of models? This work similates training over multiple BERT models to consider gender bias and finds variations can be quite wide.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6292> When making claims about the ``understanding'' or the ``bias'' of a model, such as BERT, how much are the conclusions - tested on trained models - down to the individual model (its training parameters) or to the family of models, i.e. is it down to the procedure or an artifact? Test this by simulating training over multiple BERTs and study whether gender bias exists across all models but variations are quite wide. Can use this method to test interventions, e.g. to reduce bias.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {algorithm analysis},
  modificationdate = {2022-06-28T20:44:53},
  owner            = {ISargent},
}


@InProceedings{Seung2022,
  author           = {H. Sebastian Seung},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Petascale connectomics and beyond},
  comment          = {I really enjoyed this invited talk from Sebastian Seung about mapping brains at the detail of neurons and synapses, the result being the ``Connectome''. After nemotodes's brains were mapped, \emph{Drosophila} fruit flies have now been mapped (the source for this was 0.1 petabyte of data) revealing a torroidal structure in the brain that encodes the angular direction of the fly. See \url{https://flywire.ai/}. Now work is underway on 1mm cube of mouse visual cortex using electron microscopy (1 exabyte of data). See \url{https://www.microns-explorer.org/}. The evidence is that synapses are binary switches which may be a constraint on biological learning (binary switches are known to constrain artificial neural network learning).},
  comments         = {Invited Talk From <https://iclr.cc/virtual/2022/invited-talk/7242> Fascinating! Mapping simple brains. Hardest part is mapping the connections - the Connectome. Fly brains show very typical neurons which are therefore named. https://flywire.ai/ 3D segmentation to find neurons (Drosophila is 0.1 petabyte of data). Ellipsoid body for navigation in fly brains contains a toroidal structure which represents fly's angular direction. Because mammals are good learners, study the connectome of a tiny part (1mm cube) of mouse visual cortex using electron microscopy (1 exabyte of data). Record neural response in same region to visual stimuli. https://www.microns-explorer.org/ It's fascinating how complex the structure of and relationships between neurons is. Multiple synapses between neurons - the more there are, the stronger the connection. Also, synapses are correlated in size where you get dual connections (either both large or both small). Implication is that synapses are binary switches and its known that this constrains ANNs and so may be a constraint on biological learning.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {neuroscience},
  modificationdate = {2022-06-28T20:48:04},
  owner            = {ISargent},
}

@InProceedings{ShekhovtsovSF2022,
  author           = {Alexander (Oleksandr) Shekhovtsov and Dmitrij Schlesinger and Boris Flach},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{VAE} Approximation Error: {ELBO} and Exponential Families},
  url              = {https://openreview.net/forum?id=OIs3SxU5Ynl},
  comment          = {This looks deeply into the evidence lower bound for variational Bayesian learning, such as variational autoencoders and propose improvements, that I didn't really follow. However, I did enjoy learning that Restricted Bolzmann Machines are a type of ``EF Harmonium''.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/7071> Evidence lower bound (ELBO) is used in variational Bayesian learning such as in variational autoencoders (VAEs). According to this analysis, the use of this type of learning with ``exponential family encoder and decoder'' can collapse. They propose improvements and demonstrate how these work. May be useful to refer back to if applying VAEs and if we can work what exponential family distributions are. Also, I didn't know that Restricted Bolzmann Machines are ``EF Harmoniums''‚Ä¶},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {autoencoders},
  modificationdate = {2022-06-28T20:51:55},
  owner            = {ISargent},
}


@InProceedings{SinglaF2022,
  author           = {Sahil Singla and Soheil Feizi},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Salient {ImageNet}: How to discover spurious features in Deep Learning?},
  url              = {https://openreview.net/forum?id=XVPqLyNxSyh},
  comment          = {Method of identifying features that are important for image classification. Using MTurk human classification, they then identify those that should not influence the classification (e.g. snow in a husky image).},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/5903> Used the output of the global average pooling layer Based on work of Singla et al. CVPR 2021: Select neuron that is highly predictive of a class by - Select 5 images that are highly activating of the neuron - Then produce heatmaps over the images - Then produce feature attack images Used MTurk to ask users if the neuron visualisation (the 5 images, their heatmaps and the attack images) for an ImageNet class matched the class description They also find union of heatmaps from target class (e.g. butterfly) and heatmaps from a potential spurious class (e.g. flower) and add noise to this region to evaluate the drop in accuracy to find sensitivity of model to spurious features},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {visualisation, explanation, deep learning},
  modificationdate = {2022-06-28T20:57:24},
  owner            = {ISargent},
}


@InProceedings{StrouseBWMH2022,
  author           = {DJ Strouse and Kate Baumli and David Warde-Farley and Volodymyr Mnih and Steven Hansen},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Learning more skills through optimistic exploration},
  url              = {https://openreview.net/forum?id=cU8rknuhxc},
  comment          = {Most learning algorithms penalise uncertainty. However, epistemic uncertainty, when there isn't enough information to decide, is reasonable. This paper suggests address the problems by learning with an ensemble of learners and comparing the inter- and intra-model uncertainty to penalise aleatoric uncertainty. The reward they suggest is DISDAIN (DIScriminatory DisAgreement INtrinsic).

Whilst this is aimed at reinforcement learning, its an intuitive endorsement of ensemble approaches, which may well start to reemerge over the coming years and may be worth considering at \os.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6476> Great video of a baby performing unsupervised learning! Reinforcement learning Epistemic uncertainty is good - you don't have enough information Aleatoric uncertainty is bad - the policies are in conflict and should not be Reward function penalise uncertainty no matter what type it is Address this with ensembles. Measure DISDAIN (Discriminatory disagreement intrinsic reward) as the uncertainty when predictions are aggregated across the ensemble compared to the average uncertainty of each ensemble members. Reward low DISDAIN when ensemble members agree. Demonstrate how DISDAIN learns many more skills than other approaches.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {reinforcement learning},
  modificationdate = {2022-06-28T20:51:05},
  owner            = {ISargent},
}

@InProceedings{TayEtAl2022,
  author           = {Yi Tay and Mostafa Dehghani and Jinfeng Rao and William Fedus and Samira Abnar and Hyung Won Chung and SHARAN NARANG and Dani Yogatama and Ashish Vaswani and Donald Metzler},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Scale Efficiently: Insights from Pretraining and Finetuning Transformers},
  url              = {https://openreview.net/forum?id=f2OYVDyfIB},
  comment          = {There should be more studies that analyse the outcomes of checkpoints from multiple of trained models, including across \os's model zoo. This work is a sweep across the machine learning community to distill insights into language transformers. From over 100 checkpoints, they found that it remains difficult to determine downstream performance from pretraining parameters and that the most important `knob` (hyperparameter?) for performance seems to be depth, with deep-narrow models being more pareto-optimal.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/5960> Hyperparameter sweep from the community - over 100 checkpoints - to distil insights into transformers (language). I like this work, there should be more sweeps across the community to gain insights into different approaches. Three key findings: 1. There's a gap between pretraining and finetuning. Upstream - the upstream perplexity scales with number of parameters but downstream it is hard to predict the accuracy from the number of parameters 2. Depth has a huge impact on performance but other 'knobs' don't do much 3. Existing models tend to not be pareto-optimal, although deep-narrow seem to be better.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {transformers, pretraining, finetuning, NLP, algorithm analysis, transfer learning},
  modificationdate = {2022-06-28T20:52:09},
  owner            = {ISargent},
}

@InProceedings{VardiYS2022,
  author           = {Gal Vardi and Gilad Yehudai and Ohad Shamir},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {On the Optimal Memorization Power of {ReLU} Neural Networks},
  url              = {https://openreview.net/forum?id=MkTPtnjeYTV},
  comment          = {Analysis of the ability of ReLU networks to memorise samples and demonstrate the minimum number of parameters required to perfectly memorise a dataset of given size.  This baffled me at first because I'd always though that memorisation of the data is a bad thing in machine learning. However for some applications, learning the data is a good thing and knowing this lower bound can enable better formulation of architectures.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/7215> Analysis of neural network memorisation (which has been studied since the 1980s) in this case for ReLU networks. Identifies that lower bound of parameters required to perfectly memorise a dataset of given size.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {memorisation power, machine learning},
  modificationdate = {2022-06-28T20:44:33},
  owner            = {ISargent},
}

@InProceedings{VazeHVS2022,
  author           = {Sagar Vaze and Kai Han and Andrea Vedaldi and Andrew Zisserman},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Open-Set Recognition: A Good Closed-Set Classifier is All You Need},
  url              = {https://openreview.net/forum?id=5hLP5JY9S2d},
  comment          = {A too-subtly different way of thinking about transfer learning is as closed-set classification, in which classification is only for those classes that exist within the original data, and open-set in which there are additional classes that need to be identified. In apparent contrast to the work above in ~\cite{AbnarDNS2022}, this paper finds that ``closed set classification is a good indicator of open set performance``. The contrast may be because there is a subtle difference between close/open set classification and up-/down-stream approaches.

A finding in this work is that the feature representations for unseen classes tend to me smaller than those for seen classes (it makes sense to minimise irrelevant information). Consequently, they suggest replacing maximum softmax with with maximum logit score for open dataset scoring. They also propose the Semantic Shift Benchmark (SSB) dataset, which contains seen and unseen classes that have a true semantic shift rather than a low level shift (such as a shift in image statistics).},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/6728> Closed set classification is classifying to the classes that existed in the training dataset Open set classification is classifying with classes that were not in training dataset as well as those that were - identifying the unseen classes and classifying seen classes This paper finds that closed set classification is a good indicator of open set performance (c.f. Abnar above). Finding in previous works that feature representations of unseen classes tend to be smaller than those of seen classes. Therefore replace maximum softmax with maximum logit score (MLS baseline) for open dataset scoring. Propose Semantic Shift Benchmark SSB dataset which contains seen and unseen classes that have a true semantic shift rather than a low level shift (such as image statistics)},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {fine-tuning, machine learning},
  modificationdate = {2022-06-28T21:05:00},
  owner            = {ISargent},
}

	
@InProceedings{WanHZT2022,
  author           = {Bo Wan and Wenjuan Han and Zilong Zheng and Tinne Tuytelaars},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling},
  url              = {https://openreview.net/forum?id=N0n_QyQ5lBF},
  comment          = {Propose the Contrastive Language-Image Inside-Outside Recursive Autoencoder (CLIORA) for learning how components of images relate to each other (like grammar in language) and to associated text. This model is then applied to problems such as visual question answer, visual dialogue and visual language navigation.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/6111> Motivated by grammar induction, for language, method works for images with associated description text. For visual reasoning: visual question answer, visual dialogue and visual language navigation. Propose Contrastive Language-Image Inside-Outside Recursive Autoencoder (CLIORA).},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {visual reasoning, contrastive learning, multimodal},
  modificationdate = {2022-06-28T21:09:11},
  owner            = {ISargent},
}

@InProceedings{WangZWYN2022,
  author           = {Yifei Wang and Qi Zhang and Yisen Wang and Jiansheng Yang and Zhouchen Lin},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap},
  url              = {https://openreview.net/forum?id=ECvgmYVyeUz},
  comment          = {This work evaluated a network during training using contrastive learning using their proposed Average Relative Confusion which is based on the overlap between the augmentations of the input.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6659> How to guarantee downstream performance with minimal and practical assumptions? This paper creates augmentation graph - nodes are inputs and edges indicate two inputs have overlap in their augmentations Propose Average Relative Confusion as evaluation metric based on augmentation overlap theory and say this guarantees downstream performance},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {contrastive learning, training, self-supervised},
  modificationdate = {2022-06-28T20:55:50},
  owner            = {ISargent},
}



@InProceedings{WangLP2022,
  author           = {Yifei Wang and Jonathan Lacotte and Mert Pilanci},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions},
  url              = {https://openreview.net/forum?id=Z7Lk2cQEG8a},
  comment          = {This is a mathematical analysis of neural networks with ReLU functions. Uses something called ``convex cones'' to reduce risk of gradient descent into local minima.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/7125> Mathematical analysis of neural networks with ReLU functions that applies convex cones to approach convex solutions (for which the SGD does not get caught in local minima). I don't really understand if/how this can be applied and have never encountered convex cones before but it was sort of enchanting.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {algorithm analysis, training},
  modificationdate = {2022-06-28T20:44:18},
  owner            = {ISargent},
}

@InProceedings{WangHKSCZ2022,
  author           = {Zifeng Wang and Shao-Lun Huang and Ercan Kuruoglu and Jimeng Sun and Xi Chen and Yefeng Zheng},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {{PAC-Bayes} Information Bottleneck},
  url              = {https://openreview.net/forum?id=iLHOIDsPv1P},
  comment          = {By estimating the mutual information between the weights and the input dataset, this work also finds that training has two phases. In the first the information content of the weights increase. In the second, this information is being compressed. They propose using this mutual information estimator, the PAC-Bayes Information Bottleneck, as a regulariser during training.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6239> Estimate the information in weights of neural networks. Achieved this by estimating the mutual information between the weights and the input dataset using an information bottleneck which depicts the trade-off between the sufficiency (label parameters) and minimality term (how much the parameters memorise the input dataset) Find training has 2 information phases: 1. information increases 2. then in second phase this information is being compressed No matter what the activation function More weights contribute to faster fitting Propose regularising training with PIB (?)},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {training, algorithm analysis},
  modificationdate = {2022-06-28T20:43:58},
  owner            = {ISargent},
}

@InProceedings{WuRHS2022,
  author           = {Yuhuai Wu and Markus Rabe and DeLesley Hutchins and Christian Szegedy},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Memorizing Transformers},
  url              = {https://openreview.net/forum?id=TrjbxzRcnf-},
  comment          = {This is interesting. The authors add a memorizing model to the network which is designed to memorize all the data. Backpropogation does not occur over this module but it can be drawn upon for prediction, e.g. by using k-nearest-neighbour.

See TayEtAl2022 for more on memorisation},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/6065> A different approach to acquiring new knowledge in language models - simply memorize the new data. The memory module retains all past data. Don't backpropagate into memory while training (otherwise that would be a lot of parameters!). Means kNN is an option. Is this like case-based reasoning linked to machine learning? Can also only add memorizing model at finetuning normal transformer with little training cost and very similar results.},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {transformers, memorisation},
  modificationdate = {2022-06-29T14:26:27},
  owner            = {ISargent},
}

@InProceedings{YangCYCY2022,
  author           = {Jiawei Yang and Hanbo Chen and Jiangpeng Yan and Xiaoyu Chen and Jianhua Yao},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning},
  url              = {https://openreview.net/forum?id=kQ2SOflIOVC},
  comment          = {Working with histological applications, this paper addresses pretraining using contrastive learning to produce a backbone for few-shot learning. In this case, the latent space (representations) from the pretrained model are clustered and the covariance data from the clustering is used to augment the unseen data. Can you tell I don't really understand this method?},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6718> Contrastive learning with histology data, 3 steps: 1. Pretraining 2. Base dictionary construction (k-means to cluster data in latent space) 3. Latent augmentation (augment the unseen data using the covariance data from clustering)},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {contrastive learning, medical, unsupervised, few-shot learning, transfer learning},
  modificationdate = {2022-06-28T20:56:26},
  owner            = {ISargent},
}


@InProceedings{YangCBJ2022,
  author           = {Yu Yang and Xiaotian Cheng and Hakan Bilen and Xiangyang Ji},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Learning to Annotate Part Segmentation with Gradient Matching},
  url              = {https://openreview.net/forum?id=zNR43c03lRy},
  comment          = {An alternative response to the problem of having fewer quality training examples is to generate synthetic data. Several papers at this conference suggested using generator networks (such as Generative Adversarial Networks GANs) to produced synthetic data for training. In this paper, a network is training using such generated training data and then optimised by matching the training loss and gradients (the proportion of the final loss/error that is attributed to each weight using backpropogation) to the loss and gradients when the available real data are passed through the network.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6015> Propose a method of segmenting images when training data is very limited. 1. Create synthetic data using generator and annotator 2. Train segmentation network and compute loss and gradients on these data 3. Compute loss and gradients on real labelled data using the same segmentation network 4. Optimise by matching the losses between the synthetic and the real data},
  creationdate     = {2022-05-08T15:25:21},
  keywords         = {segmentation, small dataset},
  modificationdate = {2022-06-28T21:00:17},
  owner            = {ISargent},
}



@InProceedings{YaoZF2022,
  author           = {Huaxiu Yao and Linjun Zhang and Chelsea Finn},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Meta-Learning with Fewer Tasks through Task Interpolation},
  url              = {https://openreview.net/forum?id=ajXWF7bVR8d},
  comment          = {This work applies meta-learning for task adaptation - transferring model from an initial, support, task to a new, query, task (which may or may not be a common use for meta-learning). ``Meta-overfitting'' is an issue and can be addressed using ``label-shift'', whereby noise is added to the labels (some of the labels are wrong), and ``MetaMix'', whereby some of the query set is mixed in with support data. This paper proposes meta-learning with task interpolation (MLTI), which generates additional tasks by randomly sampling a pair of tasks and training with new features and labels that have been interpolated from between these two domains.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/7141> Applying meta-learning this to task adaptation - maybe that's the same for all meta-learning problems? Solutions to meta-overfitting include label-shift - adding noise to labels in support and query set - and MetaMix - mix up support and query sets To reduce the number of examples for the new tasks, this paper proposes meta-learning with task interpolation (MLTI) - generating additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels.},
  creationdate     = {2022-05-08T15:25:22},
  keywords         = {meta-learning},
  modificationdate = {2022-06-28T20:58:24},
  owner            = {ISargent},
}


@InProceedings{YuCSYTYLW2022,
  author           = {Shixing Yu and Tianlong Chen and Jiayi Shen and Huan Yuan and Jianchao Tan and Sen Yang and Ji Liu and Zhangyang Wang},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Unified Visual Transformer Compression},
  url              = {https://openreview.net/forum?id=9jsZiUgkCZP},
  comment          = {More attempts to make training ViTs more efficient by performing in-training pruning/sparsity and adding in skip-connections.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6958> Work aims to produce more efficient ViT by adding in various compression tactics such as sparsity/pruning and skip connections learned during training. I think.},
  creationdate     = {2022-05-08T15:25:22},
  keywords         = {vision transformers, training},
  modificationdate = {2022-06-28T21:07:29},
  owner            = {ISargent},
}


@InProceedings{YunRS2022,
  author           = {Chulhee Yun and Shashank Rajput and Suvrit Sra},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Minibatch vs Local {SGD} with Shuffling: Tight Convergence Bounds and Beyond},
  url              = {https://openreview.net/forum?id=LdlwbBP2mlq},
  comment          = {Considering the federated learning, when learning occurs over distributed or devices, this paper dives deeper into the how to distribute examples to learners to maximise the efficiency of learning. They propose algorithmic modification called Synchronized Shuffling for faster convergence.},
  comments         = {Oral From <https://iclr.cc/virtual/2022/oral/7031> Distributed/federated learning, e.g. learning of edge devices. Communication is often bottleneck so minimise comms, e.g. local SGD aka federated averaging. Many different analyses of different methods of performing local SGD to determine most optimal approaches but these analyses (apparently) don't apply to without-replacement sampling which is the actual scenario. propose an algorithmic modification called synchronized shuffling for faster convergence.},
  creationdate     = {2022-05-08T15:25:22},
  keywords         = {training, federated learning, algorithm analysis},
  modificationdate = {2022-06-28T20:51:42},
  owner            = {ISargent},
}

@InProceedings{ZhangZZPYK2022,
  author           = {Chaoning Zhang and Kang Zhang and Chenshuang Zhang and Trung X. Pham and Chang Yoo and In Kweon},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {How Does {SimSiam} Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning},
  url              = {https://openreview.net/forum?id=bwq6O4Cwdl},
  comment          = {The fact that siamese networks can be trained without negative examples and yet do not collapsing (`dimensional collapse``) to some trivial solution was considered by this paper. The the first approach not to use negative examples was SimSiam (\cite{ChenH2021}) who said that this was because they didn't backpropogate the gradient over one of the encoders (called ``stop gradient``). However, this work finds that the real reason is to do with opposition in the directions of two components of the representation vector (the centre component and the residual). They also refute the claim in work similar to SimSiam, BYOL (Bootstrap Your On Latent) ~\cite{GrillEtAl2020} that batch normalisation is essential.
The paper also gives a nice summary of self-supervised, mainly siamese, approaches.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6629> The paper itself has a nice summary of recently published self-supervised - mainly siamese - approaches. Claims to be similar to the work in BardesPL2021 which introduced VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning. Contrastive learning has negative examples (''repulsive component'') and this has been thought to help avoid collapse, aka dimensional collapse, aka ``the collapsing problem'' - where the representations learned are constant and trivial (my intuition is that this is like a supervised predictor always predicting the most likely class). SimSiam does not have negative examples and yet does not collapse and it was claimed by the authors that is because it has a stop gradient (not backpropogating the gradient over one encoder) on one side and predictor on the other. Refutes this claim of original SimSiam ChenH2021 paper, first demonstrating that symmetric architectures with and without predictor lead to collapse. Their analysis decomposes the ($l_2$ normalised) representation vector into the centre component (the average/expected value for this vector), as approximated over the mini-batch, and the residual component. Collapse is when all vectors approaches the centre component and the opposite is desirable. They look at the contribution of these two components to the negative gradient when a negative sample is supplied and find that the negative centre component provides de-centring and the negative residual provides de-correlation. Demonstrate that this unifies InfoNCE and SimSiam. Also, from their paper, I learn that an earlier work refuted claim that batch normalisation is essential in BYOL (GrillEtAl2020).},
  creationdate     = {2022-05-08T15:25:22},
  keywords         = {siamese, algorithm analysis},
  modificationdate = {2022-06-28T20:54:18},
  owner            = {ISargent},
}


@InProceedings{ZhouWWSXYK2022,
  author           = {Jinghao Zhou and Chen Wei and Huiyu Wang and Wei Shen and Cihang Xie and Alan Yuille and Tao Kong},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Image {BERT} Pre-training with Online Tokenizer},
  url              = {https://openreview.net/forum?id=ydopy-e6Dg},
  comment          = {Introduce iBOT pretraining of a ViT which uses MIM, as in ~\cite{BaoDPW2022}, and finetune for downstream task including semantic segmentation.},
  comments         = {Poster From <https://iclr.cc/virtual/2022/poster/6156> Say that ViT deals with global views and neglects images' internal structures and may not scale to larger data and models Looking at Masked Language Modelling (MLM) (self-supervised approach to representation learning in TEXT), which models relationships between subwords and scales well to larger data and models. They use an equivelent that was proposed in the preprint of BaoDPW2022 - Masked Image Modelling (MIM) Can be used with CNN or ViT - this work looks at ViT, which works on patches from images (rather than pixels in CNN) iBOT has a teacher and student network and minimises both losses. Use with ViT architecture. Believe that iBOT requires a semantically meaningful tokenizer Say that MIM in iBOT is doing local clustering and the objective can be transferred to unsupervised semantic segmentation I don't really understand how this framework is working but could be an approach to self-supervised learning of backbone (with semantically meaningful representations)?},
  creationdate     = {2022-05-08T15:25:22},
  keywords         = {vision transformers},
  modificationdate = {2022-06-28T21:06:58},
  owner            = {ISargent},
}

@InProceedings{ZiyinLMU2022,
  author           = {Liu Ziyin and Kangqiao Liu and Takashi Mori and Masahito Ueda},
  booktitle        = {International Conference on Learning Representations},
  date             = {2022},
  title            = {Strength of Minibatch Noise in {SGD}},
  url              = {https://openreview.net/forum?id=uorVGbWV5sw},
  comment          = {A systematic study of stochastic gradient descent noise with minibatches and finds, among other things, that a large learning rate can help a model to generalise and that large learning rates or small batch sizes can cause the linear learning rate-batchsize law to fail.},
  comments         = {Spotlight From <https://iclr.cc/virtual/2022/spotlight/7177> ``In natural and social science, analytical solutions are of paramount importance for understanding the underlying mechanisms'' (and thus we should be applying this to formal sciences - Izzy) This work systematically studies stochastic gradient descent noise with minibatches and results are (quoted, because I can't digest these): 1. provide insight into the stability of training a neural network 2. suggest that a large learning rate can help generalization by introducing an implicit regularization 3. explain why the linear learning rate-batchsize scaling law fails at a large learning rate or at a small batchsize 4. can provide an understanding of how discrete-time nature of SGD affects the recently discovered power-law phenomenon of SGD From <https://openreview.net/forum?id=uorVGbWV5sw>},
  creationdate     = {2022-05-08T15:25:22},
  keywords         = {algorithm analysis, machine learning},
  modificationdate = {2022-06-28T20:43:12},
  owner            = {ISargent},
}

@Book{GrayS2019,
  author           = {Mary L. Gray and Siddharth Suri},
  date             = {2019-05-07},
  title            = {Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass},
  comment          = {Describes the reality of ghost work, based on 5 years of study including detailed interviews with ghost workers. Great story telling as well and good consideration of how ghost work fits into the history of employment, especially casual labour, and how it can be much better supported to the benefit of workers and, to an extent, the recipients of their work.

Both the ghost workers and and those who receive their work tend to be treated as customers of the platform, e.g. MTurk that facilitates the work. Most don't allow the workers to be identified by any more than an id code and so job creators have no sense of the person behind the work. Workers can lose out because others get to the job sooner, someone deems their work inadequate or just technology glitches. There is no recourse and no feedback e.g. on how to do the job better another time.

Ghost work fills in technology's last mile - the bit that always requires humans no matter how much technology is advanced. p53. We never seem to replace the need for human effort. p175-6

Uses the Pareto distribution to describe workers - a core small percentage do the vast amount of the work. Whereas an employer would have previously expected all their workers to distribute the workload so that most people are required to perform the bulk of the work, by using ghost work platforms they are starting to use the Pareto distribution for recruitment - avoiding the cost and risks of traditional recruitment. p103-103

Workers don't share a work site, hour or professional identity, which are key ingredients to organising workers interests. p118

Despite this, workers do find ways to collaborate - to reduce costs (signing up, avoiding scams, finding work, and getting paid); to get work done, and; to recreate the social side of work. Ghost work relies on the kindness of strangers. p122 - 123

Chapter 6 addresses how ghost work should be progressed. A few ghost work platforms are aiming at a 'double bottom line' by aiming to make money and have the other goals such as environmental and social benefits. These companies see humans in the loop as assets, a ``commons of talent'' to draw from not a fungible raw material. p141

Some ghost work platforms also use 'scaffolding' to support their workforce - bringing together teams of experienced and novice workers who bring knowledge and new insights into the work mix.

Liken Ghost Work to piecework of the 19th Century 
``It's also true that the long march toward automation has historically created new needs and different types of human labor to fill those needs. In this respect, the new, software-managed work world shares features of the factory jobs that assembled cars by placing workers on a production line where and when they were needed most. It also resembles the so-called piecework that women and children did on farms in the 19th century, assembling matchstick boxes for pennies a pop. And it overlaps in obvious ways with the outsourcing of medical transcription and call center work to the Global South that boomed with the expansion of the internet in the late 1990s.'' p8

``As the Industrial Revolution got under way and machinery began to automate the production of certain goods, such as textiles, the availability of piecework exploded. Piecework (also called ‚Äúindustrial homework,‚Äù ‚Äúputting-out work,‚Äù ‚Äúcottage industry systems,‚Äù or ‚Äúcommission systems‚Äù) was the part of manufacturing or processing a product done by a person when a machine hit its limits. Piecework jobs were broken down into small, distributable tasks that could be carried out off-site, without stopping production or diverting resources away from the factory floor.7 Assembly lines depended on old divisions of labor. Women and children living at the margins of cities dominated the expendable piecework labor pools.8 In effect, industrial piecework was the first iteration of paid, on-demand ghost work.''},
  creationdate     = {2022-05-10T14:36:21},
  keywords         = {Ethics, Labour, AI, labelling, economics, innovation, transformation},
  modificationdate = {2022-12-12T19:34:53},
  owner            = {ISargent},
  year             = {2019},
}

@Article{NikuzeFSv2022,
  author           = {Alice Nikuze and Johannes Flacke and Richard Sliuzas and Martin {van Maarseveen}},
  date             = {2022},
  journaltitle     = {Habitat International},
  title            = {Urban induced-displacement of informal settlement dwellers: A comparison of affected households' and planning officials' preferences for resettlement site attributes in Kigali, Rwanda},
  doi              = {https://doi.org/10.1016/j.habitatint.2021.102489},
  issn             = {0197-3975},
  pages            = {102489},
  url              = {https://www.sciencedirect.com/science/article/pii/S0197397521001788},
  volume           = {119},
  abstract         = {There is an increase of induced displacement of informal settlement dwellers in Kigali city due to the ongoing redevelopment of existing inner city areas and disaster risk mitigation actions in high-risk zones. Local authorities are currently much more interested in compensating the affected households in kind, namely by providing new homes in resettlement sites as a strategy to avoid the creation of new informal settlements. In this context, a resettlement site is an issue of fundamental concern for both the targeted communities and the policy makers. Understanding affected households' preferences regarding resettlement site attributes is crucially important if such relocation projects are to be successful in the long term. This study explores the preferences of affected households for resettlement attributes and compares them to the opinions of professional planning officials. Findings revealed similarities as well as significant differences between the two groups' opinions on what are the important resettlement sites' attributes. The paper further analyses the spatial implications of the two groups' preferences on the suitability of residential areas in the city. Differences in opinions led to different spatial suitability maps of the existing residential areas. Given the substantial spatial implications of the divergent views, selecting a resettlement site based on both stakeholder groups' views would be essential to contribute to more effective and conflict-free resettlement processes.},
  comment          = {Consequences of displacement of informal settlement dwellers, study in Kigali},
  creationdate     = {2022-05-26T13:43:32},
  keywords         = {Ethics, Resettlement site, Affected community, Preferences, Planning officials, Informal settlement, Disaster-risk, Urban-induced displacement, Relocation, Kigali, EthicsWS},
  modificationdate = {2022-07-05T14:16:49},
  owner            = {ISargent},
}

@Article{Uwizeyimana2022,
  author           = {Dominique E. Uwizeyimana},
  date             = {2022-04-07},
  journaltitle     = {Central Asia and the Caucasus},
  title            = {Human rights, democracy and Western aid donors' double standards in Africa: The case of Rwanda},
  doi              = {https://doi.org/10.37178/ca-c.22.1.283},
  number           = {1},
  url              = {https://www.ca-c.org/submissions/index.php/cac/article/view/597},
  volume           = {23},
  abstract         = {Dictatorships and pretend democracies characterised by gross human rights violations are not a new phenomenon on the African continent. Literature shows that most African people have never tested the democratic system being enjoyed, and sometimes taken for granted, by most citizens in many western countries. Using examples from some selected African countries, this article argues that some undemocratic regimes which are characterised by human rights violations managed to get and remain in power because of the support they received and continue to get from some major International Finance Institutions (IFIs) and bilateral donors. It also argues that while these institutions claim to use their financial aid to promote democracy and human rights in their rhetoric, they contradict themselves in practice by failing or cutting aid from local institutions that promote democracy or by supporting undemocratic and authoritarian governments despite overwhelming evidence proving that the governments being supported violates human rights of their citizens. While the author recognises that no country should be left to fend for itself in case of emergency or disaster such as a hurricane or earthquake or genocide, one of the main recommendations of this article is that of making human rights and competitive multi-party democracy a cine qua non-prerequisite for any form of aid. The author believes that doing so will create basic conditions for establishing, and possibly upholding, democratic rule in African countries which refuse to willingly establish democratic rule and respect human rights.},
  comment          = {Western countries seem to be very much concerned by economic and security interests at the expense of the human rights of people and the democracy of the aid recipient countries, study of Rwanda},
  creationdate     = {2022-05-26T13:46:33},
  keywords         = {Ethics, Human Rights},
  modificationdate = {2022-05-26T14:02:27},
  owner            = {ISargent},
}

@Article{Kelley2022,
  author           = {Stephanie Kelley},
  date             = {2022-02-10},
  journaltitle     = {Journal of Business Ethics},
  title            = {Employee Perceptions of the Effective Adoption of AI Principles},
  url              = {https://link.springer.com/article/10.1007/s10551-022-05051-y},
  abstract         = {This study examines employee perceptions on the effective adoption of artificial intelligence (AI) principles in their organizations. 49 interviews were conducted with employees of 24 organizations across 11 countries. Participants worked directly with AI across a range of positions, from junior data scientist to Chief Analytics Officer. The study found that there are eleven components that could impact the effective adoption of AI principles in organizations: communication, management support, training, an ethics office(r), a reporting mechanism, enforcement, measurement, accompanying technical processes, a sufficient technical infrastructure, organizational structure, and an interdisciplinary approach. The components are discussed in the context of business code adoption theory. The findings offer a first step in understanding potential methods for the effective adoption of AI principles in organizations},
  comment          = {''The study found that there are eleven components that could impact the effective adoption of AI principles in organizations: 
* communication, 
* management support, 
* training, 
* an ethics office(r), 
* a reporting mechanism, 
* enforcement, 
* measurement, 
* accompanying technical processes, 
* a sufficient technical infrastructure, 
* organizational structure, 
* an interdisciplinary approach. 
The components are discussed in the context of business code adoption theory''},
  creationdate     = {2022-05-26T13:58:30},
  keywords         = {AI, Ethics, corporate culture, EthicsWS},
  modificationdate = {2022-12-10T09:59:35},
  owner            = {ISargent},
}

@TechReport{Yang2021,
  author           = {Selene Yang},
  date             = {2021},
  institution      = {ILDA},
  title            = {Feminism, ethics and geospatial data. A brief reflection towards their joint analysis},
  doi              = {https://doi.org/10.5281/zenodo.4681033},
  note             = {Working paper (n)},
  url              = {https://docs.google.com/document/d/1Ee81bssn8CSdRRD2RhlYoNy10r0jhpk1niz8l59VpPo},
  address          = {Montevideo},
  comment          = {translation at https://docs.google.com/document/d/1Ee81bssn8CSdRRD2RhlYoNy10r0jhpk1niz8l59VpPo/edit?usp=sharing

''Maps, since their conception, are instruments of linguistic imposition, and during this imposition the truth of some is more equal than the truth of others; the perspective of the experts generally being that which determines value. Feminist readings of space seek a wider perspective of a space predicated ‚Äúman as generic citizen''. The challenge is to find those other views that make up the space, and what are the repercussions and impact they have when they are seen through feminist cartography. ``

On the impacts that these cartographic representations can have, Catherine D'Ignazio, Associate Professor of Urban Science and Planning in the Department of Urban Studies and Planning at MIT and author of the book Data Feminism, states in an interview for this study that:

 ``If you are developing these maps that talk about adequate schools, there is also a role for technology in deepening that inequity and potential gentrification. People are going to take action and make decisions based on these maps. It can further stratify different social spaces. This has to be part of a feminist analysis because the object of research does not end with the production of the map, but has to look at what the map does in the world, the stories about people that the map tells us. We have tremendously segregated cities, so when you produce a map like that, you're also using a proxy to exacerbate racial segregation in society.''

Undertakes qualitative analysis across four dimensions - ethics, feminism, geospatial data and cartography, using literature reviews, interviews with academics, people from the sphere of civil society and feminist activists, and an analysis of existing ethical frameworks (including Locus Charter).

List recommendations along 4 axes: technical, political, epistemological and communities and describes the feminist approach with specific detail on what to do and a what not to do. 

Technical example: Transparently document the process for reproducing data and findings
Political example: Make the scope and impact of the map clear, recognising potential bias in the process
Epistemological example: Revise your belief system with respect to knowledge production
Community example: Make it clear what, whom, and under what banner the final map will appear

Also propose a reflection matrix for working with geospatial data that asks reflective questions before, during and after map-making.

''It can be concluded through this research, that in academia, civil society organizations and activists, there is no common framework regarding the ethical treatment of geospatial data.''},
  creationdate     = {2022-06-28T11:04:17},
  editor           = {Javiera Atenas and Silvana Fumega},
  keywords         = {ethics, feminism, geospatial data, cartography, EthicsWS},
  modificationdate = {2022-07-05T14:17:56},
  owner            = {ISargent},
  year             = {2021},
}

@Article{UrbinaLIE2022,
  author           = {Fabio Urbina and Filippa Lentzos and C\'{e}dric Invernizzi and Sean Ekins},
  title            = {Dual use of artificial-intelligence-powered drug discovery},
  doi              = {https://doi.org/10.1038/s42256-022-00465-9},
  pages            = {189--191},
  volume           = {4},
  comment          = {Not been able to read this because UoS doesn't have access but its an interesting introduction:

''An international security conference explored how artificial intelligence (AI) technologies for drug discovery could be misused for de novo design of biochemical weapons. A thought experiment evolved into a computational proof.''},
  creationdate     = {2022-06-28T13:35:07},
  journal          = {Nature Machine Intelligence},
  keywords         = {AI, military, terrorism, defence, warfare},
  modificationdate = {2022-06-28T15:51:46},
  owner            = {ISargent},
  year             = {2022},
}

@Article{LarkHSPSBBKG2022,
  author           = {Tyler J. Lark and Nathan P. Hendricks and Aaron Smith and Nicholas Pates and Seth A. Spawn-Lee and Matthew Bougie and Eric G. Booth and Christopher J. Kucharik and Holly K. Gibbs},
  date             = {2022},
  journaltitle     = {Proceedings of the National Academy of Sciences},
  title            = {Environmental outcomes of the US Renewable Fuel Standard},
  doi              = {10.1073/pnas.2101084119},
  eprint           = {https://www.pnas.org/doi/pdf/10.1073/pnas.2101084119},
  number           = {9},
  pages            = {e2101084119},
  url              = {https://www.pnas.org/doi/abs/10.1073/pnas.2101084119},
  volume           = {119},
  abstract         = {Biofuels are included in many proposed strategies to reduce anthropogenic greenhouse gas emissions and limit the magnitude of global warming. The US Renewable Fuel Standard is the world's largest existing biofuel program, yet despite its prominence, there has been limited empirical assessment of the program's environmental outcomes. Even without considering likely international land use effects, we find that the production of corn-based ethanol in the United States has failed to meet the policy's own greenhouse gas emissions targets and negatively affected water quality, the area of land used for conservation, and other ecosystem processes. Our findings suggest that profound advances in technology and policy are still needed to achieve the intended environmental benefits of biofuel production and use. The Renewable Fuel Standard (RFS) specifies the use of biofuels in the United States and thereby guides nearly half of all global biofuel production, yet outcomes of this keystone climate and environmental regulation remain unclear. Here we combine econometric analyses, land use observations, and biophysical models to estimate the realized effects of the RFS in aggregate and down to the scale of individual agricultural fields across the United States. We find that the RFS increased corn prices by 30\% and the prices of other crops by 20\%, which, in turn, expanded US corn cultivation by 2.8 Mha (8.7\%) and total cropland by 2.1 Mha (2.4\%) in the years following policy enactment (2008 to 2016). These changes increased annual nationwide fertilizer use by 3 to 8\%, increased water quality degradants by 3 to 5\%, and caused enough domestic land use change emissions such that the carbon intensity of corn ethanol produced under the RFS is no less than gasoline and likely at least 24\% higher. These tradeoffs must be weighed alongside the benefits of biofuels as decision-makers consider the future of renewable energy policies and the potential for fuels like corn ethanol to meet climate mitigation goals.},
  comment          = {''Bioenergy is an essential component of most proposed pathways to reduce anthropogenic greenhouse gas (GHG) emissions and limit global warming to 1.5 or 2‚Äâ¬∞C by middle to late century (1-6). Liquid biofuels may contribute to bioenergy's share of climate mitigation by displacing petroleum-based fuels with those generated from modern-day plants (7, 8). The GHG benefits of such substitution, however, are dependent on several factors including'':
- whether biofuel production invokes additional plant growth (9-12), 
- the extent to which combusted plants (typically crops) are replaced in the food system (13-15), 
- the degree to which biofuel production directly and indirectly alters patterns of land use and management (2, 16-20)

''Because land use changes (LUCs) and other consequences induced by biofuels have the potential to cause significant novel GHG emissions and modify other ecosystem services and disservices (21-26), accurately estimating and accounting these outcomes is critical for the formation of effective climate and environmental policy (27-29).''

Studied the Renewable Fuel Standard (RFS) between 2008 to 2016 and found:
- RFS stimulated 20.8 billion L (5.5 Bgal) of additional annual ethanol production, which requires nearly 1.3 billion bushels of corn after accounting for coproducts that can be fed to animals (46)
- heightened demand led to persistent increases in corn prices of ‚àº31\% (95\% confidence interval [CI]: 5\%, 70\%) compared to BAU
-  increased demand for corn also spilled over onto other crops, increasing soybean prices by 19\% [‚àí8\%, 72\%] and wheat by 20\% [2\%, 60\%]
- increase in corn prices relative to other crops increased the area planted to corn on existing cropland by an average of 2.8 Mha* per year [95\% CI: 2.4, 3.1], which is an 8.7\% increase attributable to the RFS
-  produced a net increase in cropland area of 2.1 Mha [1.8, 2.5] relative to BAU
-  intensity of corn production and extent of cropland caused 7.5\% more reactive nitrogen (N) from synthetic fertilizer to be applied annually to the landscape
-  increased total edge-of-field phosphorus (P) runoff by 3.2\%
- Combined, the RFS-driven changes in cropland area between 2008 and 2016 caused a total net C flux of 397.7 Tg CO2e [313.3, 481.7] to the atmosphere

''our findings confirm that contemporary corn ethanol production is unlikely to contribute to climate change mitigation''},
  creationdate     = {2022-06-28T15:51:43},
  journal          = {Proceedings of the National Academy of Sciences},
  keywords         = {environment, climate, greenhouse, aviation, fuel},
  modificationdate = {2023-01-19T08:41:23},
  owner            = {ISargent},
  year             = {2022},
}

@InProceedings{KongHBM2020,
  author           = {Fanjie Kong and Bohao Huang and Kyle Bradbury and Jordan M. Malof},
  booktitle        = {2020 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
  title            = {The Synthinel-1 dataset: a collection of high resolution synthetic overhead imagery for building segmentation},
  doi              = {10.1109/wacv45572.2020.9093339},
  publisher        = {{IEEE}},
  url              = {https://doi.org/10.1109%2Fwacv45572.2020.9093339},
  comment          = {Use CityEngine software to create synthetic data for segmentation training with different overhead perspectives. Designed to contain high variability.},
  creationdate     = {2022-06-28T16:08:59},
  keywords         = {dataset, remote sensing},
  modificationdate = {2022-06-28T16:14:51},
  month            = {mar},
  owner            = {ISargent},
  year             = {2020},
}

@Article{YuS2018,
  author           = {Yu, Ye and Smith, William A. P.},
  title            = {InverseRenderNet: Learning single image inverse rendering},
  doi              = {10.48550/ARXIV.1811.12328},
  url              = {https://arxiv.org/abs/1811.12328},
  comment          = {Autoencoder to learn inverse rendering from real world images in uncontrolled conditions - determine albedo and normals, as two separate decoders (afer a single encoder) and use albedo and normals to determine illumination model in the scene without ground truth. To render requires supervision (because there are infinite solutions/it is ill-posed):
- natural illumation model and prior which constrains the possible illumination parameters
- multiview stereo run offline prior to training (on different data) for three different sources of supervision
- albedo priors which vary the smoothing depending on the chromaticities of neighbouring pixels

‚Äúshape-fromshading‚Äù in the wild},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-06-28T16:43:12},
  keywords         = {deep learning, autoencoder, shape from shading},
  modificationdate = {2022-06-28T17:05:32},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2018},
}

@Article{StrumkeSM2021,
  author           = {Str{\"u}mke, I. and Slavkovik, M. and Madai, V.I.},
  title            = {The social dilemma in artificial intelligence development and why we have to solve it},
  doi              = {https://doi.org/10.1007/s43681-021-00120-w},
  url              = {https://link.springer.com/article/10.1007/s43681-021-00120-w},
  abstract         = {While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.},
  comment          = {The paper that states the dilemma of the dev - keep job or work to personal ethical standards

AI developers face a social dilemma in AI development ethics - to choose between their job and doing the right thing to do (suggest using medicine as a template for a professional code for AI development ethics)

''a Now: Society's need for ethical conduct and the employer's need to develop products together put the developer into a dilemma, and b after introducing the ethos: what was previously a dilemma for the developer is now a trade-off that society, together with the employer, has to handle using established methods''

AI models can cement or even augment existing discriminatory practices and inequalities
Mass surveillance based on e.g. facial recognition, smart policing and safe city systems are already used by several countries
News feed models used by social media create echo chamber and foster extrmisim
Autonomous weapon systems are in production

Principles are often non-binding and vague and abstract
Developers do not have power to refuse},
  creationdate     = {2022-06-28T17:05:28},
  journal          = {AI Ethics},
  keywords         = {AI, ethics, corporate culture, EthicsWS},
  modificationdate = {2022-12-12T19:46:16},
  owner            = {ISargent},
  year             = {2021},
}

@Article{PattZ2000,
  author           = {Patt, Anthony and Zeckhauser, Richar},
  title            = {Action Bias and Environmental Decisions},
  doi              = {https://doi.org/10.1023/A:1026517309871},
  pages            = {45--72},
  url              = {https://link.springer.com/article/10.1023/A:1026517309871},
  volume           = {21},
  comment          = {It is not always the most rational thing to act. Sometimes more rational would be to not act to prevent environmental deterioration.

This paper lays out action bias model for behaviour and performs as base AB study whereby participants are surveyed to decide between water and air projects and they need to decide whether to allocate money to preserving a clean environment or cleaning up a dirty one. Cleaning one will cause the clean one to deteriorate. Preserving will have no impact on either. Similar study again with a development slated to go ahead on on a marsh or a forest and participant choose to alow it to go ahead or relocate it to the other. This latter experiment showed a definite action bias - towards moving the development - even through moving it would result in the other resource being damaged.

Whilst it may not always provide value to act, this paper suggests that know about this bias can help policy and decision making and be applied for example to giving people an opportunity to particpant because participantion creates value.},
  creationdate     = {2022-06-28T17:14:44},
  journal          = {Journal of Risk and Uncertainty},
  keywords         = {environment, behaviour},
  modificationdate = {2022-06-28T17:36:57},
  owner            = {ISargent},
  year             = {2000},
}

@Article{LevinSBHGG2021,
  author           = {Levin, Roman and Shu, Manli and Borgnia, Eitan and Huang, Furong and Goldblum, Micah and Goldstein, Tom},
  title            = {Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability},
  doi              = {10.48550/ARXIV.2108.01335},
  url              = {https://arxiv.org/abs/2108.01335},
  comment          = {Rather than looking at saliency maps, this paper looks at network parameters that are responsible for erroneous decision.

develop a framework for finding the exact filters
which are responsible for faulty predictions and studying the interactions between these filters and
images

Working with ResNet so could be very repeatable

use gradient information of the loss function as a measure of parameter sensitivity and optimality of the network at a given point in image space

''We find that samples which cause similar parameters to malfunction are semantically similar. We also show that pruning the most salient parameters for a wrongly classified sample often improves model behavior''},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-06-28T17:36:41},
  keywords         = {deep learning, explainability, discovery, saliency},
  modificationdate = {2022-06-28T17:58:47},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2021},
}

@Article{KeislerSGPRW2019,
  author           = {Ryan Keisler and Samuel W. Skillman and Sunny Gonnabathula and Justin Poehnelt and Xander Rudelis and Michael S. Warren},
  title            = {Visual search over billions of aerial and satellite images},
  doi              = {10.1016/j.cviu.2019.07.010},
  pages            = {102790},
  url              = {https://arxiv.org/abs/2002.02624},
  volume           = {187},
  comment          = {The next step after Terrapattern

Two types of imagery: Aerial over USA - National Agriculture Imagery Program (NAIP) and Landsat 8 over Earth

Features used for search initially come from last few layers of pretrained ImageNet ResNet - results good but wanted to improve

Binarise features by injecting noise in training which forces the the weights towards 0 or 1. Than at inference simply threshold at 0.5.

Customise for aerial and satellite data. Training NAIP imagery against OSM classes (as they did for TerraPattern). Great line ``We emphasize that this supervised learning step is not used to produce a network that is good at identifying particular object classes (although it does ultimately do better on these classes), but rather to create a network that produces features that are useful for generic visual search on aerial and satellite imagery'' - sounds like every time we write about Toponet.

For Landsat data used unsupervised approach an autoencoder to compress the 2048 features.

Can use the features for direct search (Hamming distance between query image and others) or hash-based search (a hash of the feature vector).

Future directions look familiar too:
We see three clear future directions for extending the work presented here.
‚Ä¢ Multi-scale search - The current system searches at one spatial scale, namely square images that are 128 pixels across. Instead we would like to enable search over a handful of spatial scales, both smaller and larger than 128 pixels across.
‚Ä¢ Geospatial filtering - The current system searches across all images that have been indexed, regardless of their geographical location. In the future we would like to enable geospatial filtering, e.g. only return results from Japan.
‚Ä¢ Temporal filtering - The current system searches across a single image layer. Although the images within this layer were acquired at different times, that temporal information has not been used in the search. In the future we would like to enable temporal filtering, e.g. only return results that were acquired in May 2018},
  creationdate     = {2022-06-28T20:18:54},
  journal          = {Computer Vision and Image Understanding},
  keywords         = {deep learning, discovery, remote sensing, search},
  modificationdate = {2022-06-28T20:34:01},
  month            = {oct},
  owner            = {ISargent},
  publisher        = {Elsevier {BV}},
  year             = {2019},
}

@Article{RadfordEtAl2021,
  author           = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  title            = {Learning Transferable Visual Models From Natural Language Supervision},
  doi              = {10.48550/ARXIV.2103.00020},
  url              = {https://arxiv.org/abs/2103.00020},
  comment          = {The CLIP paper

Rather than training image encoder and text encoder so that the correct label for the image is predicted, this approach trains the two encoders such that the correct label is paired with the image. At test time, the leaned text encoder synthesizes a zero-shot linear classifier by embedding the names or descriptions of the target dataset's classes.

Contrastive objective is more efficient than label prediction. Also, they find that the resulting models are more flexible and can be turned to fine-grained object classification, geo-localisation, action recognition in videos and OCR. 

CLIP does struggle on more abstract or systemmatic taksks such as prediction how close the nearest car is in an image, and has poor generalisation to images not covered intraining.

See also blog post:  \url{https://openai.com/blog/clip/}

Application in remote sensing:  \url{https://huggingface.co/blog/fine-tune-clip-rsicd}},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-06-29T10:12:06},
  keywords         = {deep learning, training, natural language processing, imagery},
  modificationdate = {2022-06-29T14:25:29},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2021},
}

@Report{HouseOfLordsBeyondDigital2021,
  author           = {{Baroness Lane-Fox of Soho (Chair)} and {Lord Alderdice} and {Lord Harris of Haringey} and {Baroness Benjamin} and {Baroness Jay of Paddington} and {Baroness Chisholm of Owlpen} and {Lord Duncan of Springbank} and {Baroness Morgan of Cotes} and {Lord Elder} and {Lord Pickles} and {Lord Hain} and {Baroness Young of Hornsey}},
  date             = {2021-04-21},
  institution      = {House of Lords, COVID-19 Committee},
  title            = {Beyond Digital: Planning for a Hybrid World},
  type             = {Inquiry},
  subtitle         = {1st Report of Session 2019-21},
  url              = {https://publications.parliament.uk/pa/ld5801/ldselect/ldcvd19/263/26302.htm},
  comment          = {Report on the inquiry into how a rapidly increasing reliance on digital technology, accelerated by the pandemic, may have a long-term impact on our social and economic wellbeing.

the UK Government's commitment to developing a new Digital Strategy, must go far beyond the traditional silo of `digital' and recognise that all aspects of our lives are, and will increasingly be, a hybrid blend of online and offline interactions.

Without urgent Government action we risk:
‚Ä¢ services being digitalised, sometime badly, for cost-saving reasons, without understanding the impact on those who use them;
‚Ä¢ people feeling (and being) constantly, electronically, monitored at work, working longer and longer hours, unable to switch off or maintain a separation between work and home;
‚Ä¢ thousands, maybe millions, of jobs being lost to automation with no plan in place to provide the skills and training needed for those affected to move into the new jobs that will be created; and
‚Ä¢ a variety of digital trends and local government funding constraints combining to reduce our opportunities to meet with others. From automated check-out tills, to pub and library closures, homeworking and digital personal trainers, there is a legitimate fear that the digitalisation driven by one pandemic could result in another: a pandemic of loneliness.

The Government should make a careful assessment of the climate change implications of the hybrid world and adopt policies to mitigate any negative impact.

Addressses with details and potential solutions:
‚Ä¢ Digital inequality; e.g. ‚Äú11\% of households do not have internet access‚Äù
‚Ä¢ Skills and training; Digital Skills Gap
‚Ä¢ Data and research; ``unless we have a robust evidence base to help us understand the impact of digitalisation on different communities, and the effectiveness of different digital services and interventions, we will not be able to make the most of the digital future''
‚Ä¢ Co-operation; Working in collaboration ``Communities have a wealth of knowledge about what will work best for their members, and it is by listening to their views and experiences that we can ensure that interventions will have the biggest, and best, impact.''
‚Ä¢ Resilience; regulation and rights; ``any threat to digital infrastructure will threaten our ability to work, access essential services, buy groceries online, and access our money through online banking''
‚Ä¢ Online harms. ``there is an urgent need for comprehensive research to explore the relationship between digital technology and wellbeing, particularly amongst children and young people. This research must go beyond screen time alone, and must also consider the experiences of marginalised and vulnerable young people.''

Also looks at specific issues when digitalising health, education in schools, work (including gig economy), social interaction

''In today's society, home broadband is an essential utility in the same way as water or electricity''},
  creationdate     = {2022-06-29T12:03:48},
  keywords         = {policy, digital, health, work, education, society, economics},
  modificationdate = {2022-11-25T22:42:01},
  owner            = {ISargent},
  relevance        = {relevant},
}

@Article{TayEtAl2022a,
  author           = {Tay, Yi and Tran, Vinh Q. and Dehghani, Mostafa and Ni, Jianmo and Bahri, Dara and Mehta, Harsh and Qin, Zhen and Hui, Kai and Zhao, Zhe and Gupta, Jai and Schuster, Tal and Cohen, William W. and Metzler, Donald},
  title            = {Transformer Memory as a Differentiable Search Index},
  doi              = {10.48550/ARXIV.2202.06991},
  url              = {https://arxiv.org/abs/2202.06991},
  comment          = {Similar to WuRHS2022

Paper from Google

Train network to learn the id of documents (intuition: document id not document class - as many classes as documents). A sequence to sequence task

Don't train with the whole document, but take e.g. the first L tokens, or a randomly sample contiguous set of tokens, or de-duplicated set, or... (the first seems to work best, I think)

id is output as a string

Try generating semantically structured identifiers so that similar documents have similar ids. This is achieved using ?BERT and do hierarchical embeddings to cluster. Don't seem happy with these and suggest looking at alternatives.

Works better with smaller data sets.
Works better with larger models.
Works better for shorter tokenisation of documents (similar to dataset size).
Compare to BM25 which is standard for search

Weights are differentiable so it can be incorporated into another neural model, e.g. in reinforcement learning when an agent needs to store data for later retreival.

See  \url{https://www.youtube.com/watch?app=desktop&v=qlB0TPBQ7YY&feature=youtu.be}},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-06-29T14:25:26},
  keywords         = {deep learning, indexing, search memorisation, natural language processing},
  modificationdate = {2022-06-29T14:50:07},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2022},
}

@InProceedings{Eckert,
  author           = {Eckert, Theodore},
  booktitle        = {2015 IEEE Symposium on Product Compliance Engineering (ISPCE)},
  title            = {The pre-mortem: An alternative method of predicting failure},
  doi              = {10.1109/ISPCE.2015.7138700},
  pages            = {1-4},
  url              = {https://ieeexplore.ieee.org/document/7138700},
  comment          = {The pre-mortem paper

Includes the 5 whys},
  creationdate     = {2022-06-30T10:50:48},
  keywords         = {ethics, health, safety, risk, EthicsWS},
  modificationdate = {2022-07-05T14:19:44},
  owner            = {ISargent},
  year             = {2015},
}

@Online{EthicalOSToolkit2018,
  author           = {{Omidyar Network} and {Institute for the Future}},
  date             = {2018},
  title            = {Ethical OS Toolkit},
  url              = {https://ethicalos.org/},
  comment          = {Launch notification:  \url{https://medium.com/omidyar-network/introducing-the-worlds-first-ethical-operating-system-7acc4abc2bfa}

``toolkit for helping developers and designers anticipate the future impact of technologies they're working on today''},
  copyright        = {CREATIVE COMMONS ATTRIBUTION- NONCOMMERCIAL-SHAREALIKE 4.0 INTERNATIONAL LICENSE (CC BY-NC-SA 4.0)},
  creationdate     = {2022-06-30T10:55:55},
  keywords         = {ethics, EthicsWS},
  modificationdate = {2022-12-10T10:31:51},
  owner            = {ISargent},
}

@Article{Munn2020,
  author           = {Munn, Luke},
  title            = {Angry by design: toxic communication and technical architectures},
  doi              = {https://doi.org/10.1057/s41599-020-00550-7},
  number           = {53},
  url              = {https://www.nature.com/articles/s41599-020-00550-7},
  volume           = {7},
  comment          = {social media that posts that arouse anger are more likely to reach a large audience than those that encourage feelings of contentment. This means that whenever an event occurs ‚Äî even a good one ‚Äî naysayers have a larger megaphone than supporters.},
  creationdate     = {2022-07-05T12:19:02},
  journal          = {Humanities and Social Sciences Communications},
  keywords         = {ethics, social media},
  modificationdate = {2022-07-05T12:22:08},
  owner            = {ISargent},
  year             = {2020},
}

@Online{AnandB2022,
  author           = {Suchith Anand and Kathryn Bailey},
  date             = {2022-05-25},
  title            = {How digital feudalism hurts farmers},
  url              = {https://datavaluesdigest.substack.com/p/how-digital-feudalism-hurts-farmers},
  organization     = {Data Values Digest},
  urldate          = {2022-07-05},
  comment          = {a few powerful actors control access to data and technology, raises important concerns around power imbalances as well as resulting data asymmetries and their impact on society},
  creationdate     = {2022-07-05T12:31:25},
  keywords         = {data, ethics, EthicsWS},
  modificationdate = {2022-07-05T12:34:07},
  owner            = {ISargent},
}


@Article{BalestrieroBL2022,
  author           = {Balestriero, Randall and Bottou, Leon and LeCun, Yann},
  title            = {The Effects of Regularization and Data Augmentation are Class Dependent},
  doi              = {10.48550/ARXIV.2204.03632},
  url              = {https://arxiv.org/abs/2204.03632},
  comment          = {Data augmentation and weight decay may improve overall performance but cause disastrous model performances on some classes.

This could be useful methods for checking the impact of different augmentations or uninformed weight decay.},
  copyright        = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
  creationdate     = {2022-07-18T10:46:13},
  keywords         = {deep learning, augmentation, generalisation},
  modificationdate = {2022-07-18T10:53:36},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2022},
}

@Article{KempXDEGKRSSSL2022,
  author           = {Luke Kemp and Chi Xu and Joanna Depledge and Kristie L. Ebi and Goodwin Gibbins and Timothy A. Kohler and Johan Rockstr\''{o}m and Marten Scheffer and Hans Joachim Schellnhuber and Will Steffen and Timothy M. Lenton},
  date             = {2022-03-25},
  journaltitle     = {PNAS},
  title            = {Climate Endgame: Exploring catastrophic climate change scenarios},
  doi              = {10.1073/pnas.2108146119},
  eprint           = {https://www.pnas.org/doi/pdf/10.1073/pnas.2108146119},
  number           = {34},
  pages            = {e2108146119},
  url              = {https://www.pnas.org/doi/abs/10.1073/pnas.2108146119},
  volume           = {119},
  abstract         = {Prudent risk management requires consideration of bad-to-worst-case scenarios. Yet, for climate change, such potential futures are poorly understood. Could anthropogenic climate change result in worldwide societal collapse or even eventual human extinction? At present, this is a dangerously underexplored topic. Yet there are ample reasons to suspect that climate change could result in a global catastrophe. Analyzing the mechanisms for these extreme consequences could help galvanize action, improve resilience, and inform policy, including emergency responses. We outline current knowledge about the likelihood of extreme climate change, discuss why understanding bad-to-worst cases is vital, articulate reasons for concern about catastrophic outcomes, define key terms, and put forward a research agenda. The proposed agenda covers four main questions: 1) What is the potential for climate change to drive mass extinction events? 2) What are the mechanisms that could result in human mass mortality and morbidity? 3) What are human societies' vulnerabilities to climate-triggered risk cascades, such as from conflict, political instability, and systemic financial risk? 4) How can these multiple strands of evidence‚Äîtogether with other global dangers‚Äîbe usefully synthesized into an ‚Äúintegrated catastrophe assessment‚Äù? It is time for the scientific community to grapple with the challenge of better understanding catastrophic climate change.},
  comment          = {''risk of human extinction `dangerously underexplored''

``Understanding catastrophic climate scenarios can also inform policy interventions''},
  creationdate     = {2022-08-02T13:57:31},
  journal          = {Proceedings of the National Academy of Sciences},
  keywords         = {climate, future realism},
  modificationdate = {2022-12-03T19:17:29},
  owner            = {ISargent},
  year             = {2022},
}

@Article{HESS2022100663,
  author           = {Ann-Kathrin Hess},
  date             = {2022},
  journaltitle     = {Transportation Research Interdisciplinary Perspectives},
  title            = {The relationship between car shedding and subjective well-being},
  doi              = {https://doi.org/10.1016/j.trip.2022.100663},
  issn             = {2590-1982},
  pages            = {100663},
  url              = {https://www.sciencedirect.com/science/article/pii/S2590198222001233},
  volume           = {15},
  abstract         = {The sufficiency strategy for sustainable development aims to reduce energy and resource consumption beyond technological modifications. One way to do this is to forgo ownership of certain consumer goods, such as cars. Although proponents of sufficiency claim that car shedding (i.e., giving away a vehicle so that the household no longer has its own car) might increase subjective well-being (SWB), there is little empirical evidence supporting this. This paper aims to help fill this gap by adding empirical evidence on the relationship between car shedding and SWB. Data from the Swiss Household Panel is used (2006-2017) with a fixed-effects model assessing the year-to-year changes in evaluative and affective well-being (life satisfaction, leisure satisfaction, joy, and anger) before and after car shedding. Separate analyses for non-affordability-driven and affordability-driven car shedders were conducted. Results show that non-affordability-driven car shedding has a positive effect on feelings of joy one to three years after the event. Affordability-driven car shedding, in contrast, is associated with a decrease in leisure satisfaction and feelings of joy up to three years later. Levels of positive affective wellbeing already decrease in anticipation of affordability-driven car shedding. A sufficiency measure like non-affordability-driven car shedding is not associated with reducing SWB, and this may have policy implications.},
  creationdate     = {2022-08-08T11:02:29},
  keywords         = {transport, environment, social science, car shedding, subjective well-being},
  modificationdate = {2022-08-08T11:03:12},
  owner            = {ISargent},
}

@Article{WortsmanEtAl2022,
  author           = {Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Yitzhak and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S. and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and Schmidt, Ludwig},
  title            = {Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  doi              = {10.48550/ARXIV.2203.05482},
  url              = {https://arxiv.org/abs/2203.05482},
  comment          = {Look at fine-tuning models. Standard approach is to perform a search across models trained with different hyperparamters and select the model with the best validation accuracy, or use all to create an ensemble. This paper finds that an average of the weights across the hyperparamters is almost as good as the ensemble and doesn't require as much memory. Averaging can can be as a single hit or it can be 'greedy'. The latter averages the master weights with a new model's weights and retains this average as the master model if the validation accuracy improves (discards it overwise). This second method results in slightly better results and also strikes me as an excellent option for retuning Toponet as new data become available. They test it on CLIP among others.},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-08-23T12:50:56},
  keywords         = {deep learning, transfer learning, fine tuning},
  modificationdate = {2022-10-05T19:04:52},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2022},
}

@Book{Mazzucato2013,
  author           = {Mariana Mazzucato},
  date             = {2013},
  title            = {The Entrepreneurial State},
  edition          = {3rd},
  subtitle         = {Debunking Public vs Private Sector Myths},
  comment          = {Common themes:
Socialise the risks - and the rewards
Patient capital



Keynes 1926 ``The End of Laissez Faire'' Encouraged policy makers to think big and to not do what individuals are doing p2

Components of a system of innovation: 
Feedback loops between markets and technology, applications and science
In linear view R\&D -> innovation
In non-linear view, education, training, design , quality control and effective demand are just as important p43

Vallas, Kleinman and Biscotti, 2009 point out that industry leaders simultaneously advocate government intervention to foster [technology] and argue ``hypocritically'' that government should let the market be free p74

DARPA model is used as a positive example of entrepreneurial state. Block 2008 identifies characteristics of this model:
	- Relatively small offices with budget autonomy permitted to proactive
	- Funding goes to heterogeneous groups (universities, startups, firms, consortia) without distinction between basic and applied research
	- Mandate includes helping firms get products to stage of commercial viability
	- Part of role is linking ideas, resources and people in constructive ways
P84-5

Use the iPhone (and Apple more generally) to illustrate how technological transformations are dependent on government investment in R\&D chapter 5

Use clean tech as example of how different governments are driving innovation. China and Germany both have coherent policy frameworks around clean technology both by driving demand and supply. In contrast, US, UK and other ``European Laggards'' are ``deploying patchy strategies'' without clear direction or long-term incentives p124

The ``death valley'' stage is the bit between successful proof of concept and full testing and approval and is often the stage at which firms (and ideas?) die. Brazil has been financing biotechnology firms past this stage p131

China has formally incorporated mitigating climate change into it economic strategy. Its green development strategy recognises that that future competitive advantage depends on effective resource management and it plans make ``profit'' and ``environment'' complementary pursuits. Generally p132 makes some really interesting points about China

In contrast UK's approach is ``stop-start'', established programmes have had funding cut and policies especially around technologies such as CCS are ``misguided'' p133

UK approach is based on notion that all is needed is a ``nudge'' from the state, but no other technological revolution has succeeded this way p134

As a result the UK is falling behind in green tech after being one of the countries that was catching up p135

Assumption is that venture capitalists are the risk-takers providing funding to generate innovation. But they have been shown to be risk-averse and operate to return on their investment in short term which is incompatible with transformative innovation. ``If VCs aren't interested in capital-intensive industries, or in building factories what exactly are the offering in terms of economic development? Their role should be seen for what it is: limited'' p141

ARPA-E tries to emulate DARPA's idea that it always expects and tolerates failure p144

ARPA-E's mission statement says that ``scientists are free to explore energy innovation without the expectation that all ideas will work or produce immediate commercial value, which fills the research gap created by business interests too risk averse to invest in the energy technologies of tomorrow given the uncertainties of today'' p145

Government funded R\&D in US massively reduced the cost of wind energy due to a range of discoveries and innovations. Then the withdrawal of funding caused the domestic market to stagnate and momentum for the industry moved to Germany p161

''Parasitic innovation'' p167

''Clean technology is already teaching us that changing the world requires coordination and the investment of multiple States: otherwise R\&D, support for manufacturing and support for market creation and function remain dead ends while the Earth literally suffocates on the industries we built a century ago'' p168

The challenges for new technologies are often political or social, seldom technical:
Commitment from patient capital, nurturing risky new industries, support for deployment that requires transition away from industry which has sunk costs (and is thus in the short term cheaper) p173

The cumulative innovation curve and that VCs are able to capture the value not only of their investment but also in the state investment in the work that has gone before meaning their return is out of proportion with their investment p182

An MIT study found that long-term basic and applied research not part of big business any more leading to large holes in the [US] industrial ecosystem (that presumably will mean that future innovation will not have the same innovation as that based on past research from R\&D centres like Bell Labs, Xerox PARC and Alcoa Research Lab p193

The financial sector is a parasitic drain on the economy, its share of the profits outstripping those of the real economy - and GDP counts their interest rates as a service (its rent) and the risk is assumed by the state because it is ``too big to fail''. In other sectors there are similar disfunctions - in life sciences the riskiest research is undertaken by the state but then big pharma cashes in on the outputs. In clean technology, wind and solar struggle to gain a foothold yet the executives and shareholders reap millions in returns underwritten by the state. Further, those benefitting, e.g. Apple, pay barely any tax that could fund future technological development. p196

Elements required to build an entrepreneurial state:
	- Golden share of IPR to the state and a national innovation fund meaning that innovation can be fairly and broadly shared (with the first mover still able to recover costs)
	- Income-contingent loans and equity that bring back value to the state from success innovations - socialise the rewards
	- Development banks have been shown e.g. in Germany, Brazil and China with a remit to invest and to draw back in value for the next round of investment p203-5},
  creationdate     = {2022-09-05T18:49:29},
  keywords         = {economics, innovation},
  modificationdate = {2022-10-23T11:10:39},
  owner            = {ISargent},
}

@Article{HickelOFZ2022,
  author           = {Jason Hickel and Daniel W O'Neill and Andrew L Fanning and Huzaifa Zoomkawala},
  date             = {2022},
  journaltitle     = {The Lancet Planetary Health},
  title            = {National responsibility for ecological breakdown: a fair-shares assessment of resource use, 1970-2017},
  doi              = {https://doi.org/10.1016/S2542-5196(22)00044-4},
  issn             = {2542-5196},
  number           = {4},
  pages            = {e342-e349},
  url              = {https://www.sciencedirect.com/science/article/pii/S2542519622000444},
  volume           = {6},
  abstract         = {Summary
Background
Human impacts on earth-system processes are overshooting several planetary boundaries, driving a crisis of ecological breakdown. This crisis is being caused in large part by global resource extraction, which has increased dramatically over the past half century. We propose a novel method for quantifying national responsibility for ecological breakdown by assessing nations' cumulative material use in excess of equitable and sustainable boundaries.
Methods
For this analysis, we derived national fair shares of a sustainable resource corridor. These fair shares were then subtracted from countries' actual resource use to determine the extent to which each country has overshot its fair share over the period 1970-2017. Through this approach, each country's share of responsibility for global excess resource use was calculated.
Findings
High-income nations are responsible for 74\% of global excess material use, driven primarily by the USA (27\%) and the EU-28 high-income countries (25\%). China is responsible for 15\% of global excess material use, and the rest of the Global South (ie, the low-income and middle-income countries of Latin America and the Caribbean, Africa, the Middle East, and Asia) is responsible for only 8\%. Overshoot in higher-income nations is driven disproportionately by the use of abiotic materials, whereas in lower-income nations it is driven disproportionately by the use of biomass.
Interpretation
These results show that high-income nations are the primary drivers of global ecological breakdown and they need to urgently reduce their resource use to fair and sustainable levels. Achieving sufficient reductions will likely require high-income nations to adopt transformative post-growth and degrowth approaches.
Funding
None.},
  comment          = {https://twitter.com/jasonhickel/status/1511980434070163459},
  creationdate     = {2022-09-15T08:36:50},
  keywords         = {climate, future realism},
  modificationdate = {2022-10-05T19:05:58},
  owner            = {ISargent},
}

@Article{AliJXW2019,
  author           = {Ali, Mohammed and Jones, Mark W. and Xie, Xianghua and Williams, Mark},
  date             = {2019/06/01},
  title            = {TimeCluster: dimension reduction applied to temporal data for visual analytics},
  doi              = {10.1007/s00371-019-01673-y},
  issue            = {6},
  pages            = {1432--2315},
  url              = {https://doi.org/10.1007/s00371-019-01673-y},
  volume           = {35},
  abstract         = {There is a need for solutions which assist users to understand long time-series data by observing its changes over time, finding repeated patterns, detecting outliers, and effectively labeling data instances. Although these tasks are quite distinct and are usually tackled separately, we present an interactive visual analytics system and approach that can address these issues in a single system. It enables users to visualize, understand and explore univariate or multivariate long time-series data in one image using a connected scatter plot. It supports interactive analysis and exploration for pattern discovery and outlier detection. Different dimensionality reduction techniques are used and compared in our system. Because of its power of extracting features, deep learning is used for multivariate time-series along with 2D reduction techniques for rapid and easy interpretation and interaction with large amount of time-series data. We deploy our system with different time-series datasets and report two real-world case studies that are used to evaluate our system.},
  comment          = {Interactive method of visualising time-series in 2D ``we introduce the option to switch between different dimensionality reduction techniques (t-SNE, UMAP and PCA) and also deep convolutional auto-encoder (DCAE).''},
  creationdate     = {2022-10-01T17:16:21},
  journal          = {The Visual Computer},
  keywords         = {visualisation, data, time series},
  modificationdate = {2022-10-05T19:03:23},
  owner            = {ISargent},
  year             = {2019},
}

@Article{Martin2012,
  author           = {Ben R. Martin},
  date             = {2012},
  journaltitle     = {Research Policy},
  title            = {The evolution of science policy and innovation studies},
  doi              = {https://doi.org/10.1016/j.respol.2012.03.012},
  issn             = {0048-7333},
  note             = {Exploring the Emerging Knowledge Base of 'The Knowledge Society'},
  number           = {7},
  pages            = {1219-1239},
  url              = {https://www.sciencedirect.com/science/article/pii/S004873331200073X},
  volume           = {41},
  abstract         = {This article examines the origins and evolution of the field of science policy and innovation studies (SPIS). Like other studies in this Special Issue, it seeks to systematically identify the key intellectual developments in the field over the last 50 years by analysing the publications that have been highly cited by other researchers. The analysis reveals how the emerging field of SPIS drew upon a growing range of disciplines in the late 1950s and 1960s, and how the relationship with these disciplines evolved over time. Around the mid-1980s, substantial parts of SPIS started to coalesce into a more coherent field centred on the adoption of an evolutionary (or neo-Schumpeterian) economics framework, an interactive model of the innovation process, and (a little later) the concept of `systems of innovation' and the resource-based view of the firm. The article concludes with a discussion of whether SPIS is perhaps in the early stages of becoming a discipline.},
  comment          = {Attempt to detemine the most influential works in the field of science policy and innovation studies (SPIS). Field is about 50 years old. ``First large scale quantitative study'' treat books on equal basis to articles.

SPIS definition from the Research Policy journal: ``devoted to analyzing, understanding and effectively responding to the economic, policy, management, organizational, environmental and other challenges posed by innovation, technology, R\&D and science. This includes a number of related activities concerned with the creation of knowledge (through research), the diffusion and acquisition of knowledge (e.g. through organizational learning), and its exploitation in the form of new or improved products, processes or services''

''characterised by the terms innovation, technology, R\&D and science, is studied using a range of social science disciplines (economics and economic history, policy studies, management science, organisational studies, sociology''

economics, economic history and business history, policy, management (including new product management), organsiational studies, sociology of innovation - especially diffusion but less sociology of science and technology because this comes more under science and technology studies (STS).

SPIS is possibly a discipline in its own right (p1237) to the point that it is now rare to have articles written by people in industry. [iz: is this good?]

Go into detail on the pros and cons of their method (p1222)

Using these quatitative measures of impact, this paper says that despite being a ``relatively new and still quite small field'' it has make a ``significant number of adances comparable in impact [to] economics'' p1222

Should return to for very short summaries of key papers, developments and authors in the field. 

Idea of ``science push'' linear model of innovation which arose from Vannevar Bush's influential [1945] science policy report to the US Government entitled Science the Endless Frontier.

Schmookler 1966 ``Invention and economics growth is credited with the demand-pull model'' of innovation.

''Kline and Rosenberg [1986] ... effectively ended the `science-push' versus `demand-pull' debate ... argued that one needed to move beyond simple linear models and instead put forward an interactive `chain-linked' model of the innovation process''

Nelson and Arrow on economics of research.

''Knowledge industry'' including patents and much more from Machlup which became known as knowledge economy.

Heller and eisenburg [1998] Patents can give rise to 'anti-commons' because they deter innovation.

Vernon 1966 Product-cycle theory of trade, four stage model of the product cycle in which new goods are developed in industrialised countries and spread to developing countries.

Organisational learning, learning organisation, intelligent enterprise - ideas developed around firms that are able to develop and apply innovations.

Organisational psychology has contributed work around stimulation of the productivity of researchers ``autonomy, interaction with colleagues, the balance between pure and applied research, and some degree of tension between personal and organisational goals''.

''early 1980s witnessed the emergence of what has gradually become for many a common conceptual framework based around evolutionary economics, the interactive model of the innovation process, and, a little later, the notion of `systems of innovation' and the resource-based view of the firm''

''Kanter [1983], ... demonstrated how overly `segmentalist' management could create barriers to innovation, contrasting this with a more integrative style of management which is likely to result in productivity improvement and innovation''.

''Drucker [1985] focused on Innovation and Entrepreneurship, arguing that entrepreneurship is not a specialist talent of a few gifted individuals but is pervasive in a healthy society, not just in the private sector but also in public service organisations. He also warned against infatuation with new technology-based innovation to the detriment of often more important social innovations''. Later (1993) ``argued that we are witnessing the emergence of `post-capitalist society', in which the primary resource for creating wealth is knowledge''.

''Piore and Sabel {1984}, who argued that capitalism had reached a turning-point, where it has to choose between two alternatives - to continue along the existing trajectory of mass-production technology (the course chosen at the first `industrial divide'), or to switch towards craft-based production and exploiting computer technology to make possible `flexible specialisation', thus creating an environment in which firms compete on the basis of innovations but cooperate with regard to developing the necessary technological knowledge and skills.''

''resource-based view of the firm as an alternative to the transaction-cost theory of the firm''. ```in-house knowledge of technology' as one of a firm's key resources''

Related to systems of innovation: Etzkowitz and Leydesdorff 2000 triple helix: universities, industry and government. Universities were initially for teaching, then `first academic revolution' they took on the function of research in the 19th Century, now 'second academic revolution' when taking on `third mission' of contributing to the economy and society. [izz: each revolution has downplayed the importance of those earlier roles].

Gibbons et al [1994] knowledge production can be Mode 1 - universal theories, basic research - and Mode 2 - applications. [Iz: debate about which came first, in fact]

Some of this has come out of particular institutions, e.g. SPRU (and Project SAPPHO), PREST at Manchester University, Centre for Policy Alternatives at MIT, Harvard. The list of highly cited publications is heavily dominated by US-based authors although this papers suggests a range of reason why they may be.

In many ways, this history is summarised in Martin2016},
  creationdate     = {2022-10-04T11:45:12},
  keywords         = {economics, innovation},
  modificationdate = {2022-10-23T12:38:31},
  owner            = {ISargent},
}

@Article{Martin2016,
  author           = {Martin, Ben R.},
  title            = {{Twenty challenges for innovation studies}},
  doi              = {10.1093/scipol/scv077},
  eprint           = {https://academic.oup.com/spp/article-pdf/43/3/432/7573255/scv077.pdf},
  issn             = {0302-3427},
  number           = {3},
  pages            = {432-450},
  url              = {https://doi.org/10.1093/scipol/scv077},
  volume           = {43},
  abstract         = {{With the field of innovation studies (IS) now half a century old, the occasion has been marked by several studies looking back to identify the main advances made over its lifetime. Starting from a list of 20 advances over the field's history, this discussion paper sets out 20 challenges for coming decades. The intention is to prompt a debate within the IS community on what are, or should be, the key challenges, and more generally on what sort of field we aspire to be. It is argued that the empirical focus of our studies has failed to keep pace with the fast changing world, especially the shift from manufacturing to services and the increasingly urgent need for sustainability. The way we conceptualise, define, operationalise and analyse `innovation' seems somewhat rooted in the past, leaving us less able to grapple with other less visible or `dark' forms of innovation.}},
  comment          = {What was science policy and innovation studies (SPIS) is possibly now just innovation studies (IS). 

this papers looks at what IS should be doing, such as considering the direction of innovation and not just assuming that all innovation and good.



Twenty challenges for innovation studies

1 	From visible innovation to `dark innovation' 
Innovation may not just be technology and manufacturing, other innovation exists but this is perhaps hidden or 'dark'. explains this with imprinting theory - that institutions have values and norms based on their formation and so technology and manufacturing would have been the focus for IS several decades ago. this focus is probably also reflected in the measures of innovation activity. 

Schumpeter had a broader perspective on innovation,  whilst still using manufacturing temrs he was not restricted to product or process innovations.

Other innovations may be in organisations, incremental process innovations in factories, services, social (social media), grassroots. Also 'salami publishing' cutting a piece of work into smaller parts to publish separately. Self- plagarism or worse not referencing the other works.

2 	From innovation in manufacturing to innovation in services 

3 	From `boy's toys' to the liberation of `housewives' 
Interesting table, reflects interests of researchers rather than breadth of innovation?

4 	From national and regional to global systems of innovation 
The challenge to IS researchers is to identify, map and analyse these global systems of innovation and their interactions with national and regional systems ( Lundvall 2007 ; Soete et al. 2010 )

5 	From innovation for economic productivity to innovation for sustainability (`green innovation') 
''‚Ä¶ innovation is a vector, rather than just a scalar quantity. ( Stirling 2008 : 263)''
''The 1990s saw increasing concern with environmental damage, the using up of scarce resources, and global warming. ... was regarded as rather `flaky' by some in IS, although it is now having a significant impact (e.g. Geels 2002 )''

6 	From innovation for economic growth to innovation for sustainable development (from Lundvall)
The challenge for IS scholars is to respond to the pressing world need for more equitable development, working with others on development studies and sustainability

7 	From risky innovation to socially responsible innovation 
''damage to the environment, less desirable working conditions or other adverse effects on the quality of life'' - questions whether the risk is higher or if awareness is greater and argues for more participatory approaches to decision-making, constructive technology assessment, consensus conferences or citizens juries

8 	From innovation for wealth creation to innovation for wellbeing (or from `more is better' to `enough is enough') 
Shift the focus from m-wealth to r-wealth

9 	From `winner take all' to `fairness for all'? 
''as innovation has become more collective and `open', the rewards have become increasingly individualised'' Mazzucato etc 
''wider belief that extreme wealth for a few individuals is a necessary facet of free-market capitalism''
Questions whether IS should be passive and just observe or in fact have a duty to explore how greater fairness could be achieved.

10 	From government as fixer of failures to the entrepreneurial state 
From Mazzucato
Many Nobel prizes to those who've claimed to prove that gov intervention causes innefficiencies. Much like innovation, maybe innovation policy need to be more experimental.

11 	From faith-based policy (and policy-based evidence) to evidence-based policy?
from Steinmueller
Policy makers tend to be politically wedded to a particular policy and don't draw on evidence . Difficult to build evidence as double-blind policy trials are difficult/impossible.
 
12 	Balancing the intrinsic tensions between intellectual property and open source 
highlights difference between pharmaceuticals in which patenting is apparently a big incentive to innovation, whereas in open sourcing software seems to be an incentive

13 	Balancing the intrinsic tensions between exploration and exploitation 
some organisations do both well, others do one or the other, what conditions are required for each?

14 	Balancing the intrinsic tensions between closed and open innovation 
Absortive capacity of organisation to take in innovation and new ideas. Open innovation has been used as a reason to remove R\&D capacity (someone else will do it) - but this couuld reduce absorptive capacity.

15 	Balancing the intrinsic tensions between competition and cooperation 

16 	Pricking academic bubbles 
Even academics have a tendancy to follow trends and also competition for scarce funding can encourage the raising of expectations. Also may be danger of being uncritical of Schumpeter (Iz: and Mazzucato?)? 

17 	Identifying the causes of the current economic crisis 
''Financial innovations such as sub-prime mortgages, collateralised debt obligations and credit default swaps all played a central role in creating the crisis, giving rise to a process of `destructive creation' ( Soete 2013 ).'' ``Here, it is not so much that IS researchers contributed to these financial innovations. Rather, it is that we almost completely failed to provide any analysis and understanding of them, or to offer any warnings'' (except Nightingale et al''

18 	Avoiding disciplinary sclerosis 
Intellectual in-breeding, less adventurous, more theory-driven less policy-driven, 

19 	Helping to generate a new paradigm for economics: from Ptolemaic economics to??? 
''Like Dosi (2011) , I sense that economics today is eerily reminiscent of Ptolemaic astronomy with its complicated epicycles'' ``If there is to be any chance of success, the IS community will need to join forces with newer and more sympathetic subfields of economics such as behavioural economics, experimental economics and ecological economics''

20 	Maintaining our research integrity, sense of morality and collegiality
self-policing in other areas (parliament, journalism, ...) has been shown to be ineffective. When there's competition for resources, signs of integrity and social capital eroding.

See also https://www.youtube.com/watch?v=w926VBnsO3w},
  creationdate     = {2022-10-04T14:42:51},
  journal          = {Science and Public Policy},
  keywords         = {economics, innovation},
  modificationdate = {2023-02-03T20:40:34},
  month            = {04},
  owner            = {ISargent},
  year             = {2016},
}

@Article{TouvronCJ2022,
  author           = {Hugo Touvron and Matthieu Cord and Herv√© J√©gou},
  title            = {DeiT III: Revenge of the ViT},
  eprint           = {2204.07118},
  url              = {https://arxiv.org/abs/2204.07118},
  archiveprefix    = {arXiv},
  comment          = {My take from reading The Batch and skimming the article:
 
This paper looks at (supervised) training of ViTs more efficiently and identifies some methods (using ImageNet, so not sure how applicable it would be to RS data for instance). 
	
Pre-training with lower resolution images is faster and can result in better classification outcomes
	
Training examples also had random cropping - a square that likely to retain the image's subject taken from the low res image (this was enough because they had squillions of images)
	
By using very strong colour transforms of the data and believe this encouraged the ViT, which is apparently less sensitive to object outlines than CNNs, to focus more on shapes
	
Stochastic depth regularisation skipped layers randomly and so forced individuals layers to play a greater role
	
LayerScale uses learnable scaling parameter for the layers which effectively allows the network to accumulate more layers as it learns},
  creationdate     = {2022-10-05T17:04:09},
  keywords         = {vision transformers, efficent, training},
  modificationdate = {2022-10-05T17:07:48},
  owner            = {ISargent},
  primaryclass     = {cs.CV},
  year             = {2022},
}

@Article{LambEtAl2020,
  author           = {Lamb, William F. and Mattioli, Giulio and Levi, Sebastian and Roberts, J. Timmons and Capstick, Stuart and Creutzig, Felix and Minx, Jan C. and M√ºller-Hansen, Finn and Culhane, Trevor and Steinberger, Julia K. and et al.},
  title            = {Discourses of climate delay},
  doi              = {10.1017/sus.2020.13},
  volume           = {3},
  comment          = {Redirect responsibility:
- Whatboutism
- Individualism
- The 'free rider' excuse
Push non-transformative solutions:
- Technological optimism
- All talk, little action
- Fossil fuel solutionism
- No sticks, just carrots
Emphasise the downsides:
- Policy perfectionism
- Appeal to social justice
- Appeal to well-being
Surrender:
- Change is impossible
- Doomism},
  creationdate     = {2022-10-05T18:18:33},
  journal          = {Global Sustainability},
  keywords         = {climate, sociology},
  modificationdate = {2022-10-05T19:02:56},
  owner            = {ISargent},
  publisher        = {Cambridge University Press},
  year             = {2020},
}

@InBook{RandallH2019,
  author           = {Randall, Rosemary and Hoggett, Paul},
  booktitle        = {Climate Psychology: On Indifference to Disaster},
  title            = {Engaging with Climate Change: Comparing the Cultures of Science and Activism},
  doi              = {10.1007/978-3-030-11741-2_12},
  editor           = {Hoggett, Paul},
  isbn             = {978-3-030-11741-2},
  pages            = {239--261},
  publisher        = {Springer International Publishing},
  url              = {https://doi.org/10.1007/978-3-030-11741-2_12},
  abstract         = {This chapter reports on interviews with climate scientists and activists, two groups who face the disturbing reality of climate change on a regular basis. The contrasting cultures of science and activism, one institutional and the other informal, had considerable influence over the way in which they dealt with the emotional and ethical challenges of their work. Evidence suggested scientists resorted to social defences such as hyper-rationality, whereas activists adopted a more reflexive and literate approach. This had some dysfunctional consequences for scientists, encouraging abstraction, caution and isolation.},
  address          = {Cham},
  comment          = {Study looking at the emotional responses to climate change knowledge on two groups environmnetal activists and climate scientists.

Activists trajectory: epiphany, immersion, crisis, resolution
Scientists had much more varying experiences and were also more reticent about talking about it. However, during the study it was realised that the group was a minority that were actually involved in public communication. This left them dealing with confusion of public indifference and attacked from the press.

Activists seem to have built a supportive culture (except possibly at larger NGOs) and were more emotionally literate.
Scientists could use focus of the work itself, discovery and immersion to protect, to some degree.},
  creationdate     = {2022-10-05T18:32:01},
  keywords         = {climate, environment, psychology},
  modificationdate = {2022-10-05T19:06:11},
  owner            = {ISargent},
  year             = {2019},
}

@TechReport{KattelMRS2018,
  author           = {Rainer Kattel and Mariana Mazzucato and Josh Ryan-Collins and Simon Sharpe},
  date             = {2018-07-01},
  institution      = {UCL Institute for Innovation and Public Purpose},
  title            = {The economics of change: Policy and appraisal for missions, market shaping and public purpose},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/publications/2018/jul/economics-change-policy-and-appraisal-missions-market-shaping-and-public},
  comment          = {''argue that market-shaping, `mission-oriented' policies should be evaluated on three levels: enhancing user experience and engagement; expanding technological frontiers; and broader macroeconomic multiplier effects. To do this, governments need to embrace and experiment with new tools and methodologies focused on user needs and dynamic - rather than allocative - efficiency. These include techniques from service design research that focuses on user experience and co-creation practice; and strands of evolutionary economics that focus on shifting and shaping technology and innovation frontiers and managing complex systems under conditions of uncertainty.''

Nice description of market-fixing reasoning and goes on to explain how this ``dominant analytical framework and its tool is not fit for purpose'' (because major challenges cannot be reduced to 'externalities' or 'public goods'.

Growth has a direction as well as a rate (see also Entrepreneurial state or Mission Economy?)

Regarding innovation 'top-down' can stifle innovation while 'bottom up' ``can make it dispersieve with little impact''.

How can public value be understood - small discussion of participatory evaluation, opinion polls. stakeholder workshops, citizen's juries. Others have tried to determine a monetary value e.g. contingent valuation.

How Government Digital Service was so successful - Mike Bracken threw out efficiency targets and brought in user-focussed KPIs.

The public value of the BBC is not just the niche aspects that other broadcasters would not produce, but also the more commercial offerings - rather than crowding out other broadcasters but supports innovation in these areas and also thus reaches a wider audience with all its output

Constraining state budgets so that spending is balanced by tax etc. neglects the important aspect of state spending that encourages growth

Discussion of the weaknesses of cost-benefit analysis, even social cost-benefit analysis, which are very short term in their outlook because they compare to status quo

Go on to suggest frameworks and principles applied to policy evaluation, such as systems thinking and systems dynamics which are more appropriate for complex, dynamic systems.

Core characteristics of complex systems:
- Hetergeneous agents
- Fundamental uncertainty
- Path dependence
- Disproportionality of cause and effect
- Emergence
- Absence of optimatlity

Real-time data, progress against milestones, measreus of cross-sectoral and cross-science impact, 

accept tension between top-down and bottom-up!

Deleidi studies demonstrated a larger multiplier affect with mission-oriented innovation

''Dynamic efficiency involves making the best use of resources
to achieve changes over time and so is concerned with innovation, investment, improvement and growth - including, perhaps most importantly, the creation of new resources (technologies) and shifting technology frontiers (Huerta de Soto 2009).''},
  creationdate     = {2022-10-05T19:06:09},
  keywords         = {economics, policy, missions},
  modificationdate = {2023-01-15T14:59:01},
  owner            = {ISargent},
}

@Book{Foster2015,
  author           = {John Foster},
  date             = {2015},
  title            = {After Sustainability},
  subtitle         = {Denial, Hope, Retrieval},
  url              = {https://www.routledge.com/After-Sustainability-Denial-Hope-Retrieval/Foster/p/book/9780415706407},
  comment          = {Foster's earlier book ``The Sustainability Mirage'' critiqued ``sustainability'' and, I understand was generally critical. It didn't offer what should be done once the paradigm of ``sustainability'' as he understood it had been dropped. This book, he says, addresses that issue.

I've read only the preface and prologue. I understand from these that the book is founded on a ``vicious syllogism'' with the four premises and conclusion:
1. if we don't keep below 2.0 degrees, we're in for dangerous, unpredictable, potentially catastrophic climate change
2. If we don't limit global emissions to 1,300 bn tonnes CO2e, we shall not stay below 2.0 degrees
3. If we haven't already minimally embarked on limiting emissions we will not limit them to 1,300 bn tonnes
4. We have not now even minimally embarked on such a programme
- Conclusion: We are in for dangerous, unpredictable and potentially catastrophic climate change

Each COP seems to be a ``last chance'' - global alarm clock on snooze - we are still not admitting that destructive climate change is coming. He makes the point is that denial is also something that ``the good guys''.

Argues that progress is over. Letting go has four themes:
Tragedy, not problem
Now, not the future
Wildness, not well-being
Hope, not optimism

Strikes me as rather akin to Deep Adaptation Bendell2018},
  creationdate     = {2022-10-07T13:31:56},
  keywords         = {climate, sustainability, future},
  modificationdate = {2022-11-25T21:34:16},
  owner            = {ISargent},
}

@Article{HinnefeldCMD2018,
  author           = {J. Henry Hinnefeld and Peter Cooman and Nat Mammo and Rupert Deese},
  title            = {Evaluating Fairness Metrics in the Presence of Dataset Bias},
  eprint           = {1809.09245},
  url              = {https://arxiv.org/abs/1809.09245},
  archiveprefix    = {arXiv},
  comment          = {Can bias in models, caused by bias in the data, be detected.

Starting with data containing (legitimate) imbalance in both underlying sample (some things are just more represented than others in the world - although I'm not convinced the example given is a fair illustration of this) and labels, 4 further datasets are created:
1. no sampling or label bias
2. sampling bias but no label bias
3. no sampling bias, but label bias
4. both sampling and label
However, two versions of each are created:
Experiment A - the sample and label imbalance is completely removed
Experiment B - the data balance is unmodified from the original dataset

Trained elastic net logistic classier

With each set of predictions, tested 6 metrics:
- Difference in Means
- Difference in Residuals
- Equal Opportunity
- Equal Mis-opportunity
- Disparate Impact
- Normalized Mutual Information

Metrics were not very good at differentiating between bias and legitimate imbalances in the data

Metrics were more sensitive to sample than label bias

There is no established threshold to most fairness metrics and response is dataset-dependent and so comparison of metrics should be compared against a known unbiased result

They provide some best practice guidelines},
  creationdate     = {2022-10-07T15:48:02},
  keywords         = {trust, data, bias},
  modificationdate = {2022-10-07T16:22:56},
  owner            = {ISargent},
  primaryclass     = {cs.LG},
  year             = {2018},
}

@TechReport{MeyerL2021,
  author           = {Brett Meyer and Tim Lord},
  date             = {2021-08-19},
  institution      = {Tony Blair Institute for Global Change},
  title            = {Planes, Homes and Automobiles: The Role of Behaviour Change in Delivering Net Zero},
  url              = {https://institute.global/policy/planes-homes-and-automobiles-role-behaviour-change-delivering-net-zero},
  comment          = {Technology, behaviour and combination changes are needed to reah 'net zero' 

The propotion of change that is behaviour change is increasing, as the ability of technology to help us decarbonise is saturated

CCC pathway has ehaviour changes required between 2019-2035 (paper includes targets):
- Homes and consumption
  - Install low-carbon heating and energy-efficiency measures
  - Reducing waste to landfill through reduced consumption/increased reuse and recycling
- Transport
  - Increased walking, cycling, public transport in place of car usage
  - Purchase/use zero-emissions vehicle
  - Reduce international travel and domestic flights
- Diet
  - Reduced meat and dairy consumption

Using results from BEIS Public Attitudes Tracker demonstrate that knowledge about cimate change is still poor (and declined between 2020 and 2021)

Although Research from the Centre for Climate Change and Social Transformations shows an acknowledgement of the need for action

Lots of graphs showing public attitudes to all sorts of things

''The barriers are clear: the key barriers to delivering behaviour change for net zero are knowledge, cost and hassle. Only by addressing all three of these will it be possible to deliver the required step change in behaviour, technology and adoption that achieving our carbon targets requires.''},
  creationdate     = {2022-10-07T16:46:11},
  keywords         = {climate, behaviour, social science},
  modificationdate = {2022-10-07T16:58:03},
  owner            = {ISargent},
}

@TechReport{CommGAP2010,
  date             = {2011-01-01},
  institution      = {Communication for Governance and Accountability Program (CommGAP) Washington, D.C. : World Bank Group.},
  title            = {Theories of behavior change},
  url              = {https://documents.worldbank.org/en/publication/documents-reports/documentdetail/456261468164982535/theories-of-behavior-change},
  comment          = {Elements of behavior change:
Threat, Fear, Response Efficacy, Self-Efficacy, Barriers, Benefits, Subjective Norms, Attitudes, Intentions, Cue to Action, Reactance

Major theories of behaviour change
1. Social Cognitive Theory - external (personal and environmental) factors influence behaviour - although the personal factors seem pretty internal to me! 
2. Theory of planned behaviour - behaviour depends on intention which is influenced by attitude to the behaviour, subjective norms and perceived behavioural control
3. Transtheoretical (Stages of Change) model - change is a prcess of 6 stages so you need to understand people's stage to identify the behaviour change intervention

Also briefs on attitude change},
  creationdate     = {2022-10-07T18:32:30},
  keywords         = {change, social science, behavriour},
  modificationdate = {2022-10-07T18:43:16},
  owner            = {ISargent},
}

@Article{KarlssonSG2021,
  author           = {Karlsson, L. and Singham, S. and Gottschald, D. A..},
  journaltitle     = {World Customs Journal},
  title            = {The global zone network, a safe pathway to prosperity in the post-coronavirus era?},
  number           = {1},
  pages            = {51--64},
  url              = {https://pesquisa.bvsalud.org/global-literature-on-novel-coronavirus-2019-ncov/resource/pt/covidwho-1414319},
  volume           = {15},
  comment          = {Reads like a manifesto rather than a properly researced and evidenced proposal},
  creationdate     = {2022-10-07T18:46:04},
  keywords         = {economics},
  modificationdate = {2022-10-07T18:49:07},
  owner            = {ISargent},
  year             = {2021},
}

@Article{Freeman1995,
  author           = {Freeman, Chris},
  journaltitle     = {Cambridge Journal of economics},
  title            = {The `National System of Innovation' in historical perspective},
  number           = {1},
  pages            = {5--24},
  volume           = {19},
  comment          = {This paper compares how countries have organised and sustained the development, introduction, improvement and diffusion of new products and processes within their national economies.

In 1841, Friedrich List, motivated to determine how Germany could overtake England in industrial development, identified that more than ``material'' capital was required. He cited ``mental'' or intellectual capital as important.  ``Germany developed one of the best technical educational and training systems in the world ‚Ä¶  overtaking Britain in the latter half of the 19th century'' 

The system of Innovation includes education, including non-teaching such as museums and events and government assistance and direction, etc

In the late 19th century Germany industries innovated by introducing the in-house R\&D department. In-house R\&D became more prevalent after the second World war. The dominant idea of innovation was science and technology push - The Linear Model - with R\&D being seen as the source of innovation. In the 50s and 60s, however, evidence that diffusion of innovation was more important to economic growth and being the first in the world with the radical innovations. Also social innovations we're as important as technical innovations.

In the 80s and 90s it became evident that incremental Innovations came from areas other than R\&D such as production engineers technicians and from interactions with the market.

Comparing Japan with the USSR whilst both invested a similar amount in in R\&D in the 60s and the USSR invested more in the 80s. Japan made greater gains in industry. Much of their investment was in civil research. They had greater social, technical and economic linkages in their system than the USSR, where incentives for higher productivity were low. Similarly comparing South Korea (and possibly South Asian countries) with Brazil (and possibly South American countries), aspects that led to greater growth in SK appear to be greater education as well as investment in R\&D, but also more automation and better use of communication technologies.

With globalisation there has been debate over whether increasing standardisation of products and processes has occurred, indeed whether we should be talking about an interlinked economy or ILE transnational and multinational corporations. However the evidence remains that not only is R\&D in multinational organisations still very much focused in the original country but also that due to uncertainty, localised learning and bounded rationality, there may be increasing diversity of products. ``Neoclassical assumptions [about] perfect information are at the border lines of credibility and usefulness''. In terms of diffusion of innovations whilst incremental Innovations may easily diffuse over borders radical Innovations would require changes in production capability and social and institutional frameworks and so national systems of innovation become an extremely important concept.

See also Lundvall2007 and Brown2022},
  creationdate     = {2022-10-09T16:03:39},
  keywords         = {economics, innovation, international},
  modificationdate = {2022-10-09T17:38:00},
  owner            = {ISargent},
  year             = {1995},
}

@Article{JorgensenB2007,
  author           = {Torben Beck J\o{}rgensen and Barry Bozeman},
  date             = {2007},
  journaltitle     = {Administration \& Society},
  title            = {Public Values: An Inventory},
  number           = {3},
  url              = {http://aas.sagepub.com/cgi/content/abstract/39/3/354},
  volume           = {39},
  comment          = {What it says, the method and outcomes of trying to compile an inventory of public values

Questions posed, not necesarily answered are around:
what are public values, to whom do they apply and how does private enterprise relate to them?
can public value be assessed (I guess measured?)
what are the relationships between public values, how to they fit together, conflict, is there a hierarchy or are some contained by others?

Based on review of ``leading (largest circulation) public administration periodicals in the United States, the United Kingdom, and Scandinavian countries and studies chiefly published during the period 1990-2003'' and claim these ``represent very different positions on the spectrum of the welfare state and, perhaps, different views about public values''

Result is 72 registered values, grouped into 6 ``constelations''. Values associated with:
 - the Public Sector's Contribution to Society
   - Common good
     - Public interest
     - Social cohesion
   - Altruism
     - Human dignity
   - Sustainability
     - Voice of the future
   - Regime dignity
     - Regime stability
 - Transformation of Interests to Decisions
   - Majority rule
     - Democracy
     - Will of the people
     - Collective choice
   - User democracy
     - Local governance
     - Citizen involvement
   - Protection of minorities
     - Protection of individual rights
 - the Relationship Between the Public Administration and Politicians
   - Political loyalty
     - Accountability
     - Responsiveness
 - the Relationship Between Public Administration and Its Environment
   - Openness-secrecy
     - Responsiveness
     - Listening to public opinion
   - Advocacy-neutrality
     - Compromise
     - Balancing of interests
   - Competitiveness-cooperativeness
     - Stakeholder or shareholder value
 - Intraorganizational Aspects of Public Administration
   - Robustness
     - Adaptability
     - Stability
     - Reliability
     - Timeliness
   - Innovation
     - Enthusiasm
     - Risk readiness
   - Productivity
     - Effectiveness
     - Parsimony
     - Business-like approach
   - Self-development of employees
     - Good working environment
 - the Behavior of Public-Sector Employees
   - Legality
     - Protection of rights of the individual
     - Equal treatment
     - Rule of law
     - Justice
   - Equity
     - Reasonableness
     - Fairness
     - Professionalism
   - Dialogue
     - Responsiveness
     - User democracy
     - Citizen involvement
     - Citizen's self-development
   - User orientation
     - Timeliness
     - Friendliness

Also consider the proximity of values and identify some nodal values, that seem to be related to many other values (human dignity, sustainability, citizen involvement, openness, secrecy, compromise, integrity and robustness). Other prime values, which are valued for themselves, and instrumental values, which enable other values to be achieved.

Conclusion
 - Public Value Is Not Governmental
 - Many Public Values Are Prime Values But Cannot Be Distinguished on That Basis Alone
 - Public Values Analysis Is Both Causal Inquiry (Instrumental Values) and Philosophical and Moral Inquiry (Prime Values)
 - Values Relationships Are Many and Unwieldy But Must Be Sorted Out},
  creationdate     = {2022-10-09T17:38:00},
  keywords         = {economics, public value, public administration},
  modificationdate = {2022-11-25T18:07:02},
  owner            = {ISargent},
  year             = {2007},
}

@Article{Pavitt1984,
  author           = {Keith Pavitt},
  date             = {1984},
  journaltitle     = {Research Policy},
  title            = {Sectoral patterns of technical change: Towards a taxonomy and a theory},
  doi              = {https://doi.org/10.1016/0048-7333(84)90018-0},
  issn             = {0048-7333},
  number           = {6},
  pages            = {343-373},
  url              = {https://www.sciencedirect.com/science/article/pii/0048733384900180},
  volume           = {13},
  abstract         = {The purpose of the paper is to describe and explain sectoral patterns of technical change as revealed by data on about 2000 significant innovations in Britain since 1945. Most technological knowledge turns out not to be ‚Äúinformation‚Äù that is generally applicable and easily reproducible, but specific to firms and applications, cumulative in development and varied amongst sectors in source and direction. Innovating firms principally in electronics and chemicals, are relatively big, and they develop innovations over a wide range of specific product groups within their principal sector, but relatively few outside. Firms principally in mechanical and instrument engineering are relatively small and specialised, and they exist in symbiosis with large firms, in scale intensive sectors like metal manufacture and vehicles, who make a significant contribution to their own process technology. In textile firms, on the other hand. most process innovations come from suppliers. These characteristics and variations can be classified in a three part taxonomy based on firms: (1) supplier dominated; (2) production intensive; (3) science based. They can be explained by sources of technology, requirements of users, and possibilities for appropriation. This explanation has implications for our understanding of the sources and directions of technical change, firms' diversification behaviour, the dynamic relationship between technology and industrial structure, and the formation of technological skills and advantages at the level of the firm. the region and the country.},
  comment          = {Using database of innovations that are labelled according to their sector, this paper makes a number of observations and theories about the nature of innovation in Britain, accepting that the database does not contain a complete view [Iz: it doesn't contain knowledge/data industries and innovation].

Because the data are not complete, don't attempt to make statistical inference but do cross reference with statistical analysis for US by Scherer (1982)

Consider questions like ‚Äúscience and technology push versus demand pull‚Äù (see also Scherer and Schmookler refs), whether product or process innovations dominate, and the importance of organisation size.

In general, they find that it is very hard to make generalisations across sectors.

Organisations are grouped into categories:
- Science-based firms (much R\&D, drawing on other's R\&D, e.g. chemical and electronic sectors; innovation develops basic science and engineering)
- Supplier-dominated firms (small with weak in-house R\&D and engineering, e.g. manufacturing, agriculture, housebuilding; innovation is cuts costs)
- Scale/production-intensive firms (pin factories!; innovation increases productivity)
- Specialised equipment suppliers (supply equipment and knowledge)

Considers the sector of
- The source of the technology used
- The source and nature of the technology produced
- The characteristics of the innovating firm

And thus create a taxonomy of innovations has 5 possible combinations between a), b), and c) all being the same and them all being different

Most knowledge comes from within the same sector

Product innovations == improvement in performance of capital goods == innovation used outside of the sector

Process innovations == cheapening of capital goods == innovations used inside the sector},
  creationdate     = {2022-10-11T11:41:54},
  keywords         = {economics, innovation, industry},
  modificationdate = {2022-10-23T11:49:27},
  owner            = {ISargent},
}

@TechReport{Daley2021,
  author           = {Freddie Dailey},
  date             = {2021},
  institution      = {University of Sussex and the Fossil Fuel Non-Proliferation Treaty},
  title            = {The Fossil Fuelled 5},
  subtitle         = {Comparing rhethoric with reality on fossil fuels and climate change},
  url              = {https://priceofoil.org/content/uploads/2021/11/Fossil_Fuelled_Five_report-1.pdf},
  comment          = {Compares what five coutries say they are doing with what they are actually doing. It doesn't look good. The countries are:

UK, US, Canada, Norway, Australia 

Climate policy either measures to reduce demand or to grow alternatives to ff p7

Need to stop expansion and production, instead the opposite is happening with oil and gas and coal is winding down shower than needed p7

Covid-19 stimulus - only 2.5\% of $17tr on low carbon p8

Fossil fuels being subsidised

UN stated that pandemic recovery should be to build back better p8

UK climate change act 2008, ¬£12bn funds for green industrial Revolution, but only ?a third? Of what is required to meet UK's commitment to 1.5 degrees target p15

UK has statutory duty for MER p15
[Applications for drilling don't consider emissions of product - nef podcast]

Nice summary of commitments on p16},
  creationdate     = {2022-10-12T17:51:44},
  howpublished     = {online},
  keywords         = {climate, mitigation, fossil fuels},
  modificationdate = {2022-10-12T17:56:59},
  owner            = {ISargent},
}

@TechReport{KrogstrupO2019,
  author           = {Signe Krogstrup and William Oman},
  date             = {2019-09-04},
  institution      = {International Monetary Fund},
  title            = {Macroeconomic and Financial Policies for Climate Change Mitigation: A Review of the Literature},
  url              = {https://www.imf.org/en/Publications/WP/Issues/2019/09/04/Macroeconomic-and-Financial-Policies-for-Climate-Change-Mitigation-A-Review-of-the-Literature-48612},
  comment          = {''On their own, markets cannot deliver mitigation''

Policies divided into those that aim to correct lack of accounting‚Ä¶Climate risks and those that internalise externalities and co-benefits to society p6

Price of carbon defiantly low p7

Burke et al 2015 estimate cc will reduce GDP by 23\% by 2100 but student regions very differently affected  p10

Uncertainties more important than baseline scenarios‚Ä¶tail risk p11

SGDs too! p12

Social Cost of Carbon, Shadow price of carbon ‚Ä¶ Social Value of Mitigation Action p13

Market failures, listed p15

Government failures, listed p16

Stern report p 17, [what are criticisms of this?]

With returning to p17 onwards for details of tools and instruments and what they are trying to achieve. Compare these to actual policies, instruments etc being used.},
  creationdate     = {2022-10-12T17:57:55},
  keywords         = {economics, climate, mitigation},
  modificationdate = {2022-10-12T18:00:10},
  owner            = {ISargent},
}

@TechReport{KrebelSLA2020,
  author           = {Lukasz Krebel and Alfie Stirling and Frank Van Lerven and Sarah Arnold},
  date             = {2020-07-01},
  institution      = {New Economics Foundation},
  title            = {Building a Green Stimulus for COVID-19},
  subtitle         = {A recovery plan for a greener, fairer future},
  url              = {https://neweconomics.org/2020/07/building-a-green-stimulus-for-covid19},
  comment          = {Considering economic impacts of Covid and being p7

Uneven distribution of impacts means measures should be targeted appropriately p8

Fiscal stimulus package - to address climate, inequality, insecure work [the poly-crisis should be addressed not just carbon!] p10

Can be afforded due to low rate of borrowing p12

Criteria to be satisfied by green stimulus package p16

Selected projects that this could go on p19

[here the policy is specific, spend on things, not try to create a market to trigger the spending]

Jobs etc that will result p25},
  creationdate     = {2022-10-12T18:00:27},
  keywords         = {economics, covid, climate},
  modificationdate = {2022-10-12T18:05:26},
  owner            = {ISargent},
}

@Article{Solow1972,
  author           = {Robert M Solow},
  date             = {1972},
  journaltitle     = {Social Science},
  title            = {The Economist's Approach to Pollution and Its Control},
  note             = {Winter},
  number           = {1},
  pages            = {15--25},
  url              = {https://www.jstor.org/stable/41959550},
  volume           = {47},
  comment          = {Ancient economists considered resources to be land, labour or capital 

Land -> natural resources, some are exhaustible
scarcity leads to rationing by the market, regulation or other process 

Air and water have limited capacity to absorb and assimilate waste

The assimilative capacity of air and water is provided free of charge for anyone with waste to dispose into. This resource is becoming scarce 

The normal price of products that result in pollution does not reflect the scarcity because the costs of pollution do not fall on polluter but on society 

Piecemeal regulation can transfer harm, eg. geographically

Subsidies are hard to administer because may need to be based on the improvement in conditions 

Taxes and charges can be based on absolute pollution, which is more straighforward. However, this could lead to costs that disproportionately impact the poorest (although inequality can/should also be addressed)

It isn't easy to set the price of tax because its difficult to determine the full cost of pollution 

Discusses Mills's proposed materials-use fee that is charged on the removal of material from environment. The extractor fee is refunded to anyone who can demonstrate that they have returned the material to the environment - with level set by how safely, completely etc the materials have been disposed of

We don't consume-just transform materials between forms.

Finally suggest work modelling interactions of physical environment and economic system.},
  creationdate     = {2022-10-14T06:54:42},
  keywords         = {economy, environment, tax, regulation, subsidies},
  modificationdate = {2022-10-14T12:32:43},
  owner            = {ISargent},
}

@Article{Hardin1968,
  author           = {Garrett Hardin},
  date             = {1968-12-13},
  journaltitle     = {Science},
  title            = {Tradegy of the Commons},
  url              = {https://www.jstor.org/stable/1724745},
  comment          = {Technical solutions versus Change in human values or ideas of morality 

The class of human problems which are ``No technical solution problems'' problem referred to is ``population'' and claims that no cultural group has a growth rate of zero and so hasn't solved the problem. 

The tradegy of the commons, originally from 1833 pamphlet by Lloyd, is that individuals will consider the utility of Commons for themselves resulting in negative utility for others. The result in increasing exploitation, ``ruin to all'' 

Discussion of coercion and use of 

Ends up arguing for 'the necessity of abandoning the Commons in breeding'.

:eyesup:},
  creationdate     = {2022-10-14T12:14:08},
  keywords         = {economics, pollutation, enivronment},
  modificationdate = {2022-10-23T18:40:16},
  owner            = {ISargent},
}

@Article{Ostrom2002,
  author           = {Elinor Ostrom},
  date             = {2002},
  journaltitle     = {Handbook of Agricultural Economics},
  title            = {Chapter 24 Common-pool resources and institutions: Toward a revised theory},
  note             = {Part A},
  pages            = {1615--1339},
  volume           = {2},
  comment          = {Revisits common pool resource theory.A common pool resource is a good that is not exclusive (one person's access does not limit another's) but is also exhaustable. Much is this work is on fisheries but I am considering it in terms of the (pollution) absorptive capacity of air (as in Mills in Solow 1972).

This theory counters Hardin's Tragedy of the Commons by identifying that communities act to prevent ruin.

This particular paper revisits the theory and empirical research using game theory to find that communication and other attributes of the resource and the appropriators (these are listed) can lead to different outcomes. This results in theories and practice around how CPRs can be successfully managed.},
  creationdate     = {2022-10-14T12:29:06},
  modificationdate = {2022-10-14T13:29:30},
  owner            = {ISargent},
}

@TechReport{Mazzucato2017,
  author           = {Mariana Mazzucato},
  date             = {2017-09-01},
  institution      = {UCL Institute of Innovation and Public Purpose},
  title            = {Mission-Oriented Innovation Policy},
  subtitle         = {Challenges andopportunities},
  url              = {https://www.thersa.org/globalassets/pdfs/reports/mission-oriented-policy-innovation-report.pdf},
  comment          = {- economic growth has not only a rate but also a direction,
- innovation requires investments and risk taking by both private and public actors,
- the state has a role in not only fixing markets but also in co-creating and shaping them,
- successful innovation policy combines the need to set directions from above with the ability to enable bottom up experimentation and learning,
- missions may require consensus building in civil society.

''give explicit technological and sectoral directions to achieve the `mission'. At the same time, to be successful, they must also enable bottom up experimentation and learning''

Papers on Mission-orientated innovation policy: Ergas1987 Freeman, C. (1996) `The Greening of technology and models of innovation', Technological Forecasting \& Social Change, 53(1), pp. 27-39.

''In a market failure framework, ex-ante analysis aims to estimate benefits and costs (including those associated with government failures), while ex-post analysis seeks to verify whether the estimates were correct and the market failure successfully addressed. In contrast, a mission-oriented framework requires continuous and dynamic monitoring and evaluation throughout the innovation policy process.''},
  creationdate     = {2022-10-14T14:29:12},
  keywords         = {economics, missions},
  modificationdate = {2022-10-14T17:13:24},
  owner            = {ISargent},
}

@InBook{Ergas1987,
  author           = {Henry Ergas},
  booktitle        = {Technology and Global Industry: Companies and Nations in the World Economy},
  date             = {1987},
  title            = {Does Technology Policy Matter?},
  chapter          = {9},
  doi              = {10.17226/1671},
  pages            = {191--245},
  publisher        = {The National Academies Press},
  url              = {https://nap.nationalacademies.org/read/1671/chapter/9},
  address          = {Washington, DC},
  comment          = {Innovation is ``inherently uncertain'' requiring experimentation and diffusion

''Technology policy in the US, UK and France remains intimately linked to objective of national sovereignty. Best described as ``mission-oriented'', the technology policies of these nations focus on radical innovation needed to achieve clearly set out goals of national importance. In these countries, the provision of innovation-related public goods is only a secondary concern of technology policy''

Other countries have policies that are more diffusion-oriented (Germany, Switzerland and Sweden at the time of this paper. Japan is unique in being both diffusion- and mission-oriented.

Goes on to looks at specifics of each country and identify the consequences of different approaches. For example, the UK had ``difficulties'' that arise from lack of incentives in the system and other characteristics which seem to limit the the drive to efficiencies (not his word).},
  creationdate     = {2022-10-14T17:08:04},
  institution      = {National Academies of Sciences, Engineering, and Medicine},
  keywords         = {economics, missions},
  modificationdate = {2022-11-25T21:15:55},
  owner            = {ISargent},
  year             = {1987},
}






@Article{Lundvall2007,
  author           = {Bengt-√Öke Lundvall},
  date             = {2007},
  journaltitle     = {Industry and Innovation},
  title            = {National Innovation Systems‚ÄîAnalytical Concept and Development Tool},
  doi              = {10.1080/13662710601130863},
  eprint           = {https://doi.org/10.1080/13662710601130863},
  number           = {1},
  pages            = {95-119},
  url              = {https://doi.org/10.1080/13662710601130863},
  volume           = {14},
  comment          = {Goes into detail about National Systems of Innovation. Worth reading if I want to understand more deeply. Complements Freeman1995.

Proposes that further work is required to understand what happens within firms in terms of innovation and competence building, as well as between firms and considering international differences. Therefore, need to look at what work follows on from this paper.},
  creationdate     = {2022-10-14T18:02:37},
  keywords         = {economics, innovation, international},
  modificationdate = {2022-10-14T18:08:58},
  owner            = {ISargent},
  publisher        = {Routledge},
}

@Book{Galbraith1979,
  author           = {John Kenneth Galbraith},
  date             = {1973},
  title            = {Economics and the Public Purpose},
  edition          = {3rd},
  publisher        = {Pelican},
  comment          = {Discussion of economy in terms of market system and ``planning system'' (which is the big organisation - technostructure - that plans prices, wages, etc rather han being subjec to the market). 

One of the fundamental ideas in this book is that the increase of consumption leads to a requirement for more administration and management of good consumed. With the demise of servant roles, there is a rise in the ``crypto-servent house-wife''. The housewife, as with the entrepreneur and small business owner working for more than they are paid, are all receiving compensation in the form of ``convenient social virtue''.

Discussion of inequality in the system p93

Identifies that ``bureaucratic symbiosis'' between private corporation and related public body e.g. MOD and weapons firm p159

''it is the pursuit by the technostructure of its own goals, exercising its own power to do so, and not technological innovation per se that is at the heart of the environmental problems'' p166

The operations of the planning system impairs the sovereignty of the state p188

The transnational system internationalises the tendancy to inequality ... modern imperialism p 191

nice explanation of externalities ``external diseconomies of production'' (diseconomies is just costs) p223

''economists abuse that which they love'' in reference to financial support of small firms (which are foundation of market theory) which large firms simply attract such support due to their power p272

Discussion of executive income and its taxation p287-8

Separate to industries that form technostructures, there are ``retarded industries'' that cannot achieve this. These include medical care, housing, transport infrastructure. Yet these become even more necessary with the increase in consumption p296-7

Refers to Solow1971 on p305

discussion of the US government suggesting that committee deliberations should include public hearing p317

Slightly critical of the moon missions - spending could have redressed stavation etc p313

If taxation were consistent across all enrichment it could then be lower p324

While monetary experts will meet and discuss they will not solve problems p339 (footnote)

Suggests a series of reform options - the chapters in the final section.},
  creationdate     = {2022-10-14T19:19:19},
  keywords         = {economics, macroeconomics, public purpose},
  modificationdate = {2022-10-17T14:07:47},
  owner            = {ISargent},
}

@TechReport{BEISIIPP2020,
  author           = {Mariana Mazzucato and Rainer Kattel and Sarah Albala and George Dibb and Martha McPherson and Asker Voldsgaard},
  date             = {2020-10-01},
  institution      = {UCL Institute for Innovation and Public Purpose / Department for Business, Energy and Industrial Strategy},
  title            = {Alternative policy evaluation frameworks and tools},
  subtitle         = {Exploratory study},
  titleaddon       = {BEIS Research Paper Number 2020/044},
  url              = {https://www.gov.uk/government/publications/alternative-policy-evaluation-frameworks-and-tools-exploratory-study},
  comment          = {Researched by IIPP for the Better Regulation Executive at BEIS

Propose an alternative approach to policy evaluation based on public value as collectively understood by stakeholders that include the market, the state and civil society based on literature review for five years up to 201, review of policy cases and the outcomes of a workshop in 2019. 

Key conclusions:
- Diverse range of appraisal and evaluation practices as well as real-time monitoring (e.g. dashboards) that challenge traditional approaches
- Policy evaluation includes retrospective reviews alongside prospective methods
- Reflexive capabilities that cover various public frames such as economic, legal and organisational dimensions
- Identified 80 different policy evaluation and appraisal methodologies from cost-benefit analysis to social fabric matrices, asset mapping and public value mapping
- 35\% of literature referred to market-fixing, 46\% to market-shaping and 24\% to non-market-oriented frameworks
- Alternative evaluation methods are being taken seriously by the academic and specialist community
- Market fixing frameworks are heavily reliant on quantitative models whereas market-shaping analytical methods are more diverse, e.g. agent-based modelling and living labs
- Policy-makers are using alternative tools far less 
Recommendations
- Include alternative approaches in UK's Green Book and Magenta Book
- Integrate alternative tools to existing appraisal methodologies 
- Policy appraisal and evaluations need to motivate ambitious outcomes and capture the changing policy environment
- Regulation frameworks also need reflect public value and market-shaping
- A community of practise and analysis and testing of ways in which mainstream and alternative appraisal and evaluation tools can be brought together},
  creationdate     = {2022-10-16T14:35:04},
  keywords         = {economics, policy, evaluation},
  modificationdate = {2023-01-15T14:59:12},
  owner            = {ISargent},
}

@Article{ChangA2020,
  author           = {Ha-Joon Chang and Antonio Andreoni},
  date             = {2020-01-11},
  journaltitle     = {Development and Change},
  title            = {Industrial Policy in the 21st Century},
  doi              = {https://doi.org/10.1111/dech.12570},
  issue            = {2},
  pages            = {324--351},
  url              = {https://onlinelibrary.wiley.com/doi/10.1111/dech.12570},
  volume           = {51},
  comment          = {This is a brilliant paper and covers so much more than anything else I've read to date

Issues neglected by neoclassical and also evolutionary and structuralist contributions:
- commitment under uncertainty - switching to new tech is costly [izzy - why renewables seem costly because ff infrastructure was invested in decades ago]
- learning in production - learning is not just in R\&D, but policy [iz: and management!] disconnects learning from production
- macroeconomic management - the management of the economy is as important as industrial policy to achieve national objectives
- conflict management - ``successful implementation of any
policy requires management of the conflicts that it causes and/or of existing latent
conflicts that it unintentionally stirs up''

Also detail new realities in economies:
- Shifting organization of global production, new patterns of accumulation, value creation and capture - leading to extremely powerful organisations, small enterprises cannot fully participate in global value chains
- Increasing financialization of the world economy - focus on shareholder value, performing share buybacks, doing much less in core activity of organisation, pushes economies into spiral of dis-investment and de-accumulation
- Changes in the rules of the global economic system - imperialism, old and new - rich countries ``impose `monetarist' macroeconomic policies on the developing countries in macroeconomic trouble, while conducting more `Keynesian' policies when they face similar problems themselves''},
  creationdate     = {2022-10-16T15:18:38},
  keywords         = {economics, produciton, macroeconomics},
  modificationdate = {2022-11-25T21:02:11},
  owner            = {ISargent},
}

@Article{ArgyleBFRW2022,
  author           = {Argyle, Lisa P. and Busby, Ethan C. and Fulda, Nancy and Gubler, Joshua and Rytting, Christopher and Wingate, David},
  title            = {Out of One, Many: Using Language Models to Simulate Human Samples},
  doi              = {10.48550/ARXIV.2209.06899},
  url              = {https://arxiv.org/abs/2209.06899},
  comment          = {Use GPT-3 to create proxies for specific human sub-populates and characterise human attitudes.},
  copyright        = {Creative Commons Attribution Share Alike 4.0 International},
  creationdate     = {2022-10-16T16:56:37},
  keywords         = {NLP, unsupervised, discovery},
  modificationdate = {2022-10-16T16:59:09},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2022},
}

@Article{Bardhan2016,
  author           = {Pranab Bardhan},
  title            = {State and Development: The Need for a Reappraisal of the Current literature},
  issn             = {00220515},
  number           = {3},
  pages            = {862--892},
  url              = {http://www.jstor.org/stable/43932478},
  urldate          = {2022-10-18},
  volume           = {54},
  abstract         = {This essay Mes to bring out some of the complexities that are overlooked in the usual treatment of the state in the institutional economics literature and supplement the latter with a discussion of some alternative approaches to looking at the possible developmental role of the state. It refers to a broader range of development goals (including the structural transformation of the economy) and focuses on problems like the resolution of coordination failures and collective-action problems, the conflicting issues of commitment and accountability and the need for balancing the trade-offs they generate, some ingredients of state capacity and political coalition building usually missed in the literature, the possible importance of rent shar√≠ng in a political equilibnum, the advantages and problems of political centralization and decentralization, and the multidimensionality of state functions that may not be addressed by markets or private firms.},
  comment          = {Say that the state provides a framework for law and order, enforcement of contacts and other institutions underpinning the market, yet constrained so as not to interfere with property rights. State also important for incentive frameworks of investment, enterprise and development. This paper considers development more broadly than others. Probably the discussion is more nuanced than I am currently able to detect and there's a lot about property rights that I simply don't understand as it seems to be essential to ``growth''.

Discussion of what is a strong state. This requires political centralisation (as opposed to local jurisdictions) and willingness to make commitments (despite diverse interest groups). There is a very long discussion of capacity.

There needs to be limits to government to prevent capture by special interest groups.

The state must be pluralistic to represent diverse groups.

Note the possible conflict between centralisation and pluralism. England had apparently historically managed to balance these. 

Contrast collectivist (e.g. East Asian) with individualist societies, the former helping the state's capacity more.

Goes on to discuss political decentralisation which enables greater local accountability, but had higher risk of capture. Notes that more mobile societies are less prone as electorate more aware.

Another problem with decentralisation is the devolution of responsibility without the corresponding funds - unfunded mandates.

Democracy is slow but if it has legitimacy is stabilising and curbs excesses of capitalism. There are plenty of examples of powerful interests undermining accountability processes and politicians dispensing benefits for votes.

Apparently, voting behaviour is significantly influenced more by recurring benefits arranged by local governments than by even large one-time benefits.

Discussions of developmental state and also public enterprises and Public-Private partnerships. Putin gets some mentions.},
  creationdate     = {2022-10-18T12:44:09},
  journal          = {Journal of Economic Literature},
  keywords         = {policy, state, democracy},
  modificationdate = {2022-10-22T11:00:36},
  owner            = {ISargent},
  publisher        = {American Economic Association},
  year             = {2016},
}

@Article{HaberlEtAl2020,
  author           = {Helmut Haberl and Dominik Wiedenhofer and Doris Vir\'{a}g and Gerald Kalt and Barbara Plank and Paul Brockway and Tomer Fishman and Daniel Hausknost and Fridolin Krausmann and Bartholom\''{a}us Leon-Gruchalski and Andreas Mayer and Melanie Pichler and Anke Schaffartzik and T\^{a}nia Sousa and Jan Streeck and Felix Creutzig},
  date             = {2020-06-11},
  journaltitle     = {Environmental Research Letters},
  title            = {A systematic review of the evidence on decoupling of GDP, resource use and GHG emissions, part II: synthesizing the insights},
  url              = {https://iopscience.iop.org/article/10.1088/1748-9326/ab842a},
  volume           = {15},
  comment          = {Conclude that decoupling rates are not enough

''A recent review suggest that strategies towards ‚Äãefficiency have to be complemented by those pushing ‚Äãsufficiency (Parrique et al 2019), that is, `the dir‚Äãect downscaling of economic production in many ‚Äãsectors and parallel reduction of consumption' ‚Äã(p 3). Although concrete political strategies towards ‚Äãsufficiency‚Äîor degrowth‚Äîare still fragmented and ‚Äãdiverse, they may include restrictive supply-side ‚Äãpolicy instruments targeting fossil fuels (instead of ‚Äãrelative efficiency improvements), redistribution (of ‚Äãwork and leisure, natural resources and wealth), ‚Äãa decentralization of the economy or new social ‚Äãsecurity institutions (that complement the growth‚Äã oriented welfare state). Recently suggested policies ‚Äãinclude moratoria on resource extraction and new ‚Äãinfrastructures (e.g. coal power plants, highways, air‚Äãports), bans on harmful activities (e.g. fracking, coal ‚Äãmining), the reduction of working hours and redis‚Äãtributive taxation, instead of just putting a price on ‚Äãresources and emissions (Schneider et al 2010, Kallis ‚Äã2011, Koch 2013, Sekulova et al 2013, Jackson 2016, ‚ÄãGreen and Denniss 2018, Hickel and Kallis 2019). A ‚Äãnew study suggests, however, that even energy suffi‚Äãciency actions may be associated with rebound effects ‚Äãand negative spillovers (Sorrell et al 2020).''

Find very little evidence of absolute decoupling, and these only for short period. Some evidence of relative decoupling. Mainly decoupling is due to efficiency and so little decoupling from energy used. No evidence that current rates are enough to reach climate goals. Also, decoupling was for production not consumption. Some evidence of reducing in material resource use or ``dematerialisation''. 

Grouped studies as having either ``green growth'' or ``degrowth'' agenda, it other. Very little in degrowth. Still most studies valued growth, some implicitly more than environmental goals.

Evidence that causality between GDP and resource in both directions. Past material and energy use is also relevant.

No novel policy recommendations in those papers that gave any. Rarely demand side policy to reduce consumption.

Suggest that sufficiency as well as efficiency is vital to meet climate goals and using measures of well-being better than GDP.

Table summarising each study!},
  creationdate     = {2022-10-19T14:59:35},
  keywords         = {climate, growth, econmics, GDP},
  modificationdate = {2022-12-13T10:15:33},
  owner            = {ISargent},
}

@Book{Benanav2020,
  author           = {Aaron Benanav},
  date             = {2020},
  title            = {Automation and the Future of Work},
  comment          = {Early discussion of machine p7 (bottom)

The labour share of income in G7 countries has fallen for decades p9

The automation theory argument is that technical change has reduced the demand for labour p11

This book argues that 1. The decrease in labour is not due to technical change but economic stagnation; 2. This manifests as under employment; 3. Inequality will not be addressed because elites accept/welcome low pay of workers; and 4. Abundance is possible without full or hourly full automation

De-industrialisation is due to over-capacity and global competition p24-5

Depressed prices resulted in reduced profits and lower investment and thus lower productivity improvements. The only way to stay afloat is taking market share from others (and buying back shares). Increased robotisation maintains competitiveness and, in fact, jobs because these companies/countries remain in operation p26


Manufacturing has been a unique driver of growth p34

Workers are leaving the manufacturing pool into service jobs which are low productivity p35

Instead of capital investment, companies are buying back their own shares (financialisation) p35

Services are also mostly non-tradeable so no use for international market therefore developing countries try to expand into manufacturing p37

So it's no technical dynamism but increasing stagnation 

The gap between productivity and output growth determines the demand for labour. The automation discourse says that jobs are being lost to automation (productivity) but this book argues that we have overcapacity and so demand relative to output is falling. P39

Major destroyer of livelihoods in the 20th century was not ‚Äúsilicon capitalism‚Äù but nitrogen capitalism - the green revolution p42

With increasing unemployment in 70s and 80s, and beyond, Governments changed welfare payments form short-term support to an inducement to work (by reducing their value) p47

Because there are fewer jobs and welfare is lower, people accept decreasing pay and conditions p47-8

Originally, job protection was for those job taken by the `main breadwinner'. Other jobs were less important and so were less protected. Now families relying on these unprotected roles for their main/sole income p50

Keynesian stimulation was attempted as divestment increased from 70s. But this counter-cyclical investment didn't stimulate high economic growth, private investment was not encouraged despite low interest rates p66-8

Keynes said that such conditions ‚Äúeconomic maturity‚Äù require the shrinking of labour supply, e.g. a reduction in working week rather than in increase in the labour demand p69

This was also Beveridge's 1944 plan, but it wasn't enacted

Due to competition, people should by the cheapest product. If productivity cannot be improved then wages have to decrease to retain a competitive position p60

OECD was formed to increase labour flexibility i.e. reduce labour protections p61

‚ÄúAutomation is lot like global warming: when people take it seriously, they find themselves willing to consider revisions to the basic structure of social life that they otherwise would have thought impossible‚Äù p65

Large asset owners will lose power as the state invests. They therefore threaten ‚Äúcapital strike‚Äù to prevent state investment, thus ‚Äúradical Keysianism‚Äù. Beveridge was defeated by the capitalists p70-1

There's a discussion of UBI, by both left- and right-wing versions p72-9

UBI does not separate income from assets - large asset owners retain the power p78 and control over investment decisions p79

Argue that the post-scarcity world and the steps needed to get there need to be imagined  - automation may not free us from work p82

Historic discussions of post-scarcity: The ancient Greeks distinguished the free world (citizens) from the necessary world (slaves). Thomas More divided a person's life into these realms - emancipating servant and this influence Marx and others p83-6

‚ÄúOnce necessity is assured, everyone is free to develop their individuality outside the bounds of any given community‚Äù p90

‚ÄúThe first thing people would actually do in a post-scarcity world ‚Ä¶ work to mitigate or reverse climate change and to make up for the centuries of inequality that followed colonialism‚Äù p92-3

‚ÄúEconomic growth never frees us from the need to grow more‚Äù p93},
  creationdate     = {2022-10-19T18:46:05},
  keywords         = {economics, technology, work},
  modificationdate = {2022-11-25T22:41:46},
  owner            = {ISargent},
  relevance        = {relevant},
}

@TechReport{BEIS2021,
  author           = {BEIS},
  date             = {2021-10-01},
  institution      = {Department for Business, Energy \& Industrial Strategy},
  title            = {Net Zero Strategy: Build Back Greener},
  url              = {https://www.gov.uk/government/publications/net-zero-strategy},
  comment          = {10 point 'plan'

''systems approach''

- Power
- Fuel supply and hydrogen
- Industry
- Heat and buildings
- Transport
- Natural resources, waste and fluorinated gases
- Greenhouse gas removals
- Supporting the transition with cross-cutting action (crowd-in public finance financial disclosure, skills, progress updates, ...)

1. Advancing offshore wind
2. Driving the growth of low carbon hydrogen
3. Delivering new and advanced nuclear power
4. Accelerating the shift in zero emissions vehicles
5. Green public transport, cycling and walking
6. Jet Zero and green ships
7. Greener buildings
8. Investing in carbon capture
9. Protecting our natural environment
10. Green finance and innovation

3 2050 scenarios:
1. High electrification
2. High resource (low carbon hydrogen)
3. High innovation

''our indicative pathway to 2037 prioritises emissions reductions where known technologies and solutions exist and thereby minimises reliance
on the use of greenhouse gas removals to meet our targets.''

''UK Emissions Trading Scheme as a key driver of our path to net zero''

''it will be necessary to consider whether broader reforms to our market frameworks are needed to unlock the full potential of low carbon technologies to take us to net zero''

''CCUS will be critical to achieving net zero, alongside low carbon alternatives such as low carbon hydrogen and electricity''

''Government aims to support this shift in the 2020s through policy measures that inform consumers of the embodied carbon of industrial goods and empower them to make choices that support more efficient use of resources''

''Over the 2020s, we will need to start taking more decisive steps about which technologies and infrastructure should be rolled out, where and when, and accordingly, where we need to target investment, skills, and other enabling actions''

''By the early 2030s, CO2 transport and storage infrastructure availability could potentially constrain GGR deployment, as the significant overall expansion of CCUS projects creates competition for access to the network''

Climate change to play important role in financial regulation via the Bank of Englad and Financial Conduct Authority.

Green jobs taskforce reported in July 2021 with three themes across the ‚Äúlife cycle‚Äù of green jobs: driving investment in net zero to support good quality green jobs in the UK; building pathways into good green careers; and supporting workers in the high carbon economy to transition.

Principles underpinning green public and business choices
1. Minimise the `ask' by sending clear regulatory signals
2. Make the green choice the easiest
3. Make the green choice affordable
4. Empower people and businesses to make their own choice
5. Motivate \& build public acceptability for major changes
6. Present a clear vision of how we will get to net zero and what the role of people and business will be

Has a sectoral S-curve showing position of different sectors (cars, buildings, plastics, etc along the journey from emergence, through diffusion and into reconfiguration. Power is the further along and only part way into diffusion.},
  creationdate     = {2022-10-21T07:18:47},
  keywords         = {economics, climate, policy},
  modificationdate = {2022-11-27T17:07:22},
  owner            = {ISargent},
  relevance        = {relevant},
}

@Article{CosmeSO2017,
  author           = {In\^{e}s Cosme and Rui Santos and Daniel W. O'Neill},
  date             = {2017-02-03},
  journaltitle     = {Journal of Cleaner Production},
  title            = {Assessing the degrowth discourse: A review and analysis of academicdegrowth policy proposals},
  pages            = {321--334},
  volume           = {149},
  comment          = {Analyse the degrowth literature to draw conclusions about the position of these ideas and proposals in academic discourse.

''The research method used to categorise and analyse academic degrowth proposals is Grounded Theory (GT). GT is an approach that allows the researcher to inductively construct theory about a certain issue in a systematic manner (Strauss and Corbin, 1990).''

''The difference between the ecological and neoclassical perspectives leads to different policy-making objectives. Daly (1992) defines three policy objectives for ecological economics, which have been widely applied in this research field (e.g. Deepak, 2010; Lawn, 2001; Stewen, 1998). The objectives are, in order of relative importance: (1) sustainable scale of resource use, (2) fair distribution of income and wealth, and (3) efficient allocation of resources''

Grouped degrowth topics into 3 broad goals:
1. Reduce the environmental impact of human activities
2. Redistribute income and wealth both within and between countries
3. Promote the transition from a materialistic to a convivial and participatory society

As well as identifying the ecological economics policy objectives addressed, they considered whether proposal where local, national or international and whether they were top-down or bottom up

Most proposal had a national focus and were top-down in approach, indicating that state has a large role to play despite the dominant narrative of transformation from grassroots. 

Also, literature is more focused on social equity than environmental sustainability.

Find that objectives behind proposals are sometimes unclear and say there is a need to look at degrowth proposal as components of strategy.

Neglected issues are population growth and implications of degrowth for developing countries},
  creationdate     = {2022-10-21T12:41:26},
  keywords         = {economics, policy, degrowth, environment},
  modificationdate = {2022-10-21T14:15:39},
  owner            = {ISargent},
}

@Article{RockstromEtAl2009,
  author           = {Johan Rockstr\"{o}m and Will Steffen and Kevin Noone and √Ösa Persson and {Chapin, III}, F. Stuart and Eric Lambin and Timothy M. Lenton and Marten Scheffer and Carl Folke and Hans Joachim Schellnhuber and Bj√∂rn Nykvist and de Wit, Cynthia A. and Terry Hughes and van der Leeuw, Sander and Henning Rodhe and Sverker S\''{o}rlin and Peter K. Snyder and Robert Costanza and Uno Svedin and Malin Falkenmark and Louise Karlberg and Robert W. Corell and Victoria J. Fabry and James Hansen and Brian Walker and Diana Liverman and Katherine Richardson and Paul Crutzen and Jonathan Foley},
  journaltitle     = {Ecology and Society},
  title            = {Planetary boundaries:exploring the safe operating space for humanity},
  number           = {2},
  pages            = {32},
  url              = {http://www.ecologyandsociety.org/vol14/iss2/art32/},
  volume           = {14},
  comment          = {The Planetary Boundaries paper

''The proposed concept of ‚Äúplanetary boundaries‚Äù lays the groundwork for shifting our approach to governance and management, away from the essentially sectoral analyses of limits to growth aimed at minimizing negative externalities, toward the estimation of the safe space for human development. Planetary boundaries define, as it were, the boundaries of the ‚Äúplanetary playing field‚Äù for humanity if we want to be sure of avoiding major human-induced environmental change on a global scale.''

From CosmeSO2017: ``suggests that the period of stability that Earth's environment experienced during the last millennia is endangered by human activities.''},
  creationdate     = {2022-10-21T12:49:06},
  keywords         = {economics, climate, environment},
  modificationdate = {2022-11-27T19:48:38},
  owner            = {ISargent},
  year             = {2009},
}

@TechReport{UNEP2019,
  author           = {UNEP},
  date             = {2019},
  institution      = {United Nations Environment Programme},
  title            = {Global Trends in Renewable Energy Investment 2019},
  url              = {https://www.unep.org/resources/report/global-trends-renewable-energy-investment-2019},
  comment          = {Loads of graphs showing where investments have occurred (renewable energy type, country, finance type, etc)

Tidal investments from governments and VC. However ``progress has been patchy, with many of the hightech hopefuls going out of business during the last five or six years''},
  creationdate     = {2022-10-21T14:12:43},
  keywords         = {economics, climate, investment, energy},
  modificationdate = {2022-10-21T14:15:09},
  owner            = {ISargent},
}

@Article{Sovacool2011,
  author           = {Sovacool, Benjamin K},
  date             = {2011},
  journaltitle     = {Energy and Environment},
  title            = {Four problems with global carbon markets: a critical review},
  eprint           = {http://sro.sussex.ac.uk/id/eprint/58268/1/0958-305x%252E22%252E6%252E681.pdf},
  comment          = {''
- Homogeneity problems arise from the non-linear nature of climate change, which complicate attempts to calculate carbon offsets. 

- Justice problems involve issues of dependency and the concentration of wealth among the rich, meaning carbon trading often counteracts attempts to reduce poverty. 

- Gaming problems include pressures to promote high-volume, least-cost carbon credit projects and the consequences of emissions leakage. 

- Information problems encompass transaction costs related to carbon trading and market participation and the comparatively weak institutional capacity of project evaluators
''},
  creationdate     = {2022-10-22T10:22:35},
  keywords         = {climate, markets, economics},
  modificationdate = {2022-11-25T20:42:09},
  owner            = {ISargent},
}

@TechReport{ParryBV2021,
  author           = {Ian W.H. Parry and Simon Black and Nate Vernon},
  date             = {2021-09-24},
  institution      = {International Monetary Fund},
  title            = {Still Not Getting Energy Prices Right: A Global and Country Update of Fossil Fuel Subsidies},
  url              = {https://www.imf.org/en/Publications/WP/Issues/2021/09/23/Still-Not-Getting-Energy-Prices-Right-A-Global-and-Country-Update-of-Fossil-Fuel-Subsidies-466004},
  comment          = {The IMF paper about fossil fuel subsidies. Much of the subsidies are undercharging for environmental costs (local air pollution and climate change).},
  creationdate     = {2022-10-22T10:54:41},
  keywords         = {economics, fossil fuels, climate, subsidy},
  modificationdate = {2022-10-22T10:58:36},
  owner            = {ISargent},
}

@Online{ArteagaCruzMSNJ2020,
  author           = {Erika Arteaga-Cruz and Baijayanta Mukhopadhyay and Sarah Shannon and Amulya Nidhi and Todd Jailer},
  date             = {2020-08-17},
  title            = {Connecting the right to health and anti-extractivism globally},
  url              = {https://www.scielo.br/j/sdeb/a/9xFJGWk86QbncnXbtqFXrpJ/?lang=en},
  urldate          = {2022-10-22},
  comment          = {paper arguing that financing health systems by the development of extractive industries (minerals such as gold, manganese, bauxite, copper, cobalt, zinc, tin, diamonds, and uranium, and fossil fuels, but also commercial farming, forest, and fishing industries) is counter-productive. Worse, welfare states are thus founded on the removal of land rights of indigenous peoples, and a stagnation of health improvements, while capital accumulates with the few and incorporates the value of ``(human) workers' labor, but also the products of biogeochemical processes that may be millennia-old, disrupting and destroying the mechanisms that hold our ecosystem in the careful equilibrium required to sustain life.''

Some great references.

link to slavery},
  creationdate     = {2022-10-22T12:00:55},
  doi              = {https://doi.org/10.1590/0103-11042020S108},
  keywords         = {health, climate, pollution, policy, finance},
  modificationdate = {2022-10-23T13:43:08},
  owner            = {ISargent},
}

@Online{New2021,
  author           = {Philip New},
  date             = {2021-02-04},
  title            = {If the UK is to achieve Net Zero, a carbon tax is not the silver bullet},
  url              = {https://es.catapult.org.uk/insight/carbon-tax-is-not-a-silver-bullet/},
  urldate          = {2022-10-22},
  comment          = {Contains the effective carbon prices graph and has the statement ``Our current approach tilts the balance in favour of gas boilers over cleaner alternatives because there is no price on the carbon emissions boilers emit. This stifles any incentive for innovators to create cleaner technologies.''},
  creationdate     = {2022-10-22T13:52:18},
  modificationdate = {2022-10-22T21:01:45},
  owner            = {ISargent},
}

@Online{BUS2022,
  author           = {ofgem},
  date             = {2022-10-22},
  title            = {Boiler Upgrade Scheme (BUS)},
  url              = {https://www.ofgem.gov.uk/environmental-and-social-schemes/boiler-upgrade-scheme-bus},
  urldate          = {2022-10-22},
  comment          = {Description of the Boiler Upgrade Scheme (BUS)},
  creationdate     = {2022-10-22T14:12:56},
  modificationdate = {2022-10-22T21:01:38},
  owner            = {ISargent},
}

@Article{TaufiqueNDSSV2022,
  author           = {Khan M. R. Taufique and Kristian S. Nielsen and Thomas Dietz and Rachael Shwom and Paul C. Stern and Michael P. Vandenbergh},
  date             = {2022-01-27},
  journaltitle     = {Nature Climate Change},
  title            = {Revisiting the promise of carbon labelling},
  url              = {https://www.nature.com/articles/s41558-021-01271-8},
  comment          = {Carbon labelling

Studies show some positive impacts on consumer choice but not always

Key challenges
- Labelling needs to also be understood as valuable for its impact on the producer
- High carbon emitters may be resistent to labelling and lead to weaking of schemes
- Labelling schemes are not panaceas and will not reduce emissions on their own
- Quantification needs to be accurate, this require transparency and can also aid more wider attempts to detect greenwashing. Economy-wide labelling would enable better understanding of emissions for border adjustment on other instruments},
  creationdate     = {2022-10-22T15:02:21},
  keywords         = {economics, carbon, climate, policy},
  modificationdate = {2022-11-25T20:37:56},
  owner            = {ISargent},
}

@Article{VandenburgC2010,
  author           = {Michael P. Vandenburg and Mark A. Cohen},
  date             = {2010},
  journaltitle     = {New York University Environmental Law Journal},
  title            = {Climate Change Governance: Boundaries and Leakage},
  issue            = {2},
  pages            = {221--292},
  url              = {https://heinonline.org/HOL/P?h=hein.journals/nyuev18&i=225},
  volume           = {18},
  comment          = {About carbon labels: ``Many firms are risk-averse and appear to act to protect legitimacy, reputation and brands even when changes in consumer behaviour are uncertain'' p276},
  creationdate     = {2022-10-22T15:23:18},
  keywords         = {law, policy, economics, climate, consumer},
  modificationdate = {2022-10-22T15:28:41},
  owner            = {ISargent},
}

@Article{Rechsteiner2020,
  author           = {Rudolf Rechsteiner},
  date             = {2020-10-04},
  journaltitle     = {Clean Technologies and Environmental Policy},
  title            = {German energy transition (Energiewende) and what politicians can learn for environmental and climate policy},
  url              = {https://link.springer.com/article/10.1007/s10098-020-01939-3},
  comment          = {Uses German and Swiss case to consider effective environmental policy and instruments. Quite long and detailed!

Compares Pigou's Welfare Economics approach to internalising damage costs taxes versus approaches that incentivise avoidance activities

''The German Energiewende (energy transition) started with price guarantees for avoidance activities and later turned to premiums and tenders. Dynamic efficiency was a core concept of this environmental policy.''

Avoidance policy instruments
- Rules and standards
- Subsidies and tax reductions
- Levies, eco-taxes, liability provisions, emissions trading and combined incentives

Lots of other instruments listed throughout the text.

Communication is part of strategy

And market-fixing measures, Pigou taxes - internalisation of externalities - for remaining harms not prevented by avoidance activities},
  creationdate     = {2022-10-22T16:24:23},
  keywords         = {economics, policy, climate, energy},
  modificationdate = {2022-10-22T16:45:36},
  owner            = {ISargent},
}

@TechReport{IIPCC2022,
  author           = {IPCC},
  date             = {2022-02-28},
  institution      = {United Nations Intergovernmental Panel on Climate Change},
  title            = {{IPCC WGII} Sixth Assessment Report},
  subtitle         = {Summary for Policymakers},
  url              = {https://report.ipcc.ch/ar6wg2/pdf/IPCC_AR6_WGII_SummaryForPolicymakers.pdf},
  comment          = {''SPM.D.5.3 The cumulative scientific evidence is unequivocal: Climate change is a threat to human well-being and planetary health. Any further delay in concerted anticipatory global action on adaptation and mitigation will miss a brief and rapidly closing window of opportunity to secure a liveable and sustainable future for all. (very high confidence) {1.2, 1.4, 1.5, 16.2, 16.4, 16.5, 16.6, 17.4, 17.5, 17.6, 18.3, 18.4, 18.5, CWGB URBAN, CCB DEEP, Table SM16.24, WGI SPM, SROCC SPM, SRCCL SPM}''},
  creationdate     = {2022-10-22T16:52:51},
  keywords         = {climate},
  modificationdate = {2022-10-22T21:30:11},
  owner            = {ISargent},
}

@TechReport{HepburnEtAl2020,
  author           = {Cameron Hepburn and Tera Allas and Laura Cozzi and Michael Liebreich and Jim Skea and Lorraine Whitmarsh and Giles Wilkes and Bryony Worthington},
  date             = {2020-12-09},
  institution      = {The Policy Advisory Group of the CCC},
  title            = {Sensitive intervention points to achieve net-zero emissions},
  subtitle         = {Report of the Policy Advisory Group of theCommittee on Climate Change},
  url              = {https://www.theccc.org.uk/publication/sensitive-intervention-points-to-achieve-net-zero-emissions-sixth-carbon-budget-policy-advisory-group/},
  comment          = {Using our complexity science lens, we isolate 9 categories of interventions to accelerate action, as follows. 

First, public engagement on climate could be stronger. As recently as March 2020, 61\% of the British public were either completely unaware of the concept of ‚Äúnet zero emissions‚Äù (42\%) or had heard `hardly anything about it' (19\%) (BEIS, 2020b). These figures are improving, however. By September 2020, 53\% had heard nothing (30\%) or hardly anything (23\%) about net zero. The announcement of the Prime Minister's ‚ÄúTen Point Plan‚Äù in November 2020 has also presumably increased awareness. Deeper public engagement with the changes ahead is necessary (see section 3.1). 

Second, the transition, while net positive, will create winners and losers. The losers should know that they will be supported through the transition to ensure social justice (section 3.2). Without such support, progress could falter or stop completely. 

Third, the institutions of government are not geared up for such a mammoth effort. Political leadership can come and go, bold decisions can be shied away from, and trade-offs made where achieving net zero is not the top priority. A reorganisation of government is required (section 3.3). 

Fourth, some of largest polluters do not face the biggest penalties. Following the polluter pays principle, we recommend continued efforts on carbon pricing, the removal of fossil subsidies, and a `carbon takeback obligation' requiring firms who extract or import fossil fuels to put an increasing proportion of the carbon back in the ground (section 3.4). 

Fifth, the UK has a role in leveraging global dynamics (section 3.5) in the transition, particularly as host of COP 26. This means embracing the fact that the UK can affect emissions beyond its borders, and that action can and should be taken to complement domestic measures. 

Sixth, we note the role of business in embracing net-zero and suggest how to build on growing business climate ambition (section 3.6). 

Seventh, ongoing global technological advances are occurring, and we suggest opportunities for the UK to intervene, where appropriate, to accelerate technological trends, for the UK's, and the world's benefit (section 3.7). 

Eighth, we acknowledge the work being done to align the UK's business and financial systems to the world's climate objectives and suggest Paris-aligned accounts as a simple way to accelerate this (section 3.8). 

Ninth, but not least, we note how incremental changes to the UK's legal frameworks can help unlock faster progress (section 3.9).},
  creationdate     = {2022-10-22T19:35:41},
  keywords         = {policy, climate},
  modificationdate = {2022-10-23T14:08:37},
  owner            = {ISargent},
}

@Article{Driscoll2021,
  author           = {Daniel Driscoll},
  date             = {2021-08-18},
  journaltitle     = {Social Problems},
  title            = {Populism and Carbon Tax Justice: The Yellow Vest Movement in France},
  doi              = {https://doi.org/10.1093/socpro/spab036},
  url              = {https://academic.oup.com/socpro/advance-article-abstract/doi/10.1093/socpro/spab036/6354100?login=false},
  comment          = {The yellow vest (gilets jaunes)

The findings are four-fold: 

1) the Yellow Vests are concerned about global climate change and feel their anti-climate depictions in the media are rooted in a government strategy to divide and discredit the movement; 

2) they view the government's taxing them in order to fight climate change as corrupt and unfair; 

3) they argue that the carbon tax is additionally unjust due to their precarity, which has increased over several decades; 

4) they want to fight climate change on their own terms and argue for more direct forms of democracy to equalize decision making},
  creationdate     = {2022-10-22T19:52:46},
  keywords         = {social science, climate, policy},
  modificationdate = {2022-10-22T19:55:33},
  owner            = {ISargent},
}

@Online{PflugmannRSV2019,
  author           = {Fridolin Pflugmann and Ingmar Ritzenhofen and Fabian Stockhausen and Thomas Vahlenkamp},
  date             = {2019-11-21},
  title            = {Germany's energy transition at a crossroads},
  url              = {https://www.mckinsey.com/industries/electric-power-and-natural-gas/our-insights/germanys-energy-transition-at-a-crossroads},
  urldate          = {2022-10-22},
  comment          = {McKinsey article describing how Germany is missing his targets for its transition to low carbon evergy system

Security of supply and high energy costs are a problem},
  creationdate     = {2022-10-22T20:59:33},
  modificationdate = {2022-10-22T21:03:33},
  owner            = {ISargent},
}

@Online{Wehrmann2019,
  author           = {Benjamin Wehrmann},
  date             = {2019-03-27},
  title            = {Limits to growth: Resistance against wind power in Germany},
  url              = {https://www.cleanenergywire.org/factsheets/fighting-windmills-when-growth-hits-resistance},
  urldate          = {2022-10-22},
  comment          = {Public opinion against windfarms in Germany, despite high percentage supporting renewable energy. Opposition to wind farms has partly contributed to decceleration in new wind installations.},
  creationdate     = {2022-10-22T21:10:49},
  modificationdate = {2022-10-22T21:13:34},
  owner            = {ISargent},
}

@Book{CCC6thBudget2020,
  author           = {{Committee on Climate Change}},
  date             = {2020-12-01},
  title            = {The Sixth Carbon Budget},
  subtitle         = {The UK's path to Net Zero},
  url              = {https://www.theccc.org.uk/publication/sixth-carbon-budget/},
  creationdate     = {2022-10-23T07:45:57},
  keywords         = {climate, policy},
  modificationdate = {2022-10-23T07:48:23},
  owner            = {ISargent},
}

@Online{CORE122017,
  author           = {Bowles, S. and Carlin, W. and Stevens, M.},
  date             = {2017},
  title            = {Unit 12: Markets, Efficiency, and Public Policy},
  url              = {https://www.core-econ.org/the-economy/book/text/12.html},
  note             = {Section 12 in The Economy},
  organization     = {The CORE Team},
  urldate          = {2022-10-23},
  booktitle        = {The Economy},
  creationdate     = {2022-10-23T08:35:06},
  keywords         = {economics, markets, public policy},
  modificationdate = {2022-10-23T08:43:42},
  owner            = {ISargent},
  year             = {2017},
}

@Book{NelsonW1982,
  author           = {Richard R. Nelson and Sidney G. Winter},
  date             = {1982},
  title            = {An Evolutionary Theory of Economic Change},
  publisher        = {Harvard University Press},
  address          = {Cambridge, Mass.},
  comment          = {The blurb:
''

This book contains the most sustained and serious attack on mainstream, neoclassical economics in more than forty years.

Richard R. Nelson and Sidney G. Winter focus their critique on the basic question of how firms and industries change overtime.

They marshal significant objections to the fundamental neoclassical assumptions of profit maximization and market equilibrium, which they find ineffective in the analysis of technological innovation and the dynamics of competition among firms. To replace these assumptions, they borrow from biology the concept of natural selection to construct a precise and detailed evolutionary theory of business behavior.

They grant that firms are motivated by profit and engage in search for ways of improving profits, but they do not consider them to be profit maximizing.

Likewise, they emphasize the tendency for the more profitable firms to drive the less profitable ones out of business, but they do not focus their analysis on hypothetical states of industry equilibrium. The results of their new paradigm and analytical framework are impressive.

Not only have they been able to develop more coherent and powerful models of competitive firm dynamics under conditions of growth and technological change, but their approach is compatible with findings in psychology and other social sciences.

Finally, their work has important implications for welfare economics and for government policy toward industry.

''},
  creationdate     = {2022-10-23T08:54:03},
  keywords         = {economics},
  modificationdate = {2022-10-23T16:07:48},
  owner            = {ISargent},
}

@InBook{Lazonick2016,
  author           = {Lazonick, William},
  booktitle        = {Rethinking Capitalism},
  date             = {2016},
  title            = {Innovative Enterprise and the Theory of the Firm},
  publisher        = {John Wiley \& Sons Ltd},
  comment          = {''The problem is that adherence to the theory of the market economy
prevents the economist from understanding the microeconomic sources of productivity growth in the economy. It is organisations‚Äîincluding household families, business enterprises and government agencies‚Äîand not markets that invest in the productive capabilities embodied in physical and human capital that generate productivity.''

''In sum, the theory of the firm in perfect competition is a firm in which entrepreneurship and management play no roles.''

Marx:
''If all commodities exchange for the value of the quantities of labour embodied in them, Marx asked, what is the source of capitalist profit, i.e. surplus value?''

''Marx argued that the tendency of capitalist development was to generate a `reserve army' of unemployed labour that would keep wages at a culturally determined minimum‚Äîthe dark side of market forces ‚Äîwhile giving capitalist employers the power to extract high levels of labour effort, and hence surplus value, from their employees in the production process''

Marx predicted that automation would results in male workers being replaced by cheaper labour - women and children. This didn't happen because cooperation between workers and capitalists resulted in increase in productivity even with increased automation. Further, innovation is driven by this process leading to the ``innovative enterprise''.

''Innovation is a collective, cumulative and uncertain process.''

''The innovative enterprise develops productive resources through collective and cumulative learning processes ... `` (organisational learning). the costs of this are offset by the ability of firm to gain greater market share - outperform firms who are merely optimising - and overcome technological and market uncertainties. 

However, still competitive uncertainty and so much invest in human capital. This also requires government spending on public goods and often utilises subsidies and other government support. 

Gordon Moore, founder of Intel: start-up exploit what large organisations invent and innovate.

Financialisation of firms occurs when executives focus on purpose of maximising shareholder value and loss of investment in innovation},
  creationdate     = {2022-10-23T10:14:37},
  keywords         = {economics, innovation, organisations},
  modificationdate = {2022-11-08T20:34:52},
  owner            = {ISargent},
  year             = {2016},
}

@TechReport{DeHenauH2020,
  author           = {De Henau, Jerome and Susan Himmelweit},
  date             = {2020-06-30},
  institution      = {Women's Budget Group},
  title            = {A Care-Led Recovery from Coronavirus},
  url              = {https://wbg.org.uk/analysis/reports/a-care-led-recovery-from-coronavirus/},
  comment          = {- Investing in care would creates 2.7 times as many jobs as the same investment in construction: 6.3 as many for women and 10\% more for men.
- Increasing the numbers working in care to 10\% of the employed population, as in Sweden and Denmark, and giving all care workers a pay rise to the real living wage would create 2 million jobs, increasing overall employment rates by 5\% points and decreasing the gender employment gap by 4\% points.
- 50\% more can be recouped by the Treasury in direct and indirect tax revenue from investment in care than in construction.
- Investment in care is greener than in construction, producing 30\% less greenhouse gas emissions. A care-led recovery is a green led recovery.},
  creationdate     = {2022-10-23T11:36:50},
  keywords         = {economics, policy, social care},
  modificationdate = {2022-10-23T11:39:27},
  owner            = {ISargent},
}

@Article{AbernathyU1978,
  author           = {Abernathy, William J. and James M. Utterback},
  journaltitle     = {Technology Review},
  title            = {Patterns of industrial innovation},
  pages            = {40--47},
  volume           = {80},
  comment          = {Article shows that changes within industries are incremental. Revolutionary changes come in from outside and are disruptive.

In early stages of the most to large scale production, where requirements are ambiguous, users are more likely than manufacturers to produce an innovation

New products with diversity and uncertainty are perhaps easier for smaller enterprises to work with/make a success of

Change may result from small start-ups or from state sponsorship

After radical innovation comes evolutionary innovation related to dominant product design, increased price competition and emphasis on process innovations

Suggest incompatibilities:
- product variety/diversity vs high efficiency
- high rate of innovation vs substantial reduction in cost
- diversified markest of tech industries vs high rate of product innovation(?)
- organisational structure with more challenging and less repetitive tasks vs mechanisation and reduced need for labour
- increase productivity of young industries vs standardised products},
  creationdate     = {2022-10-23T11:55:23},
  keywords         = {economics, innovation, management},
  modificationdate = {2022-11-25T22:41:25},
  owner            = {ISargent},
  relevance        = {relevant},
  year             = {1978},
}

@TechReport{Martin2010,
  author           = {Martin, B.},
  institution      = {Office of Health Economics},
  title            = {{Science Policy Research: Having an Impact on Policy?}},
  eprint           = {https://www.ohe.org/system/files/private/publications/346%20-%20Science%20Policy%20Research.pdf},
  number           = {000197},
  type             = {Seminar Briefings},
  url              = {https://ideas.repec.org/p/ohe/sembri/000197.html},
  abstract         = {Professor Ben Martin (Science and Technology Policy Studies at SPRU, University of Sussex) defines science policy research as 'economic, policy, management and organisational studies of science, technology and innovation (STI) with a view to providing useful inputs to decision-makers concerned with policies for and the management of STI'. The field is important because STI is important - it is a source of progress, a major contributor to the wealth of nations, provides the basis for new goods and services and for new capabilities, and contributes to changes in the quality of life and the environment. As globalisation and international competition increase, STI is gaining even greater importance. It also carries risks, however, and social costs. For these reasons, effective policies to encourage and manage STI are essential. This Seminar Briefing summarises Prof Martin's presentation of the results of his research on how the field of science policy research has evolved and advanced in the 50 years since its inception and how it has affected decision making.},
  comment          = {From Martin2016

Twenty advances in science policy
1. 	From individual entrepreneur to corporate innovators 
2. 	From laissez faire to government intervention  
3. 	From two factors of production to three 
4. 	From single division to multi-divisional effects 
5. 	From technology adoption to innovation diffusion 
6. 	From science push to demand pull? 
7. 	From single factor to multi-factor explanations of innovation 
8. 	From a static to a dynamic model of innovation 
9. 	From the linear model to an interactive `chain-link' model 
10. 	 From one innovation process to several sector-specific types 
11. 	 From neoclassical to evolutionary economics 
12. 	 From neoclassical to new growth theory 
13. 	 From the optimising firm to the resource-based view of the firm 
14. 	 From individual actors to systems of innovation 
15. 	 From market failure to system failure 
16.  	 From one to two `faces' of R\&D 
17.  	 From `Mode 1' to `Mode 2' 
18. 	 From single technology to multi-technology firms 
19. 	 From national to multi-level systems of innovation 
20. 	 From closed to open innovation},
  creationdate     = {2022-10-23T12:40:36},
  keywords         = {economics, policy, innovation, science},
  modificationdate = {2022-11-18T20:12:06},
  month            = Dec,
  owner            = {ISargent},
  year             = {2010},
}

@Book{Raworth2017,
  author           = {Kate Raworth},
  date             = {2017},
  title            = {Doughnut Economics},
  subtitle         = {Seven Ways to Think Like a 21st-Century Economist},
  comment          = {I thought that the Ayres and Warr reference in here referred to transition to fossil fuels enabled the transition away from slavery

Social foundations are derived from the sustainable development goals},
  creationdate     = {2022-10-23T13:44:21},
  keywords         = {economics, degrowth, sufficiency, climate, environment},
  modificationdate = {2022-12-02T22:48:51},
  owner            = {ISargent},
}

@InBook{PerezM2018,
  author           = {Perez, Carlota and Murray-Leach, Tamsin},
  booktitle        = {Re:Thinking Europe: Positions on Shaping an Idea, Austrian Council for Research and Technology Development},
  title            = {Smart \& Green: A New `European Way of Life' as the Path for Growth, Jobs and Wellbeing},
  pages            = {208--223},
  publisher        = {Verlag Holzhausen},
  address          = {Vienna},
  comment          = {Two stages of technological revolution 
Installation (creative destruction) led by finance
Deployment by production

Between them, bubble then financial collapse
Requires government intervention to transform they economy to usher in golden age

Deployment period is positive-sum game between business and social

New technological era happens with synergies across society - not just promotion of innovation for itself - products, processes, services, organisations, institutions, policies

Also shift in lifestyle

Interconnection of innovation in way of life with innovation in products etc drivers change

Setting directions, missions, change can be accelerated

Describes tech revolutions with most recent one in detail: constraints were in imagination and finance, business and government trying to return to business as usual and market led prosperity

Supply was then aided by organisational changes but this needed demand, which was supported by the creation of the welfare state

Note we are looking at smart revolution in tech but environmental crises mean green revolution in lifestyle: smart green

Green is a direction for innovation and investment. Tech is enabler of local, 'traditional'

Vital to nurture the lifestyle aspiration especially in growing countries China and India

Also need to shift to intangible products and also redesign regulatory frameworks, social behaviours. Some of this is being seen in EU.

Environmental risks and disasters are likely to pay a role in the shift

Policy, strategies and values must be:
- Consistent with potential of the tech paradigm
- Mutually compatible and reinforcing
- A positive sum game for all participants},
  creationdate     = {2022-10-25T11:24:43},
  keywords         = {economics, innovation, technology, policy},
  modificationdate = {2022-10-26T18:33:09},
  owner            = {ISargent},
  year             = {2018},
}

@InBook{SnowdonV2005,
  author           = {Snowdon, Brian and Vane, Howard R.},
  booktitle        = {Modern macroeconomics},
  date             = {2005},
  title            = {Keynes v. the `old' classical model},
  editor           = {Snowdon, Brian and Vane, Howard R.},
  pages            = {36--90},
  publisher        = {Edward Elgar},
  subtitle         = {Its origins, development and current state},
  comment          = {Explains the classical model in detail and then goes on to discuss Keynes

Say's Law, ppl will work to produce products earning wage which they will spend on those products. Keynes rejected this.

Classical economics assumes full employment and no involuntary unemployment, which became obviously a false premise in 1920s

Keynes initially challenges government policy and argued for deficits funding of programmes to reduce unemployment in 1920s but couldn't do this until he produced a general theory in 1930s

Keynes introduced quantity theory of money, that amount of money in system has impacts. Considered investment expenditure, creates extend precariousness and instability, a consumer multiplier, household and firm expenditure.

Different interpretations of Keynes:
Hydraulic
Fundamentalist
Modified equilibrium
      Prices are sticky, wages (a price) do not flexibly change with shocks. 

But it seems Keynes was misinterpreted and it may be that Keynesian isn't Keynes's

Leijonhufvud presented main Keynes innovation as about private enterprise market economy responds to demand shocks when which price and wage flexibility and complete information are nothing more than fiction

Leijonhufvud also refers to what comes later (rational expectations) as ``... movies: more and more simple-minded plots but ever more mind-boggling special effects''

Akerlof presents case for strengthening macroeconomics by incorporating cognitive biases, reciprocity, fairness, herding and social status 

''The Great depression was the most significant economic catastrophe of modern times''
Keynes's impetus to write general theory ‚Ä¶ guess on to discuss with analysing causes of great depression in some detail, discuss the subsequent war and look at Keynes's legacy},
  creationdate     = {2022-10-25T11:39:30},
  keywords         = {economics},
  modificationdate = {2022-10-28T19:35:27},
  owner            = {ISargent},
  year             = {2005},
}

@Article{Nesterova2020,
  author           = {Iana Nesterova},
  date             = {2020-04-01},
  journaltitle     = {Journal of Cleaner Production},
  title            = {Degrowth business framework: Implications for sustainabledevelopment},
  doi              = {https://doi.org/10.1016/j.jclepro.2020.121382},
  volume           = {262},
  comment          = {Spash (2017, p. 27) argues that ‚Äúhumanity would do better to create an economic system that is smaller by design, not disaster‚Äù.

Paper summarising the literature on degrowth and connects its to business. Lots of useful points and discussion: 
Sufficiency
Downscaling
Wellbeing - of humans and non-human life and ecosystems
Radical shifts in values
Degrowth business
Reorientation
Frugality
Renewables
Durability
Localisation
Technology
Behaviour
Workers' wellbeing
Decreased productivity
...

Degrowth business is a firm whose operations are aimed at, and correspond to, economy aimed at downscaling of economic activities via material and energy throughput reduction, increase in wellbeing, alongside a shift in values. 

Degrowth business is for the satisfaction of needs, focus no longer on profit-maximisation. No longer growth, capitalism, productivism, consumerism, competition, etc

A firm should understand that economy and society are embedded within the biosphere and operate accoridingly

Some businesses are suitable for degrowth, others (e.g. fashion, advertising) may not be

Ends with question of how to measure success under this regime?

Interesting quote from As Schumacher (1993c, p. 179) ``Nonrenewable goods must be used only if they are indispensable, and then only with the greatest care and the most meticulous concern for conservation. To use them heedlessly or extravagantly is an act of violence''.},
  creationdate     = {2022-10-28T19:33:25},
  keywords         = {economics, degrowth, sufficiency, production, management},
  modificationdate = {2022-11-07T10:54:13},
  owner            = {ISargent},
}

@TechReport{MazzucatoR2019,
  author           = {Mariana Mazzucato and Josh Ryan-Collins},
  date             = {2019},
  institution      = {UCL Institute forInnovation andPublic Purpose},
  title            = {Putting value creation back into `public value'},
  chapter          = {Working Paper Series (IIPP WP 2019-05)},
  subtitle         = {From market-fixing to market-shaping},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/wp2019-05},
  comment          = {''This paper examines the intellectual origins of this notion of public value and argues that it relies too heavily on an intellectual framework derived from conventional economics where the role of the public sector is largely reactive, focused on correcting market failures to enhance economic efficiency''

Gives a thorough background to orthodox ideas of public administration theories and practise and why it is being rejected by some economists.

Markets are always imperfect and thus not `constrained Pareto-efficient'. This left to analysis that looked at 'net-welfare benefit' which led to one of the main justifications for cost-benefit analysis.

Market failure is only necessary condition of government intervention. However, it is not sufficient because 'bureau-maximising' behaviour of state departments means that intervention should only occur if benefits outweight costs of market- and government-failure.

Because of government failture, New Public Management argued that governments should adopt value-maximising strategies with efficiency targets etc.

In contrast, Moore developed `public value account' which was absorbed into Blair/Clinton 'Third Way' and included measuring outcomes and evidence-based approach to definitions of value that changed over time.

Similarly, Stoker argued for `public value management'.

From Ostrom, co-production developed with user-shaped and personalised public services. In particular, the Government Digital Service rejected the New Public Management ideas and focused on the role of citizens as users. Similarly, BBC presented concept of public value to justify public funds.

There are limitations of PVM e.g. around methods of measuring the value to the public, and that public can change views and even hold multiple views at one time.

Description of how laissez-faire can only exist paired with interventionism  and discussion of actual use of instruments such as taxation. Great for references.

This paper argues for moving beyond idea that public good is not about fixing a market failure but an end in itself. Collective value creation, new ways to engage the public, new evaluation indicators, consideration of how value is shared.

Nice table that summarises the differences between correcting failures and creating value.},
  creationdate     = {2022-10-29T19:02:20},
  keywords         = {economics, policy, value, public},
  modificationdate = {2022-12-03T18:43:51},
  owner            = {ISargent},
}

@TechReport{Nelson2017,
  author           = {Richard R Nelson},
  date             = {2017-10-01},
  institution      = {UCL Institute for Innovation and Public Purpose},
  title            = {Thinking About Technology Policy: `Market Failures' versus `Innovation systems'},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/publications/2017/oct/thinking-about-technology-policy-market-failures-versus-innovation-systems},
  comment          = {Demonstrates throughout that market failure is a poor reason for various innovation policies and argues that evolutionary theory of economic change recognises the innovation system and is a useful framework for technology policy.

Founded on the distinction the Schumpeter drew between two contexts for action:
- neoclassical: when economic activity occurs in a continuous circular flow, actors have full understanding
- evolutionary economics: when innovation is going on, actors can never understand full the context

Goes on to demonstrate how neoclassical economics and the market organisation has a poor link to much in technology policy - e.g. incentives for public good and externaties. It is `intellectually strained' to raionalise much of the public realm (air traffic control, public health, etc) because of market failure.

Virtually all R\&D yields externalities - others can learn from this R\&D. Firms are often knowledgeable about their fields and can direct their research with incentives such as patents. But basic research is often better understood in the public sphere and here the interest is in open science.

The issues is not whether markets fail but how to get the job done.

Thinking of innovation as a system with multiple diverse actors and instruments does not require recourse to market failure. Institutions evolve and policymaking is a continuing process.

Goes into detail the innovation around pharmaceuticals. Patents are important for profits but contraversial because it can lead to ``evergreening'' and limits to access by low income countries.},
  creationdate     = {2022-10-30T07:09:10},
  keywords         = {economics, policy, innovation},
  modificationdate = {2022-10-30T14:45:44},
  owner            = {ISargent},
}

@Article{KimD1992,
  author           = {Linsu Kim and Carl J. Dahlman},
  journaltitle     = {Research Policy},
  title            = {Technology policy for industrialization: An integrative framework and Korea's experience},
  pages            = {437--452},
  url              = {https://www.sciencedirect.com/science/article/pii/004873339290004N},
  volume           = {21},
  comment          = {Interesting detailed investigation of the policy and instruments used by Korea after independence that led to their current industrial standing today.

Needed to balance the promotion of 3 areas:
- demand side
- supply side
- links between supply and demand

Invested in education at all level. Initially many unemployed in highly educated people when technological development was not high 60s and 70s. They were then available for absorbtion into R\&D centres that were established in 70s and 80s.
 
Private sector encouraged to invest in ICT industry when government stated they would buy computers for schools.

A lot of reverse-engineering to recreate foreign innovations. 

Some policies didn't work as expected/intended. Objective evaluation is necessary.

Restrictions on access to foreign firms maintained independence but limited access to new technology - which was overcome by training and entrepreneurship.

Strong export focus incentivised investment in technology and enabled informal assistance from foreign buyers both of which facilitated rapid development of technological capability.},
  creationdate     = {2022-10-30T09:11:45},
  keywords         = {economics, policy, industry, innovation},
  modificationdate = {2022-11-25T19:08:57},
  owner            = {ISargent},
  year             = {1992},
}

@TechReport{MazzucatoSKE2022,
  author           = {Mariana Mazzucato and Marietje Schaake and Seb Krier and Josh Entsminger},
  date             = {2022-07-28},
  institution      = {UCL Institute forInnovation andPublic Purpose / Stanford Cyber Policy Center},
  title            = {Governing artificial intelligence in the public interest},
  chapter          = {Working Paper Series (IIPPWP 2022-12).},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/wp2022-12},
  comment          = {``We propose a market-shaping perspective as a novel, alternative analytic framework for repositioning the relationship between the public and private sector in the future of AI markets for the US''.

Augments, not just automates (because there are new things that can be done with AI).

``AI differs from most innovations, because of its general-purpose nature.''

``Daron Acemoglu also suggests that existing fiscal policies skew incentives towards excessive automation''

AI could be deployed to address underfunded areas but inequalities remain with investment and in access to to data. 

Whilst there are challenges around talent, infrastructure and diffusion, direction and the domination of the area by large well-funded players is a bigger challenge.

Governments can address:
- critical resource access 
   + datasets less biased and more complete
   + compute power
   + regulation and security against bad actors
- the emergence of harmful and malicious uses of AI
   + lack of disclosure of algorithms and results (`hyper rather than science')
   + use of deep fakes
- Failure to invest sufficiently in AI safety security (robustness, privacy, values)
   + setting benchmark standards
- Risks of market concentration and weak competition (e.g. brain drain from unis)
   + national cloud (US National AI Research Resource Task Force)
   + access to experiements and datasets

Market shaping needs to:
- Improve regulatory capabilties
- Direct finance
- Improve public sector capabilities},
  creationdate     = {2022-10-30T14:44:45},
  keywords         = {economics, policy AI, machine learning, missions},
  modificationdate = {2022-12-10T15:21:08},
  owner            = {ISargent},
}

@Article{PedersenH2014,
  author           = {David Budtz Pedersen and Vincent F. Hendricks},
  date             = {2014},
  journaltitle     = {Philosophy \& Technology},
  title            = {Science Bubbles},
  pages            = {503--518},
  url              = {https://link.springer.com/article/10.1007/s13347-013-0142-7},
  volume           = {27},
  comment          = {Bubbles forming in science and tech, as well as assets and finance

``One seemingly paradoxical hypothesis suggests that too much liquidity is actually poisonous rather than beneficial for a financial market (Buchanan 2008)''

``too much money chases too few assets, good as well as bad''

``Researchers get warped incentives for conducting scientific inquiry while areas of science turn into possible bubbles and even Ponzi schemes (Mirowski 2012)''

``Increasingly, phenomena like scientific hype, fashionable fields, biases against reporting negative results, and pressures to publish are recorded in the literature''

``Because scientists are constantly competing for resources at ever more diverse levels they are incentivized‚Äîintentionally or unintentionally‚Äîto pursue the same research questions and inflate the explanatory merits of their research programs''

`` `a strategic game is being played‚Ä¶ in which being first is more important than going in the right direction' (Rip 2009, p. 669)''},
  creationdate     = {2022-11-05T17:10:12},
  keywords         = {economics, innovation, science, finance},
  modificationdate = {2022-11-25T23:06:06},
  owner            = {ISargent},
}

@Article{KitoNKN2020,
  author           = {Minami Kito and Fumiya Nagashima and Shigemi Kagawa and Keisuke Nansai},
  date             = {2020-09-24},
  journaltitle     = {Environmental Research Letters},
  title            = {Drivers of $CO_2$ emissions in international aviation: the case of Japan},
  url              = {https://iopscience.iop.org/article/10.1088/1748-9326/ab9e9b/pdf},
  comment          = {More efficient aircraft are not suffient to mitigate climate impacts of aviation because they are offset by increase in flights - Japanese example},
  creationdate     = {2022-11-07T10:17:56},
  keywords         = {climate, aviation, economics, efficiency},
  modificationdate = {2022-11-25T19:06:30},
  owner            = {ISargent},
}

@Article{BorrasE2013,
  author           = {Susana Borr\'{a}s and Charles Edquist},
  date             = {2013-04-12},
  journaltitle     = {Technological Forecasting \& Social Change},
  title            = {The choice of innovation policy instruments},
  comment          = {``A conventional and general definition of public policy instruments is `a set of techniques by which governmental authorities wield their power in attempting to ensure support and effect (or prevent) social change'''

Innovation is rarely a goal in itself

``The ultimate objectives of innovation policy are determined in a political process''

``Problems to be mitigated by innovation policy must be identified and specified in innovation terms ... system, i.e. a low innovation intensity (or a low propensity to innovate) of a certain category of innovations (product, process, etc.)''

quoting Edquist and Zabala-Iturriagagoitia, 2013: it is necessary to also know the causes behind the problem identified ‚Äî at least the most important ones

Choice of instruments:
1. a primary selection of the specific instruments
2. the concrete design and/or `customization' of the instruments
3. the design of an instrument mix

``Policy instruments are not neutral devices'' and popular acceptance can impact their outcome.

Choice of instruments may differ even if goals are similar

Identfying problems can be achieved using:
- innovation indicators
- foresight exercises 
- benchmarks and best cases
- independent expert assessment

Categories of policy instruments:
1. regulatory (``sticks'')
2. economic and financial (``carrots'')
3. soft (``sermons'')

Regulatory instruments may be important indirectly, e.g. by restricting supply of inputs they incentivise innovation with different inputs

Most economic instruments operate on the supply side - development and diffusion of innovation. An example of demand-side is public procurement of innovation (PPI) - China is doing this

Soft instruments, often termed `governance', is growing and ``transformed the role of the government from being a provider and regulator to being a coordinator and facilitator [9]''

Lists 10 activites in the system of innovation and says that instruments will act on one or more of these. These are divided into four groups:
1. Provision of knowledge inputs for the innovation process
2. Demand-side activities
3. Provision of constituents for the systems of innovation
4. Support services for innovating firms},
  creationdate     = {2022-11-07T12:41:30},
  keywords         = {policy, innovation, economics},
  modificationdate = {2022-11-25T23:05:39},
  owner            = {ISargent},
}

@Article{FlanaganU2016,
  author           = {Kieron Flanagan and Elvira Uyarra},
  date             = {2016-03-09},
  journaltitle     = {Industry and Innovation},
  title            = {Four dangers in innovation policy studies - and how to avoid them},
  pages            = {177--188},
  url              = {https://www.tandfonline.com/doi/abs/10.1080/13662716.2016.1146126?journalCode=ciai20},
  comment          = {Four dangers:

1. Idealising theoretical rationales and policy makers
policy rationales are likely to acreete in layers because new ideas are implemented in a landscape shaped by older ones. `Policy monopolies' and `policy entrapreneurs'

2. Treating policies as tools from a toolbox
But `interpretive flexibility' - policies carry different meanings from time to time, place to place, actor to actor. Not necessarily stable over time and do not work in isolation.

3. Too much faith in rational design coordination of `policy mixes'
Somewhat critical of BorrasE2013: ``Whilst the OECD acknowledges the significant co-ordination challenges presented by the sheer complexity and flexibility of the mix of policies likely to have an influence on innovation processes, [BorrasE2013] downplay these challenges. In their idealised approach, coherence will come from careful attention to problem identification and policy mix design''. But policy mixes have emergent behaviour. Scarce evidence for the value of `systemic' instruments and `strategic policy intelligence' tools such as foresight exercises to build more coherent policy visions.

4. An atemporal approach to innovation policy
dynamics unfold and interact over time, goals, rationales and instruments will emerge, evolve and fade away. Adaptive implementers are needed.

Identify some ways forward
- study of innovation processes for highlighting possibilities and challenges for policy implementation
- mutual adaptive co-ordination, informed by contextual knowledge
- pay more attention to the role of agency in making and breaking policy path dependencies and the roles institutions play in enabling and constraining action
- includes learning from failure, active experimentation and trial and error
- draw attention to uncertainties and trade-offs, such as the balance
between decentralised experimentation and the need to learn and rapidly transfer lessons, or the wider hidden complexities, uncertainties, and trade-offs between inevitably conflicting policy goals, encouraging open debate and shedding light on the hidden politics behind innovation policy choices


Useful for references for studies of innovation policy implementation in different countries and sectors

Craig Berry's summary:
1. Don't idealise the theoretical rationale of policy-makers - they are not passive recipients of policy recommendations
There are multiple policy actors with varying interests, knowledge, biases
Need to see policy as just as layered and evolutionary as innovation; e.g. policy-makers may hold onto `market failure' rationale even as systemic thinking emerges
1. Don't treat policies as tools from a toolbox
Instruments have different meaning and application in different contexts
Little evidence that any one set of innovation policy tools is most effective
1. Don't put too much faith in rational design and coherent policy `mix'
`Public policy necessarily pursues a broad and ever-changing range of more or less explicit and implicit, final and intermediate goals and objectives. It must also react to urgent and often unforeseen problems'
1. Don't forget path dependency
Policy shaped by past practice, constrained by future uncertainties},
  creationdate     = {2022-11-07T14:37:45},
  keywords         = {economics, policy, innovation, evolutionary},
  modificationdate = {2022-11-11T17:07:07},
  owner            = {ISargent},
}

@Book{Nelson1977,
  author           = {Richard R Nelson},
  date             = {1977},
  title            = {The Moon and the Ghetto},
  subtitle         = {An Essay on Public Policy Analysis},
  comment          = {Starting from the question ``if we can land a man on the moon, why can't we solve the problems of the ghetto?'', this essay discusses how public policy is applied, its methods and failures.

Chapter 2: Covers traditional policy analysis, its nature, history and current state. Later in the book, say that ``this approach assumes problems can be solved'' p143

Chapter 3: A second way of applying policy is around our organisation and organisations. 

Discussion of how we organise to deliver on policy. Economists have dominated in policy because, unlike sociologists and political scientists, they are willing to make predictions. 

Economists would have it that decisions relating to public goods (e.g. healthcare or education) should be made by the service user (who may not know best or have a broad knowledge base) or provider (who may be conflicted by any fee that they receive).

Chapter 4: A third way is to perform research to identify solutions.

Discussion of science and technology policy. This has tended to be about natural not social sciences. But just because physics is a powerful discipline, does not mean we can apply it to solve the problems of the world.

Significant advances in the social science method are required. Questions about who decides what research is done, and how. The outcomes of research should be considered a public good and scientists allowed a degree of autonomy. Economists see this differently though.

Chapter 5: The three traditions set out on chapters 2-4 (poliucy analysis, organisational design and research direction, are all confident that solutions can be found . But there is overselling of poorly evidenced prescriptions. Economists with concepts, logic and cost-benefit analysis (CBA) ``the rigor of their arguments has tended to bedazzle the eyes and to take away from the shabbiness of their predictions'' p76.

We probably need a new way of looking at policy problems at least a combination of existing traditions. 

Chapter 6: A detailed study of childcare provision - a policy problem. 

Private for-profit is not fully trusted and public provision is perceived as uniform. The market doesn't work because there is not perfect information and so some way of allowing observation of childcare in progress is needed. Also non-profit organisations don't tend to expand if the need increases so a body is required to oversee this to encourage increases in provision where required.

Chapter 7: A study of state sponsored R\&D into supersonic flight and nuclear energy.

The state supports agriculture, medicare but supersonic flight and nuclear don't fit in here. In the US, these were supported because some individuals in government could see that rate development was not matching its potential. Success in technology cannot be orderly. CBA does not go deep enough.

Discussion of change, adaptation and responses with respect to the organisation and innovation p137

Organisations have, separately: demand, supply and innovation generation. However their interaction is essential. p139

Discussion of regulation of supply, the flexibility of supply and the quality of supply p141

The producers interests should count for very little - the consumer should be priority. p151 
But CBA nets the consumers' losses with the producers' gains p152

``certain things are not well known and those who propose solutions are either charlatans or fools'' p153

From Kattel lecture - this books says that we cannot solve the ghetto problem if we continue to look for answers in science - these problems are too complex.},
  creationdate     = {2022-11-07T16:01:36},
  keywords         = {economics, policy, innovation, organisations},
  modificationdate = {2023-01-16T14:32:49},
  owner            = {ISargent},
}

@Article{OttoDCS2020,
  author           = {Ilona M. Otto and Jonathan F. Donges and Roger Cremades and Hans Joachim Schellnhuber},
  date             = {2020-01-21},
  journaltitle     = {Social Sciences},
  title            = {Social tipping dynamics for stabilizing Earth's climate by 2050},
  url              = {https://www.pnas.org/doi/10.1073/pnas.1900577117},
  comment          = {There is evidence for rapid change in society due to social, economic, environmental, etc conditions. Contagious processes of rapidly spreading technologies, behaviors, social norms, and structural reorganization in parts of the socioeconomic system (social tipping elements, STEs). This paper looks at the social tipping tipping interventions that could trigger tipping in different STEs.

1. removing fossil-fuel subsidies and incentivizing decentralized energy generation (STE1, energy production and storage systems)
2. building carbon-neutral cities (STE2, human settlements)
3. divesting from assets linked to fossil fuels (STE3, financial markets)
4. revealing the moral implications of fossil fuels (STE4, norms and value systems)
5. strengthening climate education and engagement (STE5, education system)
6. disclosing information on greenhouse gas emissions (STE6, information feedbacks)},
  creationdate     = {2022-11-07T20:45:03},
  keywords         = {sociology, climate, economics, policy},
  modificationdate = {2022-11-07T20:52:57},
  owner            = {ISargent},
}

@Article{Geels2020,
  author           = {Frank W. Geels},
  date             = {2020},
  journaltitle     = {Technological Forecasting \& Social Change},
  title            = {Micro-foundations of the multi-level perspective on socio-technical transitions: Developing a multi-dimensional model of agency through crossovers between social constructivism, evolutionary economics and neo-institutional theory},
  doi              = {https://doi.org/10.1016/j.techfore.2019.119894},
  comment          = {Quite a paper

Geels Multi-level perspective (MLP) theory of transitions has been developed since first publication 2002  by developing ideas, in response to criticism and by other authors. This paper takes the MLP theory and looks at other related theories in different fields and compares them with MLP, highlighting aspects that are borrowed and are crossovers.

This is a useful paper to return to for detail on MLP as well as the related theories of Social construction of technology (SCOT), Evolutionary economics and Neo-institutional theory.

The basic idea MLP is that technological innovations occur in niches. Some will gradually building up internal momentum and may place some pressure on the wider socio-technical regime (e.g. markets, industry, policy, science, etc) which may resist the change. The regime also exists within a wider socio-technical landscape which is external. Developments in the landscape also puts pressure on the regime and the niches. Changes in landscape open up windows of opportunity for the innovations to break into the regime which both changes the regime and the landscape.

SCOT sits within the Science and Technologies Studies (STS) field (this is discussed in Martin2012). ``innovation is a social process of aligning heterogeneous elements, which involves actors moving between spheres such as science, markets, regulation and production.'' Core notions from SCOT within MLP are thet the MLP conceptualises technologies as socially constructed, rather than developing according to an internal technical logic, shares the broader STS assessment that science and technology are omnipresent in modern societies, and have contributed to major transformations in agro-food, energy, transport, housing, entertainment, and communication in the last two centuries.

``Evolutionary economics has two complementary components, which are relevant for transitions and the MLP. Macro-evolution addresses long-term techno-economic patterns ... Schumpeter (1939: 102) ... Micro-evolution concerns mechanisms of variation, selection and retention that underlie genealogical lineages and trajectories ... Nelson and Winter (1982)''. The ideas of transition are part of MLP (later MLP accommodates more gradual transitions, however). The regime, technological trajectory and path dependence in MLP are derived from evolutionary economics. Other aspect of MLP come from evolutionary biology.
 
Neo-institutional theory: Institutional theory is important, because ‚Äúrules, norms, and belief systems undergird all stable social systems, including economic systems‚Äù (Scott, 2008: 437). Fits especially with the regimes aspect.


``Institutional theory emphasizes that organizations operate not only in economic environments, but also in institutional environments'' - competition is for social fitness, which arises from appropriateness or legitimacy. These may influence reputation, license-to-operate, access to capital and government support are 

Transitions research

``Framing struggles are consequential because it matters if a problem like climate change is framed as a `market failure' (which would lead to market-based instruments such as a carbon tax) or as a `planetary boundary' (which may lead to stronger regulatory or innovation policies with greater urgency). It also matters how specific innovations are framed: are wind turbines seen as renewable energy technologies or as ugly artefacts that spoil the landscape and kill birds? Are nuclear plants framed as low-carbon technologies or as existential threats? The implication is that transitions should not only be seen as techno-economic management challenges, but also as socio-cultural processes which involve wider publics and cultural meanings.''},
  creationdate     = {2022-11-08T20:17:57},
  keywords         = {sociology, innovation, economics, transformation},
  modificationdate = {2023-02-22T17:14:31},
  owner            = {ISargent},
}

@Article{WeissC2017,
  author           = {Martin Weiss and Claudio Cattaneo},
  date             = {2017},
  journaltitle     = {Ecological Economics},
  title            = {Degrowth - Taking Stock and Reviewing an Emerging Academic Paradigm},
  pages            = {220--230},
  url              = {https://www.sciencedirect.com/science/article/pii/S0921800916305900},
  volume           = {137},
  comment          = {Alternative development trajectories for the global economy have received more interest/effort since the 2008 financial crisis

Degrowth is marginal, left-wing, European

``degrowth has emerged as a radical call for a voluntary and equitable downscaling of the economy towards a sustainable, just, and participatory steady-state society (R\&D, 2010; Schneider et al., 2010; Kallis, 2011)''

``degrowth postulates that indefinite economic growth on a finite planet is impossible; facilitating growth as the overarching aim of socio-economic policy will eventually lead to involuntary economic decline with far-reaching social and political consequences''

Paper identifies that theory is well-versed by hypothesis testing and empirical results are lacking. It also needs to be more inclusive of marginalised poor. 

Also identifies wider benefits of degrowth (than just on environment) such as reduced psychological stress and increase community collaboration.

Appendix A covers references to history and context of degrowth, conceptual aspects of degrowth, characterisation of the economy, elements of systems theory, complementary initiatives (to degrowth field), deviant views and degreowth critique, empirical insights, degrowth implementation examples.},
  creationdate     = {2022-11-11T11:23:48},
  keywords         = {economics, degrowth, climate},
  modificationdate = {2022-12-13T19:39:18},
  owner            = {ISargent},
}

@Article{RodriguezLabajosEtAl2019,
  author           = {Beatriz Rodr\`{i}guez-Labajos and Ivonne Y\'{a}nez and Patrick Bond and Lucie Greyl and Serah Munguti and Godwin Uyi Ojo and Winfridus Overbeek},
  date             = {2019},
  journaltitle     = {Ecological Economics},
  title            = {Not So Natural an Alliance? Degrowth and Environmental Justice Movements in the Global South},
  doi              = {https://doi.org/10.1016/j.ecolecon.2018.11.007},
  issn             = {0921-8009},
  pages            = {175--184},
  url              = {https://www.sciencedirect.com/science/article/pii/S0921800918307626},
  volume           = {157},
  comment          = {Identifies areas of discord between degrowth movement and environmental justice move in the Global South (EJ):

- Degrowth is not an appealing term in the South	
  - Different history/experience of poverty and scarcity
  - `Voluntary' degrowth, only through crises and urban elites
  - Against the people's basic principles of living and working hard
  - Growing (e.g., healthy crops, creativity) is part of EJ agendas
  - Austerity is a ``degrowth strategy for poor people''
- Beyond detached terms, detached ideas \& approaches	
  - Multiple meanings of ideas in multi-cultural, pluri-national countries
  - Degrowth is too anthropocentric
  - Issues framed differently from how Southern groups organize and discuss problems
- Communication (\& dissemination) issues	
  - Still scant mention of Degrowth among activist groups in the South
  - Semantic controversies: denying the opponent actually legitimises it
  - Other language is suggested: redistribution; appropriate use of welfare‚Ä¶
- Eurocentric thinking (again!)	
  - Western/high-income countries centred approach -> individualistic
  - Aversion to standardising principles that undermine the flourishing of local initiatives
- Not radical enough	
  - Degrowth proposals seem to accommodate stances within the boundaries of the system (not shared perspective!): is degrowth anti-capitalist?
  - Why not move the discourse towards other terms such as eco-socialism, re-commoning, Nature-centred perspective?

Its not all back and this paper also identifies analogies between degrowth and environmental justice in the South around the themes of time, resource availability, hard infrastructure, finances, institutions and socio-economics organisation, commons, social comparison, material needs and consumer imaginary},
  creationdate     = {2022-11-11T12:01:26},
  journal          = {Ecological Economics},
  keywords         = {Degrowth, Environmental justice, Global South, economics},
  modificationdate = {2022-11-11T12:10:18},
  owner            = {ISargent},
  year             = {2019},
}

@Article{Koster2022,
  author           = {Ferry Koster},
  date             = {2022},
  journaltitle     = {Journal of Advances in Management Research},
  title            = {Organizations in the knowledge economy. An investigation of knowledge-intensive work practices across 28 European countries},
  issn             = {ISSN: 0972-7981},
  url              = {https://www.emerald.com/insight/content/doi/10.1108/JAMR-05-2021-0176/full/html},
  comment          = {Analyses are based on data about over 20,000 companies in 28 European countries

Identify knowledge intensive working practices (KIWP) grouped broadly under
1. decentralized decision making (producing knowledge)
  - tend to rely more on self-organization, autonomy and decentralized decision making
2. organizational learning practices (developing and distributing knowledge)
  - formal and informal learning practices help organizations to develop unique resources enabling them to be competitive
3. the use of technology (applying knowledge)
  - people doing work that is more knowledge-intensive are more likely the work with IT

concluded that the use of these practices is more common in Sweden, the UK and Finland and that companies in Romania, Bulgaria and Lithuania make less use of these practices},
  creationdate     = {2022-11-11T13:01:34},
  keywords         = {organisation, innovation, transformation, economics},
  modificationdate = {2022-11-25T18:52:34},
  owner            = {ISargent},
}

@InCollection{JovanovicR2005,
  author           = {Boyan Jovanovic and Peter L. Rousseau},
  date             = {2005},
  title            = {Chapter 18 - General Purpose Technologies},
  doi              = {https://doi.org/10.1016/S1574-0684(05)01018-X},
  editor           = {Philippe Aghion and Steven N. Durlauf},
  pages            = {1181-1224},
  publisher        = {Elsevier},
  series           = {Handbook of Economic Growth},
  url              = {https://www.sciencedirect.com/science/article/pii/S157406840501018X},
  volume           = {1},
  abstract         = {A general purpose technology or GPT is a term coined to describe a new method of producing and inventing that is important enough to have a protracted aggregate impact. Electricity and information technology (IT) probably are the two most important GPTs so far. We analyze how the U.S. economy reacted to them. We date the Electrification era from 1894 until 1930, and the IT era from 1971 until the present. While we document some differences between the two technologies, we follow David [In: Technology and Productivity: The Challenge for Economic Policy (1991) 315-347] and emphasize their similarities. Our main findings are: 1.Productivity growth in the two GPT eras tended to be lower than it was in other periods, with productivity slowdowns taking place at the start of the two eras and the IT era slowdown stronger than that seen during Electrification.2.Both GPTs were widely adopted, but electricity's adoption was faster and more uniform over sectors.3.Both improved as they were adopted, but measured by its relative price decline, IT has shown a much faster improvement than Electricity did.4.Both have spawned innovation, but here, too, IT dominates Electricity in terms of the number of patents and trademarks issued.5.Both were accompanied by a rise in ‚Äúcreative destruction‚Äù and turbulence as measured by the entry and exit of firms, by mergers and takeovers, and by changing valuations on the stock exchange. In sum, Electrification spread faster than IT has been spreading, and it did so more evenly and broadly over sectors. Also, IT comprises a smaller fraction of the physical capital stock than electrified machinery did at its corresponding stage. On the other hand, IT seems to be technologically more dynamic; the ongoing spread of IT and its continuing precipitous price decline are reasons for optimism about productivity growth in the 21st century.},
  comment          = {Bresnahan and Trajtenberg (1996) argue that a GPT should have the following three characteristics:
1. Pervasiveness - The GPT should spread to most sectors.
2. Improvement - The GPT should get better over time and, hence, should keep lowering the costs of its users.
3. Innovation spawning - The GPT should make it easier to invent and produce new products or processes.

Paper compares the Electrification and IT eras

May be worth returning to to consider how plausable a general model of technological revolutions is

[IZ - c.f. surges in Perez2002]},
  creationdate     = {2022-11-11T16:52:07},
  issn             = {1574-0684},
  keywords         = {technology, innovation, economics, growth},
  modificationdate = {2022-12-11T13:25:55},
  owner            = {ISargent},
}

@InCollection{Dow2000Ch5,
  author           = {Dow, Christopher},
  booktitle        = {Major Recessions: Britain and the World 1920-1995},
  date             = {2000},
  title            = {Shocks and Responses in Major Fluctuations},
  chapter          = {5},
  doi              = {10.1093/0199241236.003.0005},
  eprint           = {https://academic.oup.com/book/0/chapter/297065838/chapter-ag-pdf/44508820/book_34766_section_297065838.ag.pdf},
  isbn             = {9780199241231},
  publisher        = {Oxford University Press},
  url              = {https://doi.org/10.1093/0199241236.003.0005},
  abstract         = {{This chapter discusses how the economy behaves in the course of major fluctuations. The detailed case studies of individual major recessions in Part II of the book suggest extensions to the standard account of the economic response to shocks. These are expounded in Sect. 5.1, which thus completes the theoretical introduction to the case studies provided in Part I. Section 5.2 is primarily empirical and tests statistical indicators of some main types of shock, and Sect. 5.3 uses this material to give a summary characterization of large and small fluctuations. Appendix A5 gives new estimates of fiscal policy impact.}},
  comment          = {older view is that economic fluctuations are caused by endogenous factors, then that they are cause by exogenous forces. This book is largely in agreement with the latter but notes some endogenous effects such as sings of confidence



Considers the last 5 major recessions (1920-21, 1929-32, 1973-75, 1979-82 and 1989-93) and looks at evidence for:
(a) the reaction to a shock of consumers - largely about prospects and optimism in terms of consumption, dept creation and dept repayment. Identifies that confidence is not necessarily in line with economic fluctuations since consumer will carry past experience forward. Finds that `expections' assumes more clarity of the future than most comsumers have.
(b) the reaction of business - investments are in response to confidence and can have an amplifying (sometimes stabilising) effect on output fluctuations meaning that stock changes contributed to almost all recessions
(c) the reaction of the whole system - ``Consumers' behaviour and firms' investment behaviour together determine the economy's response to shocks, and go far to determine macro fluctuations.''

``In all major recessions, fixed investment was heavily affected and in most cases constituted a fair share of the recession (e.g. a quarter). In two cases (1973 and 1979) this was in part the result of contractionary monetary policy. In all cases it probably reflected also a lessening of confidence induced by the fall in output. Loss of confidence evidently also affected consumer spending in some cases. Thus, changes in mood seem to have been a factor in all major recessions.''

`` it takes longer to restore than to destroy confidence, and once destroyed it may respond less to new positive impulses.''},
  creationdate     = {2022-11-12T18:56:00},
  keywords         = {economics, shocks, recession},
  modificationdate = {2022-11-27T19:52:05},
  owner            = {ISargent},
}

@InCollection{Dow2000Ch4,
  author           = {Dow, Christopher},
  booktitle        = {Major Recessions: Britain and the World 1920-1995},
  date             = {2000},
  title            = {Supply and Demand Influences on the Rate of Growth},
  chapter          = {4},
  doi              = {10.1093/0199241236.003.0004},
  eprint           = {https://academic.oup.com/book/0/chapter/297065069/chapter-ag-pdf/44508779/book_34766_section_297065069.ag.pdf},
  isbn             = {9780199241231},
  publisher        = {Oxford University Press},
  url              = {https://doi.org/10.1093/0199241236.003.0004},
  abstract         = {{This book is mostly about demand, and how in the short term fluctuations in demand cause fluctuations in output and productivity growth. Over the longer term, major variations in growth rates have undoubtedly originated from the supply rather than the demand side. The aim of this chapter is to summarize what is known in general about variations in the rate of growth; and to argue that the kind of effects that supply‚Äêside factors have is different from what is needed to explain the abrupt short‚Äêterm falls in output that occur in major recessions. The discussion thus touches on a large subject of which knowledge is incomplete, but since its relevance is indirect, discussion is brief and touches only on what is essential for the present purpose: Sect. 4.1 summarizes what is known about variations in growth rates; Sect. 4.2 first gives a general explanation--eclectic but not basically novel for the process of growth, and then goes on to offer explanations for some particular ways in which growth rates have varied since 1920; Sect. 4.3 summarizes conclusions. There are two short appendices: Appendix A4.l is a note on growth accounting and two other studies of growth; Appendix A4.2 gives estimates of the growth of output and exports of manufactures of six countries from 1870 to 1970.}},
  comment          = {``The conclusion I come to is that major long‚Äêterm variations in the rate of growth of productivity‚Äîin the same country over time and also between countries‚Äîhave probably originated (chiefly) on the supply side. On the other hand, the kind of abrupt short‚Äêterm falls in output, productivity, and employment that occur in major recessions‚Äîusually in many countries simultaneously or at nearly the same time‚Äîmust have originated largely or entirely from the demand side, and must occur essentially through the effect of recession on employment and on (human and physical) investment''},
  creationdate     = {2022-11-12T19:48:31},
  keywords         = {economics, shocks, recession, supply, demand},
  modificationdate = {2022-11-27T19:51:46},
  owner            = {ISargent},
}

@InCollection{Dow2000Ch12,
  author           = {Dow, Christopher},
  booktitle        = {Major Recessions: Britain and the World 1920-1995},
  date             = {2000},
  title            = {Are Recurrent Major Recessions Inevitable?},
  chapter          = {12},
  doi              = {10.1093/0199241236.003.0012},
  eprint           = {https://academic.oup.com/book/0/chapter/297080307/chapter-ag-pdf/44508776/book_34766_section_297080307.ag.pdf},
  isbn             = {9780199241231},
  publisher        = {Oxford University Press},
  url              = {https://doi.org/10.1093/0199241236.003.0012},
  abstract         = {{Previous chapters of this book have sought to explain why the major recessions of the twentieth century occurred; this chapter tries to answer the question of whether recurrent major recessions are inevitable, or whether there are steps that governments (or central banks) can take to avoid or mitigate them. The questions involved extend beyond those dealt with earlier, and raise not only the disputable issues of economic theory but also many new ones, including broadly political questions. Section 12.1 deals with background issues, attributing a degree of effectiveness to policy, and recapitulating this and other respects in which the author's view differs from a neoclassical view; the general limits to state action are then discussed, and finally a view is set out about inflation. Section 12.2 deals with general questions about the instruments of economic policy; despite the waves of deconstruction that are generally taken to have destroyed the intellectual foundations for a Keynesian fiscal policy, the author sees a theoretical case for it--along with severe practical limits that stem from the reactions of financial markets to government borrowing; the section goes on to discuss the effect and role of monetary policy. Section 12.3 turns to practical possibilities, and considers the kind of action that, despite the above constraints presented, ought to be possible; Sect. 12.4 then assesses the likelihood that governments will avoid or minimize major recessions in the future.}},
  comment          = {Discussion of pressures on governments/ministers that lead them to take short term action on recessions and also to tend towards countering inflation rather than to promote recovery ``The Bias of Policy Towards Disinflation Rather Than Expansion''

Considers that inflation is not easily controlled with monetary policy and that taxation has been demonstrated in countries experiencing hyperinflation (due to poor tax collection plus spending) to restore fiscal order

``A strong government that was prepared to defend its policy and appeared competent and businesslike might be in a position to adopt a more positive and explicit policy of expansion that involved enlarged deficits for a period of years.''

Really useful chapter on Fiscal and Monetary policy - worth returning to.},
  creationdate     = {2022-11-12T19:56:28},
  keywords         = {economics, shocks, recession, fiscal, monetary},
  modificationdate = {2022-12-02T21:55:46},
  owner            = {ISargent},
}

@Book{Chang2014,
  author           = {Chang, Ha-Joon},
  title            = {Economics: The User's Guide},
  isbn             = {9780718197032},
  publisher        = {Pelican},
  comment          = {Just fantastic - not yet finished but absolutely covers everything really clearly

Say's Law p116},
  creationdate     = {2022-11-12T20:16:38},
  modificationdate = {2022-12-03T11:25:26},
  owner            = {ISargent},
  year             = {2014},
}

@Article{ChangA2021,
  author           = {Ha-Joon Chang and Antonio Andreoni},
  date             = {2021},
  journaltitle     = {The European Journal of Development Research},
  title            = {Bringing Production Back into Development: An introduction},
  doi              = {https://doi.org/10.1057/s41287-021-00359-3},
  issue            = {2},
  pages            = {165--178},
  volume           = {33},
  abstract         = {Production was at the heart of economics from the days of Classical economics. However, with the rise of Neoclassical economics in the late 19th century, production has lost its status as the ultimate interest of economics. Several opportunities for fruitful integration of alternative streams of economics research‚ÄîEvolutionary, Structuralist and Keynesian in particular‚Äîhave been also missed. Even the humanist approaches to development, such as Sen's Human Capability Approach, paid little attention to the domain of production. In this article, we argue that the fragmentation of the production-centred paradigm has weakened both academic research and policy-making related to economic development. We introduce and discuss eight articles developed around the special issue theme of Bringing Production Back into Development. We argue that a renewed `productionist' agenda is essential to address the structural challenges faced by developing countries, even more so after the revelation of structural weaknesses by the pandemic.},
  creationdate     = {2022-11-13T11:56:24},
  keywords         = {economics, production},
  modificationdate = {2022-11-19T11:33:35},
  owner            = {ISargent},
}

@Article{AndreoniC2017,
  author           = {Andreoni, Antonio and Chang, Ha-Joon},
  date             = {2017},
  journaltitle     = {Cambridge Journal of Regions, Economy and Society},
  title            = {{Bringing production and employment back into development: Alice Amsden's legacy for a new developmentalist agenda}},
  doi              = {10.1093/cjres/rsw029},
  eprint           = {https://academic.oup.com/cjres/article-pdf/10/1/173/10492398/rsw029.pdf},
  issn             = {1752-1378},
  number           = {1},
  pages            = {173--187},
  url              = {https://doi.org/10.1093/cjres/rsw029},
  volume           = {10},
  abstract         = {{Building on Alice Amsden's legacy, the article criticises the currently dominant view of development for its neglect of production and employment. To remedy its shortcomings, the article introduces a new theoretical synthesis that sees development as a process of production transformation, led by the expansion of collective capabilities and resulting in the creation of good quality jobs and sustainable structural change. Within this new developmentalist framework, the article highlights the policy challenges, the opportunities and the trade-offs associated with reconciling industrialisation, generation of good quality jobs and environmental sustainability, as emerging from the post-2015 sustainable development goals.}},
  comment          = {Critiques current view of development which is a combination of Neoclassical (NC) (from after WWII) with Amartya Sen's Capability Approach (CA) (from 1980s). 

Whilst production was fundamental to classical ideas about development, NC became increasing fixated on markets resulting in:
1. production is a black box
2. technological and organisation learning in production is  barely considered
3. assumptions that production is homogeneous
4. economy is framed as transaction between individuals (atomistic assumption)
5. bias towards consumption

CA criticised NC but remained:
1. individualistic, neglecting the collective dimensions of the economy
2. focused on consumption being key to human welfare, neglecting the role of production (e.g. that a job is about more than earning to consume)

Result is neglect of full and productive employment as a critical dimension of development

By focussing on markets rather than production, economic consequences could include undermining the innovative effects of large organisations if policies implemented to correct monopolies without descretion

By considering production homogeneous, policies are applied across whole economy rather than providing selective supports

The atomistic assumption neglects behaviour inside organisations and their collective nature

Pro-consumer (rather than producer) (a bit like Say's Law) leads to policies to alleviate poverty rather than un/under-employment

Proposes New Developmentalist Perspective

* Recognise the ``inevitably collective nature of the production process''
* ``Productive structures are ecomplex social organisations''
* transformation of production will transform institutions, society and ideology
* Production is heterogeneous inputs, outputs, firms, production units
* Physical effort may be reduced, intellectual effort increased

Looks at Sustainable Development Goals (SDGs) 
* Undervaluing of production

``point out the critical need to understand the trade-offs between different sustainability dimensions‚Äîsocial, environmental and economic‚Äîand the need to reconcile them in a way that allows developing countries to transform their production structure and create good employment.''},
  creationdate     = {2022-11-13T11:58:05},
  keywords         = {economics, production, organisation, work, development},
  modificationdate = {2022-11-25T22:41:04},
  owner            = {ISargent},
  relevance        = {relevant},
}

@Article{Chang2002,
  author           = {Ha-Joon Chang},
  date             = {2002},
  journaltitle     = {Cambridge Journal of Economics},
  title            = {Breaking the mould: an institutionalist political economy alternative to the neo-liberal theory of the market and the state},
  number           = {5},
  pages            = {539--559},
  url              = {https://www.jstor.org/stable/23600312},
  volume           = {26},
  comment          = {Critiques neo-liberal (NL) economics and proposes  Institutionalist Political Economy (IPE)

Another easy read from Chang!

NL `unholy' alliance between neoclassical (NC) (analytical tools) and Austrian-libertarian (political and moral philosophy)

State cannot be assumed to be impartical, onmipotent social guardian but self-seeking politicians under pressure from interest groups leads to government failures

NL absorbed welfare economics as it was `non-commital' (unlike Keynesianism) and and found ways to avoid state intervention such as minimising the state, prioritising entrepreneurship and finding interventionist policy too difficicult or dangerous

I understand that NC was still dominant in academia but NL in politics - not sure if NL ever really existed in academia?

NL has limitations that are rarely interrogated:
* foundation of free-market is flawed, all markets are regulated e.g. child labour is illegal
* market failures exist but are inconsistenly understood/defined. Failures of the market (e.g. inequality) are irrelevant in NC economics. Also a perfect market to NC is a non-competitive market failure in Schumpeterian economics (because innovations are immediately dissipated destroying the incentives for entrapreneurship. Markets are only. Instead says that institutional economics sees markets as one of many institutions of the capitalist economy
* despite definitive counter-evidence, NL tends to assume that markets came before states. And yet evidence is that states have both created and shaped markets.
* NL see markets as non-political but they demonstrably are: rights, wages, standards, entitlements, immigration control - all have political dimension

IPE is not New Institutionalist Economics but founded on work of Marx, Veblen, Schumpter, Polanyi and others

Includes acceptance that human motivations are varied, complexly interacting and institutions play a role in this

Bringing institutions and politics into the analytical core},
  creationdate     = {2022-11-13T12:38:01},
  keywords         = {economics, institutions, policy},
  modificationdate = {2022-11-13T13:45:04},
  owner            = {ISargent},
}

@TechReport{Buchanan2003,
  author           = {James M. Buchanan},
  date             = {2003},
  institution      = {Center for Study of Public Choice, George Mason University},
  title            = {Public Choice: The Origins and Development of a Research Program},
  url              = {https://s3.us-east-1.amazonaws.com/publicchoicesociety.org-assets/content/general/PublicChoiceBooklet.pdf},
  comment          = {On the back of Arrow's impossiblity theorem, Arrow and Black's welfare economics (market failure to meet idealised standards)

Democracy interpreted as a majority voting can not work

Theoretical demonstrations of how individuals welfare is not maximised by government, collective choice is inefficient.

Introduced The Calculus of Consent with two-level  framework of ordinary politics (decisions made by voting) and constitutional politics (decisions made according to frameworks)

``Public choice includes both `methodological individualism' and `rational choice', directly from economic theory to the analysis of politics. At one level of abstraction, these two elements are themselves relatively empty of empirical content. To model the behavior of persons, whether in markets or in politics, as maximizing utilities, and as behaving rationally in so doing, does not require specification of the arguments in utility functions. Economists go further than this initial step, however, when they identify and place arguments into the categories of `goods' and `bads'. Persons are then modeled as acting so as to maximize some index of ‚Äúgoods‚Äù and to minimize some index of `bads'.'' - provides some justification for this approach.

Also claims failure of collectivist schemes - nonperformance measured against promised claims.

No empirical evidence, anywhere},
  creationdate     = {2022-11-13T13:47:58},
  keywords         = {economics, policy, public choice},
  modificationdate = {2022-11-13T14:16:30},
  owner            = {ISargent},
}

@Article{Backhouse2005,
  author           = {Roger E. Backhouse},
  date             = {2005},
  journaltitle     = {History of Political Economy},
  title            = {The Rise of Free Market Economics: Economists and the Role of the State since 1970},
  doi              = {https://doi.org/10.1215/00182702-37-Suppl_1-355},
  pages            = {355--392},
  url              = {https://read.dukeupress.edu/hope/article-abstract/37/Suppl_1/355/92366/The-Rise-of-Free-Market-Economics-Economists-and},
  volume           = {37},
  comment          = {Tells the history of economic thinking 1970-2000 from a number of perspectives. 

Change in opinion towards belief that high rewards were needed to provide incentives and drive productivity and that mobility meant people would not get stuck even if tail of the income distribution were getting bigger (aka increasing inequality)

Until 1970s, governments were assumed to be concerned with maximising social welfare and to have all the information they needed

oil crisis (1973-4) (major supply shock), depression, inflation, unemployment - all as Friedman predicted and Keynsian theory could not account for

Regulation was seen as creating perverse incentives and distorting resource allocation

Work on Public Choice Theory in 1960s developed ideas around government optimising social welfare function with assumptions that state is inefficient and state actors are motivated by their own ends

competition introduced into the electricity and gas

Hayek has earlier (1930s) critiqued socialism.

Public Choice Theory and Hayek were theoretical but real-world experience of stated owned enterprises and regulating the private sector seemed to bare out thesee ideas

Nordhaus1975 model of the manipulation of policy to maximise chances of reelection by myopic voters

In 1950s and 60s ideas included selective industrialisation and protection and import substiution to develop. In 1970s interst turned to the application of standard economics based on utility and profit maximisation. in the 1980s emphasis on fiscal discipline and market liberalisation latbelled as Washington Consensus in 1990 by John Williamson.

As an alternative to Marxism, rational choice liberalism had three broad elements:
- self-interested rational actor
- set-theoretic and axiomatic treatment of human rationality
- commitment to univrsal and objective scientific law

Keynes, Toynbee, Russell, Spengler, Eliot and Schumpeter had all argued that capitalism would collapse.


Think tanks played a huge role in spreading ideas and influencing politicians, some wanting to avoid socialism that would result from capitalisms collapse, also looking to counter how ideas from the liberal (left) Brookings Institution were entering policy and counter the New Deal coalition. Influenced Thatcher and Reagan: including RAND Corporation, Mont Pelerin Society and Institute of Economic Affairs

Univerisities and instiutional organisations also played a part: University of Chicago (Friedman), Public Choice Society, Thomas Jerfferson Center, Center for Study of Public Choice, (New York University, George Mason and Auburn) (``Austrians'')

In the 1980s IMF became involved in more than providing short-term loads, negotiating credit packages. World Bank made loads with conditions of liberalising economies.

Notes that initiaties are result of wealthy individuals funding research and promotion

Moreover, the very nature of economics, despite ideas that for example using mathematics protects it from ideology, is subject to value judgements including the nature of mathematics chosen.

``Good economics'' a subject discussed at workshops},
  creationdate     = {2022-11-13T16:23:45},
  keywords         = {economics, history, policy},
  modificationdate = {2022-11-25T22:40:26},
  owner            = {ISargent},
  relevance        = {relevant},
  year             = {2005},
}

@Article{Simon1991,
  author           = {Simon, Herbert A.},
  journaltitle     = {Journal of Economic Perspectives},
  title            = {Organizations and Markets},
  doi              = {10.1257/jep.5.2.25},
  issue            = {2},
  pages            = {25--44},
  url              = {https://www.aeaweb.org/articles?id=10.1257/jep.5.2.25},
  volume           = {5},
  comment          = {Neoclassical economics focused on markets but organisations are dominant feature of economic landscape and most actors in modern economy are agents of the firm. This paper considers why there are firms and what motivates those who work within them.

Rather than a market economy, we have an organisational economy. However the boundary between markets and organisations is blurred, and varies with society within which the markets and organisations sit

In employees utility function, work is usually considered to have negative utility (loafing/shirking has positive utility). Neoclassical economics says that it's the contract that motivates the employee to accept authority and leaves the utility function open to be specified. However this doesn't stack up - many employees go beyond contact and contracts are usually ``incomplete''

``New institutional economics and related approaches are acts of faith, out perhaps piety''

Firm size and number has Pareto distribution - this didn't match ideas of optimum firm size but does indicate a probabilistic mechanism

There is a gap between ownership and control, goals of owners - profit, goals of managers - career status, wealth, quiet life

New institutional economics finds that employment achieves great savings on transaction costs

Factors in organisations:
- Rewards as motivators - these are difficult to specify especially in roles with a great deal of interdependence and evidence is that rewards alone have limited motivational effect
 - Loyalty and identification with organisational goals - discussion of `docility' and how it leads to altruism and positive outcomes for organisations that cultivate loyalty and [I guess what we now call engagement]
- Coordination - probably emerges out of necessities it at least efficiencies and allows actors to form more stable expectations. Coordination probably has wholly economic motivations and rewards when it is between organisations but within them it combats externalities

Note Devons' point that if markets had a simplifying effect, why is it we turn to central planning on complex situations such as war

At the end, calls for gathering of evidence to understand economic systems},
  creationdate     = {2022-11-17T06:57:19},
  keywords         = {economics, organisations},
  modificationdate = {2022-11-17T08:39:44},
  owner            = {ISargent},
  year             = {1991},
}

@Article{ForayMN2012,
  author           = {D. Foray and D.C. Mowery and R.R. Nelson},
  date             = {2012},
  journaltitle     = {Research Policy},
  title            = {Public {R\&D} and social challenges: What lessons from mission {R\&D} programs?},
  doi              = {https://doi.org/10.1016/j.respol.2012.07.011},
  issn             = {0048-7333},
  note             = {The need for a new generation of policy instruments to respond to the Grand Challenges},
  number           = {10},
  pages            = {1697-1702},
  url              = {https://www.sciencedirect.com/science/article/pii/S0048733312002193},
  volume           = {41},
  comment          = {Editorial piece from special issue on mission-oriented public {R\&D} programs. Gives overview of problem and describes content of special issue.

Considers Manhattan Project and Apollo Missions but recognises that are also not the right models for the challenges we face (climate change, disease).

Papers in the issue includes summaries of programmes in particular fields as well as policy instruments for developing mission oriented {R\&D}.

Defence R\&D large investment and considered `surreptitious' industrial policy

Health R\&D is often focussed on particular diseases

Energy R\&D is a common area with goals from climate change abatement to improved economic competitiveness

Instruments include:
- Public procurement, more effective outcomes if broad function of innovation rather than technical specification is given. Also more effective in combination with other instruments such as R\&D investment
- regulation and taxes combined with vigorous technology policy
- R\&D subsidy - little incentive in future economic landscape is uncertain
- Grand Innovation Prizes - may bring in actors who would not otherwise have engaged. how much IP to grant to winners?

Public programmes should
- focus on long term support
- encourage many different technologies
- create strong demand from potential users
- use patenting (with licenses) as last resort
- cultivate excellent communications
- avoid capture by powerful user groups
- promote technology adoption as well as development
- decentralise to bring in diverse player by centralise administration
- stable and credible funding},
  creationdate     = {2022-11-17T07:26:11},
  keywords         = {economics, innovation, research, policy, instruments},
  modificationdate = {2022-11-17T19:10:17},
  owner            = {ISargent},
}

@Article{GraceSDZE2016,
  author           = {Katja Grace and John Salvatier and Allan Dafoe and Baobao Zhang and Owain Evans},
  title            = {When Will {AI} Exceed Human Performance? Evidence from {AI} Experts},
  eprint           = {1705.08807},
  eprinttype       = {arXiv},
  url              = {http://arxiv.org/abs/1705.08807},
  volume           = {abs/1705.08807},
  bibsource        = {dblp computer science bibliography,  \url{https://dblp.org}},
  biburl           = {https://dblp.org/rec/journals/corr/GraceSDZE17.bib},
  comment          = {Survey of 352 `top' AI researchers. Lots of disagreement.

When will machines achieve high level machine intelligence - wide range of views and depends on how the question was asked

Also discusses AI safety and how experts seem to underestimate the need to address this (despite `5\% chance of human extinction')

Summarised brilliantly here:  \url{https://www.youtube.com/watch?v=HOJ1NVtlnyQ}},
  creationdate     = {2022-11-17T08:35:16},
  journal          = {CoRR},
  modificationdate = {2022-11-17T08:40:01},
  owner            = {ISargent},
  timestamp        = {Mon, 13 Aug 2018 16:46:02 +0200},
  year             = {2017},
}

@Article{BertiL2014,
  author           = {Pietro Berti and Les Levidow},
  date             = {2014},
  journaltitle     = {Energy Policy},
  title            = {Fuelling expectations: A policy-promise lock-in of UK biofuel policy},
  doi              = {https://doi.org/10.1016/j.enpol.2013.09.044},
  issn             = {0301-4215},
  pages            = {135-143},
  url              = {https://www.sciencedirect.com/science/article/pii/S0301421513009683},
  volume           = {66},
  abstract         = {Controversy over EU-wide biofuel policy resonated within the UK, fuelling policy disagreements among UK public authorities. They disagreed over how to protect a space for future second-generation biofuels, which were expected to overcome harm from first-generation biofuels. The UK government defended rising targets for available biofuels as a necessary stimulus for industry to help fulfil the UK's EU obligations and eventually develop second-generation biofuels. By contrast, Parliamentary Select Committees opposed biofuel targets on grounds that these would instead lock-in first-generation biofuels, thus delaying or pre-empting second-generation biofuels. Those disagreements can be explained by different institutional responsibilities and reputational stakes towards `promise-requirement cycles', whereby techno-optimistic promises generate future requirements for the actors involved. The UK government's stance illustrates a `policy-promise lock-in', a dilemma whereby promised support is a requirement for credibility towards technology innovators and thus technoscientific development - but may delay the redirection of support from incumbent to preferable emerging technologies. Thus the sociology of expectations - previously applied to technological expectations from technology innovators - can be extended to analyse public authorities.},
  comment          = {Expectations create a set of `promises' which can then be converted into requirements

Thus governments act as selectors of technological expectations

Interesting questions raised over setting policy that is stable enough to build confidence and stimulate innovation and yet flexible enough to avoid ``policy-promise lock-in'' if problems arise with early stage developments that arise from policy.

``Promises and diffuse scenarios are used to convince funding organisations to invest money and attract other practitioners to join the development (Geels and Smit, 2000: 881). Technology innovators may exaggerate their promises''


November 2001 the European Commission had started formal negotiations on an EU Directive on Biofuels (EC, 2001), which became law in May 2003 (EU, 2003)

July 2002 the UK government introduced the first financial incentive: a fuel duty discount only for biodiesel (20p per litre)

2003 Department of Trade and Industry (DTI)3 published an Energy White Paper considered biofuels as an ‚Äúimportant potential route for achieving the goal of zero-carbon transport, creating new opportunities for agriculture in the UK as well as globally‚Äù (DTI, 2003: 69). This was a policy change from previous focus on hydrogen fuel.

Later in 2003 the European Commission issued the first EU Biofuels Directive, initiating an EU-wide biofuel policy (EU, 2003). The Directive set non-binding ‚Äúreference‚Äù targets through 2010, requiring increasing proportions of all diesel and petrol sold in Member States to be biofuels

In 2003 Parliament's Environment, Food and Rural Affairs Committee (EFRAC) acknowledged lack of knowledge on impacts and recommended the development of an auditing system on biofuels' environmental and socio-economic impacts in producer countries which UK gov doubted would be practically feasible

2005: UK government announcing future implementation of the Renewable Transport Fuel Obligation (RTFO), whose mandatory targets started incentivising biofuel production from 2008 onwards but, owing to uncertainty about benefits RTFO's mandatory targets were more cautious than the EU's higher reference target of 5.75\% per energy content6 by 2010

2006-7 NGOs turned against biofuels - first-generation biofuels were widely recognised as environmentally and socio-economically problematic - and called for a policy moratorium

Gallagher Review 2008 [official enquiry on biofuels] acknowledged drawbacks of biofuels but rejected the idea of a moratorium because this would damage investment in biofuels

This led to a slow-down UK biofuel targets in 2009 and increased R\&D funding for second generation biofuels.

https://doi.org/10.1068/c09206j argued that biofuel advocates ‚Äúsuccessfully transplanted their ecomodernist discourse into policy makers' consciousness and vocabularies‚Äù saying that the advocates' discourse had ‚Äúsuperior appeal‚Äù compared to biofuel critics.

By 2008 UK targets were explicitly defended as `cautious' in response to high-profile calls for a moratorium, and were eventually delayed in 2009. This caution relates to the risk of locking in a nascent industry for first-generation biofuels, which the UK government initially presented as environmentally and socio-economically risky and excessively expensive (EFRAC, 2004gr: 6; HM Govt, 2004: 2).

Dunlop : Reputation and investment `sunk costs' were a reason for not changing the policy despite criticism of biofuels

Boucher: technology increasingly framed as reduced to GHG emissions, less so social and environmental sustainability, improving energy security and rural economies},
  creationdate     = {2022-11-17T16:01:35},
  keywords         = {economics, Policy, Biofuels, Expectations},
  modificationdate = {2022-11-25T22:49:16},
  owner            = {ISargent},
  relevance        = {relevant},
}

@Article{RavenV2004,
  author           = {Rob Raven and Geert Verbong},
  date             = {2004},
  journaltitle     = {Innovation},
  title            = {Ruling out innovations - technological regimes, rules and failures: The cases of heat pumppower generation and bio-gas production in TheNetherlands},
  doi              = {10.5172/impp.2004.6.2.178},
  number           = {2},
  pages            = {178--198},
  url              = {https://www.tandfonline.com/doi/abs/10.5172/impp.2004.6.2.178},
  volume           = {6},
  comment          = {Test the Geels Regimes model empirically the develop of  heat pump power generation and bio-gas production. Both these technologies 'failed' due to rules which directed the directon of innovation. 

I think they found examples not in The Netherlands where they were successful

Interesting that heat pumps are now a success},
  creationdate     = {2022-11-17T19:10:17},
  keywords         = {innovation, transition, technology, economics},
  modificationdate = {2022-11-25T18:29:15},
  owner            = {ISargent},
}

@Article{Geels2004,
  author           = {Frank W. Geels},
  date             = {2004},
  journaltitle     = {Research Policy},
  title            = {From sectoral systems of innovation to socio-technical systems: Insights about dynamics and change from sociology and institutional theory},
  doi              = {https://doi.org/10.1016/j.respol.2004.01.015},
  issn             = {0048-7333},
  number           = {6},
  pages            = {897-920},
  url              = {https://www.sciencedirect.com/science/article/pii/S0048733304000496},
  volume           = {33},
  abstract         = {In the last decade `sectoral systems of innovation' have emerged as a new approach in innovation studies. This article makes four contributions to the approach by addressing some open issues. The first contribution is to explicitly incorporate the user side in the analysis. Hence, the unit of analysis is widened from sectoral systems of innovation to socio-technical systems. The second contribution is to suggest an analytical distinction between systems, actors involved in them, and the institutions which guide actor's perceptions and activities. Thirdly, the article opens up the black box of institutions, making them an integral part of the analysis. Institutions should not just be used to explain inertia and stability. They can also be used to conceptualise the dynamic interplay between actors and structures. The fourth contribution is to address issues of change from one system to another. The article provides a coherent conceptual multi-level perspective, using insights from sociology, institutional theory and innovation studies. The perspective is particularly useful to analyse long-term dynamics, shifts from one socio-technical system to another and the co-evolution of technology and society.},
  comment          = {Introduces a different perspective on systems of innovation and refers to the multi-level perspective model to consider how socio-technical regimes change

Important to understand creation of technology, its diffusion and utilisation

This paper defines system as being both the supply side (innovations) and the demand side (user environment) - from innovation systems to socio-technical systems

Also distinguishes between systems (resources, material aspects), actors involved in maintaining and changing the system, and the rules and institutions which guide actor's perceptions and activities

Better conceptualises institutions and how they play a role in dynamic developments, rather than explaining inertia and stability

How one system changes into another - focus of the not on (economic) performance, but on dynamics and change

``Radical novelties may have a `mis-match' with the existing regime (Freeman and Perez, 1988)''},
  creationdate     = {2022-11-17T19:56:30},
  keywords         = {innovation, Institutional theory, Regimes, transformation, economics},
  modificationdate = {2022-11-17T20:11:16},
  owner            = {ISargent},
}

@Article{Nordhaus1975,
  author           = {William D. Nordhaus},
  date             = {1975},
  journaltitle     = {The Review of Economic Studies},
  title            = {The Political Business Cycle},
  number           = {2},
  pages            = {169--190},
  url              = {https://www.jstor.org/stable/2296528},
  volume           = {42},
  comment          = {model of the manipulation of policy to maximise chances of reelection by myopic voters},
  creationdate     = {2022-11-17T20:19:03},
  keywords         = {economics, policy},
  modificationdate = {2022-11-27T19:51:13},
  owner            = {ISargent},
}

@Article{Kremer1993,
  author           = {Michael Kremer},
  date             = {1993},
  journaltitle     = {The Quarterly Journal of Economics},
  title            = {Population Growth and Technological Change: One Million {B.C.} to 1990},
  number           = {3},
  pages            = {681--716},
  url              = {https://www.jstor.org/stable/2118405?seq=19#metadata_info_tab_contents},
  comment          = {Creates a model and demonstrates it on population and population growth rate data and concludes that higher population spurs technological change (I acutally don't see how this can be derived from only population data but...). I think the assumption is that more people means more chance of invention. 

I believe Syed2019 explains this more in terms of access to diverse thinking in larger populations.},
  creationdate     = {2022-11-17T20:29:33},
  keywords         = {economics, technology, population},
  modificationdate = {2022-11-17T20:44:49},
  owner            = {ISargent},
  vokume           = {108},
}

@Article{Kelton2016,
  author           = {Stephanie Kelton},
  date             = {2016},
  title            = {The Failure of Austerity: Rethinking Fiscal Policy},
  booktitle        = {Rethinking Capitalism},
  comment          = {2008 crash contained using
- interest rates cuts
- liquidity provision
- quantitative easing
by US Federal Reserve, lender of last resort in time of crisis

mid-2008, financial crisis bleeding into US economy. Job growth turned sharply negative. 

Minsky's financial instability hypothesis is that during a boom, private actors (households, banks, etc) take on debt. During a 'bust' they tighten their belts and pay down debt.

Keynes identified that the spending multiplier works in reverse - a diminution in aggregate spending causes even less spending

However, with a large enough state, there is an automatic balance - tax will decline and draws on the welfare state will increase, creating a government deficit (not because of decisions by the current administration)

Traditional to think of government deficits as something that requires borrowing  which takes resources from savers and crowds out other economic activity

Instead, it should be seen as a flow of funds that increases the stock of net financial assets to the non-government sector

NC economics states that, on observing a fiscal deficit, private sector agents will anticipate a rise in taxes and therefore will save rather than spend

Great narrative of the aftermath of 2008 financial crisis especially in Eurozone also US and UK

Policies to improve the human condition should be evaluated on their social and economic outcomes rather than on narrow budget considerations

MMT},
  creationdate     = {2022-11-18T10:48:56},
  keywords         = {economics, policy, deficit, recession},
  modificationdate = {2022-12-03T17:50:35},
  owner            = {ISargent},
  publisher        = {John Wiley \& Sons Ltd},
}

@Article{Cooper2010,
  author           = {Jeffrey A. Cooper},
  date             = {2010},
  journaltitle     = {Florida Tax Review},
  title            = {Ghosts of 1932: The Lost History of Estate and Gift Taxation},
  url              = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1438181},
  comment          = {Insights into the congressional arguments and decision-making during the Great Depression

Estate taxation had been introduced in response to threat and actual war, then repealed, repeatedly but had stayed in place after WWI. It was reduced in response to budget surpluses. This was part of redistribution of wealth although was hotly debated and fluctuated for some years. In 1920s there was a battle over estate taxation - whether to raise/broaden or lower it

Revenue Act of 1932 in response to falling revenue after 1929 stock market crash, with increased taxation provisions was to address deficit as congress was agreed that this budget needed balancing to aid recovery. However, it did not include any borrowing despite some arguing for this.

This act had no expiration date - possibly an error or a `slight of hand'

``estate tax rates were increased as a means of generating additional revenue and preserving the nation's credit rating,11 while a gift tax was enacted to prevent wealthy taxpayers from circumventing the estate tax by making intervivos gifts''},
  creationdate     = {2022-11-19T10:28:04},
  keywords         = {economics, policy, deficit, history},
  modificationdate = {2022-11-19T11:05:12},
  owner            = {ISargent},
}

@TechReport{Draper2013,
  author           = {Stephanie Draper},
  date             = {2013},
  institution      = {Forum for the Future},
  title            = {Creating the big shift: system innovation for sustainability},
  url              = {https://www.forumforthefuture.org/creating-the-big-shift-system-innovation-for-sustainability},
  comment          = {6 steps to systems change:
1. Experience the need for change
2. Diagnose the problem
3. Create pioneering practices
4. Enable the tipping point
5. Sustain the transition
6. Set the rules of the new mainstream

Focus on businesses making the change. Case studies from Unilever, Nike, containerisation

Systems thinking

``At Forum for the Future we have always had a focus on the scale, knowledge and influence that big business can bring to bear. While incumbents' stake in `business as usual' makes them at risk of resisting change or finding it hard to be truly innovative, we have found that there is a business case for progressive companies to shape their external environment - based on differentiation, shared costs, reputational gains, long-term solutions and, importantly, leadership.''},
  creationdate     = {2022-11-25T11:29:14},
  keywords         = {systems, tranformation, economics, policy, environment},
  modificationdate = {2022-11-25T12:12:12},
  owner            = {ISargent},
}

@Book{Kuznets1934,
  author           = {United States. Bureau of Foreign and Domestic Commerce and National Bureau of Economic Research},
  date             = {1934-01-04},
  title            = {National Income, 1929-1932: Letter from the Acting Secretary of Commerce Transmitting in Response to Senate Resolution No. 220 (72nd Cong.) a Report on National Income, 1929-32},
  publisher        = {U.S. Government Printing Office},
  series           = {73rd Cong., 2d sess. Senate. Doc. 124},
  titleaddon       = {Letter from the Acting Secretary of Commerce Transmitting in Response to Senate Resolution No. 220(72d Cong.) a Report on National Income, 1929-32},
  url              = {https://fraser.stlouisfed.org/files/docs/publications/natincome_1934/19340104_nationalinc.pdf},
  comment          = {Criticises the use of simple national income measuresments to infer national welfare.

``The welfare of a nation can, therefore, scarcely be inferred from a measurement of national income as defined above.''

``Dr. Simon Kuznets, was retained by the Bureau of Foreign and Domestic Commerce to plan and supervise this study. Dr. Kuznets, who was in full charge of the work, was responsible for the preparation of the final estimates, as well as the organization and the text of the report. ''},
  creationdate     = {2022-11-26T17:39:36},
  institution      = {Bureau of Foreign and Domestic Commerce},
  keywords         = {economics, growth, welfare},
  lccn             = {34026496},
  modificationdate = {2022-11-26T18:14:11},
  owner            = {ISargent},
}

@TechReport{StiglitzSF2009,
  author           = {Joseph E. Stiglitz and Amartya Sen and Jean-Paul Fitoussi},
  date             = {2009},
  institution      = {Commission on the Measurement of Economic Performance and Social Progress},
  title            = {Report by the Commission on the Measurement of Economic Performance and Social Progress},
  url              = {https://ec.europa.eu/eurostat/documents/8131721/8131772/Stiglitz-Sen-Fitoussi-Commission-report.pdf},
  comment          = {From  \url{https://www.promarket.org/2021/10/31/gdp-invention-economic-growth-kuznets-history/} ``Joseph Stiglitz, Amartya Sen, and Jean-Paul Fitoussi launched a devastating attack on environmental grounds, highlighting GDP's indifference to the social and environmental harms of economic activity. ''},
  creationdate     = {2022-11-26T18:08:58},
  keywords         = {economics, growth, environment, welfare},
  modificationdate = {2022-11-26T18:14:02},
  owner            = {ISargent},
}

@Booklet{Butler2012,
  author           = {Eamonn Butler},
  date             = {2012},
  title            = {Public Choice - A Primer},
  url              = {https://iea.org.uk/publications/research/public-choice-a-primer},
  comment          = {I found this astonishing - an insight into why public sector is treated with such disdain. Basically, if you thought that market actors were self-interested, wait til you see what motivates government actors and bureaucrats, who have been captured by interest groups. As a consequence, we need to subject all government actors to competition to ensure scrutiny and remove opportunity for acting in their own self interest. Supplies almost no empirical evidence.

Its very difficult not to read this as a treatise from a group that want to own most of the state.

Public choice scholars `pointed out' that the people who make public decision are just as self-interested as anyone else

Political parties have very strong objective to get elected

Buchanan and Tullock saw the political system as a process by which individuals seek to protect their own interests rather than strive to achieve some public interest...the real problem was government failure, monopoies, externalities and limited or one-sided information were much more evident in government than markets

Lobby groups are successful at winning concessions but they don't represent consumers because consumers have a wider set of concerns and are more numerous and thus harder to organise. A reason that consuders don't get involved in lobbying is that they can see someone else doing it and thus they free-ride the benefits.

Government may be employed to do important things that the market does not deliver (well)

``the problems that government intervention creates can be even more damanging than those it is intended to correct''

Elections are a problem because different outcomes can occur depending on the system employed. Also, voters tend to not express their true beliefs because, for instance, they vote tactically. Another problem is that elections are very infrequent whereas markets are constantly adjusting.

The general public have little motivation to put much effort into public debate. They are rationally ignorant, since they can influence things very little. It is not obvious why they bother to vote.

Public activities are not paid for my tax but rather a debt to be paid by future generations

Political parties choose policies because they think they will win not because they think they are right

Logrolling is always happening whereby multiple policies are put in together in order to get agreement from otherwise opposing sides

Rent seeking occurs when government give themselves monopolies over the provision of services. This ``massively distorts'' public decisions, markets and reduces competition and benefits certain groups.

Bureaucrats are motivated by the size of their budgets and are not exposed to the scrutiny of well-informed customers (unlike business people). There is a threat that bureaucrats will humble their political masters by leaking damaging information.

``so much state spending has been captured by special interest groups''

So we also have democratic failure as well as government failure!



The rational choice for everyone is to support a tax system that treats everyone equally [no it is not - izzy]},
  creationdate     = {2022-11-26T20:31:14},
  isbn             = {978-0-255-36650-2},
  keywords         = {economics, policy},
  modificationdate = {2022-12-03T18:43:36},
  owner            = {ISargent},
  publisher        = {Institute of Economic Affairs},
  year             = {2012},
}

@Online{HarrariKB2021,
  author           = {Daniel Harari and Matthew Keep and Philip Brien},
  date             = {2021-12-17},
  title            = {Coronavirus: Economic impact},
  url              = {https://commonslibrary.parliament.uk/research-briefings/cbp-8866/},
  organization     = {House of Commons Library, UK Parliament},
  subtitle         = {Research Briefing},
  urldate          = {2022-11-27},
  comment          = {Inflation in 2021 was partly a result of the disruption to global supply chains and a surge in energy prices

The budget deficit was 15.1\% of GDP in 2020/21 a peacetime record},
  creationdate     = {2022-11-27T09:06:34},
  keywords         = {economics, deficit, Covid-19},
  modificationdate = {2022-11-27T10:13:49},
  owner            = {ISargent},
}

@TechReport{BrowneL2010,
  author           = {James Browne and Peter Levell},
  date             = {2010-08-25},
  institution      = {Institute for Fiscal Studies},
  title            = {The distributional effect of tax and benefit reforms to be introduced between June 2010 and April 2014: a revised assessment},
  url              = {https://ifs.org.uk/publications/distributional-effect-tax-and-benefit-reforms-be-introduced-between-june-2010-and},
  comment          = {From  \url{https://www-cdn.oxfam.org/s3fs-public/file_attachments/cs-true-cost-austerity-inequality-uk-120913-en_0.pdf}

This report anticipated that: As a result of the tax and welfare changes to be implemented between 2010 and 2014, the poorest two-tenths of the population will have seen greater cuts to their net income, in percentage terms, than every other group, except the very richest tenth},
  creationdate     = {2022-11-27T09:14:58},
  keywords         = {economics, deficit, inequality},
  modificationdate = {2022-11-27T10:13:51},
  owner            = {ISargent},
}

@TechReport{BrewerBJ2011,
  author           = {Mike Brewer and James Browne and Robert Joyce},
  date             = {2011-10-11},
  institution      = {Institute for Fiscal Studies},
  title            = {Child and Working-Age Poverty from 2010 to 2020},
  url              = {https://ifs.org.uk/publications/child-and-working-age-poverty-2010-2020},
  comment          = {From  \url{https://www-cdn.oxfam.org/s3fs-public/file_attachments/cs-true-cost-austerity-inequality-uk-120913-en_0.pdf}

Relative poverty amongst working-age adults is expected to rise from 16.7
per cent (2011/12) to 18.5 per cent (2014/15). By 2020, relative poverty is expected to rise between three to four
percentage points to 24.4 per cent among children and 20.0 per cent among working-age adults.

Over the decade to 2020, an additional 800,000 children are expected to
be living in poverty - almost one in four British children.1},
  creationdate     = {2022-11-27T09:29:26},
  keywords         = {economics, deficit, inequality},
  modificationdate = {2022-12-17T20:37:33},
  owner            = {ISargent},
  year             = {2011},
}

@Online{Poinasamy2013,
  author           = {Krisnah Poinasamy},
  date             = {2013-09-01},
  title            = {The True Cost of Austerity and Inequality: {UK} Case Study},
  url              = {https://www-cdn.oxfam.org/s3fs-public/file_attachments/cs-true-cost-austerity-inequality-uk-120913-en_0.pdf},
  organization     = {Oxfam International},
  urldate          = {2022-11-27},
  comment          = {Great for references on the impacts of austerity between 2008 crisis and covid-19 pandemic},
  creationdate     = {2022-11-27T09:43:47},
  keywords         = {economics, austerity, inequality},
  modificationdate = {2022-12-03T17:19:21},
  owner            = {ISargent},
}

@TechReport{HMTreasury2022,
  author           = {{HM Treasury}},
  date             = {2022-11-17},
  institution      = {HM Treasury},
  title            = {Autumn Statement 2022},
  url              = {https://www.gov.uk/government/publications/autumn-statement-2022-documents},
  comment          = {Lowering additional rate tax threshold and freezing basic-rate - both resulting in more tax including from the poorest taxpayers

t reduces the income tax additional rate threshold from ¬£150,000 to ¬£125,140, increasing taxes for those on high incomes. Income tax, National Insurance and Inheritance Tax thresholds will be maintained at their current levels for a further two years, to April 2028

 The Energy Profits Levy will be increased by 10 percentage points to 35\% and extended to the end of March 2028, and a new, temporary 45\% Electricity Generator Levy will be applied on the extraordinary returns being made by electricity generators.

for the years beyond the current Spending Review period, planned departmental resource spending will continue to grow, but slower than the economy, at 1\% a year in real terms until 2027-28

make available up to ¬£4.7 billion in 2024-25 for adult social care system in England

core schools budget in England will receive ¬£2.3 billion of additional funding in each of 2023-24 and 2024-25

in 2023-24 an additional Cost of Living Payment of ¬£900 will be provided to households on means-tested benefits, of ¬£300 to pensioner households, and of ¬£150 to individuals on disability benefits

national ambition to reduce energy consumption by 15\% by 2030, delivered through public and private investment, and a range of cost-free and low-cost steps to reduce energy demand

additional support to increase labour market participation; increasing public investment in infrastructure across this Parliament; delivering planned skills reforms; and supporting R\&D by increasing public funding to ¬£20 billion in 2024-25},
  creationdate     = {2022-11-27T10:06:10},
  keywords         = {economics, deficit, policy, inequality},
  modificationdate = {2023-01-18T20:55:33},
  owner            = {ISargent},
}

@Online{AdamEtAl2022,
  author           = {Stuart Adam and Carl Emmerson and Paul Johnson and Robert Joyce and Heidi Karjalainen and Peter Levell and Isabel Stockton and Tom Waters and Thomas Wernham and Xiaowei Xu and Ben Zaranko},
  date             = {2022-11-17},
  title            = {Autumn Statement 2022 response},
  url              = {https://ifs.org.uk/articles/autumn-statement-2022-response},
  comment          = {raise questions about how rapidly rising public sector costs can be met},
  creationdate     = {2022-11-27T10:24:49},
  keywords         = {economics, policy, deficit},
  modificationdate = {2022-11-27T10:27:10},
  owner            = {ISargent},
}

@Online{ONS082022,
  author           = {{Office for National Statistics}},
  date             = {2022-08-11},
  title            = {Measures of National Well-being Dashboard: Quality of Life in the UK},
  url              = {https://www.ons.gov.uk/peoplepopulationandcommunity/wellbeing/articles/measuresofnationalwellbeingdashboardqualityoflifeintheuk/2022-08-12},
  urldate          = {2022-11-27},
  comment          = {there is a trend for reduced health satisfaction and increased mental health distress over the last few years},
  creationdate     = {2022-11-27T11:40:47},
  keywords         = {health, economics},
  modificationdate = {2022-11-27T18:00:01},
  owner            = {ISargent},
}

@Online{WorldData2020,
  author           = {{WorldData.org}},
  date             = {2020},
  title            = {Life expectancy},
  url              = {https://www.worlddata.info/life-expectancy.php},
  urldate          = {2022-11-27},
  comment          = {UK life expectancy in UK (Male: 79.0 Female: 82.9) compared to Western Europe (Male: 79.04 Female: 84.09)},
  creationdate     = {2022-11-27T11:43:17},
  modificationdate = {2022-11-27T11:51:28},
  owner            = {ISargent},
}

@Online{BMA2022,
  author           = {{BMA}},
  date             = {2022-11-01},
  editor           = {{British Medical Association}},
  title            = {NHS backlog data analysis},
  url              = {https://www.bma.org.uk/advice-and-support/nhs-delivery-and-workforce/pressures/nhs-backlog-data-analysis},
  urldate          = {2022-11-27},
  comment          = {NHS backlogs were on the increase from at least 2015 and have been increasing rapidly since 2020.},
  creationdate     = {2022-11-27T11:52:49},
  keywords         = {health, policy},
  modificationdate = {2022-12-16T17:02:22},
  owner            = {ISargent},
}

@Online{ONSIncome2022,
  author           = {{Office for National Statistics}},
  date             = {2022-03-28},
  title            = {Average household income, UK: financial year ending 2021},
  url              = {https://www.ons.gov.uk/peoplepopulationandcommunity/personalandhouseholdfinances/incomeandwealth/bulletins/householddisposableincomeandinequality/financialyearending2021},
  urldate          = {2022-11-27},
  comment          = {mean and median equivalenced disposable income have increased over the last 4 decades although the gap between them has increased over this time (but slightly decreased in last few years). See ONSInequality2022},
  creationdate     = {2022-11-27T12:05:14},
  keywords         = {economics, income},
  modificationdate = {2022-11-27T17:59:48},
  owner            = {ISargent},
}

@Online{ONSInequality2022,
  author           = {{Office for National Statistics}},
  date             = {2022-03-28},
  title            = {Household income inequality, UK: financial year ending 2021},
  url              = {https://www.ons.gov.uk/peoplepopulationandcommunity/personalandhouseholdfinances/incomeandwealth/bulletins/householdincomeinequalityfinancial/financialyearending2021},
  urldate          = {2022-11-27},
  comment          = {Gini coefficient fell slightly over previous year but confidence intervals still overlap. Slight downward trend since 2008/09

But alternative measures of inequality have increased over the 10-years to 2021},
  creationdate     = {2022-11-27T12:11:15},
  keywords         = {economics, inequality},
  modificationdate = {2022-11-27T17:59:37},
  owner            = {ISargent},
}

@TechReport{CorlettOT2022,
  author           = {Adam Corlett and Felicia Odamtten and Lalitha Try},
  date             = {2022-07-04},
  institution      = {Resolution Foundation},
  title            = {The Living Standards Audit 2022},
  eprint           = {https://www.resolutionfoundation.org/app/uploads/2022/07/Living-Standards-Audit-2022.pdf},
  url              = {https://www.resolutionfoundation.org/publications/the-living-standards-audit-2022/},
  comment          = {Figure 3 amazing graph on page 19 showing the growth in equivalised income after housing costs for each 20th of the population (excluding the poorest 20th because of uncertainty about data reliability) for each 5 year period from early 1960s. Shows how the variation of real income can grow and decline for different groups and that only twice do wealthiest experience a recession (1973 oil crisis and 2008 financial crisis) whereas there are multiple periods when the poorest experience a decline

Financialised UK experienced a greater drop in income after 2008 crisis than neighbouring coutries

Inequality has been rising since mid-1970s

Figure 9 page 25 is the change in disposable income for different groups showing the young children, those with disabilities, single parent housholds, racialised, non-working, North England and Wales, and women are worse off in their groups.},
  creationdate     = {2022-11-27T12:25:50},
  keywords         = {economics, inequality, policy},
  modificationdate = {2022-12-03T17:20:28},
  owner            = {ISargent},
}

@TechReport{CorlettT2022,
  author           = {Adam Corlett and Lalitha Try},
  date             = {2022-09-01},
  institution      = {Resolution Foundation},
  title            = {In at the deep end: The living standards crisis facing the new Prime Minister},
  url              = {https://www.resolutionfoundation.org/publications/in-at-the-deep-end/},
  comment          = {average incomes are set to decline due to cost of living crisis and the number of people in absolute poverty is set to increase - to 21\% -  14 million people in 2023-24},
  creationdate     = {2022-11-27T12:47:37},
  keywords         = {economics, policy},
  modificationdate = {2022-11-27T12:50:12},
  owner            = {ISargent},
}

@TechReport{BoEMonetary2022,
  author           = {{Bank of England}},
  date             = {2022-11-03},
  institution      = {Bank of England},
  title            = {Monetary Policy Report - November 2022},
  url              = {https://www.bankofengland.co.uk/monetary-policy-report/2022/november-2022},
  urldate          = {2022-11-27},
  creationdate     = {2022-11-27T13:13:28},
  modificationdate = {2022-12-03T11:05:18},
  owner            = {ISargent},
}

@Book{OECDProductivityIndicators2021,
  author           = {{Organisation for Economic Co-operation and Development}},
  date             = {2021},
  title            = {OECD Compendium of Productivity Indicators},
  doi              = {https://doi.org/https://doi.org/10.1787/f25cdb25-en},
  pages            = {30},
  url              = {https://www.oecd-ilibrary.org/content/publication/f25cdb25-en},
  comment          = {The labour share of income has been declining since the mid-1990s for majority of countries (but somewhere else this doesn't seem to be the case for UK)

and a decoupling of labour productivity growth from growth in real labour income in a majority (around two thirds) of OECD countries since the mid-1990s},
  creationdate     = {2022-11-27T16:24:11},
  keywords         = {economics, policy, labour},
  modificationdate = {2022-12-09T09:08:39},
  owner            = {ISargent},
}

@Article{Elkington1998,
  author           = {John Elkington},
  journaltitle     = {Measuring Business Excellence},
  title            = {Accounting for the Triple Bottom Line},
  doi              = {10.1108/eb025539},
  issue            = {3},
  url              = {https://www.emerald.com/insight/content/doi/10.1108/eb025539/full/html},
  volume           = {2},
  comment          = {abridged version of Cannibals With Forks: the triple bottom line of 21st ing to grasp the full scale of the 'sustaincentury business by John Elkington (Capstone Publishing Ltd, 1997. ISBN 1-900961-27-X)

The economic bottom line How it is assessed and what long-term
indicators of sustainability might be added.
* Environmental bottom line What is 'natural capital' and can it be quantified and accounted for? 
* Social bottom line Factors which businesses cannot ignore as
globalization gathers steam. 
* The triple bottom line Making it happen.

(See also Robert S. Kaplan and David P. Norton, The Balanced Scorecard:Translating Strategy into Action (Boston, Mass.: HBS Press, 1996).)},
  creationdate     = {2022-11-27T17:29:27},
  keywords         = {economics, accounting, environmenet, society},
  modificationdate = {2022-11-29T11:55:49},
  owner            = {ISargent},
  year             = {1998},
}

@TechReport{JohnstonU2022,
  author           = {Neil Johnston and Elise Uberoi},
  date             = {2022-11-21},
  institution      = {House of Commons Library},
  title            = {Political disengagement in the UK: who is disengaged?},
  subtitle         = {Research Briefing},
  url              = {https://commonslibrary.parliament.uk/research-briefings/cbp-7501/},
  comment          = {Political engagement has fallen since 1950s but voter turn out has begun to increase in recent years

Trust in governement has fallen over the last 30 years

Certain groups (disabled, ethnic minorities, women, young people) are somewaht less engaged

Polticians do not seem to represent national diversity

Section on Voter ID and quote from Jount Committee on Human Rights:

``will have a discriminatory impact on some voters with protected characteristics under the Equality Act 2010, including the disabled, certain ethnic minorities and Gypsy and Traveller communities''},
  creationdate     = {2022-11-27T18:42:49},
  keywords         = {politics},
  modificationdate = {2022-11-27T18:54:27},
  owner            = {ISargent},
}

@Online{EA2022,
  author           = {{Environment Agency}},
  date             = {2022-07-22},
  title            = {Water and sewerage companies in England: environmental performance report 2021},
  url              = {https://www.gov.uk/government/publications/water-and-sewerage-companies-in-england-environmental-performance-report-2021/water-and-sewerage-companies-in-england-environmental-performance-report-2021},
  urldate          = {2022-11-27},
  comment          = {the environmental performance of England's 9 water and sewerage companies was the worst we have seen for years},
  creationdate     = {2022-11-27T19:11:56},
  keywords         = {environment, policy},
  modificationdate = {2022-11-27T19:13:11},
  owner            = {ISargent},
}

@Article{WatkinseEtAl2017,
  author           = {Watkins, Johnathan and Wulaningsih, Wahyu and Da Zhou, Charlie and Marshall, Dominic C and Sylianteng, Guia D C and Dela Rosa, Phyllis G and Miguel, Viveka A and Raine, Rosalind and King, Lawrence P and Maruthappu, Mahiben},
  date             = {2017},
  journaltitle     = {BMJ Open},
  title            = {Effects of health and social care spending constraints on mortality in England: a time trend analysis},
  doi              = {10.1136/bmjopen-2017-017722},
  eprint           = {https://bmjopen.bmj.com/content/7/11/e017722.full.pdf},
  issn             = {2044-6055},
  number           = {11},
  url              = {https://bmjopen.bmj.com/content/7/11/e017722},
  volume           = {7},
  abstract         = {Objective Since 2010, England has experienced relative constraints in public expenditure on healthcare (PEH) and social care (PES). We sought to determine whether these constraints have affected mortality rates.Methods We collected data on health and social care resources and finances for England from 2001 to 2014. Time trend analyses were conducted to compare the actual mortality rates in 2011{\textendash}2014 with the counterfactual rates expected based on trends before spending constraints. Fixed-effects regression analyses were conducted using annual data on PES and PEH with mortality as the outcome, with further adjustments for macroeconomic factors and resources. Analyses were stratified by age group, place of death and lower-tier local authority (n=325). Mortality rates to 2020 were projected based on recent trends.Results Spending constraints between 2010 and 2014 were associated with an estimated 45 368 (95\% CI 34 530 to 56 206) higher than expected number of deaths compared with pre-2010 trends. Deaths in those aged >=60 and in care homes accounted for the majority. PES was more strongly linked with care home and home mortality than PEH, with each {\textsterling}10 per capita decline in real PES associated with an increase of 5.10 (3.65{\textendash}6.54) (p\&lt;0.001) care home deaths per 100 000. These associations persisted in lag analyses and after adjustment for macroeconomic factors. Furthermore, we found that changes in real PES per capita may be linked to mortality mostly via changes in nurse numbers. Projections to 2020 based on 2009-2014 trend was cumulatively linked to an estimated 152 141 (95\% CI 134 597 and 169 685) additional deaths.Conclusions Spending constraints, especially PES, are associated with a substantial mortality gap. We suggest that spending should be targeted on improving care delivered in care homes and at home; and maintaining or increasing nurse numbers.},
  creationdate     = {2022-11-30T16:37:12},
  elocation-id     = {e017722},
  keywords         = {economics, health, policy},
  modificationdate = {2022-11-30T16:38:02},
  owner            = {ISargent},
  publisher        = {British Medical Journal Publishing Group},
}

@TechReport{MarmotEtAl2020,
  author           = {Marmot, M. and Allen, J. and Boyce, T. and Goldblatt, P. and Morrison, J.},
  date             = {2020-02-01},
  institution      = {Institute of Health Equity},
  title            = {Health Equity in England: The Marmot Review 10 Years On},
  url              = {health.org.uk/publications/reports/the-marmot-review-10-years-on},
  abstract         = {The report highlights that:

people can expect to spend more of their lives in poor health
improvements to life expectancy have stalled, and declined for women in the most deprived 10\% of areas
the health gap has grown between wealthy and deprived areas 
place matters - living in a deprived area of the North East is worse for your health than living in a similarly deprived area in London, to the extent that life expectancy is nearly five years less.},
  creationdate     = {2022-11-30T16:39:36},
  keywords         = {health, policy},
  modificationdate = {2022-11-30T17:05:01},
  owner            = {ISargent},
  year             = {2020},
}

@Article{LeesonT2021,
  author           = {Leeson, Peter T. and Henry A. Thompson},
  date             = {2021-03-22},
  journaltitle     = {Public choice},
  title            = {Public choice and public health},
  doi              = {10.1007/s11127-021-00900-2},
  pages            = {1--37},
  url              = {https://link.springer.com/article/10.1007/s11127-021-00900-2},
  comment          = {Analysis of public health from a public choice perspective finds

1. Public health regulations often are driven by private interests, not public ones
2. The allocation of public health resources often reflects private interests, not public ones
3. Public health policies may have perverse effects, undermining instead of promoting health-consumer welfare

but then this is a public choice paper!

It also notes that there is very little analysis on contageous disease and hopes that an outcome of Covid-19 pandemic will rectify this},
  creationdate     = {2022-12-01T22:27:43},
  keywords         = {economics, policy, health},
  modificationdate = {2023-02-02T13:56:16},
  owner            = {ISargent},
}

@Article{Dalingwater2014,
  author           = {Louise Dalingwater},
  title            = {Post-New Public Management ({NPM}) and the Reconfiguration of Health Services in England},
  doi              = {10.4000/osb.1714},
  pages            = {51--64},
  url              = {https://journals.openedition.org/osb/1714},
  creationdate     = {2022-12-01T22:35:46},
  keywords         = {economics, policy, health},
  modificationdate = {2022-12-01T22:39:26},
  owner            = {ISargent},
  year             = {2014},
}

@TechReport{CCCCOP272022,
  author           = {Sasha Abraham and Rose Armitage and Miriam Kennedy and Chris Stark and Mike Thompson and Viv Scott and Richard Millar and Marili Boufounou and Bea Natzler},
  date             = {2022-12-01},
  institution      = {Committee on Climate Change},
  title            = {COP27: Key outcomes and next steps for the UK},
  url              = {https://www.theccc.org.uk/publication/cop27-key-outcomes-and-next-steps-for-the-uk/},
  comment          = {"tangible progress has not been demonstrated across a host of areas
necessary to meet the UK's 2030 NDC and Sixth Carbon Budget"

Key messages
The UK has an important international leadership role to play in driving global implementation, underpinned by action at home:

* Defining the UK's role. The delayed 2030 Strategic Framework (the Government's vision for the UK's long-term international role tackling climate change and biodiversity loss) is an opportunity to set out the UK's leadership role in helping the world achieve the goals of the Paris Agreement.
* Future COPs and UK diplomatic capability. After exiting the EU and convening COP26, the UK Government should decide what its priorities are in COP negotiations and communicate these at a high level. The relationships and capabilities built through the Presidency should be used to actively champion progress towards the goals of the Paris Agreement and take forward the delivery of pledges and initiatives.
* Mobilising finance. As a major finance centre and sponsor of the multilateral development banks, the UK should pay particular attention to its positions on mobilising finance, which are vital to global success on climate change, and how it contributes to future Just Energy Transition Partnerships.
* Delivering the UK's contributions to the Paris Agreement. The UK must implement its Net Zero Strategy to deliver its legislated domestic targets and international commitments. It must strengthen its response on climate adaptation, which remains weak, with an ambitious, action-oriented third National Adaptation Programme in 2023.},
  creationdate     = {2022-12-02T11:00:31},
  keywords         = {environment},
  modificationdate = {2022-12-02T11:09:13},
  owner            = {ISargent},
}

@Book{Moore1995,
  author           = {Mark H. Moore},
  title            = {Creating Public Value: Strategic Management in Government},
  isbn             = {9780674175587},
  comment          = {The book on Public Value

From MazzucatoR2019 In contrast, Moore developed `public value account' which was absorbed into Blair/Clinton 'Third Way' and included measuring outcomes and evidence-based approach to definitions of value that changed over time.},
  creationdate     = {2022-12-02T15:07:53},
  keywords         = {economics, policy},
  modificationdate = {2022-12-02T15:50:37},
  owner            = {ISargent},
  year             = {1995},
}

@TechReport{SternKH2020,
  author           = {Scott Stern and Petra Krylova and Jaromir Harmacek},
  date             = {2020},
  institution      = {Social Progress Imperative},
  title            = {2020 Social Progress Index: Methodology Summary},
  eprint           = {https://www.socialprogress.org/static/1aa2d19690906eb93c6cdb281e5ee68b/2020-social-progress-index-methodology.pdf},
  url              = {https://www.socialprogress.org/},
  creationdate     = {2022-12-02T17:08:53},
  keywords         = {economics, policy},
  modificationdate = {2022-12-02T17:15:07},
  owner            = {ISargent},
}

@Online{UNFCCC2022,
  author           = {{UNFCC}, United Nations Framework Convention on Climate Change},
  date             = {2022-11-12},
  title            = {Nationally Determined Contributions ({NDCs})},
  url              = {https://unfccc.int/ndc-information/nationally-determined-contributions-ndcs},
  comment          = {References the Oberlin Environmental Dashboard  \url{https://environmentaldashboard.org/} p240-242 and suggests that the Doughnut is already a dashboard},
  creationdate     = {2022-12-02T17:26:41},
  keywords         = {climate, policy, economics},
  modificationdate = {2022-12-13T14:18:49},
  owner            = {ISargent},
}

@TechReport{OECDGreenGrowth2011,
  author           = {OECD},
  institution      = {Organization for Economic Co-Operation and Development},
  title            = {Towards Green Growth. A Summary for Policy Makers},
  creationdate     = {2022-12-02T22:48:49},
  keywords         = {economics, policy, environment},
  modificationdate = {2022-12-09T09:08:27},
  owner            = {ISargent},
  year             = {2011},
}

@Article{Lerner1943,
  author           = {Abba P. Lerner},
  date             = {1943},
  journaltitle     = {Social Research},
  title            = {Functional Finance and the Federal Debt},
  number           = {1},
  pages            = {38--51},
  volume           = {10},
  comment          = {The paper on functional Finance/modern monetary theory Argued for judging measures by the way they work not some judgement about what is right 

The effect of income tax is to make the rich man act as a kind of agent working for society on commission. He receives only part of the return on the investment but he loses only a part of the money that is invested 

The corporation was devised, making it possible for many individuals to combine and undertake risky enterprises without one person having to risk all his fortune on one venture 

It is the fear of inflation which is the only rational basis for suspicion of the printing of money

One if the greatest deterrents to private investment is the fear that the depression will come before the investment has paid for itself 

The argument against deficit spending is answered with: 
1. The national debt does not have to keep on increasing
2. Even if the national debt does grow, the interest on it does not
have to be raised out of current taxes
3. Even if the interest on the debt is raised out of current taxes,
these taxes constitute only the interest on only a fraction of the
benefit enjoyed from the government spending, and are not lost
to the nation but are merely transferred from taxpayers to bond-
holders
4. High income taxes need not discourage investment, because
appropriate deductions for losses can diminish the capital actually
risked by the investor in the same proportion as his net income
from the investment is reduced. 
p50

MMT},
  creationdate     = {2022-12-03T11:34:25},
  keywords         = {economics, policy},
  modificationdate = {2022-12-03T17:50:25},
  owner            = {ISargent},
}

@Online{FurmanS2019,
  author           = {Jason Furman and Lawrence H. Summers},
  date             = {2019},
  title            = {Who's Afraid of Budget Deficits? How Washington Should End Its Debt Obsession},
  url              = {https://www.foreignaffairs.com/united-states/whos-afraid-budget-deficits},
  organization     = {Foreign Affairs},
  urldate          = {2022-12-03},
  comment          = {``Government deficits also seem to be hurting the economy less than they used to. Textbook economic theory holds that high levels of government debt make it more expensive for companies to borrow. But these days, interest rates are low, stock market prices are high relative to company earnings, and major companies hold large amounts of cash on their balance sheets. No one seriously argues that the cost of capital is holding back businesses from investing. Cutting the deficit, then, is unlikely to spur much private investment.''

``Higher levels of debt do have downsides. They could make it harder for governments to summon the political will to stimulate the economy in a downturn. But saying that a country would be better off with lower debt is not the same as saying that it would be better off lowering its debt. The risks associated with high debt levels are small relative to the harm cutting deficits would do.''

``There is a widely held misconception that the deficit has risen primarily because government programs have grown more generous. Not so. Deficits have ballooned because a series of tax cuts have dramatically reduced government revenue below past projections and historical levels. The tax cuts passed by Presidents George W. Bush and Donald Trump totaled three percent of gdp‚Äîmuch more than the projected increases in entitlement spending over the next 30 years.''

Advocates the ``do-no-harm approach'': focus on important investments but do no harm.

MMT},
  creationdate     = {2022-12-03T11:43:40},
  keywords         = {economics, policy},
  modificationdate = {2022-12-03T17:50:15},
  owner            = {ISargent},
}

@Article{Stein1966,
  author           = {Herbert Stein},
  date             = {1966},
  journaltitle     = {The Journal of Law \& Economics},
  title            = {Pre-Revolutionary Fiscal Policy: The Regime of Herbert Hoover},
  pages            = {189--223},
  url              = {https://www.jstor.org/stable/724999},
  volume           = {9},
  comment          = {Herbert Hoover: ``Even before he became Secretary of Commerce, Hoover believed the era of laissez-faire to be gone''

Describes a much more nuanced economic approach of Hoover than the simple-put ``Classical'' that Keynes referred to it as},
  creationdate     = {2022-12-03T12:12:45},
  keywords         = {economics, policy},
  modificationdate = {2022-12-13T14:54:20},
  owner            = {ISargent},
}

@TechReport{OECDFiscalConsolidation2012,
  author           = {Douglas Sutherland and Peter Hoeller and Rossana Merola},
  date             = {2012-01-10},
  institution      = {Organisation for Economic Cooperation and Development},
  title            = {Fiscal Consolidation: Part 1.How Much is Needed and How to Reduce Debt to a Prudent Level?},
  doi              = {10.1787/18151973},
  eprint           = {https://www.oecd-ilibrary.org/docserver/5k9h28rhqnxt-en.pdf?expires=1670072593&id=id&accname=guest&checksum=0A5D4F0C8CE077D04845903F7F05B129},
  url              = {https://www.oecd-ilibrary.org/economics/fiscal-consolidation-part-1-how-much-is-needed-and-how-to-reduce-debt-to-a-prudent-level_5k9h28rhqnxt-en},
  comment          = {A mainstream perspective on Fiscal Consolidation and fiscal deficit


``Although the ‚Äúoptimal‚Äù size of government is not known, an accepted tenet of public finance is that beyond some level of revenue collection, the marginal net social costs - including the excess burden of taxation - of additional public expenditure increase more than proportionately with the additional taxation needed to finance spending. Against that background and given the current high level of public spending in many countries and the future spending pressures due to population ageing, the largest part of consolidation probably should consist of cuts in public spending. Since many countries rely on so-called tax expenditures for the pursuit of selected policy goals (e.g., home ownership), the reduction or elimination of base-eroding tax preferences will appear as revenue enhancements rather than spending cuts. In other cases where spending is low, there may be a case to put greater emphasis on revenue measures.''},
  creationdate     = {2022-12-03T13:00:01},
  keywords         = {economics, policy},
  modificationdate = {2022-12-09T09:08:50},
  owner            = {ISargent},
}

@TechReport{OECDBeyondGrowth2020,
  author           = {{OECD}},
  date             = {2020-09-11},
  institution      = {Organisation for Economic Cooperation and Development},
  title            = {Beyond Growth: Towards a New Economic Approach},
  doi              = {10.1787/33a25ba3-en.},
  eprint           = {https://www.oecd.org/naec/projects/Beyond_Growth_33a25ba3-en.pdf},
  url              = {https://www.oecd.org/governance/beyond-growth-33a25ba3-en.htm},
  comment          = {``The report argues that the dominant approach to economic policymaking over the last forty years, based on an orthodox and subsequently revised model of neoclassical economic theory, is not adequate to address these challenges''

`` In macroeconomic policy, the neoclassical framework encouraged a view that high levels of government debt `crowd out' private investment, so fiscal deficits should be limited, and monetary policy (adjustments to interest rates) should play the primary role in controlling inflation and managing overall demand''

``In the period before the financial crisis, this economic model (often described as the `Washington Consensus') was strongly influenced by a particular form of economic analysis. Based on an orthodox version of `neoclassical' economic theory, this assumed that the liberalisation of markets would generally improve their efficiency in allocating resources, and would therefore tend to optimise overall economic welfare. Although markets sometimes failed - for example in the presence of negative externalities, or in the provision of public goods - governments were also seen as prone to failure. They tended to have less information than market actors, and to be captured vested interests. So policy rooted in this kind of analysis tended to be sceptical of government intervention, with deregulation of various kinds widely favoured.''

``Over the last decade (and in some fields for longer) policy makers have modified some aspects of this analytical framework. Drawing on longstanding developments in academic economics, it has been acknowledged that orthodox neoclassical analysis has limitations: that liberalised markets are not always efficient and market failures can be significant.33 Policy makers have recognised the need for greater government intervention, in fields such as labour market, regional and environmental policy, as well as in monetary and financial policy. In many of these fields, and others, the OECD has supported these new analytical and policy developments.''},
  creationdate     = {2022-12-03T13:06:32},
  keywords         = {economics, policy},
  modificationdate = {2022-12-09T09:08:01},
  owner            = {ISargent},
}

@InCollection{GoodfriendK1997,
  author           = {Marvin Goodfriend and Robert King},
  booktitle        = {NBER Macroeconomics Annual 1997},
  date             = {1997},
  title            = {The New Neoclassical Synthesis and the Role of Monetary Policy},
  pages            = {231--296},
  publisher        = {National Bureau of Economic Research, Inc},
  url              = {https://EconPapers.repec.org/RePEc:nbr:nberch:11040},
  comment          = {Neoclassical combined with Keynesian ideas of business cycles and wage and price stickiness becomes the Neoclassical Synthesis.

Monetarism initially threatened Neoclassical Synthesis (partly because monetarists said they were intellectually derived from pre-Keynesian quantity theory of money)

Describes ideas of monetarism

Rational Expectations was an idea introduced in the early 1970s, again initially incompatible with NC synthesis. - perceived variations in availability led to changes in price

Then Real Business Cycles (RBC) are introduced which I believe (uses the word intertemporal a lot) assumes that decisions are made by economic actors on the basis of expectations about now and a time in the future.

``In the RBC model, changes in tax rates have a powerful effect on real activity'' 

Also talks about New-Keynesian, Second-Generation New Keynesian and Dynamic Price-Setting models but I've not read this

Finally, bringing all the above together creates the New Neoclassical Synthesis! Goes on to discuss the impact and role of monetary policy

``The models of the New Neoclassical Synthesis are complex since they
involve intertemporal optimization, rational expectations, monopolistic
competition, costly price adjustment and dynamic price setting, and an
important role for monetary policy''},
  creationdate     = {2022-12-03T13:50:53},
  keywords         = {Economics, policy},
  modificationdate = {2022-12-03T14:15:37},
  owner            = {ISargent},
}

@TechReport{HMTreasury2010,
  author           = {{HM Treasury}},
  date             = {2010},
  institution      = {HM Treasury},
  title            = {Budget June 2010},
  eprint           = {https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/248096/0061.pdf},
  url              = {https://www.gov.uk/government/publications/budget-june-2010},
  comment          = {Why austerity:

``The Government has set out a credible deficit reduction plan that should provide businesses with the confidence they need to plan and invest, supporting the necessary recovery in business investment.''},
  creationdate     = {2022-12-03T14:14:02},
  isbn             = {9780102966305},
  keywords         = {economics, policy},
  modificationdate = {2022-12-03T14:19:07},
  owner            = {ISargent},
}

@TechReport{HoCBiodiversity2021,
  author           = {{House of Commons Environmental Audit Committee}},
  date             = {2021-06-30},
  institution      = {House of Commons Environmental Audit Committee},
  title            = {Biodiversity in the UK:bloom or bust? First Report of Session 2021--22},
  eprint           = {https://committees.parliament.uk/publications/6498/documents/70656/default/},
  url              = {https://publications.parliament.uk/pa/cm5802/cmselect/cmenvaud/136/136-report.html},
  comment          = {UK is one of the most nature-depleted countries in the world

15 percent of UK species are threatened with extinction

UK has the lowest level of biodiversity remaining.

UK has failed to meet at least 14 of the 19 Aichi biodiversity targets},
  creationdate     = {2022-12-03T15:09:23},
  keywords         = {environment, biodiversity},
  modificationdate = {2022-12-03T15:13:00},
  owner            = {ISargent},
}

@Online{OHID2022,
  author           = {{Office for Health Improvement and Disparities}},
  date             = {2022-02-28},
  title            = {Air pollution: applying All Our Health},
  url              = {https://www.gov.uk/government/publications/air-pollution-applying-all-our-health/air-pollution-applying-all-our-health},
  urldate          = {2022-12-03},
  creationdate     = {2022-12-03T15:17:50},
  modificationdate = {2022-12-03T15:18:55},
  owner            = {ISargent},
}

@Article{DefraJNCC2021,
  author           = {Defra, Department for Environment, Food and Rural Affairs and {JNCC}, the Joint Nature Conservation Committee},
  date             = {2021-10-28},
  title            = {UK Biodiversity Indicators 2021},
  url              = {https://jncc.gov.uk/our-work/uk-biodiversity-indicators-2021/},
  comment          = {Update on progress against Convention on Biological Diversity targets. They don't look good but there is book synthesis of the detail in here. However, HoCBiodiversity2021 says that UK has failed to meet at least 14 of the 19 Aichi biodiversity targets and DwyerW2020 says UK will fail to meet 2050 net-zero emissions targets and most of the Convention on Biological Diversity global 2020 targets},
  creationdate     = {2022-12-03T15:26:51},
  modificationdate = {2022-12-13T14:16:11},
  owner            = {ISargent},
}

@TechReport{IPPR2021,
  author           = {Harry Quilter-Pinner and Rachel Statham and Will Jennings and Viktor Valgar{\dh}sson},
  date             = {2021-12-04},
  institution      = {Institute of Public Policy Research},
  title            = {Trust issues: Dealing with distrust in politics},
  eprint           = {https://www.ippr.org/files/2021-12/trust-issues-dec-21.pdf},
  url              = {https://www.ippr.org/research/publications/trust-issues},
  comment          = {Very few people have trust in politicians

``Growing distrust in politicians should be of particular concern to democrats and progressives. A lack of trust matters for two main reasons. First, growing distrust can lead to a downwards spiral of democratic decline, with voters disengaging, becoming polarised, or turning to populist leaders and causes (Hooghe and Dassonneville 2018). Second, it matters for social progress: a lack of trust undermines the ability of government to intervene and deliver better policy outcomes (Hetherington 2006).''},
  creationdate     = {2022-12-03T16:01:38},
  keywords         = {economics, politics, policy, trust},
  modificationdate = {2022-12-03T18:31:22},
  owner            = {ISargent},
}

@TechReport{BrewerHKST2022,
  author           = {Mike Brewer and Karl Handscomb and Gavin Kelly and James Smith and Lalitha Try},
  date             = {2022-01-19},
  institution      = {Resolution Foundation},
  title            = {Social Insecurity: Assessing trends in social security to prepare for the decade of change ahead},
  eprint           = {https://economy2030.resolutionfoundation.org/wp-content/uploads/2022/01/Social-Insecurity.pdf},
  url              = {https://economy2030.resolutionfoundation.org/reports/social-insecurity/},
  abstract         = {The UK is facing a decade of unprecedented economic change as we adjust to a post-Covid-19 economy, a new economic context outside the European Union (EU), and the decarbonisation of the economy.  And the social security system has a key role to play in the years ahead: it is part of the policy toolkit for helping individuals and the economy as a whole deal with a period of enhanced labour market change, but it also needs to address the legacy problems of slow growth in living standards and high inequality. This report considers how well the UK's social security system for working-age households is equipped to meet these challenges, and, in particular, how well aligned it is with the country's likely future economic and social challenges.},
  creationdate     = {2022-12-03T17:27:20},
  keywords         = {economics, policy},
  modificationdate = {2022-12-03T17:29:22},
  owner            = {ISargent},
}

@InBook{Himmelweit2021,
  author           = {Susan Himmelweit},
  booktitle        = {The Political Economy of Industrial Strategy in the UK: From Productivity Problems to Development Dilemmas},
  title            = {Care As investment In social Infrastructure},
  isbn             = {9781788213394},
  pages            = {191--202},
  publisher        = {Agenda Publishing},
  url              = {http://www.jstor.org/stable/j.ctv1mvw8s5.22},
  urldate          = {2022-12-04},
  abstract         = {It may be surprising to see a section on care in a book on industrial strategy. How care is provided is rarely acknowledged to have strategic importance and tends to be seen as more a part of a nation's welfare and family policy than its industrial structure. However, care is a part of the foundational economy. It provides services that enable those who require help to function in society to have the basic capabilities that others take for granted. It is normal in their life-course for people to need care, through youth, disability or frail old age. Hence care and},
  comment          = {I've only skimmed the intro but this is saying a thing I've been thinking so nice to have a citation for it!},
  creationdate     = {2022-12-04T11:15:50},
  modificationdate = {2022-12-16T11:05:01},
  owner            = {ISargent},
  year             = {2021},
}

@InBook{Cornia2020,
  author           = {Giovanni Andrea Cornia},
  booktitle        = {The Macroeconomics of Developing Countries: An Intermediate Textbook},
  date             = {2020-03-26},
  title            = {Genesis, context, focus, and accounting relations of standard macroeconomics},
  isbn             = {9780198856672},
  comment          = {Macroeconomic analysis uses macro prices:
* wage rate
* exchange rate
* interest rate
* inflation rate

Commonly used policy tools: monetary, fiscal, exchange rate, and debt management policies

Other policy instruments: financial and banking regulation

Specific issues analysed by long-term supply-side macro models are economic growth and income distribution

growth models are refined but rarely incorporate factors like population structure, income distribution,... and environmental captial ... and social capital has been shown to reduce transaction costs as well as making like better

neoclassical economists believed that markets always cleared but this didn't happen in the Great Depression and thus Keynes ... 

Key aggregate balances include:
* balance of payments
* public deficit
* public debt
* private debt
* rate of inflation
* adequate regulation of the financial sector

There's a section that goes over macroeconomic accounting e.g. how to calculate GDP, balance of payments etc

Finally section on the Evolution of theory of macroeconomics:
1. Classical
2. Keynesian
3. Neoclassical synthesis
4. Monetarism revival (Friedman/Chicago School)
5. New classicial - Real Business Cycle
6. Structuralist},
  creationdate     = {2022-12-08T16:41:09},
  keywords         = {economics},
  modificationdate = {2023-01-18T20:49:39},
  owner            = {ISargent},
  year             = {2020},
}

@Book{BerryFB2021,
  title            = {The Political Economy of Industrial Strategy in the UK: From Productivity Problems to Development Dilemmas},
  editor           = {Craig Berry and Julie Froud and Tom Barker},
  isbn             = {9781788213394},
  publisher        = {Agenda Publishing},
  url              = {http://www.jstor.org/stable/j.ctv1mvw8s5},
  urldate          = {2022-12-08},
  abstract         = {Does the UK still have an industrial strategy? How should we understand the renewed interest within government in industrial policy - and now its apparent reversal - in recent years? This collection of essay by leading academics and practitioners including Victoria Chick, Kate Bell, Simon Lee, Karel Williams, Susan Himmelweit, Laurie Macfarlane and Ron Martin - among many others- considers the effectiveness of recent industrial policies in addressing the UK's economic malaise. In offering a broad political economy perspective on economic statecraft and development in the UK, the book focuses on the political and institutional foundations of industrial policy, the value of "foundational" economic practices, the challenge of greening capitalism and addressing regional inequalities, and the new financial and corporate governance structures required to radicalize industrial strategy.},
  creationdate     = {2022-12-08T18:23:14},
  keywords         = {economics},
  modificationdate = {2022-12-08T18:54:15},
  owner            = {ISargent},
  year             = {2021},
}

@InBook{Berry2021,
  author           = {Craig Berry},
  date             = {2021},
  title            = {Conclusion: Building a Progressive Industrial Strategy Amid and After Covid-19},
  doi              = {10.2307/j.ctv1mvw8s5.30},
  url              = {https://www.jstor.org/stable/j.ctv1mvw8s5},
  comment          = {period after 2007-08 crash was initially referred to post-crisis era but may soon be relabelled as inter-crisis or pre-pandemic era ``of course it seems likely that the climate crisis is already upon us - and to which the spread of Covid-19 is imtimately related - will in time assume terminological pre-eminance''

Argument between left and right over size of state boils down to:
a. whether we expect state actors to make poor decisions about allocation
b. whether we trust more the wisdom of people acting via democratic or via market-based processes

And industrial strategy is not one if it aims to maintain an economy fuelled by rent-seeking and unproductive activities

Very critical of neoliberal dominance - task of progressives is to convinced those not well served by NL that a different economic model may serve them better

Treasury is UK key institution for industry although the May government's establishment of Department for Business, Energy and Industrial Strategy (BEIS) seems to be trying to take away some of Treasury's power. Treasury tends to be sceptical of targetted industrial policies for fear of failure and distorted markets.

Main view of Treasury is that industrial policy is for increasing productivity. However, core problem is reduced to extracting greater value from labour inputs and this leads to neoliberal policies

The impact of Covid-19 is only comparable to world wards and changed how we see fiferent sectors - it could change politics as wars did.

Climate change - our options are to radically change energy production and use or to abandom large-scale productivity activity. Will need to swiftly abandon pseudo-competitive energy sector where sustainable energy is disincentivised.

Rise of platform firms is associated with los of domestic control over key economic infrastructure and resrouces - they locate most profitablu overseas 

To leave voters harms of Brexit was ``a price worth paying'' for ``taking back control'' (YouGov poll in 2017)

Only 9 percent of Britons was to return to 'normality' after covid

Coyle references on dethroning GDP as a yardstick of economic policy

Also scathing about Johnson

``fiscal expansion constrained only by evidence of real economic harm, rather than theoretical assumptions'' Stirling et al 2019},
  creationdate     = {2022-12-08T18:23:44},
  keywords         = {economics},
  modificationdate = {2022-12-08T18:52:37},
  owner            = {ISargent},
}

@TechReport{OECDInnovationPolicies2020,
  author           = {{OECD}},
  date             = {2020-10-15},
  institution      = {Organisation for Economic Cooperation and Development},
  title            = {Broad-based Innovation Policies for All Regions and Cities},
  url              = {https://www.oecd.org/publications/broadening-innovation-policy-299731d2-
en.htm},
  comment          = {Establishes 6 key principles that help broaden innovation policy to benefit all types of regions and cities:
1. Build on your regional innovation system, involving everyone
2. Ensure your regional innovation system is adaptive
3. Integrate mechanisms that support learning into policy development
4. Seek opportunities for local innovation along global value chains
5. Embrace disruption rather than fight it
6. Foster links between policy domains and its intermediaries},
  creationdate     = {2022-12-08T18:52:29},
  keywords         = {economics},
  modificationdate = {2022-12-09T09:08:13},
  owner            = {ISargent},
  year             = {2020},
}

@Article{LentonEtAl2022,
  author           = {Timothy M. Lenton and Scarlett Benson and Talia Smith and Theodora Ewer and Victor Lanel and Elizabeth Petykowski and Thomas W. R. Powell and Jesse F. Abrams and Fenna Blomsma and Simon Sharpe},
  date             = {2022-01-10},
  journaltitle     = {Global Sustainability},
  title            = {Operationalising positive tipping points towards global sustainability},
  url              = {https://www.cambridge.org/core/journals/global-sustainability/article/operationalising-positive-tipping-points-towards-global-sustainability/8E318C85A8E462AEC26913EC43FE60B1},
  comment          = {Targets such as 1.5 degrees demand transformative rates of societal change roughly 7 percent per year decline in ghg from now on

Thus need to identify `positive tipping points' or `sensitive intervention points' (See Hepburn)

Positive tipping points are intentional

Many theories including: social-technical / socio-technical  systems, social-ecological systems, transitions management, Multi-level perspective (Geels), leverage points...

Needs to happen faster than theory current suggests (i.e. >20 years)

Theory of how to tip a system includes concepts include forcing, enabling conditions, system features and control variables

``the key challenge in indentifying tipping points is thus to indentify the cirtical control variable(s) and features of a particular system''

Aspect of current conceptualisation of this system is that change is being triggered by agents external to the system, and does not capture endogenous evolution of the system

Tipping points often occur when there is a critical mass of individuals, although sometimes other factors occur. After ZeppiniFK2014 there are a range of models, which incorporate ideas like
* increasing returns
* learning by doing
* economies of scale
* technological reinforcement
* coordination tipping point - only occurs with mass coordination of individuals like for EV charging points
* informational cascades
* herding behaviour
* percolation threshold

Three phases to operationalising positive tipping points:
* identifying and creating enabling conditions
  * population size
  * social network structure
  * information/capability
  * price
  * performance/quality
  * desirability/symbolism
  * accessibility/convenience
  * complementarity
* Sensing the potential - e.g. 
  * workshops to identify tipping points
  * citizens' assmeblies and juries
  * formalise mathematical model of change
  * agent-based modelling
  * changes in dynamical behaviour of system - e.g. reduced resilience whereby system takes longer to recover from perturbations, even possible early warning signs before past stock market bubbles

List *who* should drive the change, and *how*:
Social, technological, ecological innovations, policy interventions and public investment, private investment and markets, public information and behavioural nudges.

``Existing regimes ... are stabilised by damping feedbacks ... many forms ... social realm, cultural norms, sunk costs, subsidies, ease of raising finance and lobbying groups''

Alternative to strengthening positive feedback is to weaken negative feedbacks},
  creationdate     = {2022-12-08T19:27:30},
  keywords         = {environment, sociology},
  modificationdate = {2022-12-09T08:47:33},
  owner            = {ISargent},
}

@TechReport{McCann2019,
  author           = {Philip McCann},
  date             = {2019},
  institution      = {UK Research and Innovation},
  title            = {UK Research and Innovation: A Place-Based Shift?},
  eprint           = {https://www.ifm.eng.cam.ac.uk/uploads/Research/CSTI/UKRI_Place/McCann_-_UK_Research_and_Innovation_-_A_Place-Based_Shift_vFinal.pdf},
  comment          = {UK productivity has bee flat since 2008 whereas in other countries it has risen some with more unemployment but not all

Reasons why advanced economies have face falling productivity growth relative to the post-war era may include:
* marginal costs for new knowledge generation
* waning of the IT revolution
* plateauing educational attainment (v student debt)
* aging population
* demand contractions

ICT has not been as important to increasing productivity as expected

London has very high productivity compared to other parts of UK, the interrgeional inequalities over such a short distance is exceptional in industrialised countries

Idea that growth would spread out from London [like a geographical trickle-down!]

Centralised government is inapproprirate under these conditions and makes improving productivity in places other than London difficult

Talks about Local Enterprise Partnerships LRPs

There is a slow shift towards a more place-based logic

Gives a history of place-based thinking

World Bank tries to be `space-blind' but OECD-Barca report is placed based

Standard research funding model is space-blind

UKRI research could build on knowledge about place-based research and innovation by:
* establishment of baselines
* development of theory of change (see below)
* foresight analysis and modelling
* output and outcome indicators
* monitoring of policy outcomes
* interpretation of different outomces
* dissemination of learning and best-practise

Identifies that a theory of change needs outlining for each place that determines 
* policy inputs, outputs and outcomes
* diffusion processes and, dessemination mechanism
Also explicit use of established baselines

efficiency is inputs to outputs
effectiveness/impact is outputs to outcomes},
  creationdate     = {2022-12-08T21:13:23},
  keywords         = {economics, policy, innovation},
  modificationdate = {2022-12-08T21:38:50},
  owner            = {ISargent},
}

@InBook{Benton2021,
  author           = {Dustin Benton},
  booktitle        = {The Political Economy of Industrial Strategy in the UK: From Productivity Problems to Development Dilemmas},
  date             = {2021},
  title            = {Clean and Lean: An Industrial Strategy for an Era of Globalization and Climate Change},
  doi              = {10.2307/j.ctv1mvw8s5.29},
  isbn             = {9781788213394},
  pages            = {277--284},
  publisher        = {Agenda Publishing},
  url              = {http://www.jstor.org/stable/j.ctv1mvw8s5.29},
  urldate          = {2022-12-09},
  abstract         = {The UK's economy has seen six years of gently declining growth rates, from around 0.6 per cent per quarter in 2014 after the government's austerity policies were gently relaxed, to 0.35 per cent per quarter in 2018 and 0.25 per cent per quarter in 2019. Of course, Brexit may have something to do with the UK's performance: the Institute for Fiscal Studies has shown that the economy is already ¬£50- 60 billion smaller than it would have been had the UK not voted to leave the EU, and that UK business investment growth is the lowest in the G7 (Emmerson et al.},
  comment          = {Paper that says that clean and green economy is good for jobs and society as well as environment

Between 2015 and 2018 the green economy grew at 5\% ayear (ONS report from 2018)

Green economy could provide good quality jobs e.g. 10,000 direct jobs in offshore wind could triple by 2030

Claim that ``the average UK manufacturer spends five times as much on resource costs as on labour...'' I'm not sure if this is the case but the reference given (later in the paragraph:  \url{https://green-alliance.org.uk/wp-content/uploads/2021/11/Lean_and_clean.pdf}) demonstrates that material costs are far more volatile that n labour and they have been higher than labour costs in recent years

``...more scope to raise productivity via resource efficiency than by cutting labour costs''

However, government decisions are not supporting clean/green technology - e.g. Brexit making it harder to attract tech industry

Contrasts the strategy for off shore eind and EVs and finds the starting point similar but only wind got the long term support with deployment

``because circular economy activity, encompassing remanufacturing, recycling, servitisation and repair, is well-correlated to skill levels that have been hollowed out by mechanisation and globalisation, these jobs are likely to reduce structural, and not just cyclical, unemployment''

future-proofed economic growth that addresses inequality and support good quality jobs should use policy to drive change to zero emissions vehicles, drive innovation in energy efficiency, deploy modular factory-built building retrofits, invest in resource productivity and circular economy approaches to heavy industry},
  creationdate     = {2022-12-09T08:03:35},
  keywords         = {economics, policy, environment, work, industry},
  modificationdate = {2023-01-18T20:08:49},
  owner            = {ISargent},
  year             = {2021},
}

@Article{ZeppiniFK2014,
  author           = {Paolo Zeppini and Koen Frenken and Roland Kupers},
  date             = {2014},
  journaltitle     = {Environmental Innovation and Societal Transitions},
  title            = {Thresholds models of technological transitions},
  doi              = {https://doi.org/10.1016/j.eist.2013.10.002},
  issn             = {2210-4224},
  pages            = {54-70},
  url              = {https://www.sciencedirect.com/science/article/pii/S2210422413000713},
  volume           = {11},
  abstract         = {We present a systematic review of seven threshold models of technological transitions from physics, biology, economics and sociology. The very same phenomenon of a technological transition can be explained by very different logics, ranging from economic explanations based on price, performance and increasing returns to alternative explanations based on word-of-mouth recommendation, convergence of expectations, or social mimicking behaviour. Our review serves as a menu for future modelling exercises that can take one or more elementary transition models as a basis, and extend these model to fit more specific sectoral, technological or territorial contexts.},
  comment          = {Heavily referenced in LentonEtAl2022

Considers 7 models of technological transition:
* hyperselection (Bruckner et al 1996)
* adoption (Arthur 1989)
* coordination game (a class of economic models of strategic interaction)
* information cascades (Banerjee 1992 and Bikhchandani et al 1992)
* co-evolution (technologies are often composed of components that interact in complex ways to produce particular functionalities)
* percolation (diffusion through society, e.g. word of mouth)
* social influence (e.g. Granovetter 1978)

Most, but not all, models follow economic assumption of utility maximisation

The same phenomenon of a technological transition can be explained by very different underlying logics e.g. prices, recommendations, expectations and mimicking

Mentions Geels's work as being evolutionary which is at odd with the typical revolutionary framing of two competing technologies

These models should be considered canonical and as building blocks. Contextual factors would be needed to specify the framework for evaluation in any given context},
  creationdate     = {2022-12-09T08:46:22},
  keywords         = {Technological lock-in, Tipping point, Critical mass, Coordination, Sustainability},
  modificationdate = {2022-12-09T09:00:34},
  owner            = {ISargent},
}

@Book{Perez2002,
  author           = {Carlota Perez},
  date             = {2002},
  title            = {Technological Revolutions and Financial Capital},
  isbn             = {9781781005323},
  comment          = {When technologies become `common sense' a new regulatory framework with sppropriate institutions is required to steer and facilitate the functions of the new economy in a socially and economically equitable manner p4

A technological revolution comprises a cluster of technology, low cost input of energy, rapid transport and communications p8

Each technology has potential in all economic activities p8

Compares with Kuznets's Epochal Innovations p9

In constrast to technological revolution, techno-economic paradigms (Chapter 2 section C) includes much more intangible ideas such as common sense, principles, best practise, standards, the way organisations are structured, [I understand this to be those things that are obvious to those living within the paradigm that would not have been obvious beforehand]

Organisations change to enable the new paradigm: hierarchies were good for previous paradigms where information needed to flow from top but they are now rigid and clumsy p17-19

Instead a decentralised organisation with a strategy core is more flexible and networked p19

See references to Castells chapters for more information on social, cultural, economic and political, and including organisational impacts of change of paradigm p19

As the paradigm shifts there will be an accumulation and installation in new direction and disaccumulation and uninstallation from the old direction p20

Society is shaped by and shapes the revolution p22

The history of the understanding of `creative distruction' p22

`great surges of development' p23

Changes occur initially by demands of the changing economy and then the needs resulting from the consequent turbulence p25

There is likely to be a loss of jobs, skills and geographical displacement, social unrest, the collapse of social adaptability ultimate lead to an acceptance of `common sense' p26-7

It can be difficult to vision the future potential from the new technology - examples of people in the past who could (e.g. Alexander Graham Bell, who had difficulty being understood) and couldn't (e.g. Eddison and the boss of IBM)

The exhaustion of the old paradigm creates a need for radical entrapreneurship and also creates idle capital to invest p33

Once design, product and profit is visible, engineers, designers and entrepreneurs will be fired to innovate in the new trajectory p34

There is a list of tensions on p39

Fitting Hitler and Roosevelt into the model p41

Installation period: tense coexistence of two paradigms p43

At the end: evolutions begin to wain p45-6

Not a straight jacket for history - a heurstic device P49

Phases:
* Irruption - Old models not working meanwhile new entrepreneurs, new ideas, successful behaviors p49-50 
* Frenzy - Rich getting richer. Veblen \& Engels Migrations. Productivity explosion. Regulation seen as hindering. Individualism p50-52
* Turning Point - Collective wellbeing. Regulation needed p52-53
* Synergy - Labour Laws, Full employment (as near as) redistribution. Middle class. Financial capital directly tied to production p53-54
* Maturity - Meadows Limits to Growth Report. signs of prosperity but broken promises. workers protests. Protests of marginalised p54-56

The current surge, forming the Age of Information and Telecommunications, began in 1971 with the creation of the microprocessor. This Irrupted into previous surge which has formed the Age of Oil, the Automobile and Mass Production which is considered to have started around 1908 when the Model-T rolled off the production line

Not read p58 onwards},
  creationdate     = {2022-12-09T10:17:36},
  keywords         = {economics, innovation, transformation},
  modificationdate = {2022-12-11T13:27:49},
  owner            = {ISargent},
}

@Article{DiasT2019,
  author           = {Raquel Dias and Ali Torkamani},
  date             = {2019},
  journaltitle     = {Genome Medicine},
  title            = {Artificial intelligence in clinical and genomic diagnostics},
  url              = {https://genomemedicine.biomedcentral.com/articles/10.1186/s13073-019-0689-8},
  creationdate     = {2022-12-09T21:04:08},
  keywords         = {AI, Machine Learning, Medicine, Genomics},
  modificationdate = {2022-12-09T21:05:06},
  owner            = {ISargent},
}

@Book{Topol2019,
  author           = {Topol, Eric},
  date             = {2019},
  title            = {Deep Medicine: How Artificial Intelligence Can Make Healthcare Human Again},
  isbn             = {9781541644649},
  publisher        = {Basic Books},
  url              = {https://books.google.co.uk/books?id=\_EFlDwAAQBAJ},
  abstract         = {A visit to a physician these days is cold: physicians spend most of their time typing at computers, making minimal eye contact. Appointments generally last only a few minutes, with scarce time for the doctor to connect to a patient's story, or explain how and why different procedures and treatments might be undertaken. As a result, errors abound: indeed, misdiagnosis is the fourth-leading cause of death in the United States, trailing only heart disease, cancer, and stroke. This is because, despite having access to more resources than ever, doctors are vulnerable not just to the economic demand to see more patients, but to distraction, burnout, data overload, and their own intrinsic biases. Physicians are simply overmatched.

As Eric Topol argues in Deep Medicine, artificial intelligence can help. Natural-language processing could automatically record notes from our doctor visits; virtual psychiatrists could better predict the risk of suicide or other mental health issues for vulnerable patients; deep-learning software will make every physician a master diagnostician; and we could even use smartphone apps to take our own medical "selfies" for skin exams and receive immediate analysis. . On top of that, the virtual smartphone assistants of today--Alexa, Siri, Cortana--could analyze our daily health data to reduce the need for doctor visits and trips to the emergency room, and support for people suffering from asthma, epilepsy, and heart disease. By integrating tools like these into their daily medical practice, doctors would be able to spend less time collecting and cataloging information, and more time providing thorough, intimate, and meaningful care for their patients, as no machine can.

Artificial intelligence can also help remedy the debilitating cost of healthcare, both for individuals and the economy writ large. The medical sector now absorbs 20 percent of the US gross domestic product--it is largest sector by dollars and jobs. And it's very inefficient. Take the cost of medical scans: There are over 20 million medical scans performed in the US every day, and an MRI, for example, costs hundreds to thousands of dollars. AI could process 260 million medical scans (more than 2 weeks' worth) in less than 24 hours for a cost of only $1000. We pay billions and billions of dollars for the same work today.

The American health care system needs a serious reboot, and artificial intelligence is just the thing to press the restart button. As innovative as it is hopeful, Deep Medicine ultimately shows us how we can leverage artificial intelligence for better care at lower costs with more empathy, for the benefit of patients and physicians alike.},
  comment          = {Book about how medicine could be revolutionised by AI

\url{https://www.google.co.uk/books/edition/Deep_Medicine/_EFlDwAAQBAJ}},
  creationdate     = {2022-12-09T21:23:10},
  keywords         = {artificial intelligence, medicine},
  lccn             = {2018043932},
  modificationdate = {2022-12-10T19:59:07},
  owner            = {ISargent},
}

@Article{CastillaRhoRAH2017,
  author           = {Castilla-Rho, Juan Carlos and Rojas, Rodrigo and Andersen, Martin S. and Holley, Cameron and Mariethoz, Gregoire},
  date             = {2017-09-01},
  journaltitle     = {Nature Human Behaviour},
  title            = {Social tipping points in global groundwater management},
  doi              = {10.1038/s41562-017-0181-7},
  issue            = {9},
  pages            = {640--649},
  url              = {https://www.nature.com/articles/s41562-017-0181-7},
  volume           = {1},
  abstract         = {Groundwater is critical to global food security, environmental flows, and millions of rural livelihoods in the face of climate change1. Although a third of Earth's largest groundwater basins are being depleted by irrigated agriculture2, little is known about the conditions that lead resource users to comply with conservation policies. Here we developed an agent-based model3,4of irrigated agriculture rooted in principles of cooperation5,6and collective action7and grounded on the World Values Survey Wave 6 (n‚Äâ=‚Äâ90,350). Simulations of three major aquifer systems facing unsustainable demands reveal tipping points where social norms towards groundwater conservation shift abruptly with small changes in cultural values and monitoring and enforcement provisions. These tipping points are amplified by group size and best invoked by engaging a minority of rule followers. Overall, we present a powerful tool for evaluating the contingency of regulatory compliance upon cultural, socioeconomic, institutional and physical conditions, and its susceptibility to change beyond thresholds. Managing these thresholds may help to avoid unsustainable groundwater development, reduce enforcement costs, better account for cultural diversity in transboundary aquifer management and increase community resilience to changes in regional climate. Although we focus on groundwater, our methods and findings apply broadly to other resource management issues.},
  creationdate     = {2022-12-10T09:12:23},
  keywords         = {transformation, social science, economics},
  modificationdate = {2022-12-10T19:59:28},
  owner            = {ISargent},
  year             = {2017},
}





@Article{Zuboff2015,
  author           = {Shoshana Zuboff},
  date             = {2015},
  journaltitle     = {Journal of Information Technology},
  title            = {Big other: Surveillance Capitalism and the Prospects of an Information Civilization},
  doi              = {10.1057/jit.2015.5},
  eprint           = {https://journals.sagepub.com/doi/epdf/10.1057/jit.2015.5},
  number           = {1},
  pages            = {75-89},
  url              = {https://doi.org/10.1057/jit.2015.5},
  volume           = {30},
  abstract         = {This article describes an emergent logic of accumulation in the networked sphere, `surveillance capitalism,' and considers its implications for `information civilization.' The institutionalizing practices and operational assumptions of Google Inc. are the primary lens for this analysis as they are rendered in two recent articles authored by Google Chief Economist Hal Varian. Varian asserts four uses that follow from computer-mediated transactions: data extraction and analysis,' `new contractual forms due to better monitoring,' `personalization and customization, ' and continuous experiments. ' An examination of the nature and consequences of these uses sheds light on the implicit logic of surveillance capitalism and the global architecture of computer mediation upon which it depends. This architecture produces a distributed and largely uncontested new expression of power that I christen: Big Other. ' It is constituted by unexpected and often illegible mechanisms of extraction, commodification, and control that effectively exile persons from their own behavior while producing new markets of behavioral prediction and modification. Surveillance capitalism challenges democratic norms and departs in key ways from the centuries-long evolution of market capitalism.},
  comment          = {The surveillance capitalism paper

Those actions of big tech, principally Google in this paper, that challenged existing social norms have been legally challenged. As a result google has obscured these activities, bypassing detection by users. Also has been creation of dependency on the technologies making it more difficult for individuals to avoid having their data extracted and exploited e.g. by third parties who use moments of vulnerability.

See also \url{https://www.youtube.com/watch?v=hIXhnWUmMvw}},
  creationdate     = {2022-12-10T10:59:23},
  keywords         = {artificial intelligence, data, trust},
  modificationdate = {2023-02-19T16:54:32},
  owner            = {ISargent},
}

@Article{Hooker2021,
  author           = {Sara Hooker},
  date             = {2021-04-09},
  journaltitle     = {Patterns},
  title            = {Moving beyond ``algorithmic bias is a data problem''},
  doi              = {10.1016/j.patter.2021.100241},
  issue            = {4},
  url              = {https://www.sciencedirect.com/science/article/pii/S2666389921000611},
  volume           = {2},
  comment          = {Piece on bias in AI making it clear that it can't be wholly addressed in the data pipeline and therefore needs to be understood as an outcome of the algorithm.

``The goal of this article is not to convince you to ignore the data pipeline and focus solely on model design bias but rather that understanding the role that both data and the model play in contributing to bias can be a powerful tool in mitigating harm. Algorithm design is not impartial, and mitigating harm here is often more feasible than collecting comprehensive labels. ''},
  creationdate     = {2022-12-10T15:32:29},
  keywords         = {AI, machine leraning, data, bias, trust},
  modificationdate = {2022-12-10T15:35:03},
  owner            = {ISargent},
}

@Article{Arenas2021,
  author           = {Laura Arenas and Anna Mar√≠a Gil-Lafuente},
  date             = {2021},
  journaltitle     = {International Journal of Sensor Networks and Data Communications},
  title            = {Emerging Technologies, Innovation, and Volatility: A MiniReview},
  eprint           = {https://www.hilarispublisher.com/open-access/emerging-technologies-innovation-and-volatility-a-minireview.pdf},
  comment          = {stock markets are volatile as investors become over enthusiastic about the new technology

builds on technological revolutions of Perez},
  creationdate     = {2022-12-10T17:27:16},
  keywords         = {transformation, economics, policy},
  modificationdate = {2022-12-17T15:37:37},
  owner            = {ISargent},
}

@Article{Silberman1996,
  author           = {James M. Silberman and Charles Weiss and Mark Dutz},
  journaltitle     = {Technology In Society},
  title            = {Marshall Plan Productivity Assistance: A Unique Program of Mass Technology Transfer and a Precedent for the Former Soviet Union},
  number           = {4},
  pages            = {443--460},
  url              = {https://reader.elsevier.com/reader/sd/pii/S0160791X96000231?token=6379D6DAD108BD25CB1EE74F27FB8E26E09AAF8F5D1D19FE09BAA07785000928BB9705A716A99BC053BEA29859EE9202&originRegion=eu-west-1&originCreation=20221210194810},
  volume           = {18},
  abstract         = {The Productivity Program of the Marshall Plan made a major contribution to the increase in Western European productivityin the 195Os, well before there was significant policy liberalization, competition, or foreign investment in these countries. Prior to the program, European manufacturing and management practice was a generation behind the US, and productivity was one-third of US levels.The cost of this program over ten years was $300 million, or only 1.5\% of Marshall Plan capital assistance. Its 1500 study tours brought tens of thousands of people from European and Asian countries to the United States to observe management and production. On returning home, tour members vigorously spread new ideas throughout their countries, which also received a wide variety of follow-up technical services. Europe's leaders supported national productivity drives out of fear of communism and social unrest, not in response to competitive market forces. The drives helped jhas achieve almost immediate productivity gains with little new investment. This relatively inexpensive idea could increase incomes and improve the supply and variety of consumer goods in present-day Eastern Europe and the former Soviet Union.},
  creationdate     = {2022-12-10T19:50:23},
  keywords         = {economics, industry, policy, transformation},
  modificationdate = {2022-12-10T20:55:41},
  owner            = {ISargent},
  year             = {1996},
}

@Online{MarshallPlan1948,
  author           = {{National Archives}},
  date             = {1948},
  title            = {Transcripts of Secretary of State George Marshall's Speech and the European Recovery Act/Marshall Plan},
  url              = {https://www.archives.gov/milestone-documents/marshall-plan},
  urldate          = {2022-12-10},
  creationdate     = {2022-12-10T19:55:39},
  keywords         = {policy, transition},
  modificationdate = {2022-12-11T12:06:03},
  owner            = {ISargent},
}

@Article{HoyerEtAl2022,
  author           = {Daniel Hoyer and James S Bennett and Harvey Whitehouse and Pieter Fran\c{c}ois and Kevin Feeney and Jill Levine and Jenny Reddish and Donagh Davis and Peter Turchin},
  date             = {2022},
  journaltitle     = {SocArXiv},
  title            = {Flattening the Curve: Learning the lessons of world history to mitigate societal crises},
  doi              = {10.31235/osf.io/hyj48},
  url              = {https://osf.io/preprints/socarxiv/hyj48/},
  comment          = {This is from Peter Turchin who did the data science analysis of historical data in order to identify signals for impending unrest in society 
   \url{http://www.theguardian.com/technology/2019/nov/12/history-as-a-giant-data-set-how-analysing-the-past-could-help-save-the-future}

Analyses 100 historical societies and determines the severity of their crises based on 12 `consequences'. Finds 4 periods when none of these consequences materialises:
* Republican Rome: Conflict of the Orders (494-287 BCE)
* England: Chartist Movement: 1819-1867 CE
* Russia: Reform Period: 1855-1881 CE
* USA: Progressive Era: 1914-1939 CE

Looks at each of these in detail

Two different conclusions can be drawn from these periods
First that they were preceded by periods of land expansion which meant that wealth could be extracted and people exported 
Second that institutional reform restored popular wellbeing in all four cases

``The cases explored here suggest some possible answers. It appears incumbent on those with the greatest access to power, wealth, and authority to `future think' and recognize the signs of unrest early on. Crucially, elites must be willing to give up some private gains for the public good, for example through supporting welfare programs or promoting redistribution of wealth and labour autonomy to the working classes''},
  creationdate     = {2022-12-10T20:17:38},
  keywords         = {history, economics, social science, transformation},
  modificationdate = {2022-12-10T20:44:00},
  owner            = {ISargent},
}

@Article{Perez2010,
  author           = {Carlota Perez},
  date             = {2010},
  journaltitle     = {Cambridge Journal of Economics},
  title            = {Technological revolutions and techno-economic paradigms},
  doi              = {10.1093/cje/bep051},
  pages            = {185--202},
  volume           = {34},
  comment          = {Consideres technological revolutions specifically from the innovation perspective, after Schumpeter, because it is innovation rather than invention that is of interest to markets and thus results in meaningful change.

Radical innovations are improved on by incremental innovations

Innovation doesn't happen in isolation, there are many agents of change in the collective process: suppliers, distributors and many others, including consumers. 

Radical innovations stimulate the growth of whole industries - and technology systems. These modify business, institutions and culture and require rules and regulations. Ultimately, these adaptations shape the technology itself

Goes on to discuss the 5 Technological Revolutions

Great surges of development break with Kondratiev's and Schumpeter's notion of Long Waves

From Perez 1983 finds 3 different types of core industry in the revolution:
* motive - what is cheap (semiconductors, oil, steel, coal, water power)
* carrier - products of the revolution (h/w and s/w, cars and appliances, steel shops, iron machines, textile machines)
* infrastructure - (internet, roads and electricity, world transport, transcontinental railways and steamship routes and ports, national railways and canals)

Discusses the techno-economic or meta- paradigm - emergin heuristic routines and approaches, changes in cost structure. 

Lots of examples from each surge

Also, changes beyond the economy - suburbanisation, globalisation. Discusses organisational changes need to enable flexible networked increasingly global operationsIZ*.  but there is inertia: ``The operations manuals and hierarchical structures of government ministries in the 1960s were fundamentally similar to those of a big mass production corporation. Yet, at present, these two sorts of institutions are very different.''

``On the view being described here, the notions of long run equilibrium and continuous progress are rejected in favour of more complex processes of overcoming multiple disequilibria originated in massive innovation, in internal differentiation within and between sectors, of creative destruction, assimilation, learning and unlearning successive technological spaces and best practice models and of reaching and overcoming maturity through successive surges of change.''

IZ* [I misunderstood this section but it makes me realise that this isn't described in Perez's account: Markets and competition, which were common place in the private sector entered into the public sector Public Choice Theory and New Public Management]},
  creationdate     = {2022-12-11T11:17:32},
  keywords         = {economics, transformation, innovation, technology, institutions},
  modificationdate = {2022-12-11T15:39:08},
  owner            = {ISargent},
  year             = {2010},
}

@Article{Brown2021,
  author           = {Ross Brown},
  date             = {2021},
  journaltitle     = {European Planning Studies},
  title            = {Mission-oriented or mission adrift? A critical examination of mission-oriented innovation policies},
  doi              = {10.1080/09654313.2020.1779189},
  issue            = {4},
  pages            = {739--761},
  url              = {https://www.tandfonline.com/doi/abs/10.1080/09654313.2020.1779189},
  volume           = {29},
  comment          = {Contrasts mission-oriented innovation policies with diffusion oriented approaches for the new Scottish National Investment Bank SNIB. (\cite{Freeman1995} goes into this distinction). Finds that the mission oriented approach applied to this bank ``constitutes 'fuzzy' policy making which is highly opaque lacking sufficient detail and fails to align itself properly with the demand conditions within the Scottish innovation system''. Suggest some version of diffusion-oriented policies would work better up to include hybrid and generating breakthrough innovation firms.

According to Mazzucato and Penna, state investment banks have three roles: counter-cyclical capital development and new venture support

Is paper asks ``are mission oriented innovation policies sufficiently nuanced to assist policymakers in the operational and strategic deployment of new policy instruments such as the SNIB?''

``Mission-oriented countries often heavily prioritise a highly linear [science and technology approach to innovation] STI view of innovation (Jensen at al 2007)''

Diffusion oriented approach ... ``is more experimental interactive va and relational towards innovation ... knowledge arise from doing, using and interacting (DUI)''

Garudand Karn√∏e 2003 vividly demonstrate the differences between gui and STI breakthrough approaches towards innovation in their study of Danish and US wind turbine industry. In Denmark there was less emphasis on developing dramatic solutions instead strong networks of actors gradually built up their technological competencies. In us the focus was on producing radically new Hi-Tec lightweight and high-speed turbines. Denmark prevailed.

Identifies that diffusion oriented approaches often have local embeddedness local orientation and this discourages blue skies research and precludes getting involved in the creation of startups.

Considers:
* types of mission
* types of innovation
* types of instruments

Missions:
Goes into some detail pretty king blueprint for the bank identifying that these are rather high-level and don't offer practical mechanism for achieving the objectives. Highlights concerns about the risk of `policy capture', `agency problems', `implementation failures' and the fact that the bank aims to make a positive financial return could mean it becomes risk-averse.

Criticises the advice that policymakers should pick the problem not the sector by saying that ``selecting missions may have unintended consequences of preferentially benefiting certain sectors over others which goes against the banks principal of supporting firms `whatever sector they appear' ''

Innovation:
Identify that much research in Scotland occurs in universities and very little in the SME sector. High-tech SMEs constitute a very small part of the business population. Suggest that the focus on high growth firms could damage the non-high tech SME sector. A note that the unpredictable nature of firm growth some suggest it's random.

Instruments:
Find that there has only been a partial assessment of funding gaps and goes into more detail about funding approaches

According to Haldane (2018, 7) the UK does R well but D poorly where the refers to development that the diffusion and dissemination of innovation. 

The diffusion oriented approach they suggest is is similar to a strategy undertaken by countries such as Israel via their Yozma Fund.

Also See Freeman1995 for discussion of ST(I) - linear - approach  compared to (DUI) diffusion - approach which emerged in the 50s and 60s. Also Lundvall2007, Martin2016.},
  creationdate     = {2022-12-11T11:27:40},
  keywords         = {economics, missions, innovation, policy},
  modificationdate = {2023-02-02T10:55:17},
  owner            = {ISargent},
  year             = {2021},
}

@Article{Bhutoria2022,
  author           = {Aditi Bhutoria},
  title            = {Personalized education and Artificial Intelligence in the United States, China, and India: A systematic review using a Human-In-The-Loop model},
  doi              = {https://doi.org/10.1016/j.caeai.2022.100068},
  issn             = {2666-920X},
  pages            = {100068},
  url              = {https://www.sciencedirect.com/science/article/pii/S2666920X22000236},
  volume           = {3},
  abstract         = {The traditional ‚Äúone size fits all‚Äù education system has been largely criticized in recent years on the ground of its lacking the capacity to meet individual student needs. Global education systems are leaning towards a more personalized, student-centered approach. Innovations like Big Data, Machine Learning, and Artificial Intelligence (AI) have given the modern-day technology to accommodate the distinctive features of human beings - smart machines and computers have been built to understand individual-specific needs. This opens an avenue for ‚Äúpersonalization‚Äù in the education sector. From, mushrooming of Education Technology (EdTech) start-ups to government funding in AI research, it is evident that the next generation educational reforms would take a quantum leap forward piloted by Big Data analysis and AI. The objective of this paper is to organize the vast literature on the use of AI for personalization of education and to shed light on the key themes by which an AI-driven approach makes structural modifications to the existing education system. To this effect, the paper employed a systematic review using a Human-In-The-Loop natural language processing model of past two years' literature (2019-2021) in English language from IEEE Xplore on countries China, India and the USA. This process yielded more than 2000 search results at first and these were eventually shortlisted to 353 relevant papers for in-depth analysis. Being the pioneers in EdTech innovations, insights from research done in these three countries provides valuable input for the development of global education systems and research. The findings bring forward AI's success in catering to specific learning requirements, learning habits, and learning abilities of students and guiding them into optimized learning paths across all three countries. Not just that, it is also evident from the literature that AI augments educational content, customizes it for any individual according to their needs, and raises the flag of caution for anticipated learning difficulties. This recalibrates the role of instructors as well as optimizes the teaching-learning environment for a better learning experience. The upward trajectory of educational development with AI opens a new horizon of personalized education for the future generation, but also comes with its challenges. Data privacy issues, availability of digital resources, and affordability constraints have been reported in the recent literature as impediments in the way of promoting such technologies for day-to-day practice.},
  comment          = {assimilates recent research trends on the incorporation of technology for personalized education in the three top EdTech hubs of the world: the United States, China, and India

EdTech},
  creationdate     = {2022-12-11T15:37:48},
  journal          = {Computers and Education: Artificial Intelligence},
  keywords         = {education, Artificial intelligence},
  modificationdate = {2022-12-11T15:52:06},
  owner            = {ISargent},
  year             = {2022},
}

@Article{WangWHHC2021,
  author           = {Haifeng Wang and Hua Wu and Zhongjun He and Liang Huang and Kenneth Ward Church},
  title            = {Progress in Machine Translation},
  doi              = {https://doi.org/10.1016/j.eng.2021.03.023},
  issn             = {2095-8099},
  url              = {https://www.sciencedirect.com/science/article/pii/S2095809921002745},
  abstract         = {After more than 70 years of evolution, great achievements have been made in machine translation. Especially in recent years, translation quality has been greatly improved with the emergence of neural machine translation (NMT). In this article, we first review the history of machine translation from rule-based machine translation to example-based machine translation and statistical machine translation. We then introduce NMT in more detail, including the basic framework and the current dominant framework, Transformer, as well as multilingual translation models to deal with the data sparseness problem. In addition, we introduce cutting-edge simultaneous translation methods that achieve a balance between translation quality and latency. We then describe various products and applications of machine translation. At the end of this article, we briefly discuss challenges and future research directions in this field.},
  comment          = {Paper review SoTA in machine translation - spoken/written language

``A good translation should have at least two characteristics: adequacy and fluency. Nowadays, NMT methods can produce translations for some language pairs and domains with very high adequacy and fluency in particular text translation scenarios; however, such methods are far from perfect, especially in simultaneous scenarios. Many aspects remain to be improved.''},
  creationdate     = {2022-12-11T15:50:48},
  journal          = {Engineering},
  keywords         = {Machine translation, Neural machine translation, Simultaneous translation},
  modificationdate = {2022-12-11T15:52:40},
  owner            = {ISargent},
  year             = {2021},
}

@Online{IndigenousKnowledgeGraph2021,
  author           = {{IVOW AI Developers}},
  date             = {2021},
  title            = {Indigenous Knowledge Graph},
  url              = {https://www.ivow.ai/ikgstories.html},
  comment          = {Building a knowledge graph of indigenous values},
  creationdate     = {2022-12-11T15:55:40},
  keywords         = {artificial intelligence, knowledge graph, culture},
  modificationdate = {2022-12-11T16:00:53},
  owner            = {ISargent},
}

@Misc{Nolan2022,
  author           = {Nolan,Beatrice},
  date             = {2022-06-26},
  title            = {The average data scientist earns almost \$100,000 a year - and the barriers to entry for candidates are being broken down},
  language         = {English},
  url              = {https://www.proquest.com/newspapers/average-data-scientist-earns-almost-100-000-year/docview/2680788252/se-2},
  comment          = {There's a machine learning talent shortage etc...},
  creationdate     = {2022-12-11T16:18:09},
  journal          = {Business Insider},
  keywords         = {Machine learning, Data science, economics},
  modificationdate = {2022-12-11T17:49:48},
  month            = {6},
  owner            = {ISargent},
  year             = {2022},
}

@Article{TshitoyanDWDRKPCJ2019,
  author           = {Vahe Tshitoyan and John Dagdelen and Leigh Weston and Alexander Dunn and Ziqin Rong and Olga Kononova and Kristin A. Persson and Gerbrand Ceder and Anubhav Jain},
  date             = {2019-07-03},
  journaltitle     = {Nature},
  title            = {Unsupervised word embeddings capture latent knowledge from materials science literature},
  doi              = {10.1038/s41586-019-1335-8},
  pages            = {95--98},
  url              = {https://www.nature.com/articles/s41586-019-1335-8},
  volume           = {571},
  creationdate     = {2022-12-11T16:26:21},
  keywords         = {artificial intelligence, science, mining, discovery},
  modificationdate = {2022-12-11T17:49:32},
  owner            = {ISargent},
  year             = {2019},
}

@Article{MontesdeOcaZapiainSD2021,
  author           = {Montes de Oca Zapiain, David and James A. Stewart and Dingreville, R\'{e}mi},
  date             = {2021-01-04},
  journaltitle     = {npj Computational Materials},
  title            = {Accelerating phase-field-based microstructure evolution predictions via surrogate models trained by machine learning methods},
  doi              = {10.1038/s41524-020-00471-8},
  issue            = {3},
  url              = {https://www.nature.com/articles/s41524-020-00471-8},
  volume           = {7},
  comment          = {Machine learning for developing new materials},
  creationdate     = {2022-12-11T16:37:12},
  modificationdate = {2022-12-11T17:49:00},
  owner            = {ISargent},
  year             = {2021},
}

@Article{AzizAWA2021,
  author           = {Nurhasyimah Abd Aziz and Nur Afiqah Amalin Adnan and Dzuraidah Abd Wahab and Abdul Hadi Azman},
  date             = {2021},
  journaltitle     = {Journal of Cleaner Production},
  title            = {Component design optimisation based on artificial intelligence in support of additive manufacturing repair and restoration: Current status and future outlook for remanufacturing},
  doi              = {https://doi.org/10.1016/j.jclepro.2021.126401},
  issn             = {0959-6526},
  pages            = {126401},
  url              = {https://www.sciencedirect.com/science/article/pii/S0959652621006211},
  volume           = {296},
  abstract         = {The Circular Economy concept aims to ensure environmental sustainability through the recovery of durable products that have reached the end of their useable life. Recovery strategies such as remanufacturing enable durable parts and cores to be restored to their original functionality and performance, thereby minimising the consumption of virgin materials and energy required for the production of new parts and components. To date, the repair and restoration processes concerning those parts and cores that can be remanufactured involved conventional methods such as material overlay and welding. These conventional methods are highly dependent on skilled manual labour or specialised industrial robots. With the notable growth in the global remanufacturing industry, it is imperative to deploy highly-efficient and sustainable methods to automate repair and restoration. Recent trends in remanufacturing repair and restoration indicate an increasing interest in metal additive manufacturing technology. To enhance the additive manufacturing efficiency for automated repair and restoration, it is crucial to optimise the core design. This paper provides a comprehensive and comparative outline of remanufacturing repair and restoration, using both conventional and automated methods. This paper also presents and discusses comprehensive insight into the application of AI-based techniques for design optimisation specific to additive manufacturing repair. Component design optimisation is crucial due to its impact on process efficiency and the life cycle of components. The review indicates that, despite the increasing interest in using additive manufacturing for repair and restoration, reports on the application of AI for design optimisation specific to repair and restoration using additive manufacturing remain limited. Furthermore, there are no established guidelines concerning design for repair and restoration using additive manufacturing. The paper concludes with recommendations for further research and presents a future outlook on AI-based optimisation for component design to facilitate repair and restoration using additive manufacturing. Automation is expected to facilitate the removal of roadblocks specific to process inefficiency and human limitations during conventional repair and restoration in remanufacturing.},
  comment          = {Based on premise of circular economy - need to restore and remanufacture durable parts.

AI can be used to optimise compents for additive manufacturing (3D printing)},
  creationdate     = {2022-12-11T16:44:33},
  keywords         = {Additive manufacturing, Remanufacturing, Repair and restoration, Artificial intelligence, Design optimisation},
  modificationdate = {2022-12-11T16:56:05},
  owner            = {ISargent},
}

@Online{Lopez2020,
  author           = {Elyssa Lopez},
  date             = {2020-03-09},
  title            = {Artificial intelligence: friend or foe to Philippine call centre workers?},
  url              = {https://www.scmp.com/week-asia/economics/article/3073999/artificial-intelligence-friend-or-foe-philippine-call-centre},
  urldate          = {2022-12-11},
  comment          = {China post article about training up ppl to work AI while the machines do the boring stuff},
  creationdate     = {2022-12-11T16:55:59},
  keywords         = {economics, artificial intelligence},
  modificationdate = {2022-12-11T16:58:01},
  owner            = {ISargent},
}

@Article{CastroDEFKKSv2020,
  author           = {Juana Castro and Stefan Drews and Filippos Exadaktylos and Jo\"{e}l Foramitti and Franziska Klein and h\'{e}o Konc and Ivan Savin and Jeroen van den Bergh},
  date             = {2020},
  journaltitle     = {WIREs Climate Change},
  title            = {A review of agent-based modeling of climate-energy policy},
  doi              = {10.1002/wcc.647},
  issue            = {4},
  url              = {https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/wcc.647},
  volume           = {11},
  comment          = {Review 61 studies that employed ABMs to study climate-energy policies. This focused on three main themes,namely, emissions reduction, product/technology diffusion, and energy conservation, and associated subthemes. Common examples of the latter are carbon and electricity markets, energy-efficiency investments in residential buildings,and diffusion of electric vehicles and renewable energy technologies.},
  creationdate     = {2022-12-11T17:05:00},
  keywords         = {artificial intelligence, climate, agent-based modelling, policy},
  modificationdate = {2022-12-11T17:12:55},
  owner            = {ISargent},
  year             = {2020},
}

@InProceedings{HutchinsonRGHP2022,
  author           = {Hutchinson, Ben and Rostamzadeh, Negar and Greer, Christina and Heller, Katherine and Prabhakaran, Vinodkumar},
  booktitle        = {2022 ACM Conference on Fairness, Accountability, and Transparency},
  title            = {Evaluation Gaps in Machine Learning Practice},
  doi              = {10.1145/3531146.3533233},
  isbn             = {9781450393522},
  location         = {Seoul, Republic of Korea},
  pages            = {1859--1876},
  publisher        = {Association for Computing Machinery},
  series           = {FAccT '22},
  url              = {https://doi.org/10.1145/3531146.3533233},
  abstract         = {Forming a reliable judgement of a machine learning (ML) model's appropriateness for an application ecosystem is critical for its responsible use, and requires considering a broad range of factors including harms, benefits, and responsibilities. In practice, however, evaluations of ML models frequently focus on only a narrow range of decontextualized predictive behaviours. We examine the evaluation gaps between the idealized breadth of evaluation concerns and the observed narrow focus of actual evaluations. Through an empirical study of papers from recent high-profile conferences in the Computer Vision and Natural Language Processing communities, we demonstrate a general focus on a handful of evaluation methods. By considering the metrics and test data distributions used in these methods, we draw attention to which properties of models are centered in the field, revealing the properties that are frequently neglected or sidelined during evaluation. By studying these properties, we demonstrate the machine learning discipline's implicit assumption of a range of commitments which have normative impacts; these include commitments to consequentialism, abstractability from context, the quantifiability of impacts, the limited role of model inputs in evaluation, and the equivalence of different failure modes. Shedding light on these assumptions enables us to question their appropriateness for ML system contexts, pointing the way towards more contextualized evaluation methodologies for robustly examining the trustworthiness of ML models.},
  address          = {New York, NY, USA},
  comment          = {Review recent submissions on computer visions and natural language processing and find that there is a focus on a few evalutaion methods, neglecting others.},
  creationdate     = {2022-12-11T18:37:01},
  keywords         = {applications, machine learning, evaluation},
  modificationdate = {2022-12-11T18:38:25},
  numpages         = {18},
  owner            = {ISargent},
  year             = {2022},
}

@Article{Mitchell2021,
  author           = {Mitchell, Melanie},
  title            = {Why AI is Harder Than We Think},
  doi              = {10.48550/ARXIV.2104.12871},
  url              = {https://arxiv.org/abs/2104.12871},
  comment          = {Excellent paper challenging ideas of intelligence and assumptions about the ability to artificially create it. Rich source of AI history.

Describes periods of AI Winter and AI Spring and their causes and consequences (e.g. don't use the term AI)

Sets out 4 fallacies:
1. Narrow intelligence is on a continuum with general intelligence
2. Easy things are easy and hard things are hard
3. The lure of wishful mnemonics
4.  Intelligence is all in the brain

Lots of references to common sense},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2022-12-11T19:46:36},
  keywords         = {Artificial Intelligence},
  modificationdate = {2022-12-11T19:51:25},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2021},
}

@Online{GHCL2022,
  author           = {{GitHub Copilot Litigation}},
  date             = {2022-11-03},
  title            = {We've filed a lawsuit challenging GitHub Copilot, an AI product that relies on unprecedented open-source software piracy. Because AI needs to be fair \& ethical for everyone.},
  url              = {https://githubcopilotlitigation.com/},
  urldate          = {2022-11-27},
  comment          = {Copyright lawsuit against GitHub for their tool that suggests code corrections based on the code that others have supplied to the platform},
  creationdate     = {2022-12-12T20:03:15},
  modificationdate = {2022-12-12T20:06:41},
  owner            = {ISargent},
}

@Online{UNRadicalTransform2022,
  author           = {{United Nations}},
  date             = {2022-10-27},
  title            = {Climate change: No `credible pathway' to 1.5C limit, UNEP warns},
  url              = {https://news.un.org/en/story/2022/10/1129912},
  subtitle         = {``Only a root-and-branch transformation of our economies and societies can save us from accelerating climate disaster''},
  urldate          = {2022-12-04},
  comment          = {``Only a root-and-branch transformation of our economies and societies can save us from accelerating climate disaster''},
  creationdate     = {2022-12-12T20:51:48},
  modificationdate = {2022-12-12T20:55:48},
  owner            = {ISargent},
}






@Article{HickelK2020,
  author           = {Jason Hickel and Giorgos Kallis},
  date             = {2020},
  journaltitle     = {New Political Economy},
  title            = {Is Green Growth Possible?},
  doi              = {10.1080/13563467.2019.1598964},
  eprint           = {https://doi.org/10.1080/13563467.2019.1598964},
  number           = {4},
  pages            = {469-486},
  url              = {https://www.tandfonline.com/doi/full/10.1080/13563467.2019.1598964},
  volume           = {25},
  comment          = {Looks at GDP growth and climate outcomes based on assessment of studies on historical trends and model-based projects

Consider the amount of decoupling between GDP growth and carbon emissions

Find that its highly unlikely that continued economic growth can be achieved while keeping gloabl warming below 1.5 or 2 degrees},
  creationdate     = {2022-12-13T17:29:01},
  keywords         = {economics, climate, environment},
  modificationdate = {2022-12-13T19:40:46},
  owner            = {ISargent},
  publisher        = {Routledge},
}

@Online{USCongress1981,
  author           = {{US Congress}},
  date             = {1981-07-23},
  title            = {H.R.4242 - Economic Recovery Tax Act of 1981},
  url              = {https://www.congress.gov/bill/97th-congress/house-bill/4242},
  urldate          = {2022-12-11},
  comment          = {Reagan cuts highest tax rate from 70 to 50 percent},
  creationdate     = {2022-12-14T18:14:21},
  keywords         = {economics, policy},
  modificationdate = {2022-12-14T18:16:28},
  owner            = {ISargent},
}

@Online{HouseOfCommons2013,
  author           = {{House of Commons Library}},
  date             = {2013-09-20},
  title            = {VAT : the temporary cut in the standard rate},
  url              = {https://commonslibrary.parliament.uk/research-briefings/sn00701/},
  urldate          = {2022-12-11},
  comment          = {Alistair Darling reduces VAT rate from 17.5 to 15 percent to stimulate demand},
  creationdate     = {2022-12-14T18:21:26},
  modificationdate = {2022-12-14T18:23:18},
  owner            = {ISargent},
}

@Online{ONSTrustInGov2022,
  author           = {{ONS}},
  date             = {2022-07-13},
  editor           = {{Office for National Statistics}},
  title            = {Trust in government, UK: 2022},
  url              = {https://www.ons.gov.uk/peoplepopulationandcommunity/wellbeing/bulletins/trustingovernmentuk/2022},
  urldate          = {2022-12-11},
  creationdate     = {2022-12-14T19:14:49},
  modificationdate = {2022-12-16T17:01:42},
  owner            = {ISargent},
}

@TechReport{HeydeckerOW2022,
  author           = {Rachel Heydecker and Hannah Ormston and Jennifer Wallace},
  date             = {2022-01-01},
  institution      = {Carnegie UK},
  title            = {{GDWe}: A spotlight on democraticwellbeing},
  eprint           = {https://d1ssu070pg2v9i.cloudfront.net/pex/pex_carnegie2021/2022/01/20123523/GDWe-A-spotlight-on-democratic-wellbeing-FINAL.pdf},
  url              = {https://www.carnegieuktrust.org.uk/publications/gdwe-a-spotlight-on-democratic-wellbeing/},
  comment          = {Really interesting report making a case for Gross Domestric Wellbeing (GDWe)

Made up of social wellbeing, economic wellbeing, environmental wellbeing and democratic wellbeing

"the majority of the public had not had any practical use for GDP
statistics (72\%) in the past, with 8\% referring to these in the past 3 months and a further 13\% more than 3 months ago"

Emphasis on more work on democratic wellbeing, including more indicators in the ONS Measures of National Wellbeing Dashboard},
  creationdate     = {2022-12-14T19:29:56},
  isbn             = {978-1-912908-79-0},
  keywords         = {trust, policy, government, economics},
  modificationdate = {2022-12-14T20:05:18},
  owner            = {ISargent},
}

@Online{Oberlin2020,
  author           = {{Oberlin College}},
  date             = {2020-01-06},
  title            = {Oberlin Environmental Dashboard},
  url              = {https://environmentaldashboard.org/},
  urldate          = {2022-12-22},
  creationdate     = {2022-12-14T19:52:40},
  modificationdate = {2022-12-14T19:59:06},
  owner            = {ISargent},
}

@Article{NatureCooperativeHuman2018,
  author           = {{Anon.}},
  date             = {2018-07-09},
  journaltitle     = {Nature Human Behaviour},
  title            = {The cooperative human},
  doi              = {10.1038/s41562-018-0389-1},
  pages            = {427--428},
  url              = {https://www.nature.com/articles/s41562-018-0389-1},
  volume           = {2},
  comment          = {Editorial for a special issue on how cooperative humans seem to be in the wild. Issue includes CastillaRhoRAH2017},
  creationdate     = {2022-12-14T20:05:15},
  modificationdate = {2022-12-14T22:28:14},
  owner            = {ISargent},
  year             = {2018},
}

@Online{WEFNext72022,
  author           = {World Economic Forum},
  date             = {2022-09-19},
  title            = {This Indigenous principle could transform how we invest in nature},
  url              = {https://www.weforum.org/agenda/2022/09/indigenous-principle-invest-in-nature/},
  urldate          = {2022-12-11},
  comment          = {Indigenous ``next 7'' principles considers the impact on the next 7 generations},
  creationdate     = {2022-12-14T20:42:52},
  keywords         = {economics, anthropology, sociology, climate, environment},
  modificationdate = {2022-12-14T20:44:39},
  owner            = {ISargent},
}

@Online{LGA2022,
  author           = {{Local Government Association}},
  date             = {2022-06-30},
  title            = {England's leaky homes will cost poorer families ¬£250 extra a year in wasted energy},
  url              = {https://www.local.gov.uk/about/news/englands-leaky-homes-will-cost-poorer-families-ps250-extra-year-wasted-energy},
  creationdate     = {2022-12-15T10:32:40},
  modificationdate = {2022-12-15T10:39:01},
  owner            = {ISargent},
}

@Online{Keep2021,
  author           = {Matthew Keep},
  date             = {2021-03-08},
  title            = {Infrastructure policies and investment},
  url              = {https://commonslibrary.parliament.uk/research-briefings/sn06594/},
  comment          = {There is broad consensus that over the past 40 years the UK has under-invested in infrastructure},
  creationdate     = {2022-12-15T18:24:12},
  keywords         = {economics, policy},
  modificationdate = {2022-12-15T18:26:47},
  owner            = {ISargent},
}

@Article{Ostrom1996,
  author           = {Elinor Ostrom},
  date             = {1996},
  journaltitle     = {World Development},
  title            = {Crossing the great divide: Coproduction, synergy, and development},
  doi              = {https://doi.org/10.1016/0305-750X(96)00023-X},
  issn             = {0305-750X},
  number           = {6},
  pages            = {1073-1087},
  url              = {https://www.sciencedirect.com/science/article/pii/0305750X9600023X},
  volume           = {24},
  abstract         = {Coproduction is a process through which inputs from individuals who are not ‚Äúin‚Äù the same organization are transformed into goods and services. Two cases are presented ‚Äî one from Brazil and one from Nigeria ‚Äî where public officials play a major role. In Brazil, public officials actively encourage a high level of citizen input to the production of urban infrastructure. In Nigeria, public officials discourage citizen contributions to primary education. The third section of the paper provides a brief overview of the theory of coproduction and its relevance for understanding the two cases. The last section addresses the implications of coproduction in polycentric systems for synergy and development.},
  comment          = {``Coproduction implies that citizens can play an active role in producing public goods and services of consequence to them''

Example from Brazil whereby citizens were involved in digging and installing small feeder lines for water and sanitation which could then be linked into the lrager trunk lines. This meant it could be away from traffic and thus much cheaper and locals could continue to maintain the feeder lines.

Second example was various schools in Nigeria that had a range of states of repair, moral and students outcomes. ``When coproduction is discouraged by taking over schools that villagers had perceived as being ``their'' schools, by creating chaotic changes in who was responsible for funding and running a primary school system, and by top-down administrative command as the style for all decision making, only the most determined citizens will persist in coproductive activities.''},
  creationdate     = {2022-12-16T13:09:57},
  keywords         = {economics, policy, sociogy},
  modificationdate = {2022-12-16T13:29:52},
  owner            = {ISargent},
}

@Article{zuErmgassenDBCMRC2022,
  author           = {zu Ermgassen, Sophus O.S.E. and Michal P. Drewniok and Joseph W. Bull and Corlet Walker, Christine M. and Mattia Mancini and Josh Ryan-Collins and Cabrera Serrenho, Andr\'{e}},
  date             = {2022-11-01},
  journaltitle     = {Ecological Economics},
  title            = {A home for all within planetary boundaries: Pathways for meeting England's housing needs without transgressing national climate and biodiversity goals},
  doi              = {10.1016/j.ecolecon.2022.107562},
  url              = {https://www.sciencedirect.com/science/article/pii/S0921800922002245},
  volume           = {201},
  comment          = {Highlights: 

* The primary government response to England's housing affordability crisis is to build 300,000 new homes per year

* Using embodied and operational emissions models we estimate the government's business-as-usual housing strategy consumes England's whole cumulative carbon budget [1.5¬∞C] by 2050

* Other strategies for meeting society's housing needs are theoretically possible, but they face a challenging political economy

* `Growth-dependencies' in the housing sector mean social welfare risks declining if house prices and construction rates fall

* Solutions include decarbonising the existing housing stock through rapid retrofitting, and policies disincentivising the overconsumption of floorspace


A super snappy summary of the state of housing stock with regard to climate and biodiversity.

``Government household and housing stock data show that the UK has a surplus of dwellings relative to households (Fig. 1). This surplus has grown from 660,000-1.23 million homes from 1996 to 2019 (Mulheirn, 2019)''

``In summary, this exploration of the drivers of housing unaffordability suggests the problem may be less with the total supply of housing units and more with their distribution across the population and `overconsumption' by wealthier groups, enabled by rising incomes and easy credit conditions. Policy reforms that could dampen the demand for housing beyond a basic level of need could theoretically enable the UK housing system to satisfy greater housing need without relying on rapid housing expansion. This is welcome, as a solely supply-side explanation would imply that the only way to satisfy more housing need is through housing expansion, despite the inherent environmental impacts.''},
  creationdate     = {2022-12-16T13:35:58},
  keywords         = {economics, policy, environment},
  modificationdate = {2023-01-14T15:26:36},
  owner            = {ISargent},
}

@TechReport{KedwardGR2022,
  author           = {Kedward, Katie and Gabor, Daniela and Ryan-Collins, Josh},
  institution      = {UCL Institute for Innovation and Public Purpose},
  title            = {Aligning finance with the green transition: From a risk-based to an allocative green credit policy regime},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/wp2022-11},
  comment          = {Challenges current `risk-based' approach to financing which  prioritises `monetary dominance'

``Its overarching logic, framed by the macro-financial status-quo of monetary dominance, is to outsource the pace and nature of decarbonization to private finance''

``The state is expected to assist private finance in its efforts to lead the green transition, given the twin assumptions of limited fiscal capacity and the superiority of private credit markets in efficiently allocating capital (Bezemer et al. 2021; Gabor 2021).''

``the risk-based approach has not succeeded in materially shifting financial flows away from transition-incompatible activities and towards the rapid build-out of urgently needed green solutions.''},
  creationdate     = {2022-12-16T13:49:13},
  modificationdate = {2022-12-16T14:39:04},
  owner            = {ISargent},
  series           = {Working Paper Series (IIPP WP 2022-11)},
  year             = {2022},
}

@TechReport{OECDUKRecovery2010,
  author           = {OECD},
  date             = {2010},
  institution      = {Organisation for Economic Cooperation and Development},
  title            = {United Kingdom: Policies for a Sustainable Recovery},
  doi              = {10.1787/9789264201774-en},
  eprint           = {https://www.oecd-ilibrary.org/docserver/9789264201774-en.pdf?expires=1671202590&id=id&accname=guest&checksum=C6EB8B5AD77AD51487059D1DF0AF04A8},
  url              = {https://www.oecd-ilibrary.org/economics/united-kingdom-policies-for-a-sustainable-recovery_9789264201774-en},
  comment          = {1. a credible fiscal consolidation plan
2. a strategy to tackle structural problems
3. the UK should increase its ability to tap new sources of growth

Not sure if this is why the Austerity budgets...

* Ensure fiscal sustainability. Implement the consolidation plan. Raise the retirement age to improve fiscal
sustainability. Ensure full independence for the recently created Office for Budget Responsibility.
* Reform the regulatory framework for the financial sector. Ensure appropriate regulation and supervision
of the financial system, both through national measures and constructive engagement at the international
and European level. Create a ‚Äúfirewall‚Äù between high risk investment banking and commercial banking.
* Improve educational outcomes. Increase participation in quality early-childhood education. Improve
educational outcomes and skill formation, especially among disadvantaged children. Discourage early
leaving from the education system. Increase the quality of vocational training and the availability of
high-quality apprenticeship positions to ensure that relevant skills are provided.
* Increase efforts to make work pay and to help workers to fi nd and retain work. Ensure adequate staffing
of Public Employment Services and target existing activation efforts on the most disadvantaged and
hardest-to-place youth.
* Tackle high levels of disability benefit claimants. Ensure that all claimants are covered by the announced
Work Program scheme. Monitor health status earlier and more frequently in the workforce.
* Pursue public sector reforms to improve productivity. Improve productivity and control costs in health care
by containing capitation fees and wages. Reinforce competition among health care providers to mitigate
price pressures. Raise consistency in the allocation of health care responsibility across government
bodies. Improve productivity in education (e.g. through further decentralisation of decision making).
* Promote green growth. Further enhance integration of environmental concerns into national and sectoral
policies in order to move towards green growth and create incentives for the private sector to invest in
green technologies and undertake climate adaptation actions. Turn the Climate Change Levy into a fullfl edged carbon tax. Abolish the reduced VAT rate for domestic energy use and reassess the economic and
environmental effi ciency of other green taxes.
* Increase the effi ciency of the tax system. Address the economic and environmental ineffi ciencies in the
VAT system created by exemptions and reduced rates.
* Prioritise investment in innovation, infrastructure and R\&D. While fiscal consolidation makes severe
budget cuts necessary, growth enhancing activities such as infrastructure, green investment and R\&D
spending should be prioritised. Implement a national road pricing scheme to mitigate road congestion.
* Improve the functioning of the housing market. Make the planning system more flexible, more predictable
and provide incentives for local communities to release land for building, while continuing to protect
the environment. Shift property taxation from stamp duties towards recurrent taxes based on market
property values.},
  creationdate     = {2022-12-16T14:39:07},
  keywords         = {economics, policy},
  modificationdate = {2022-12-16T14:55:09},
  owner            = {ISargent},
  publishser       = {OECD Publishing},
  series           = {Better Policies},
  year             = {2010},
}

@Online{Rozenbaum2020,
  author           = {Mia Rozenbaum},
  date             = {2020-07-06},
  title            = {The increase in zoonotic diseases: the WHO, the why and the when?},
  url              = {https://www.understandinganimalresearch.org.uk/news/the-increase-in-zoonotic-diseases-the-who-the-why-and-the-when},
  organization     = {Understanding Animal Research},
  comment          = {60\% of emerging infectious diseases in humans are zoonotic.

the spill over of pathogens from animal hosts to people may have more than tripled in the last decade},
  creationdate     = {2022-12-17T20:33:40},
  modificationdate = {2022-12-17T20:36:03},
  owner            = {ISargent},
}

@InBook{IPCCSR15Ch2,
  author           = {{IPCC}},
  booktitle        = {Global Warming of 1.5$^o$C. An IPCC Special Report on the impacts of global warming of 1.5$^o$C above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change, sustainable development, and efforts to eradicate poverty},
  date             = {2018},
  title            = {Mitigation pathways compatible with 1.5$^o$C in the context of sustainable development},
  doi              = {10.1017/9781009157940.001},
  editor           = {Masson-Delmotte, V. and P. Zhai and H.-O. P\"{o}rtner and D. Roberts and J. Skea and P.R. Shukla and A. Pirani and W. Moufouma-Okia and C. P\'{e}an and R. Pidcock and S. Connors and J.B.R. Matthews and Y. Chen and X. Zhou and M.I. Gomis and E. Lonnoy and T. Maycock and M. Tignor and T. Waterfield},
  url              = {https://www.ipcc.ch/sr15/chapter/chapter-2/},
  comment          = {Based on a range of models, pathways, policies and technologies finds the social cost of carbon (SCC) can vary considerably

Find that results are better when carbon pricing is in tandem with policy

See also summary articles in Zotero (``IPCC: Not just a carbon price, but a really high one'') which says ``United Nations report estimated that governments would need to impose effective carbon prices of \$135 to \$5,500 per ton of carbon dioxide pollution by 2030 to keep overall global warming below 1.5 degrees Celsius''},
  creationdate     = {2023-01-08T09:10:54},
  institution      = {United Nations Intergovernmental Panel on Climate Change},
  keywords         = {economics, climate},
  modificationdate = {2023-01-18T21:00:56},
  owner            = {ISargent},
}

@TechReport{WeissM2020,
  author           = {Weiss, Mitchell B. and Sarah Mehta},
  date             = {2020},
  institution      = {Harvard Business School},
  title            = {TraceTogether},
  note             = {Revised July 2020},
  subtitle         = {Case 820-111},
  url              = {https://www.dropbox.com/s/hlkfzsdn8dcbi96/Trace Together HBS Case.pdf?dl=0},
  comment          = {Description of the development and roll-out of Singaporean contact-tracing app.

Based on untested ideas, possibly worked well in a technical sense but doesn't seem to have had an impact on covid cases.

Questions about privacy form public, although design seemed to try to ensure privacy.

Code was ultimately open sourced and other governments used it.},
  creationdate     = {2023-01-14T15:55:22},
  keywords         = {policy, health, covid-9},
  modificationdate = {2023-02-02T13:57:19},
  owner            = {izzyolivine},
}

@Online{KattelDK2022,
  author           = {Rainer Kattel and Wolfgang Drechsler and Erkki Karo},
  date             = {2022-11-23},
  title            = {Innovations need bureaucracy},
  url              = {https://medium.com/iipp-blog/innovations-need-bureaucracy-e13b3a79222c},
  comment          = {Blog post summarising the book How to Make and Entreprenaurial State: Why Innovation Needs Bureaucracy

Begins with the example of Physikalisch-Technische Reichsanstalt PTR established in Germany in 1887 for developing physical standards using funding, land and organisational design by Werner Siemens. Aim to build up scientific bureaucracy - blueprint of how to move from agile and start-up phase to more stable delivery-focus. 

Siemens is a `bureaucracy hacker'

Appointed a charismatic leader

Mission Mystique (term coined by Charles Goodsell in 2010) enables the innovation bureaucracy to cope with the risks and uncertainties associated with innovaiton and lead dynamic changes

Such innovation bureaucracies are established to deal with emerging technological or socio-economic challanges. This was predicted by Max Weber who described how charismatic authority becomes bureaucratic authority and then back to charismatic. Particular categories of organisation - charismatic networks and expert organisations - is often an oscillation between these extremes: agile stability

Looks at two present-day examples

Vinnova, Swedish Innovation Agency, working now being reframed from focusing primarily on technological issues to tackling socio-economic challenges such as rethinking food systems to privde healthy sustainable food in schools.

Government Data Service GDS, changed governement's digital transformation mindset enabling the break-up of oligopolistic markets broken by creation of many SME contracts. gov.uk created. People hired into GDS were from places like BBC.},
  creationdate     = {2023-01-14T16:06:23},
  modificationdate = {2023-01-15T07:43:41},
  owner            = {izzyolivine},
}

@TechReport{Kattel2022,
  author           = {Rainer Kattel},
  date             = {2022-03-31},
  institution      = {Institute of Innovation and Public Purpose},
  title            = {Dynamic capabilities of the public sector: Towards a new synthesis},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/publications/2022/mar/dynamic-capabilities-public-sector-towards-new-synthesis},
  comment          = {I feel I may need to read this again as I get more familiar with the topic. 

Agencies that have been sources of policy innovation have tended to be peripheral agencies, not central (Weberian) and such agencies experience less political interference. This is possibly the ``Schumpeterian alternative''.

``Kattel, Drechsler and Karo 2019 have shown, first, such `central-decentral' dynamics in state capacity help explain dynamic capabilities on the system level, but not on the organisational level; and second, the dynamics can be explained through Weber's theory of authority, in particular through the interplay between charismatic and legal-rational forms of authority (Kattel, Drechsler and Karo 2019).''

NPM reforms in 1980s opened public sector up to private sector managerial practice - strategeic manager, agile management - as well as focus on short-term efficiencies - based on the measurement of inputs and outputs, benchmarking and governement indicators. Focus was on inefficiences in big machine-like organisations rather than innovative capacities of public sector.

Pollitt and Bouckeart (2011) posit that Neo-Weberian state (NWS, see Bouckeart2022) is emerging - public organisations provide ``public services, and at the same time recognises the need for more citizen engagement in the design and delivery of public services''. Also identify new public governance theories - ``emphasise the importance of the co-creation and co-production of public services''.

Find that this is little work analysing the capacities and capabilities of public sector organisations. Suggest that these can be understood around organisational routines. Hypothesise the there are 3 main types of routine:
* sense-making (e.g. information gathering and processing)
* connecting (e.g. new networks and coalitions)
* shaping (e.g. new directionality for organisation)

Tests the hypothesis against three case studies: UK's Government Digital Service (GDS), the city of Barcelona and Swedish innovation agency Vinnova.

``In all three cases, we can argue that existing sense-making routines limited organisational learning and autonomy at the same time. New leadership and new organisational structures were critical to instil both new epistemological perspectives and to make sure there were rapid learning feedback loops.''

New connecting routines were created in all three cases, such as through `democratising' of innovation.

``In terms of shaping ‚Äî executing or implementing ‚Äî new activities, both GDS and Barcelona offer more mature cases as Vinnova's implementation processes are at earlier stages.''

Sources of dynamic capabilities:
1. political leadership
2. managerial leadership (new managers)
3. new organisation

``Such organisations aim to be both dynamic and resilient by design. We can call these Neo-Weberian agencies.''},
  creationdate     = {2023-01-15T08:13:00},
  keywords         = {economics, bureaucracy},
  modificationdate = {2023-01-21T14:31:03},
  owner            = {izzyolivine},
  series           = {IIPP Working paper},
  year             = {2022},
}

@TechReport{Bouckaert2022,
  author           = {Geert Bouckaert},
  date             = {2022-06-27},
  institution      = {UCL Institute for Innovation for Public Purpose},
  title            = {The neo-Weberian state: From ideal type model to reality?},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/publications/2022/jun/neo-weberian-state-ideal-type-model-reality},
  comment          = {I think this paper proposes the name ``neo-Weberian state'' (NWS) to fit many European states, or at least builds on earlier work by the author to propose the name. I would need to look more widely to understand better. (from Kattel2022: ``Introduced by Pollitt and Bouckaert in 2011, the Neo-Weberian state posits that a new paradigm of the state is emerging in the era of post-New Public Management reforms.'')

Reference earlier work that identifies 4 ideal types: maintain, modernise, marketise and minimise. Find that in realit, states can be hybrids or blends of these. Maintain and modernise combine in NWS. A combination of marketise and minimised is a fit with New Public Management (NPM).

OECD promosed NPM and New Zealand showcased this. However, reform is more than simply "more or less" NPM, there are other types of modernisation such as NWS.

Weber considered the difference between  `community'(Gemeinschaft) to `society' (Gesellschaft). He considered rational spirit of bureaucracy as efficient and powerful. This paper describes the Weberian state model as holding space between bureaucracy, society and business.

Develops the `driver'-space which is defined by different mechanisms: hierachy (H), markets (M) and networks (N). NWS is more about H and some N, and less M. I find Table 1 which describes the Weberian and Neo components of NWS. One of the Neo elements is ``Shift from an internal orientation towards bureaucratic rulefollowing towards an external orientation towards meeting citizens' needs and wishes. The primary route to achieving this is not the employment of market mechanisms (although they may occasionally come in handy), but the creation of a professional culture of quality and service. ''

There's lots of discussion of the three components H, M and N and transition between them.

NPM is more about M and some N, much less H. New Public Governance (NPG) has the bias towards N, some M and not much H.},
  creationdate     = {2023-01-15T14:56:36},
  keywords         = {economics, bureaucracy},
  modificationdate = {2023-01-15T16:01:56},
  owner            = {izzyolivine},
}

@Article{TonuristKL2017,
  author           = {Piret T\~{o}nurist and Rainer Kattel and Veiko Lember},
  date             = {2017},
  journaltitle     = {Public Management Review},
  title            = {Innovation labs in the public sector: what they are and what they do?},
  doi              = {10.1080/14719037.2017.1287939},
  number           = {10},
  pages            = {1455--1479},
  url              = {https://www.tandfonline.com/doi/abs/10.1080/14719037.2017.1287939},
  volume           = {19},
  comment          = {Maps and analyses innovation labs (i-labs) in the public sector - 35 in total - with more detail on 11 of them. 

Table 1 gives overview of organisation theories that explain organisational change - useful to return to.

This studies tests possible reasons for creating innovation labs (from classical organizational and evolutionary theories): 
* emulation
* individual learning
* old and new structures (competition and conflict)
* external complexity (environment)
* technology
* expertise / legitimacy

Discusses financing, performance measures

i-labs usually built around a particular user-design-led method (e..g human-centred design, friendly hacker). They tend to employ people from a wide range of backgrounds.

Reasons for formation, mainly from interviews with executives:
* support for the role of external complexity and technology
* conflict between old and new organizational structures was not brought up as a specific reason
* internal learning effects were deemed subservient to external changes
* specific know-how and the autonomy of i-labs were deemed essential for the survival of the organizations
* some emulation and fad of labs can be justified as a causal factor
* ``politicians were able to show credible commitment to innovation through the creation of public-sector i-labs''
* the reasons for formation do not necessarily remain relevant to goals and logics later on
* other main activities include coordination with other government bodies

Autonomy in salary-setting and staff evaluation, goal-setting was present in many organisations. i-labs are ``supposed'' to be disruptive. ``exist in turbulent and conflicting environments''. However, they have no authority over other public-sector structures and have limited ability to catalyse and push through public-sector-wide changes.

Argue that:
1. creation of i-labs can be tied to external complexity and technology propositions - tech plays a central role
2. its a bit of a fad after ealier i-labs
3. its supposed to catalyse change but autonomy alone is not enough to challenge existing structures [my comments below on this]
4. i-labs tend to have somewhat higher `mortality' that other public sector organisations
5. have a reliance on external ICT capabilities

[izzy - our experience of research and innovation is that it is difficult to permeate the existing organisation. p1474 of this paper discusses how ``and the lack of supportive culture and authority to routinize new solutions limit the potential of i-labs to enact the change-agent's role'']},
  creationdate     = {2023-01-15T16:48:21},
  keywords         = {economics, bureaucracy},
  modificationdate = {2023-01-15T17:44:04},
  owner            = {izzyolivine},
  year             = {2017},
}

@Article{Kattel2015,
  author           = {Rainer Kattel},
  journaltitle     = {NISPAcee Journal of Public Administration and Policy},
  title            = {What would Max Weber say about public sector innovation},
  url              = {https://content.sciendo.com/configurable/contentpage/journals$002fnispa$002f8$002f1$002farticle-p9.xml},
  comment          = {``The aim of this article is to, fi rst, give a brief overview of prevailing attempts to conceptualize (define) public-sector innovation and, second, contrast it with older literature on innovation''

conceptualise public sector innovation in 3 periods:
1. the Schumpeterian period - public sector innovation related to wider theories of evolutionary change
2. the organizational-theory period - innovation in public sector similar to those in private companies, mainly organisational theory
3. the autochthonous-theory period - dissociating public and private innovation},
  creationdate     = {2023-01-15T17:43:07},
  keywords         = {economics, bureaucracy},
  modificationdate = {2023-01-15T18:48:45},
  owner            = {izzyolivine},
  year             = {2015},
}

@InBook{DunleavyMBT2006,
  author           = {Patrick Dunleavy and Helen Margetts and Simon Bastow and Jane Tinkler},
  booktitle        = {Digital Era Governance: IT Corporations, the State, and e-Government},
  date             = {2006},
  title            = {The Theory of Modern Bureaucracy and the Neglected Role of IT},
  chapter          = {1},
  doi              = {10.1093/acprof:oso/9780199296194.001.0001},
  comment          = {Public administration literature tends to marginalise IT.

Suggests that Weber was not original in his observation of modern bureaucracies as German Brockhaus encyclopedia of 1819 complains about the use of pens when word of mouth has previously done the work.

Weber's analysis was distinctive in how he identified that it was necessary to bring together qualified officials with a systematized organisation.

Give nice history of bureaucracy from paper-based systems, including search, to IT.

The Weberian concept with in-house operations seemed an inadequate idea by the 1990s when much IT is done by external agencies.

Mintzberg (e.g. Mintzberg1996) characterised some Weberian bureaucracies as `machine bureaucracies'. Within this model, IT services are not core but part of the support services. They may even be out-sourced.

``Machine bureaucracies tend to be the dominant organizational form for the biggest users of civilian government IT at national government level''

``there is unlikely to be a director of IT on the management board''

Shows Hood's categorisation of government roles, each having detector (finding out) and effector (getting done) tools:
* Nodality - government is central to society's information networks
* Authority - make laws and regulation that coerce/enforce
* Treasure - secure the provision of goods and services
* Organisation - delivery of services
* Expertise - accumulation [and application?]  of knowledge

Herbert Simon argued that computers could reshape an organisation in 3 ways:
* creating more accessible organisational `memory'
* more information and more potential to problem-solve in modern societies
* increasing the decision-processing capacity - anticipating web and internet impacts

Nice quote from Rose 1990 about how technology is not just the hardware and software but also ``the inculcation of a form of life, the reshaping of various roles for human practices, the mental techniques required in terms of certain practices of communication, the practices of the self orientated around the mobile telephone, the word processor, the World Wide Web, and so forth.''

`audit explosion' - a growth of internal regulators and the linking of key performance indicators (KPIs) to NPM reorganizations (Power 1994).

IT systems effect on policy:
1. can limit  policy-makers' discretionary action whereas that other constaints can be overcome
2. Work-arounds with IT systems can be time/money/capacity prohibative
3. The costs, complexity, and difficulty of IT investments and renewals tend to grow over time
4. The above have feedback implications for administrators' behaviour
5. This can lead to contracting out IT which means specifying what the service and capability should be, which can be less flexible, as can simply working with contractor rather than in-house

Contractors generally reckoned that by winning a contract they would be able to earn much more by requests for new capacity or specification changes.

The Weberian model seemed partial, almost from the start, because it could not explain many real-world examples (including Britain). 

In many systems, those who enter the civil service are trained (to an elite level) in a range of (often general) skills but not IT - and so machine bureaucracies (unlike welfare state agencies - Mintzberg's Professional bureaucracies) tended to be led by IT illiterate managers.  [Does this reflect Mintzberg1996 - if they've managed something, they can manage anything?]. In US, in contrast, departments were run by relevant specialists - although this also seems to be the case.},
  creationdate     = {2023-01-16T10:39:36},
  keywords         = {economics, bureaucracy, transformation},
  modificationdate = {2023-01-18T09:30:56},
  owner            = {izzyolivine},
  year             = {2006},
}

@Article{Mintzberg1996,
  author           = {Henry Mintzberg},
  date             = {1996},
  journaltitle     = {Harvard Business Review},
  title            = {Managing Government, Governing Management},
  comment          = {``Capitalism did not triumph at all, balance did''

Discusses the relationship between different organisations and people

private v public debate:
* capitalism versus communism
* privatization versus nationalization
* the markets of business versus the controls of government
is limited dichotomy

There are 4 types of organisation:
* privately owned
* publicly owned - should really be called state owned
* cooperatively owned - absence of stock market pressures is important for their ability to take a long-term perspective
* non-owned (aka NGOs but also non-business owned and non-cooperatively owned, NBO and NCO)

Private- and state-owned are similar in that they are controlled by hierachies and can be transformed into each other

Despite discourse of people as `customers' of government, looking at the functions that state performs, people can be 
* customer - fits only a few roles of government (lottery tickets!)
* citizen - use of public, government and state infrastructure
* client - one-sided professional service, what the state provides us
* subject - one-sided, respecting state controls

``Couldn't the current malaise about government really stem from its being too much like business rather than not enough?''

Discusses management - or rather Management

Three assumptions underlie the Management view of management, which collapse when considering what governent agencies have to do:
* activities can be isolated and autonomous - Many government activities are interconnected and cannot be isolated
* performance can be evaluated by objective measures - Many activities are in the public sector precisely because of measurement problems / requires soft judgment
* activities can be managed by professional managers - managers are too often ignorant of the subject of their management.

``management. Such a situation just

breeds cynicism. In mortal fear of not meeting the
holy numbers, managers run around reorganizing constantly, engendering more confusion than clarification.''

Discusses model of managing government
1. Government-as-Machine - countervailing force to corruption, lacks flexibility, still dominant
2. Government-as-Network - interactive and free-flowing, organised around projects
3. Performance-Control - make government more like business, the ideal is the divisional structure that conglomerates in particular have popularized
4. Virtual-Government - best government is no government, superstructure exists to arrange for private organizations to provide public services
5. Normative-Control - Control is rooted in values and beliefs, has been essential but not recognised: service and dedication muted the negative effects of bureaucracy.

Normative model has 5 elements:
* Selection
* Socialisation
* Guidance
* Responsibility
* Judgement

Discuss governing managment

``If people believe that government is bumbling and bureaucratic, then that is what it will be''

Businesses can learn from governments, not just vice versa

``the mistaken belief that those who have managed something can manage anything''

``Private sector values are now pervading all of society''

DunleavyMBT2006 has a useful perspective on Mintzberg's earlier work on which this article is built, I believe

Simon1991 also talks about the difficulty of defining rewards as motivators},
  creationdate     = {2023-01-16T11:04:54},
  keywords         = {economics, bureaucracy},
  modificationdate = {2023-01-16T13:10:18},
  owner            = {izzyolivine},
}

@Online{Woods2011,
  author           = {Dan Woods},
  date             = {2011-12-15},
  title            = {Explaining the {API} Revolution to your CEO},
  url              = {https://www.forbes.com/sites/danwoods/2011/12/15/explaining-the-api-revolution-to-your-ceo/},
  urldate          = {2023-01-16},
  comment          = {Brief article, a bit out of date. Main conclusion I gleaned was to make internal APIs that could then be externalised having been tested.

APIs:
* are channel to new customers and markets
* can be private
* promote innovation
* are a better way to organize IT
* are not only for huge companies
* create a path to lots of Apps
* to create lots of apps that can lead to lots of customers},
  creationdate     = {2023-01-16T13:54:08},
  keywords         = {transformation, technology},
  modificationdate = {2023-01-16T14:08:30},
  owner            = {izzyolivine},
}

@Misc{Kattel2022PTR,
  author           = {Rainer Kattel},
  date             = {2022},
  title            = {Case study: Physikalisch-Technische Reichsanstalt},
  comment          = {Case study for MPA module: Creative Bureaucracies

Outlines the PTR, how it arose

Scientific bureaucracy},
  creationdate     = {2023-01-16T14:14:34},
  modificationdate = {2023-01-16T17:57:13},
  owner            = {izzyolivine},
}

@Misc{Kattel2022Estonia,
  author           = {Rainer Kattel},
  date             = {2022},
  title            = {Case study: Estonia},
  comment          = {Description of Estonia's digital government

Developed as a crazy idea, bureaucracy hacking, mission mystique

Decentralised 

Infrastructure is x-road

Digital ID is compulsory

However, there are problems more recently

Maybe the time of agile bottom up transformation has had its time and perhaps more stronger and more formalised coordination structures are now required?},
  creationdate     = {2023-01-16T17:56:36},
  modificationdate = {2023-01-16T18:02:57},
  owner            = {izzyolivine},
}

@Article{Peters2021,
  author           = {B Guy Peters},
  date             = {2021-12-22},
  journaltitle     = {Oxford Research Encyclodeia: Politics},
  title            = {Administrative Traditions: Concepts and Variables},
  doi              = {10.1093/acrefore/9780190228637.013.1451},
  url              = {https://oxfordre.com/politics/display/10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-1451},
  comment          = {``that once patterns of administration or policy have been established, they tend to persist'' sometimes reemerging after other patterns have been overlayed on top.

The institution shapes individuals' preferences - New Instituitionalism

Identifies the elements of administrative traditions:
1. state and society
   * organic - state linked and not particularly distinct from society, reform would alter fundamental nature of state
   * contractarian - state arises from conscious social and political contract, constitution, reformable, e.g anglo-american
2. law versus management
   * legalistic: public administration is for administering public law, virtually Weberian, administrators trained as lawyers  e.g. German and French systems (althought NPM has overlayed managerialist ideas)
   * managerialist: public administration is to get things done, law is the beginning (not the end) for PA, e.g. NPM, UK, NZ
   * senior public servant as policy advisor somewhat cuts across these two conceptions - capacity to draft law but also advise on possible social, economic, political consequences of policy
3. administration and politics
   * some traditions assert that public service should be politically neutral, although it often isn't, government should accept administrators (or quietly move them aside)
   * others see political involvement as acceptible even beneficial, government is expected to appoint its own administrators
   * ``NPM devalues the concept of a career, neutral civil service in favor of a more committed and perhaps temporary service''
4. the career
   * career civil servants, in some cases trained in dedicated educational establishments
   * recruitment into and out of civil service
5. state and society II - the role of social interest in government decision making
   * involvement of societal actors can seen seen as legitimating the state and restraining its autonomy, corporatism is common example
   * societal interests represented by advisory commitees, interest groups, NGOs
   * interest groups undermine the authority of the state
   * government fosters support from interest groups
6. uniformity - in policy and administration
   * create uniformity across the nation e.g. France; French, Belgian, Portungese direct rule over colonies
   * recognise differences across the nation e.g. German federal system; British idirect rule over India
   * equality versus self-determination
   * more co-ordinated federalism may result in greater uniformity
7. accountability
   * controls enforced by political actors and legislature versus accountability is primarily internal action
   * accountability enforced after action, or action requires approval
   * perception of corruption leading to NPM (but some NPM reforms have reduced accountability)

Uses these variable to define 4 traditions in Westerrn administration:
* Anglo-American - (some US divergence)
* Germanic
* Napoleonic
* Scandinavian

- Variation within traditions
- Dilution in former colonies
- Netherlands, and to some extent Belgium, combine Germnaic with Napoleonic
- Finland is Scandinavian but with some elements remaining from Russian, whilst this was overlaid on Swedish
- Czech Republic, Slovakia, Hungary recent Russian and earlier Germanic from Austro-Hungarian Empire
- Japan Germanic and Napoleonic from late 19th Century, with Indigenous and Anglo-American from constitution from after WWII
- Tradition in countries can also be reduced to even finer divisions
- There are other administration traditions in the world: Islamic, Confucian, Latin American and African},
  creationdate     = {2023-01-17T09:21:01},
  keywords         = {economics, policy, bureaucracy},
  modificationdate = {2023-02-24T11:40:21},
  owner            = {izzyolivine},
  year             = {2021},
}

@Misc{WinigE2016,
  author           = {Laura Winig and David Eaves},
  date             = {2016},
  title            = {Hacking Bureaucracy:Reimagining California's Food Stamp Program in the Digital Age},
  howpublished     = {John F. Kennedy School of Government, Harvard Kennedy School (HKS), Harvard University.},
  note             = {Case Number 2085.0},
  comment          = {Case study demonstrating how attention to user experience can complete change a government service.

US food stamp service, SNAP, and particularly California's version, CalFresh},
  creationdate     = {2023-01-17T12:56:49},
  modificationdate = {2023-01-17T13:00:29},
  owner            = {izzyolivine},
}

@Article{MergelGW2021,
  author           = {Ines Mergel and Sukumar Ganapati and Andrew B. Whitford},
  date             = {2021},
  journaltitle     = {Public Administration Review},
  title            = {Agile: A New Way of Governing},
  doi              = {10.1111/puar.13202},
  issue            = {1},
  note             = {The American Society for Public Administration.},
  pages            = {161--165},
  url              = {https://onlinelibrary.wiley.com/doi/10.1111/puar.13202},
  volume           = {18},
  comment          = {``Agencies are now changing their project management techniques and even procurement practices, incorporating new values and methods that are foreign to classically ‚Äúbureaucratic‚Äù organizations''

Core Values of Agile
1. Individuals and interactions over processes and tools
2. Working software over comprehensive documentation
3.Customer collaboration over contract negotiation
4. Responding to change over following a plan

12 Principles of Agile
1. Seek to fulfill the customer's needs. Do so through the early delivery of software. Continuously improve that software.
2. Respond to the demand for changes to that software because doing so better positions the customer for success.
3. Shorten the timescale for the delivery of working software. Deliver changes frequently.
4. Developers should work hand in hand with business users.
5. Center fabrication around individuals motivated to succeed.
6. Emphasize face-to-face conversation within the team and between the development team and the broader organization.
7. The most important benchmarks are working software.
8. Sustainable development is the goal. All involved parties should be able to maintain a constant pace of engagement.
9. Continuously focus on technical quality and good design.
10. Emphasize simplicity.
11. Self-organization in teams improves design and production.
12. Regularly reflect on how to improve this process.
Source: Beck et al. (2001).

4 values and 12 principles establish a feedback loop

``Agile projects have four times more successes and one-third fewer failures than waterfall projects (SerradorP2015; Standish Group 2015)''

``agile emphasizes bottom-up change over top-down direction (or even
outside-in from vendors or consultants)''

``Agile Is Antithetical to Many Typical Bureaucratic Line Organizations...managers who need to take responsibility for actions may not be willing to do so given how cross-functional agile teams work ... If experimentation is not part of the toolbox, and if bureaus value organizational reputation and avoid public failures, agile never gains traction ... in organizations largely characterized by ‚Äúwe have seen this before, let's wait until the next wave comes in,‚Äù traditionalists could see agile as another fad that will be replaced''},
  creationdate     = {2023-01-17T13:04:51},
  keywords         = {policy, transformation},
  modificationdate = {2023-01-21T14:29:26},
  owner            = {izzyolivine},
}

@Book{HerdM2018,
  author           = {Pamela Herd and Donald Moynihan},
  date             = {2018},
  title            = {Administrative Burden: Policymaking by other means},
  doi              = {10.7758/9781610448789},
  url              = {https://www.jstor.org/stable/10.7758/9781610448789},
  comment          = {Loads of examples of how administrative burden can be used to enact policies, sometimes in a convert manner, for public good or sometimes bad.

Examples include voter registration, polling stations, food stamps, health insurance, abortion, tax credits, old age benefits, social security,

``focus on the costs that people encounter when they search for information about public services (learning costs), comply with rules and requirements (compliance costs), and experience the stresses, loss of autonomy, or stigma that come from such encounters (psychological costs)''

``Individuals care as much or more about the process of their interactions with the state as they do about the outcome''

Burdens can be a policy instrument which thwart people's access - could be easier for gov to do than legislature required for more visible policymaking.

``Higher voter participation tends to increase the share of low-income voters, resulting in more generous welfare services, greater equality, more progressive taxation, and less restrictive welfare participation rules. If policymakers and administrators use their authority to influence who votes in elections, they are also influencing the policies that will be adopted after the election, and the burdens that accompany those policies''

Some policies create their own industries which can then lobby for the extention of the policy - e.g. tax credits in US, the tax preparation service lobbied not only for the expansion of the policy but also to maintain enough documentation requirements to ensure tax credit remains
burdensome enough that low-income workers seek professional tax preparation help

``Shifting burdens away from citizens requires a well-functioning administrative state''

``Republicans figured out how to build a politics of burdens that Democrats have been unable or unwilling to develop. Republicans have done so despite the fact that in other areas‚Äîsuch as the regulation of businesses, campaign donations, or firearms‚Äîthey have also been successful in opposing governmentally imposed burdens in the name of liberty''

highlights:  \url{https://highlights.sawyerh.com/volumes/vB9VLalTilxmp1ivWjpV}},
  creationdate     = {2023-01-17T13:57:28},
  keywords         = {economics, policy, transformation},
  modificationdate = {2023-01-17T14:42:34},
  owner            = {izzyolivine},
  year             = {2018},
}

@Article{SerradorP2015,
  author           = {Pedro Serrador and Jeffrey K. Pinto},
  date             = {2015},
  journaltitle     = {International Journal of Project Management},
  title            = {Does Agile work? ‚Äî A quantitative analysis of agile project success},
  doi              = {https://doi.org/10.1016/j.ijproman.2015.01.006},
  issn             = {0263-7863},
  number           = {5},
  pages            = {1040-1051},
  url              = {https://www.sciencedirect.com/science/article/pii/S0263786315000071},
  volume           = {33},
  abstract         = {The Agile project management methodology has been widely used in recent years as a means to counter the dangers of traditional, front-end planning methods that often lead to downstream development pathologies. Although numerous authors have pointed to the advantages of Agile, with its emphasis on individuals and interactions over processes, customer collaboration over contracts and formal negotiations, and responsiveness over rigid planning, there are, to date, very few large-scale, empirical studies to support the contention that Agile methods can improve the likelihood of project success. Developed originally for software development, it is still predominantly an IT phenomenon. But due to its success it has now spread to non-IT projects. Using a data sample of 1002 projects across multiple industries and countries, we tested the effect of Agile use in organizations on two dimensions of project success: efficiency and overall stakeholder satisfaction against organizational goals. We further examined the moderating effects of variables such as perceived quality of the vision/goals of the project, project complexity, and project team experience. Our findings suggest that Agile methods do have a positive impact on both dimensions of project success. Further, the quality of the vision/goals is a marginally significant moderator of this effect. Implications of these findings and directions for future research are discussed.},
  comment          = {Includes details of the methodology, statistical methods, etc and statistical significance of results

``two other proposed moderators (experience of the team and project complexity) were not found to moderate the relationship between Agile and project success''

Suggest further research, including into the timing, role and nature of the planning process

Agile ``has achieved best success to date within certain settings; notably, high technology, healthcare, and professional service'},
  creationdate     = {2023-01-17T14:45:16},
  keywords         = {Success, Agile, Methodology, Efficiency},
  modificationdate = {2023-01-17T14:54:36},
  owner            = {izzyolivine},
}

@Online{AdHocUSDSPlaybook,
  author           = {{Ad Hoc}},
  title            = {The Ad Hoc Government Digital Services Playbook},
  url              = {https://adhoc.team/playbook/},
  comment          = {``This playbook is for agencies ready to replace enterprise software patterns with proven techniques from the world of commercial software''

includes roles of users, subject matter experts

The Plays
1. Adopt a digital services approach
2. Understand the problem and the user before the solution
3. Invite technologists to meetings
4. Design contracts for agile development
5. Build small rather than buy big
6. Give delivery teams direct access to the cloud
7. Design simple services
8. Make the right thing the easiest thing
9. Treat API users like end users
10. Plan for demand
11. Choose smooth migrations over sudden switches
12. Avoid falling into operations and maintenance},
  creationdate     = {2023-01-17T14:58:12},
  keywords         = {transformation},
  modificationdate = {2023-01-18T18:02:05},
  owner            = {izzyolivine},
}

@Article{DouglasJonesWS2021,
  author           = {Rachel Douglas-Jones and Antonia Walford and Nick Seaver},
  journaltitle     = {Journal of the Royal Anthropological Institute},
  title            = {Introduction: Towards an anthropology of data},
  issue            = {S1: TOWARDS AN ANTHROPOLOGY OF DATA},
  url              = {https://rai.onlinelibrary.wiley.com/doi/epdf/10.1111/1467-9655.13477?saml_referrer},
  volume           = {27},
  comment          = {Introduction to a spection issue. Describes data not as something that is a break with the past but as something that continues from the past.

``In this special issue, we draw data's apparent novelty into conversation withmany of anthropology's central concepts, from kinship to value to personhood.''

Discusses the response to data in many fields and then in anthropology and likens the new questions that have emerged to the questions around kinship that emerged around new reproductive technologies in 1990s.

``permitting the exploration of other charismatic and emergent forms of social distribution, perhaps along the lines of what Michelle Murphy (2015) calls `phantasmagrams ... intangible form[s] brought into sensibility as a palpable presencewith the help of quantitative practices' (see also Murphy 2017). Murphy is here thinkingspecifically of economic forms, but we might also think of the way recommendationalgorithms draw on vast amounts of consumer data to redistribute people accordingto logics of `likeness' and `liking' (Lury \& Day 2019; Seaver 2012)''

Topics in the issues:
* Aadhaar, the nation-wide biometric identity programme of the Government of India - as the system took shape, the programme's central task turned from verifying `are you who you say you are' to the much morevexed question of `who are you?''
*  the representation of culture as a mathematized, mappable space
* `data is always a temporal formation' - it isdated, sampled from a particular moment in time. But anthropologists can do morethan relocate data in its proper temporal context: we can examine how data is enlistedin efforts to produce new temporalities
* taxonomies, DNA of biological species, finding the temporalitiesof both data collection and storage entangled with the history of colonialism
* the creation of bunkers for data conceptualised as a vulnerable collection of networked traces,always at risk of being wiped out of existence by catastrophic events
* energy trackers: the value of data is both about saving money on heating bills and about a newunderstanding of the home gained through working with the data sets over large coffeeshop tables at meet-ups
* dataeconomies of the Large-Scale Biosphere-Atmosphere project: environmental data collaborations in the Brazilian Amazon
* Scandinavian communities convened around the use of everyday tracking devices, the sovereign body, and Indigenous Data Sovereignty
* an account of a report on the environmental and health effects of toxins flowing through Lake Athabasca in Alberta, Canada
*  late nineteenth-century crowd theory, connection and contagion,  and online `crowds'
* data's capacity to produce new social compositions while indexing the old},
  creationdate     = {2023-01-18T08:51:28},
  keywords         = {data, anthropology},
  modificationdate = {2023-01-18T20:09:57},
  owner            = {ISargent},
  year             = {2021},
}

@TechReport{ESC2022,
  author           = {ESC},
  date             = {2022},
  institution      = {Energy Systems Catapult},
  title            = {Is your organisation set upto deliver Net Zero: 16 considerations for public sector bodies},
  eprint           = {https://es.catapult.org.uk/guide/mep-net-zero-considerations-for-public-sector-bodies/?reportDownload=https://es.catapult.org.uk/wp-content/uploads/2022/12/Net-Zero-considerations-for-Public-Sector-Report-Digital.pdf},
  comment          = {4 themes:
* Leadership and purpose, capturing strategy and values
* Governance and process, capturing decision-making and internal reporting
* People and capabilities, capturing skills and capacity within the department, sector and supply chain
* Organisational structure, capturing the way the organisation is set-up and individuals and teams interact within it.

Overarching conclusions:
1. The Net Zero Target Operating Model attributes are likely to be relevant across all public sector organisations.
2. Whilst the attributes are relevant to all organisations, they will look different for different organisations.
3. Typically, stronger leadership at a more senior level promotes greater commitment across the organisation to support decarbonisation delivery.
4. Developing a high-level strategy which can be communicated across the organisation sets a clear statement of intent, however, a strategy should be backed up with detailed scaled delivery plans.
5. Linking decarbonisation to organisational values makes explicit its importance to departmental operations.
6. Incorporating carbon evaluation metrics into operational process, including business case development and approval, and other decision-making, will unlock and support scaled delivery of decarbonisation.
7. Enhancing existing information reporting systems with energy, cost and carbon related data will empower stakeholders through better and more timely knowledge.
8. Capacity needs to be built for scale and in the right places in the organisation, through mapping of the needs and requirements in each area of the organisation. Skills needs will vary dependent on the type of activity that each actor is going to fulfil.
9. If capacity is not available within the organisation then it should be sought from the supply chain, though care should be taken to ensure that consistent and high-quality support is obtained. Capacity will be needed to support delivery, from installation to onsite security escorting contractors.
10. Improving general carbon literacy throughout the public sector will support better buy-in, wider adoption, and scaled decarbonisation. 11. Having a clearly defined Net Zero organisational structure, that complements the overall organisational structure, will provide clarity to those across the organisation on roles and responsibilities. Attributing clear targets and goals to each group will support delivery.
12. A high-level Net Zero strategy and its underlying delivery plans must consider how all the Net Zero Target Operating Model attributes will be fulfilled, to support decarbonisation at scale in line with relevant targets. This may mean a step change in current deployment plans.
13. Trials and tests of technologies, process and decision-making, and different commercial routes must continue, but be more joined up. Knowledge from trials should be captured and shared more widely to help demonstrate scaled delivery models.
Recording standard information for sharing amongst a community either within a sector or more widely would help others understand how they can deploy at scale.
Departments and other public sector organisations need a committed multi-year budget to be able to start to deliver at scale.
15. Clear direction on expectations for departments and other public sector organisations would support the development of scaled decarbonisation plans.
16. More guidance and collaboration across Government, to support shared learning and speed of uptake efficiently.},
  creationdate     = {2023-01-18T16:54:26},
  keywords         = {climate, bureaucracy, economics, transition},
  modificationdate = {2023-01-22T16:39:04},
  owner            = {ISargent},
}

@Book{Schwartz2017,
  author           = {Mark Schwarz},
  date             = {2017},
  title            = {A Seat at The Table. IT Leadership in the Age of Agility},
  isbn             = {978-194278-8119},
  subtitle         = {IT Leadership in the Age of Agility},
  url              = {https://itrevolution.com/product/a-seat-at-the-table/},
  comment          = {``the way the CIO role is defined, conceived, and executed today is incompatible with Agile thinking''

Book is about reconceiving the role of the CIO.

Brilliant, easy to follow, book attempting to identify the role of the CIO in an Agile organisation. CIOs cannot get a 'seat at the table' (in the c-suite) without proving that IT is of strategic value. Books on Agile do not acknowledge the CIO and books on being a CIO do not acknowledge Agile. Currently, IT is considered something that costs and needs control, a plan, etc which works against Agile practise.

Notes that immediate cultural change is ``strangely non-Agile'' p13

There's always conflict: pleasing the customer does not always mean strategic goals are being met or it could mean that the senior management cannot understand what is happening. Sometimes its just that the CIO feels excluded. p14

Scope creep: changes that the business stakeholders request when they realize that a system won‚Äôt actually meet their needs as specified ... but which might make it difficult for IT to show that it is delivering on schedule p30 this incentivises getting the requirements perfect from the outset and feature bloat p52 ``a requirement is a constraint masquerading as a decision'' p105 ``Scope doesn't creep, understanding grows'' (Patton) p108

Jean-Paul Sartre, an early Agilist - consciousness chooses at any given instant what it is p83

Plan-drived IT ``espouses all the wrong values'' as it is made at beginning when uncertainty highest etc p86 decisions should be deferred until the last possible moment p96

There us a Beyond Budgeting movement - the annual budgeting cycle is not agile p27

Alternative approaches including identifying different plans with indicators to determine which plans to apply p100 and understand different scenarios p103

Get started with MVP or even advertising non existent product may be enough p110

Progress using TDD, ATDD and BDD p115

``The best framework I have found for working with desired outcomes as requirements is Gojko Adzic‚Äôs Impact Mapping: Making a Big Impact with Software Products and Projects'' p116 impact -> change in someone's behaviour p116 identify desired outcomes for the customer rather than a set of requirements or features p119-120

Strangler pattern, incrementally modernise a legacy system p132-134

Section 7 on enterprise architecture EA, how the organisation's capabilities, logics and operation are implemented - this should be in-house because no two organisations are the same and so off the shelf will require too much tweaking anyway. 

EA sould be in constant transform p137, p142, always evolving, extensible, little technical debt, well documented, robust automated tests p145-161

``Three major trends have dramatically altered the tradeoff between building and buying: virtualization, abstraction, and scriptability.'' p163

``IT used to be about software and hardware. Increasingly, it is just about software. This causes me joy.' p166

Governance process is passive, saying no, judgemental process, its like a reality TV show. p175-6

Some kind of oversight is always desired so they came up with an Agile governence and oversight modelhelp interface with expectations of waterfall style organisation, including:
- investment decision and oversight process form a seamless continuum - initiative informs governance decision
- progress gauged by operational results
- boundaries set for planning, don't waste time on too much planning
- decisions made on high-level objectives, not detailed requirements
- transparent, trusted processes for turning business objectives into product parameters
- optimise the whole - EA, people and data
 p181-3

Brooks' Law: In The Mythical Man-Month, Fred Brooks argues that adding people to a project that is already
behind schedule makes it slip even further behind schedule. p206

Shadow IT: rogue IT that happens outside of the IT department because the IT department is unable to support the IT that other departments need supported section 12

GitHub source code, social community, resume - loads of reasons to use GitHub and work in the open p248-250

open source economy contrasts with every day economy, which is an economy of scarcity. Instead, an open source economy nurtures a gift culture or economy because there is an abundance of goods. p250

IT leaders steward IT people/skills assets, EA assets and data assets p275-6 (also the whole book)

DevOps: When something is difficult it frightening we do it more often p292-3},
  creationdate     = {2023-01-21T14:58:51},
  keywords         = {transformation, technology},
  modificationdate = {2023-02-14T17:56:41},
  owner            = {izzy_olivine},
}

@Online{GovUKAgileDelivery,
  author           = {{Gov.UK Agile delivery community}},
  date             = {2016-05-23},
  title            = {Writing user stories},
  url              = {https://www.gov.uk/service-manual/agile-delivery/writing-user-stories},
  comment          = {As a‚Ä¶ [who is the user?]

I need/want/expect to‚Ä¶ [what does the user want to do?]

So that‚Ä¶ [why does the user want to do this?]},
  creationdate     = {2023-01-21T15:12:05},
  keywords         = {transformation, technology, agile},
  modificationdate = {2023-01-21T15:59:33},
  owner            = {izzy_olivine},
}

@Online{USDSPlaybook,
  author           = {{U.S. Digital Service}},
  title            = {Digital Services Playbook},
  url              = {https://playbook.cio.gov/},
  comment          = {MVP ``solves a core user need as soon as possible, no longer than three months from the beginning of the project''},
  creationdate     = {2023-01-21T15:57:20},
  keywords         = {transformation, technology, agile},
  modificationdate = {2023-01-21T15:59:16},
  owner            = {izzy_olivine},
}

@Article{GhorbaniWZK2019,
  author           = {Ghorbani, Amirata and Wexler, James and Zou, James and Kim, Been},
  title            = {Towards Automatic Concept-based Explanations},
  doi              = {10.48550/ARXIV.1902.03129},
  url              = {https://doi.org/10.48550/arxiv.1902.03129},
  comment          = {takes a set of images from a known class and performs segmentation over these images to extract candidate `concepts' (candidate sub-parts that are needed to explain the class). These candidate concepts are then clustered in the activation space (the space into which the trained network transforms the data) of the final layer - each cluster representing a concept},
  copyright        = {arXiv.org perpetual, non-exclusive license},
  creationdate     = {2023-01-26T11:07:25},
  keywords         = {Machine Learning, visualisation, deep learning},
  modificationdate = {2023-02-02T13:42:08},
  owner            = {ISargent},
  publisher        = {arXiv},
  year             = {2019},
}

@TechReport{ConwayEtAl2021,
  author           = {Rowan Conway and Nora Clinton and Ryan Bellinson and Kuhn Von Burgsdorff, Luca and Alex Cooke and Van Spronsen, Kirsten and Hanna Groen and Robyn Smith and Fermin Cerezo and Christopher Thompson and Sarah Dew and Dan Hill and Nico van Meeteren},
  date             = {2021},
  institution      = {UCL Institute for Innovation and Public Purpose},
  title            = {Mission-Oriented Innovation in Action 2021 Casebook: Vinnova},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/news/2022/jan/iipps-mission-oriented-innovation-network-moin-launches-its-2021-moin-casebook},
  comment          = {Vinnova's mission to have healthy sustainable streets

Mission arrived at after first identifying angles - intervention or leverage points. In this case, `streets' was the angle and the mission was devised around this

Brought together a `constellation' of actors (including Volvo!) to co-design a portfolio of prototypes and demonstrators

Demonstrators were then built and installed to gain feedback 

Took away parking spaces, the aim was to reimagine those spaces so that citizens value rather than oppose the change

Surveyed 322 people and 70\% were positive

``if the mission does not receive high-level political or private-sector buy-in and is therefore not integrated into existing structures, then it is unlikely to survive.''

``Vinnova could tap into those existing funding structures, operational environments and capabilities, and work with them to reorient them towards new `north stars'''


``Instead of getting top-level buy-in from the start, the agency focused on developing momentum before bringing its ideas to the national level''

``While representatives of the public sector, industry and communities can help frame the mission at the start, citizen participation is most valuable when testing downstream applications in localised contexts, with genuine decision-making and even co-ownership in play''},
  creationdate     = {2023-01-27T17:31:55},
  keywords         = {economics, innovation, transformation, bureaucracy},
  modificationdate = {2023-02-02T13:42:35},
  owner            = {izzy_olivine},
}

@TechReport{Teece2022,
  author           = {David J. Teece},
  date             = {2022},
  institution      = {UCL Institute for Innovation and Public Purpose},
  title            = {Evolutionary Economics, Routines, and Dynamic Capabilities},
  url              = {https://www.ucl.ac.uk/bartlett/public-purpose/publications/2022/oct/evolutionary-economics-routines-and-dynamic-capabilities},
  comment          = {Looks at organisations (with focus on private sector) and considers the development of a change-orieted organisational structure

Starts with idea of evolutionary economics but identifies that dynamic capabilities cannot sit within this theory -  this is more Schumpeterian and also has roots in behaviour theory of the firm

About dynamic capabilities - something that entrepreneurs have - that embraces discontinuous change

Largely about manangers, assumes they are source of culture and change in organisation. Sense is of hierachical organisations [IMO even the entrepreneurial ones]

Managers and entrepreneurs are different

``I believe the dynamic capabilities framework can serve as a vehicle for clarifying the relationship between routines and innovation''

``Organisations need routines to get the day-to-day work done. They economise on bounded rationality. The dynamic capabilities framework recognises routines as the very essence of operational (ordinary) capabilities''

(Irritatingly) talks about the `exceptional talents' of `great innovators and integrators such as Henry Ford ... Elon Musk' which seems to assume a predisposition rather than fortune of these people

However, discussion of an ``entrepreneurial state of mind'' and ``entrepreneurial decision-making'' and how these lead to dynamic capabilities

`ordinary capabilities' == `first-order capabilities' (Winter) == `metaroutines' - include industry best practice and incremental changes
These are bought or imitated by rival and so are unlikely to give rise to competitive advantage

Instead, `Teecian dynamic capabilities' which are characteristics that reside on the top management, organisational culture and structure and drive strategic activities. Winter may have described this as ad hoc problem solving and improviation but Teece notes that it may suggest a `quasi-routine for how an entrepreneurially-led organisation solves problems'. Entrepreneurial decision-making is a hybrid of routine and ad hoc approaches.

Schumpeter's entrepreneur: leader  ... new techniques ... new comminations. Everyone has the skills to some degree.

Urban see Musk as innovator using first principles as building blocks combined with experience and instinct

Winter sees innovation as requiring ``talented cooks'' who first imagine the dish, based on understanding of the ingredients/conditions and then iterate over attempted solutions: ``there is not simple answer to the question of where knowledge comes from''

``there are creative and insight-dependent components that cannot be routinised''

Contrasts 2 roles of managers: operational, entrepreneurial and leadership and tables the responsibilities, activities, levers and goals of each.

Entrepreneurship is not adaptation but making of ``new combinations''

``Tenacity, unwavering self-confidence, optimism and a tolerance for stress [iz: and privilege] are traits of successful entrepreneurs

The entrepreneurial state of mind, scanning/sensing and open communication channels should be encouraged through the organisation
Entrepreneurial managers sense, seize, orchestrate, invest in R\&D, develop new business models and seek competitive advantage

``Evolutionary innovations are generally modelled along a single dimension (usually technology) in which change occurs, when in fact there are many ways in which organisations can change, including their internal structure, organisational boundaries, business models, market positioning''. Also time

Organisation change in anticipation of environmental change - but entrepreneurs also shape the environment

``wild orchestration''

``Dynamic capabilities of the public sector are higher-order bundles of political, policy and organizational routines and managerial decisions that drive the strategic activities of public organisations in regimes of deep uncertainty and wicked challenges''},
  creationdate     = {2023-01-27T17:56:28},
  keywords         = {economics, bureaucracy, organisation, transformation},
  modificationdate = {2023-02-24T17:59:44},
  owner            = {izzy_olivine},
}

@Article{MattijsenBBHVBEO2023,
  author           = {Juliette C Mattijsen and van Bree, Egid M and Evelyn A Brakema and Maud M T E Huynen and Eva H Visser and Peter J Blankestijn and Philip N D Elders and Hans C Ossebaard},
  date             = {2023},
  journaltitle     = {Lancet Planet Health},
  title            = {Educational activism for planetary health - a case examplefrom The Netherlands},
  url              = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9834507/},
  comment          = {When simple activism alone did not create much change in the Dutch health sector - which is responsible for 7\% of Dutch emissions (check this) then a programme of education was rolled out by activists ultimately with senior/government endoresement (as I read it)},
  creationdate     = {2023-01-29T19:05:57},
  keywords         = {climate, health, environment, education, activism},
  modificationdate = {2023-01-29T19:10:00},
  owner            = {izzy_olivine},
}

@InBook{Tarling2023,
  author           = {Kate Tarling},
  booktitle        = {The Service Organization},
  date             = {2023-02-01},
  title            = {Chapter 3: Reveal how services perform in the real world},
  url              = {https://lpp-books.sumupstore.com/product/the-service-organization-kate-tarling},
  comment          = {Use metrics to represent what good looks like these include:
* How well service is achieving the intent behind it
* How often the right service outcome is achieved
* How are users are supported in what they need
* Tme, effort, risk, issues, errors, avoidable burden and cost involved for everyone

When people aren't confident the contact dental handle more contact - school how confident they feel

Measuring satisfaction or delight isn't always useful

Efficiency is about doing the things right
Effectiveness is about doing the right things

Get insights early even before the service is given the go ahead

Model described here is mechanistic it doesn't address themes of equity ethics etc

Understanding policy intent and outcomes doesn't reduce the chance that the intent might be harmful badly thought through or in conflict with another policy applying the ideas in this chapter won't make a service perfect},
  creationdate     = {2023-02-02T10:07:38},
  keywords         = {transformation, Agile, bureaucracy, economics},
  modificationdate = {2023-02-02T10:10:18},
  owner            = {izzy_olivine},
}

@InBook{Drechsler2019,
  author           = {Drechsler, Wolfgang},
  booktitle        = {Science, Numbers and Politics},
  date             = {2019},
  title            = {Kings and Indicators: Options for Governing Without Numbers},
  comment          = {Notes from Case study: Kings and Indicators \url{https://docs.google.com/document/d/1qIWa7sJ7Vd1dcmA0QEupsKN5cEM0zjoNJuuMXh_47pE/}:

Bhutan has legal code dating back centuries stating let place of state is to bring her happiness to citizens

Is case study describes how indicators were not initially part of the Bhutan's idea of National happiness. Indicators are not neutral representations of the world and remain measure what can be measured and not really matters.

Idea that modernisation would bring more happiness. Bhutan's PA is completely western. Traditional institutions abolished at the latest with the 2008 constitution recent civil service reform brought NPM-style government performance management system.

Gross national happiness refers to quantifying subjective well-being and Buddhist happiness

The need to be part of the world and and to be able to receive support from UN created the pressure to quantify GNH},
  creationdate     = {2023-02-02T10:32:14},
  keywords         = {economics, bureaucracy, public administration},
  modificationdate = {2023-02-02T13:46:07},
  owner            = {izzy_olivine},
}

@Online{LeeR2019,
  author           = {Nikki Lee and Kara Reinsel},
  date             = {2019-08-22},
  title            = {Building product management capacity in government part 1 ‚Äì Our coaching philosophy},
  url              = {https://18f.gsa.gov/2019/08/22/building-product-management-capacity-in-government-part-1/},
  comment          = {Talks about their Model - Pair - Coach cycle by which they use experiential learning to build product management ability within in the team 

In our experience the best p.m. generally come from the programme side finding someone who really understands the problem space is difficult},
  creationdate     = {2023-02-02T10:36:50},
  keywords         = {transformation, Agile, bureaucracy, economics},
  modificationdate = {2023-02-02T10:38:24},
  owner            = {izzy_olivine},
}

@Book{GreenwayTBL2018,
  author           = {Andrew Greenway and Ben Terrett and Mike Bracken and Tom Loosemore},
  date             = {2018},
  title            = {Digital Transformation At Scale: Why the Strategy is Delivery},
  url              = {https://www.andrewgreenway.com/book},
  comment          = {Short easy read about my angel to digitally transform an organisation to using Agile approaches

4 things are required for a digital transformation: a crisis, a political leader,  a team and a mission.

``... a crisis is almost always an essential condition for digitally transforming a government and there's no shortage of them challenges choosing the right crisis''

``Megaprojects and the eye-popping budget overruns are often a good source of crisis material 9 out of 10 government projects with an initial budget of at least ¬£1 billion end up spending more than originally planned''

``Before a country can really begin its journey of digital transformation it needs to find ... groups of engaged people''

``your first digital team will define the working culture and how things are done''

Also covers:
* Design principles
* Starting small
* Release fast, iteratively
* Roles with the team
* Clean structure and working patterns
* Culture
* Performance metrics
* Platforms

``Agile is a rejection of applying for certainty to delivering policy with technology''

``many innovation teams find themselves trapped in the purgatory of being an add on to the day to day rather than a force charged with fundamentally reshaping the organisation''

``innovation teams are destined to always run one step ahead of the rest of the organisation and incentivised to help everyone catch up with them how can you be innovative if everyone is doing the same as you?''

``arguably by having shown that things could be done differently they have done their job whether or not the business brothers to put the theory into practice''

``to have a chance of success a digital mandate must make it possible to stop poorly conceived usually expensive and long IT contracts from being let''

Gather evidence

``there is a real advantage to keeping your strategic ambitions ambiguous as long as possible''

``the digital strategy must act as a signal towards the operating model you want your whole organisation to adopt and the culture that will allow that to happen successfully''

Set the right expectation if you don't know what to under promise and over deliver
However
Making your first draught strategy ambitious gives you more chips to bargain with later

In government there's a paternalistic view that the user doesn't know what they need it's a bit of an excuse they need a public service that is simple and clear enough for them to complete it accurately and quickly so they can get on with their day. Intuitively know they need to have certain qualities.

Creating new rules and standards allows you to scale practise across an organisation quickly

``Change is physically and mentally draining the conflict it brings especially so. Digital transformation of any large organisation is tiring partly because it is about loss''

``we're unconvinced that organisations are unable to provide their employees with a reliable system for filing their travel expenses should be better in the house on nailing the implications of artificial intelligence''

``direction a government chooses to take with AI is as much a political choice that as it is a technological one that is so far removed from the old paperwork as to feel like an entirely separate conversation''},
  creationdate     = {2023-02-02T10:39:28},
  keywords         = {transformation, Agile, bureaucracy, economics},
  modificationdate = {2023-02-02T10:41:46},
  owner            = {izzy_olivine},
}

@InBook{Drechsler2018,
  author           = {Drechsler, Wolfgang},
  booktitle        = {Public Policy in the `Asian Century'},
  date             = {2018},
  title            = {Beyond the Western Paradigm: Confucian Public Administration},
  doi              = {10.1057/978-1-137-60252-7_2},
  editor           = {Bice, S. and Poole, A. and Sullivan, H},
  publisher        = {Palgrave Macmillan},
  url              = {https://link.springer.com/chapter/10.1057/978-1-137-60252-7_2},
  comment          = {Challenges the idea that there is one form of public administration (PA), Western, and that this should be assumed to be global, good and the only approach.

Both the global financial crisis and the emergence of of Southeast and East Asian tiger States have challenged Western PA.

Western pa has many forms New Public Management, NPM-plus, Weberianism, New Public Governance, Public Value, Weberian-plus, Neo-Weberian State.

Construct a model to demonstrate where good PA falls. This there are three possible forms of good PA. Small nucleus the almost always works anywhere. A larger core that is generally valid. A third level where solutions work well well within a given paradigm but not necessarily outside of this and us these solutions are not easily transferred.

Details Confucian PA and the various forms and origins of this. Particular aspects of Confucian PA are:
* Imperial civil service exam
* Perpetually reforming and adapting PA
* Concept of Mandate of Heaven (by which failure would indicate the mandate has been lost and the public servants would tose their job) which incentivises strong performance as well as as a desire to innovate

This is different to Legalism the Qianlong Emperor would say ``there is no governing by laws there is only governing by people''.},
  creationdate     = {2023-02-02T10:47:56},
  keywords         = {economics, bureaucracy, public administration},
  modificationdate = {2023-02-02T10:50:55},
  owner            = {izzy_olivine},
}

@Booklet{Hirschman1967,
  author           = {Albert O. Hirschman},
  date             = {1967},
  title            = {The Principle of the Hiding Hand},
  eprint           = {https://www.nationalaffairs.com/storage/app/uploads/public/58e/1a4/a29/58e1a4a298835643416368.pdf},
  url              = {https://www.nationalaffairs.com/public_interest/detail/the-principle-of-the-hiding-hand},
  comment          = {From \url{https://www.newyorker.com/magazine/2013/06/24/the-gift-of-doubt}: People don‚Äôt seek out challenges, he went on. They are ‚Äúapt to take on and plunge into new tasks because of the erroneously presumed absence of a challenge - because the task looks easier and more manageable than it will turn out to be.‚Äù This was the Hiding Hand principle‚Äîa play on Adam Smith‚Äôs Invisible Hand

See also \url{https://en.wikipedia.org/wiki/Hiding_hand_principle}

See also Planning Fallacy

Although Sunstein funds that the planning fallancy is more likely to be malevalent than benevalent.},
  creationdate     = {2023-02-02T13:20:56},
  keywords         = {economics, policy, institution, transformation},
  modificationdate = {2023-02-02T13:32:11},
  owner            = {izzy_olivine},
}

@Online{Wells2023,
  author           = {Tamas Wells},
  date             = {2023-02-13},
  title            = {The rise and fall of innovation labs in the aid sector},
  url              = {https://devpolicy.org/the-rise-and-fall-of-innovation-labs-in-the-aid-sector-20230213/},
  comment          = {Innovation labs in aid agencies were on the rise but are now declining. Considers that this is because:

1. hierachical administrative culture, which is difficult to innovate within (``radical's dilemma'') and so labs tend to be separate, and are therefore more easy to cut off
2. innovation labs tend to cut against the grain of usual brueaucratic processes and can struggle to gain or maintain strong patronage, especially if leadership changes
3. innovation is a ``magic concept'' - it has powerful appeal but is also highly ambiguous in its meaning which leaves uncertainty in overall expectations about the impact of an innovation lab

These 3 areas are part of both the rise and fall of the labs},
  creationdate     = {2023-02-13T15:12:08},
  journaltitle     = {{DevPolicy} Blog},
  keywords         = {economics, innovation},
  modificationdate = {2023-02-13T15:17:49},
  owner            = {izzy_olivine},
}

@InBook{DemmkeM2012,
  author           = {Christoph Demmke and Timo Moilanen},
  booktitle        = {The Sage Handbook of Public Administration},
  date             = {2012},
  title            = {The Pursuit of Public Service Ethics - Promises, Developments and Prospects},
  chapter          = {44},
  doi              = {https://dx.doi.org/10.4135/9781446200506},
  editor           = {B. Guy Peters and Jon Pierre},
  url              = {https://sk.sagepub.com/reference/the-sage-handbook-of-public-administration-2e/n45.xml},
  comment          = {``On the one hand there have never been so many regulatory activities, reforms and studies in the field and the other hand, scientific evidence about the effectiveness of the different reforms, measures and regulatory strategies is lacking''

``Ethics policies have been largely scandal- not value-driven''

Accountability - system of external control - compliance approach
Ethics - system is internal control - integrity approach

Ethically good also defined in terms of law obedience, impartiality and standardisation

Weberian approach has an ethic of neutrality but this is unrealistic and too narrow in today's multilevel governance

There are codes of rules and regulations which set clear expectations

There are codes of ethics, such as UK Committee on Standards in Public Life 7 principles: selflessness, integrity, objectivity, accountability, openness, honesty and leadership. They are not statutory, there are few guidelines and they cannot be enforced.

There are codes of conduct - aspirational and expectation values. May be seen as transforming princioles of ethics into practice.

Increased public and media scrutiny leads to more scandals and failure often attributed to not enough law. There is a trend towards more rules and monitoring.

Could these ethics policies impact administrative procedures? There is also little understanding of the nature of growing number of specialised ethics bodies.  

The trends in ethics literature:
Focus on scandals and failures of public officials and resulting decreased levels of trust
Consideration of whether there is now too much it too little ethics rules
Broadening and diversification if the whole discussion

You still not much clarity on what works to support ethical practise.  Also focus on rules etc. and less on the impact (or costs and benefits) of policies on behaviours etc.

Higher prestige positions attract offers of board memberships in companies and organisations - rules and standards may be appropriate in this case

Strict transparency requirements do not automatically improve public trust. More ethical rules may cause even more cynicism and have not resulted to a rise in public confidence in government.

Argues that approach to integrity in government must advance beyond the "bad person" model and look at social psychology of organisational life and the capacity of individuals and leaders understand be critical of their own behaviour.

There is conflicting evidence and explanations of how NPM has contributed to increased or decreased integrity. 

Ethically behaviour in the workplace is influenced by:
Individual characteristics
Moral issue characteristics
Organisational characteristics

Discusses the possible impact of the financial crisis on ethical motivations and behaviour in the workplace assumption that result would be negative but there are are also some reasons for positive behavioural outcomes.

``more ... studies ... are badly needed''},
  creationdate     = {2023-02-13T17:41:46},
  keywords         = {public administration, bureaucracy, economics, ethics, trust},
  modificationdate = {2023-02-13T17:44:21},
  owner            = {izzy_olivine},
}

@Article{PetersS1994,
  author           = {B. Guy Peters and Donald J Savoie},
  date             = {1994},
  journaltitle     = {Public Administration Review},
  title            = {Civil Service Reform: Misdiagnosing the Patient},
  doi              = {https://doi.org/10.2307/976426},
  number           = {5},
  pages            = {418--425},
  volume           = {54},
  comment          = {About the reforms of Reagan and Thatcher which has public servants focus on management rather than policy

``result has been that government departments and agencies that were well managed in the 1970s are still well managed but the reforms have had limited impact on those that traditionally were not well managed''

Now less deferential to expertise and now requires strong policy advisory capacity

Useful overview of specific elements of NPM (Thatcherism, Reaganism, the New Right, Neo Conservativism)

``there was a contradiction between the desire to empower manners like large private sector firms were doing and the strongly held reservations that the political leadership had about the capacity of bureaucracy and bureaucrats to be efficient''

Amusing comment on creating a mission statement - to install in all employees a central purpose: ``holding staff meeting after staff meeting to define a central mission to which all employees could relate':

The reasons for these reforms revered to blame civil service and assume that all organisations, private or public and with public sector, are the same

Herbert Simon noted that adminstrative life often has paired features such that maximizing one week minimise the other

Reasons to blame civil service. It's:
 a monopoly - no competition, can extract higher than needed funds
 our of touch - both with political masters (and rather like the status quo) and with what clients world want
 out of control- pursues it's own goals. Notes that if it doesn't, it's uninnovative so can't win.
It's badly managed - wrong rewards and incentives, assumption that private sector motivational devices would be better
 financially mismanaged

Reforms dubbed ``neo-Taylorism''

Measurement may not have worked because horror stories were hidden

Comment on dichotomy of politics versus administration but I'm not sure what point is being made

Overlooked questions of accountability

Result was badly shaken civil service and need to improve morale

There doesn't seem to be much change where it was required},
  creationdate     = {2023-02-13T17:45:17},
  keywords         = {public administration, bureaucracy, economics},
  modificationdate = {2023-02-24T12:18:21},
  owner            = {izzy_olivine},
}

@InBook{Gregory2012,
  author           = {Robert Gregory},
  booktitle        = {The Sage Handbook of Public Administration},
  date             = {2012},
  title            = {Accountability in Modern Government},
  doi              = {https://dx.doi.org/10.4135/9781446200506},
  editor           = {B. Guy Peters and Jon Pierre},
  url              = {https://sk.sagepub.com/reference/the-sage-handbook-of-public-administration-2e/n44.xml},
  comment          = {Discusses theories of accountability and responsibility, or objective and subjective responsibility

Different authors identify different types of accountability e.g. hierarchical, legal, professional, political, direct democratic, bureaucratic 

Or different conceptions such as parliamentary control, managerialism (e.g. NPM), judicial/quasi-judicial review, constituency relations and market 

Highly penetrating scrutiny (highlighting crises in finance, environment etc) from increasing range of media subjects government officials to irony that, with so many more means to deliver public goods, it is more difficult to satisfy demands for accountability

Discusses impact of NPM - it removed rules so as to give freedom to act but resulted in at least equivalent transaction costs in performance review, legalistic procedures

Harmon's paradox, which I understand to be the conduct that can occur between the (objective responsibility) of accountability to mandated goals and the (subjective responsibility) accountability as a moral agent. The argument that someone cannot be held responsible for consequences of following one's orders was rejected by the Nuremberg Trials.

With so many scrutiny instruments such as legislative processes and committees, constitutional / statutory requirements, official information and privacy enactments, ombudsman, auditing and media watch dogs, politicians maybe more likely to be sanctioned less for failing to achieve than for failing to do so correctly

Argues that the challenge is to create balance between the imperative of holding power to account and the need for more creative, trusted constructive and yet risky responses to political, policy, administrative and managerial demands of government},
  creationdate     = {2023-02-13T17:49:13},
  keywords         = {public administration, bureaucracy, economics, ethics, trust},
  modificationdate = {2023-02-13T17:52:24},
  owner            = {izzy_olivine},
}

@Online{Kattel2019,
  author           = {Rainer Kattel},
  date             = {2019-02-01},
  title            = {Innovation as an ethical dilemma},
  url              = {https://medium.com/iipp-blog/innovation-as-an-ethical-dilemma-a664554c1069},
  comment          = {About the nature of
innovation: unpredictable, stemming from creativity and serendipity
civil servants: apolitical, critically implementing political will and saying truth to power, serving both today's political will and their conscience

But uncertainty is wasteful and so early stage innovation is heretical to efficiency orthodoxy 

Innovation in public sector is still too often about efficiency and materialism

Bureaucracy needs to evolve (as capitalism has)

Useful link for when I talk about the MPA},
  creationdate     = {2023-02-13T18:50:01},
  keywords         = {public administration, bureaucracy, economics, ethics, trust, innovation},
  modificationdate = {2023-02-13T18:52:14},
  owner            = {izzy_olivine},
}

@InBook{Wardley2016,
  author           = {Simon Wardley},
  booktitle        = {Wardley maps: Topographical intelligence in business},
  date             = {2016-04-10},
  title            = {Finding a path},
  url              = {https://medium.com/wardleymaps/finding-a-path-cdb1249078c0},
  comment          = {About Wardley mapping

A business, like all organisms, needs to continuously adapt to changes in order to survive and if we could somehow describe this then maybe that would give us a map?

Throughout our history, it has always been standardisation of components that has enabled creations of greater complexity

The desire to differentiate creates the novel, the desire to keep up with others makes it commonplace

The map has an anchor which is the user

Each component needs the component below it, however the higher up the map a component is then the more visible it becomes to the user. The lower it is then the less visible it becomes.

There is a flow of risk, information and money between components

Stages of evolution:
- genesis
- custom built
- product (including rental)
- commodity (including utility)

the x-axis of evolution shows the terms for activities alone

A single node on one map can be an entire map from another person‚Äôs perspective. Equally, the entire map of your business might be a single component for someone else.},
  creationdate     = {2023-02-13T18:53:22},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-13T19:00:11},
  owner            = {izzy_olivine},
}

@TechReport{MargettsN2017,
  author           = {Helen Margetts and Andre Naumann},
  date             = {2017-02-28},
  institution      = {Centre for Technology and Global Affairs, University of Oxford},
  title            = {Government as a Platform: What can Estonia Show the World},
  eprint           = {https://www.ospi.es/export/sites/ospi/documents/documentos/Government-as-a-platform_Estonia.pdf},
  url              = {https://www.ctga.ox.ac.uk/article/government-platform-what-can-estonia-show-world},
  comment          = {Tim O'Reilly spoke about GaaP has two aspects - a platform that others e.g. private sector can build upon and a way that citizens can participate in government. I find this second idea very interesting but I can only find evidence that GaaP is just at the level of services at the moment.

He proposed seven principles of GaaP: openness, simplicity, participation, `learning from hackers', data mining, experimentation and `leading by example'. This paper looks at Estonia and identifies that it meets the first (except it learns `by example') and does less well on the final three. It's argue that they have focused on the service now and less in the future service. UK seems to be a bit the opposite by embracing experimentation, days mining and a `hacking' culture but struggles with openness, simplicity and participation.

Lots of detail in the Estonian case and quite a bit on UK.

Quotes a study that find the costs are in organisation and processes, not technology and important elements are political will, organisational reforms, adaptation of legal frameworks and redesign of work processes.

I also like that Estonia's CIO is the `Central' Information Officer},
  creationdate     = {2023-02-13T18:58:53},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-13T19:02:28},
  owner            = {izzy_olivine},
}

@Online{Durant2016,
  author           = {David Durant},
  date             = {2016-02-29},
  title            = {Foundations for Government as a Platform},
  url              = {https://governmentasaplatform.blog.gov.uk/2016/02/29/governmentasaplatform-foundations/},
  comment          = {Short post listing principles:
- Be independent
- Committed to maintaining the product
- Make it easy for the user
- Be easy to integrate
- Be ready to grow
- Be easy to adopt
- Support service separation
- Avoid being tied down to one supplier
- Meet technical and design standards
- Be open about performance
- Be open about cost},
  creationdate     = {2023-02-13T19:09:59},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-13T19:11:30},
  owner            = {izzy_olivine},
}

@Online{Yegge2011,
  author           = {Steve Yegge},
  date             = {2011-10-11},
  title            = {Stevey's Google Platforms Rant},
  url              = {https://gist.github.com/chitchcock/1281611},
  comment          = {Great blog post largely critical of Amazon and Bezos but ultimately saying that the one thing Amazon does well is platforms and that Google is terrible at this. Platforms is why AWS hosts so much because components are already there.},
  creationdate     = {2023-02-13T19:12:20},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-13T19:14:26},
  owner            = {izzy_olivine},
}

@Online{Bracken2015,
  author           = {Mike Bracken},
  date             = {2019-03-29},
  title            = {Government as a Platform: the next phase of digital transformation},
  url              = {https://gds.blog.gov.uk/2015/03/29/government-as-a-platform-the-next-phase-of-digital-transformation/},
  comment          = {Introduction to what GDS means by Government as a Platform GaaP},
  creationdate     = {2023-02-13T19:15:39},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-13T19:16:49},
  owner            = {izzy_olivine},
}

@Online{Sidawi2023,
  author           = {Nour Sidawi},
  date             = {2023-01-28},
  title            = {Why are the future leaders scheme (FLS) fails and what to do about it},
  url              = {https://medium.com/future-leaders-scheme/why-the-future-leaders-scheme-fls-fails-and-what-to-do-about-it-74a37bfdc91},
  comment          = {Most recent post in the series about future leaders scheme and its wrongs, which are mainly around creating homogeneous leaders especially by filtering out diversity

``This scheme is systemically rooted in the current educational cultural and corporate structures of the CK civil service it is the result of a fractured process that presumes button passing rather than a team sport ... The scheme... Focuses on competences models and techniques which in some ways is like rearranging the deck chairs on a sinking ship''

One size fits all training ... homogeneity of thinking, self-referential nature and a culture of conformity and emotional detachment},
  creationdate     = {2023-02-13T19:17:23},
  keywords         = {bureaucracy, economics, public administration, trust},
  modificationdate = {2023-02-13T19:18:40},
  owner            = {izzy_olivine},
}

@TechReport{Pope2019,
  author           = {Richard Pope},
  date             = {2019},
  institution      = {Harvard Kennedy School},
  title            = {Playbook: Government as a Platform},
  eprint           = {https://ash.harvard.edu/files/ash/files/293091_hvd_ash_gvmnt_as_platform_v2.pdf},
  comment          = {Basically everything you need to think about in creating a platform-based government

What platforms are, how to identify them
Unshaved users and go where they are

Rather than designing then top down, maybe take component of product that can be more generally used and turn it into platform

Documentation, procurement, standards, culture, design, measuring and monitoring, trust, governance},
  creationdate     = {2023-02-13T19:20:27},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-13T19:22:36},
  owner            = {izzy_olivine},
}

@InProceedings{AylettBullockL2022,
  author           = {Joseph Aylett-Bullock and Miguel Luengo-Oroz},
  booktitle        = {3rd KDD Workshop on Data-driven Humanitarian Mapping},
  date             = {2022},
  title            = {Multi-AI Complex Systems in Humanitarian Response},
  eprint           = {https://arxiv.org/pdf/2208.11282.pdf},
  location         = {Washington, DC, USA},
  url              = {https://arxiv.org/abs/2208.11282},
  comment          = {Fascinating perspective on the use of AI (e.g, reinforcement learning), along with humans, in data processing and decision-making in humanitarian situations. Sums up the concern: ``Multi-AI systems can be thought of as a complex interacting network of interconnected complex systems. These systems are being increasingly used in many domains, including in humanitarian response, but their behaviours are often not understood in their entirety''.

``risks and harms include: 
- questions of biases and fairness which can oppress minority voices
- accountability of systems and the lack of legal frameworks
- challenges surrounding transparency and human oversight
- a lack of expertise in the proper and appropriate deployment and use of AI
- data privacy and protection concerns; and the meaningful participation of affected communities in every stage of the AI lifecycle, as well as their ownership over such systems''

``drive to draft AI ethical guidelines, frameworks, and training materials at the international, national, and sector specific levels''

Their proposal for future research / activities are more widely relavant than simply humanitarian applications, imo:
1. ``development of frameworks for building and testing multi-AI systems, as well as for understanding emergent behaviours of such systems is essential''
  - mapping the network of information flows
  - stresss tests for systems
2. ``cross-pollination of these technical communities with legal, ethics, and humanitarian response experts''
  - systematic mapping exercise to understand the potential gaps in existing ethical principles and guidelines
  - adapt current risk and harms assessments
3. communicate these concepts to project managers and decision-makers
  - operational guidelines
  - capacity building exercises
  - communities of practice
4. greater collaboration including: complex systems, multi-agent modelling, systems engineering, and reinforcement learning},
  creationdate     = {2023-02-14T12:16:18},
  keywords         = {humanitarian, artificial intelligence, trust, complexity, systems},
  modificationdate = {2023-02-14T12:30:34},
  owner            = {izzy_olivine},
}

@TechReport{BennettY2019,
  author           = {Andrew Bennett and Chris Yiu},
  date             = {2019-06-26},
  institution      = {Tony Blair Institute for Global Change},
  title            = {Transforming Government for the 21st Century},
  url              = {https://institute.global/policy/transforming-government-21st-century},
  comment          = {Increased complexity
Decentralised and complex society


Governments must:
- embrace technology-enabled experimentation and decentralisation - iteration, empowered teams
- set agenda - be purposeful, national missions
- provide software and data infrastructure
- reset structures, break through silos, more pathways for promotion, diverse training schemes, cross-functional teams, technology to enable interoperability between teams ...

``Francis Maude advocated a ‚Äútight-loose‚Äù model for government in the United Kingdom (UK): tight central control over key areas of public spending to drive down costs, combined with devolution of power and the opening up of partnerships to promote innovation''

Princples:
1. purposeful government and policy, national missions for grand challenges (Mazzucato gets lots of mentions)
2. provide public services and infrastructure that allow individuals, communities, businesses and the public sector to achieve their potential
3. be able to respond quickly

``embed a culture of continuous improvement both within and outside the public sector''

``anticipatory frameworks for regulation would cohere with a government strategy intent on iterating, experimenting and harnessing the opportunities of technological change''

Discussion of metrics of public value, GDP, CBA, social value and ``doughnut dashboads''

Gaap, mostly tier 1 and 2 - but should move on tier 3 as well - society wide platform (banks, charities and other external organsations)

``governments should establish a new presumption in favour of all new services having to publish and document an API''

``governments must create an electronic-identity system for all citizens'' 

``Buying Into The Future report suggest[s] creating spend controls for in-house expenditure, to incentivise governments not to reject ready-made solutions in the private sector''

``Restructuring can also be extremely costly, according to the Institute for Government, a UK think tank, with new departments costing up to ¬£15 million (\$19 million) to establish.112 This cost can rise even higher when one takes into account productivity losses‚Äîmainly, but not only, if these changes are rushed‚Äîand settlements due to levelling up the salaries of staff from merging departments'' but there is some transformation needed - be strategic

Case study: Spotify's multidisciplinary teams ``Recreating government versions of Spotify‚Äôs chapters and guilds ‚Äì formal and informal knowledge-sharing networks ‚Äì would therefore be a promising first step.''

Keep high performers and increase churn...},
  creationdate     = {2023-02-14T16:57:37},
  keywords         = {transformation, economics, innovation, policy, digital},
  modificationdate = {2023-02-14T18:08:25},
  owner            = {izzy_olivine},
}

@Online{Henrich2011,
  author           = {Joseph Henrich},
  date             = {2011},
  title            = {A cultural species: How culture drove human evolution},
  url              = {https://www.apa.org/science/about/psa/2011/11/human-evolution},
  comment          = {Finds that cultural information is necessary for human survival

``we are an ultra-cultural species'' and there is an interaction between culture and evolution

``humans are heavily dependent on an information economy for survival''

``our ecological success, technology, and adaptation to diverse environments is not due to our intelligence. Alone and stripped of our culture, we are hopeless as a species''

Key concepts:
1. Cultural capacities as adaptations: Culture, cultural transmission, and cultural evolution arise from genetically evolved psychological adaptations for acquiring ideas, beliefs, values, practices, mental models, and strategies
2. Cultural evolution: These cognitive adaptations give rise to a robust second system of inheritance that operates by different transmission rules than genetic inheritance, and can thus produce phenomena not observed in other less cultural species
3. Culture-gene coevolution: The second system of inheritance created by cultural evolution can alter both the social and physical environments faced by evolving genes

Example of cooking and `cooked food' - shrunk our digestive tracks, teeth, stomachs, and gape, freeing up energy for more brain building, and perhaps a greater reliance on cultural information

Two types of status: dominance and prestige
Two facets for the emotion pride: authentic and hubristic pride, suggested that hubristic pride is associated with dominance-status and authentic pride with prestige-status},
  creationdate     = {2023-02-19T13:13:45},
  keywords         = {sociology, culture, evolution},
  modificationdate = {2023-02-19T13:30:33},
  owner            = {izzy_olivine},
}

@Article{Kvangraven2020,
  author           = {Ingrid Harvold Kvangraven},
  date             = {2020},
  journaltitle     = {Review of Political Economy},
  title            = {Nobel Rebels in Disguise -Assessing the Rise and Rule of the Randomistas},
  pages            = {305--341},
  url              = {https://www.tandfonline.com/doi/abs/10.1080/09538259.2020.1810886},
  comment          = {Criticism of the Randomised Control Trial (RCT) approach of the likes of Abhijit Banerjee, Esther Duflo and Michael Kremer (e.g. BanerjeeD2019)},
  creationdate     = {2023-02-19T13:31:52},
  keywords         = {economics, sociology},
  modificationdate = {2023-02-19T14:35:58},
  owner            = {izzy_olivine},
}

@Article{GardnerTRS2021,
  author           = {Charlie J. Gardner and Aaron Thierry and William Rowlandson and Julia K. Steinberger},
  date             = {2021-05-31},
  journaltitle     = {Frontiers in Sustainability},
  title            = {From Publications to Public Actions: The Role of Universities in Facilitating Academic Advocacy and Activism in the Climate and Ecological Emergency},
  doi              = {10.3389/frsus.2021.679019},
  url              = {https://www.frontiersin.org/articles/10.3389/frsus.2021.679019/full},
  comment          = {Paper making the case for activitism over publications for scientists because 
1. the time lags inherent in education and research pathways to impact are too long given the urgency of the climate and ecological emergency
2. publications fail to address either real-world political processes or the forces invested in maintaining the status quo},
  creationdate     = {2023-02-19T14:44:01},
  keywords         = {politics, climate, environment, science},
  modificationdate = {2023-02-19T14:47:34},
  owner            = {izzy_olivine},
}

@Article{KemenyPS2022,
  author           = {Tom Kemeny and Sergio Petralia and Michael Storper},
  title            = {Disruptive innovation and spatial inequality},
  doi              = {10.1080/00343404.2022.2076824},
  eprint           = {https://doi.org/10.1080/00343404.2022.2076824},
  number           = {0},
  pages            = {1-18},
  url              = {https://doi.org/10.1080/00343404.2022.2076824},
  volume           = {0},
  comment          = {4 strands of work on disruptive innovations:
1. largely focussed on national economies
2. subnational regional variation in production and absorption of innovations
3. links betweent technological change and wage formation
4. post-1980 rise in income inequality in the US

Technological revolutions are discussed but only mentions Perez with reference to the use of the terms `radical' and considers that we are entering the 4th industrial revolution

This work: identifies particular kinds of innovation that are likely to be economically disruptive; places such technologies in space and time; and traces directly the relationship between the geographies of regional economic performance and disruptive innovations

Find:
1. disruptive innovations exhibit distinctive spatial clustering in phases understood to be those in which industrial revolutions reshape the economy; they are increasingly dispersed in other periods
2. that the ranks of locations that capture the most disruptive innovation are relatively unstable across industrial revolutions
3. regression estimates suggest a role for disruptive innovation in regulating overall patterns of spatial output and income inequality},
  creationdate     = {2023-02-22T11:02:09},
  journal          = {Regional Studies},
  keywords         = {economics, technology, transformation, inequality, geography},
  modificationdate = {2023-02-22T11:14:10},
  owner            = {ISargent},
  publisher        = {Routledge},
  year             = {2022},
}

@Article{HammesW2005,
  author           = {David Hammes and Douglas Wills},
  date             = {2005},
  journaltitle     = {The Independent Review},
  title            = {Black Gold The End of Bretton Woods and the Oil-Price Shocks of the 1970s},
  issn             = {1086-1653},
  number           = {4},
  pages            = {501--511},
  url              = {https://www.independent.org/pdf/tir/tir_09_4_2_hammes.pdf},
  volume           = {IX},
  comment          = {Finds that price adjustment in response to inflation of dollar is main cause},
  creationdate     = {2023-02-22T17:03:11},
  keywords         = {economics, markets},
  modificationdate = {2023-02-22T17:06:13},
  owner            = {izzy_olivine},
}

@Online{Seshadri2014,
  author           = {Praveen Seshadri},
  date             = {2023-02-14},
  title            = {The maze is in the mouse},
  url              = {https://medium.com/@pravse/the-maze-is-in-the-mouse-980c57cfd61a},
  comment          = {Blog post about how cultural problems at Google
1. no mission
2. no urgency
3. delusions of exceptionalism
4. mismanagement

Few ``Googlers'' think they serve the customer, instead for other Googlers. Feedbacks are internal. 

Also lots of risk management:
- code tests
- prelaunch reviews (15 approvals)
- avoid nonobvious decisions
- sticking to how things are
- avoid upsetting employees
- avoid upsetting managers

``If this were an algorithm, we‚Äôd call it ‚Äúmost cautious wins‚Äù and there is almost always someone who is cautious tending to should-do-nothing''

Discouragement of heroes - don't work too hard else others may feel they have to

Also lots of planning and inability to change the plan

Suggests asking ``who did I create value for today?''

Discussion of hiring/recruitment, talent management and retention, managerial ability

Suggests a playbook:
1. Lead with commitment to a mission
2. Definite ambitious causes that you will collectively fight for (indicate assuming wartime)
3. Winnow layers of middle managerment, decrease hierachy depth

Uses Microsoft as an example to follow},
  creationdate     = {2023-02-23T09:32:16},
  keywords         = {organisations, transformation, economics},
  modificationdate = {2023-02-23T10:02:58},
  owner            = {ISargent},
}

@TechReport{BlairH2023,
  author           = {Tony Blair and William Hague},
  date             = {2023-02-22},
  institution      = {Tony Blair Institute for Global Change},
  title            = {A New National Purpose: Innovation Can Power the Future of Britain},
  url              = {https://institute.global/policy/new-national-purpose-innovation-can-power-future-britain},
  comment          = {Argues for a new national purpose

Investment in 
- artificial intelligence (the exec summ refers to ``sovereign general-purpose AI systems, enabled by the required supercomputing capabilities, to underpin broad swaths of public-service delivery'')
- Biotech
- Climate Tech

``Ensure that decision-makers and advisors are experts in the areas within which they are operating, as would be the case in a technology company''

``flat, non-hierarchical structures that empower executive decision-makers to manage portfolios''

``curtail the business case, ``value for money'' and similar green-book criteria''

Gives strong reasons for investing in R\&D and education/training in technology

Also pushes for digital ID

43 technical recommendations:
- nature of government institutions, people and processes
- invest in AI and compute, and reduce restrictions to these technologies
- centralise NHS and other health data
- digital ID and data sharing between governement agencies
- train in tech, recruit experts and students internationally, reduce barriers to new courses
- invest in R\&D, university differentiation, UKRI resstructuring, ARIA funding, lab and catapult networks
- raise funding by consolidating pensions
- reduce barriers to spin-outs and R\&D infrastructure
- seek associate membership of EU research and international coalitions
- governance and export controls on AI},
  creationdate     = {2023-02-23T15:03:00},
  keywords         = {policy, governement, transformation, economics},
  modificationdate = {2023-02-23T16:01:12},
  owner            = {ISargent},
}

@Online{Labour2023,
  author           = {Labour},
  date             = {2023},
  title            = {A `Mission-Driven' Government to End `Sticking Plaster' Politics},
  url              = {https://labour.org.uk/wp-content/uploads/2023/02/5-Missions-for-a-Better-Britain.pdf},
  comment          = {Labours 5 missions and how they arrived at them},
  creationdate     = {2023-02-23T16:24:35},
  eprint           = {https://labour.org.uk/wp-content/uploads/2023/02/5-Missions-for-a-Better-Britain.pdf},
  keywords         = {economics, policy, transformation, missions},
  modificationdate = {2023-02-23T16:26:16},
  owner            = {ISargent},
}

@Online{GodboutK2014,
  author           = {Greg Godbout and Noah Kunin},
  date             = {2014-05-14},
  title            = {Hacking bureaucracy: improving hiring and software deployment},
  url              = {https://18f.gsa.gov/2014/05/14/hacking-bureaucracy-improving-hiring-and-software/},
  comment          = {18F post

Where the idea of bureaucracy hackers comes from

Its not enough to build software, human platform is required on which to build software platform

Agile approach to hiring as well as software deployment},
  creationdate     = {2023-02-24T11:49:54},
  keywords         = {transformation, organisation, innovation},
  modificationdate = {2023-02-24T12:06:47},
  owner            = {izzy_olivine},
}

@Online{ChappenDPP2022,
  author           = {Eleni Chappen and Jessica Dussault and Laura Ponc\'{e} and Allison Press},
  date             = {2022-09-12},
  title            = {Creating a culture of innovation at your agency},
  url              = {https://18f.gsa.gov/2022/09/12/creating-a-culture-of-innovation/},
  comment          = {18F surveyed multiple digital innovation groups in cultural heritage institutions and federal agencies asking about the impact of innovation at their organization

Challenges facing innocation labs
- Lack of leadership support
- Too broad of a scope
- Moving from experimentation to delivery without adequate support
- Difficult to quantify success

Innovation groups focus on teaching their organisations to innovation by building relationships and sharing skills},
  creationdate     = {2023-02-24T12:03:28},
  keywords         = {transformation, organisation, innovation},
  modificationdate = {2023-02-24T12:08:38},
  owner            = {izzy_olivine},
}

@Online{Weber2021,
  author           = {Isabella Weber},
  date             = {2021-10-27},
  title            = {How China Escaped Shock Therapy},
  url              = {https://www.youtube.com/watch?v=mpv2Xjfh9No},
  organization     = {New Economic Thinking},
  comment          = {Interesting, short, video describing how China reformed their economy to more market-based from planned economy.

This is a huge transformation

China's state institutions were not market players. Prices were consciously set not to reflect costs.

Options were to 
- implement current (1980s) approach, now called ``shock therapy'' - overnight liberalisation of prices, or 
- dual track reform - planned and market track - produce to meet the plan and then have the option to produce for the market

George Soros identified in Hungary and Yugoslavia that rapid price liberalisation would be dangerous

Friedman pushed for price liberalisation because this had worked in postwar Germany (Erhart Miracle). But in Germany, there were market institutions.

``Catch-up development requires a strong entrepreneurial innovative state''},
  creationdate     = {2023-02-24T12:49:58},
  keywords         = {economics, markets, transformation, development, industry},
  modificationdate = {2023-02-24T14:56:48},
  owner            = {izzy_olivine},
}

@TechReport{BreznitzO2012,
  author           = {Dan Breznitz and Darius Ornston},
  date             = {2012},
  institution      = {World Bank},
  title            = {Scaling up and Sustaining Innovation Policies and Projects: Schumpeterian Development Agencies in Small Open Economies},
  eprint           = {https://openknowledge.worldbank.org/bitstream/handle/10986/26797/703730WP0P12450IC00SDAs0WB0Feb02011.pdf},
  url              = {https://openknowledge.worldbank.org/handle/10986/26797},
  comment          = {This paper seeks to illuminate this processof developmental initiatives, shifting attention from policy programs to the processes that generate them and specifically analyse  the  experience of reform-minded policymakers in Finland and Israel

Argues:
-  `Schumpeterian development agencies' (SDAs), public organizations with a mandate to facilitate innovation in new industries, played a critical role in precipitating industrial adjustment
- these agencies occupied a _peripheral_ position in the public sector where limited access to resources exposed these agencies to new ideas and limited political interference

1. concept of the Schumpeterian development agency
2. policy-makers in small states introduced STI programmes and faced scling and monitoring of policies with exposure to domestic networks and international competition
3. policy-makers relied on agencies and instruments, and these relied on inter-personal networks and international competition to scale and monitor developmental projects

Washington concensus seeked to identify a best practice that in reality either cannot be applied without translation or does not work in the same way in the unique circumstances of each application

In small states, inter-elite networks mean that policy-makers, industry representatives and other key decision-makers are more likely to know and trust one another. This means projects can be scaled. But its also harder to kill projects. SDAs can find it harder to penetrate these networks. 

Small states tend to be more internationally open which, for several reasons, facilitates monitoring and enables easier adaptation or abandonment of programmes. However, agencies that had STI policies that comply with interestnational regulations are monitored less and find it more difficult to adapt policies particularly during good times.

Finland - Sitra - independant think-tank and SDA. Demand-side innovation policy and investment in easly stage risk. Science (and Technology) Policy Council linked ministers and prime minister and also ran courses on economic policy and the importance of innovation for policy-makers, corp execs, trade union leaders and journalists. Adaptations happened during downturns.

Israel - Office of the Chief Scientist in the Ministry of Trade and Industry (OCS) -  conditionally repayable loans, intensive and repeated meeting with decision makers in private industry, educating them about the value of R&D and infusing them with enthusiasm toward technological innovation

``In successfully scaling new initiatives, Finnish and Israeli SDAs dramatically raised their profile within the public sector and the economy as a whole, increasing political interference and inhibiting policy experimentation.''},
  creationdate     = {2023-02-24T14:56:00},
  keywords         = {economics, markets, transformation, development, industry},
  modificationdate = {2023-02-24T17:04:39},
  owner            = {izzy_olivine},
}

@Article{DavideParrilliA2016,
  author           = {Davide Parrilli, Mario and Alcalde Heras, Henar},
  date             = {2016},
  journaltitle     = {Research Policy},
  title            = {STI and DUI innovation modes: Scientific-technological and context-specific nuances},
  url              = {https://www.sciencedirect.com/science/article/pii/S0048733316000020},
  comment          = {argue that the STI interaction mode alone has a stronger effect on technological innovation (i.e. product and process), whereas the DUI mode tends to have a stronger impact on non-technological innovation (i.e. commercial and organisational).

the debate on STI and DUI modes originates in the so-called ‚Äúinnovation paradox‚Äù in which the inputs (e.g. R\&D expenditure) are not reflected in the level of innovation and economic output

STI innovation mode supports interactions with centres producing new knowledge ‚Äì mainly research centres and universities, scientific brokers and foundations for the diffusion of scientific research ‚Äì which generate the codified and explicit knowledge that can be used by the firm to produce innovations

DUI innovation - in the firm generated by the capacity of the firm to develop informal and formal exchanges internal to the firm, but also interactions with suppliers, customers and competitors

these modes might complement each other in the production of higher outcomes in terms of both innovation and economic performance

This paper studies the Basque Autonomous Community in Spain

``From a policy-making and a business practice perspective, some critical implications may be drawn. In particular, the fact that most businesses adopt a DUI type of interaction does not imply that it is an effective interaction mode. It delivers lower impact (than STI factors) in technological and radical innovation, whereas it matters more for non-technological innovation. And it is inadequate when it is bounded to the regional environment (DUI-regional)''.},
  creationdate     = {2023-02-24T17:13:28},
  keywords         = {economics, innovation, transformation, policy, technology, organisations},
  modificationdate = {2023-02-24T17:31:04},
  owner            = {izzy_olivine},
}

@Misc{ChatGPTSTIDUI2023,
  author           = {ChatGPT},
  date             = {2023-02-24},
  title            = {explain the different between STI and DUI innovation policy with examples},
  abstract         = {STI (Science, Technology, and Innovation) and DUI (Doing, Using, and Interacting) are two different types of innovation policies, each with its own focus and objectives.

STI innovation policy emphasizes the importance of scientific research and development, technology advancement, and innovation in driving economic growth and societal progress. STI policies are often associated with funding for research and development, tax incentives for innovation, and the creation of science parks and innovation hubs. The objective of STI policies is to create new technologies, products, and services that can drive economic growth and improve the quality of life for citizens.

Examples of STI innovation policy include the funding of scientific research and development by the National Science Foundation in the United States, the creation of science parks such as the Cambridge Science Park in the UK, and tax incentives for innovation offered by many countries to encourage private sector investment in research and development.

DUI innovation policy, on the other hand, emphasizes the importance of innovation in everyday practices, including doing, using, and interacting. DUI policies focus on the adoption of existing technologies and the development of new practices that can improve productivity, reduce costs, and enhance competitiveness. The objective of DUI policies is to promote innovation at the grassroots level and to encourage the adoption of new practices by firms, organizations, and individuals.

Examples of DUI innovation policy include the provision of training and education to workers to help them adopt new technologies and practices, the promotion of collaborative practices and partnerships between firms, and the development of user-centered design methodologies that involve users in the design of new products and services.

In summary, STI policies focus on the creation of new technologies and innovations through scientific research and development, while DUI policies focus on the adoption of existing technologies and the development of new practices through everyday doing, using, and interacting.},
  creationdate     = {2023-02-24T17:39:01},
  keywords         = {economics, innovation, policy, technology},
  modificationdate = {2023-02-24T17:40:26},
  owner            = {izzy_olivine},
}

@Online{McNaughton2021,
  author           = {Matthew McNaughton},
  date             = {2021-04-06},
  title            = {Civil Society Coalition Outlines Key Reforms of {NIDS} Bill to Parliament},
  url              = {https://medium.com/slashroots/civil-society-coalition-outlines-key-reforms-of-nids-bill-to-parliament-244aff411055},
  comment          = {Jamaican National Identification System is a biometric ID system

The supreme court struck down the original verion of the National Identification and Registration Bill because it was considered unconstitutional

Therefore, this coalition is working towards ensureing the NIDS is people-centred and rights-respecting and delivers social inclusion and improved access to legal identification},
  creationdate     = {2023-02-26T15:57:02},
  keywords         = {transformation, policy, trust},
  modificationdate = {2023-02-26T16:05:39},
  owner            = {izzy_olivine},
}

@Article{RittelW1973,
  author           = {Horst W. J. Rittel and Melvin M. Webber},
  date             = {1973},
  journaltitle     = {Policy Sciences},
  title            = {Dilemmas in a General Theory of Planning},
  number           = {2},
  pages            = {155--169},
  url              = {https://www.sympoetic.net/Managing_Complexity/complexity_files/1973 Rittel and Webber Wicked Problems.pdf},
  volume           = {4},
  comment          = {The wicked problem paper.

US society has solved many fundamental but relatively easy problems (clean water, transport, waste disposal, ...). People continue to demand change to the system. The planning system needs to turn to other issues. It needs to define its goals and problems whilst addressing issues of equity.

PPBS - Planning, Programming and Budgeting System - requires statement of desired outcomes (introduced as a response to recognition that incrementalism - tweaking policy rather than determining if it is the correct policy - was not working)

``one of the most intractable problems is that of defining problems ((of knowing what distinguishes an observed condition from a desired condition)'' as well as working out what actions would solve the problem.

Talks about the problem of the idealised planning system and how it actually works - which is constant adjustment and evaluation (Iz - it needs to be agile?). The application of science and engineering approaches to society has not worked.

``Planning problems are inherently wicked'' (not tame or benign) and have at least 10 distinguishing characteristics:
1. There is no definitive formulation of a wicked problem - all the possible solutions are part of the definition of the problem
2. Wicked problems have no stopping rule - solving and understanding are part of the same process which ends when some external criterion is met
3. Solutions to wicked problems are not true-or-false, but good-or-bad - there are many parties whom are equipped, interested and/or entitled to judge
4. There is no immediate and no ultimate test of a solution to a wicked problem - any solution will generate waves of consequences
5. Every solution to a wicked problem is a `one-shot operation'; because there is no opportunity to learn by trial-and-error, every attempt counts significantly 
6. Wicked problems do not have an enumerable (or an exhaustively describable) set of potential solutions, nor is there a well-described set of permissible operations that may be incorporated into the plan
7. Every wicked problem is essentially unique 
8. Every wicked problem can be considered to be a symptom of another problem
9. The existence of a discrepancy representing a wicked problem can be explained in numerous ways. The choice of explanation determines the nature of the problem's resolution
10. The planner has no right to be wrong - a problem statement is not a hypothesis to be refuted and thus planners are liable for the consequences of actions they generate

Small minorities can comprise large numbers of people, the concept of the social product is not very meaningful; possibly there is no aggregate measure for the welfare of a highly diversified society

A paper of its time, with commentary on pluralism and a new awareness of societal ills (inequality, consumption and pollution) and that different groups have different values and cultures.},
  creationdate     = {2023-03-02T15:23:02},
  keywords         = {policy, economics, society},
  modificationdate = {2023-03-02T15:53:07},
  owner            = {ISargent},
}

@Article{Willis2018,
  author           = {Rebecca Willis},
  date             = {2018},
  journaltitle     = {The Sociological Review},
  title            = {How Members of Parliament understand and respond to climate change},
  doi              = {10.1177/0038026117731658},
  eprint           = {https://journals.sagepub.com/doi/reader/10.1177/0038026117731658},
  number           = {3},
  pages            = {475-491},
  url              = {https://journals.sagepub.com/doi/10.1177/0038026117731658},
  volume           = {66},
  abstract         = {Action on climate change, to meet the targets set in the 2015 Paris Agreement, requires strong political support at the national level. Whilst the political and governance challenges of climate change have been discussed at length, there is little understanding of how politicians, as influential individuals within the political system, understand or respond to climate change. This article presents findings from 14 qualitative interviews with Members of the UK Parliament, to discuss how politicians conceptualise climate change, and their deliberations on whether or how to act on the issue. First, it reviews an interdisciplinary literature from sociology, political theory and science and technology studies, to investigate how politicians navigate their work and life. Second, it presents ‚Äòcomposite narratives‚Äô to provide four different MPs‚Äô stories. Last, it draws conclusions and implications for practice. It highlights three crucial factors: identity, or how politicians consider the climate issue in the context of their professional identity and the cultural norms of their workplace; representation, how politicians assess their role as a representative, and whether proposed political action on climate is seen as compatible with this representative function; and working practices, how day-to-day work rituals and pressures influence the aims, ambitions and engagement of politicians with climate change.},
  comment          = {See also https://green-alliance.org.uk/wp-content/uploads/2021/11/Building_a_political_mandate_for_climate_action.pdf

Most politicians do understand the need to act on climate change. MPs have three linked considerations:
1. How does climate action fit within their role?
2. What mandate do they have?
3. How to address climate change in day to day realities of political life?

Politicians see climate change as an ``outsider issue'' and tends to mainly be considered in economic terms. Politicians get little push from voters on the issue of climate change and so finding ``representative claims'' for climate action can be difficult. Three representative claims that may be used:
- Cosmopolitan claim - its in the interests of the global community to act
- Local prevention claim - its in the interests of the local community to prevent impacts such as local flooding
- Co-benefits claim - most common includes improving local economies and services by supporting climate action
- Surrogate claim - don't talk about climate but act on it e.g. on sustainable transport

During interviews, interviewees tended to steer the conversation away from climate ``like they don't want to think about [it]''

Created stories for 4 composite polticians:
- The climate champion, willing to speak out even though many constituents do not seem concerned
- The newcomer, cautious and careful to put his constituency first
- The realist, focuses on the tangible and achievable and justifies on social and economic grounds
- The ex-minister, relaxed and willing to speak out

Agenda for action:
- widen the mandate by creating climate reponsibilities in departments and local regions
- involve people, such as with deliberative processes
- devising policies that grow support, such as around energy infrastructure, transport, divestment and a just transition
- consider the long term in institutional changes},
  creationdate     = {2023-03-03T08:29:20},
  keywords         = {policy, climate, environment, politics},
  modificationdate = {2023-03-03T08:51:16},
  owner            = {ISargent},
  year             = {2018},
}

@Book{Urry2016,
  author           = {Urry, John},
  date             = {2016},
  title            = {What Is the Future?},
  comment          = {Looks like a really interesting book on futures thinking. In the conclusion:

``thinking future is a way of bringing back planning for the future but under a new framing. Issues are now so big and wicked ... coordinate futures ... I suggest that futures thinking is a major way of brining the state and civil society back in from the cold ...''

RAND corporation developed ideas of futures thinking and developing scenarios of future

accessed at \url{https://web-s-ebscohost-com.libproxy.ucl.ac.uk/ehost/ebookviewer/ebook/bmxlYmtfXzEzNTMzNjlfX0FO0?sid=29e678ad-54e5-4d5a-915f-1d07199e5940@redis&vid=0&format=EK&rid=1}},
  creationdate     = {2023-03-03T08:59:18},
  keywords         = {futures, policy, economics},
  modificationdate = {2023-03-03T09:11:20},
  owner            = {ISargent},
}

@Comment{jabref-meta: databaseType:biblatex;}
