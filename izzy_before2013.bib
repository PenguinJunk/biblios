@String { ao        = {Applied Optics} }
@String { csr       = {Continental Shelf Research} }
@String { cvgip     = {Computing Vision Graphics Image Processing} }
@String { iefuzzy   = {IEEE Transactions on Fuzzy Systems} }
@String { iegrs     = {IEEE Transactions on Geoscience and Remote Sensing} }
@String { ieip      = {IEEE Transactions on Image Processing} }
@String { ieit      = {IEEE Transactions on Information Theory} }
@String { iepami    = {IEEE Transactions on Pattern Analysis and Machine Intelligence} }
@String { iesmc     = {IEEE Transactions on Systems Man and Cybernetics} }
@String { iesp      = {IEEE Transactions on Signal Processing} }
@String { ijprs     = {International Journal of Photogrammetry and Remote Sensing} }
@String { ijrs      = {International Journal of Remote Sensing} }
@String { jgr       = {Journal of Geophysical Research} }
@String { jmr       = {Journal of Marine Research} }
@String { joptsocam = {Journal of the Optical Society of America} }
@String { jpr       = {Journal of Plankton Research} }
@String { lo        = {Limnology and Oceanography} }
@String { pers      = {Photogrammetric Engineering and Remote Sensing} }
@String { rse       = {Remote Sensing of Environment} }

@InProceedings{GatesHK99,
  author    = {J Gates and M Haseyama and H Kitajima},
  title     = {A real-time line extraction algorithm.},
  year      = {1999},
  volume    = {4 - IMAGE AND VIDEO PROCESSING, MULTIMEDIA, AND COMMUNICATIONS},
  pages     = {68--71},
  comment   = {A line-finding algorithm that starts with an edge detector (Laplacian in this case) which is thresholded to produce a binary image. The line detector then searches for the first edge pixel from the bottom left corner. When this is found the algorithm searches in concentric (rectangular) arcs which gradually increase in size. Every time an edge pixel is found in the arc, the angle of the subsequent arc is limited according to the possible locations line being detected. They tested this against the Hough transform and found it faster but of comparable accuracy. Seems pretty simplistic to me, but may be worth using in a line-detection comparison study.},
  crossref  = {ISCAS99},
  haveiread = {Y},
  creationdate = {2005/01/01},
}

@InProceedings{Haverkamp04,
  author       = {Donna Haverkamp},
  title        = {Automatic {B}uilding {E}xtraction from {IKONOS} {I}magery},
  url          = {http://www.spaceimaging.com/whitepapers_pdfs/2004/AUTOMATIC%20BUILDING%20EXTRACTION%20FROM%20IKONOS%20IMAGERY-ASPRS2004.PDF},
  creationdate = {2005/01/01},
  crossref     = {ASPRS04},
  owner        = {izzy},
  text         = {4. Haverkamp, D, 2004. Automatic Building Extraction from IKONOS Imagery. Proceedings of ASPRS 2004 Conference. Denver, Colorado, May 23-28, 2004. ((c)2004, ASPRS)},
  year         = {2004},
}

@InBook{LiedtkeBPS01,
  author           = {Liedtke, C-E and B\''{u}ckner, J and Pahl, M and Stahlhut, O},
  title            = {Knowledge based system for the interpretation of complex scenes},
  pages            = {3--12},
  comment          = {Describes AIDA and geoAIDA. Both use semantic nets to represent expert knowledge about complex scenes. Includes brief overview of quite a few prior systems.},
  creationdate     = {2005/01/01},
  crossref         = {Ascona01},
  modificationdate = {2022-10-30T14:45:31},
  owner            = {izzy},
  whotorecommendto = {Will T, Layla G},
  year             = {2001},
}

@InProceedings{OlsenKF02,
  author    = {Olsen, Brian Pilemann and Knudsen, Thomas and Frederiksen, Poul},
  title     = {Digital {C}hange {D}etection {F}or {M}ap {D}atabase {U}pdate},
  year      = {2002},
  url       = {http://research.kms.dk/~bpo/xian2002/xian2002paper.pdf},
  comment   = {Change detection and detection of buildings in rgb and cir imagery.},
  crossref  = {ISPRS02},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{Pan02,
  author       = {Heping Pan},
  title        = {A basic theory of intelligent photogrammetron},
  pages        = {B-200},
  url          = {http://www.ISPRS.org/commission3/proceedings/papers/paper131.pdf},
  comment      = {Really interesting paper making some very interesting points: ``The tenet of intelligent photogrammetry is that photogrammetry is a nonlinear process for which a full automation, if indeed required, is only possible if and only if the system is an autonomous and intelligent agent system.'' Their theory of a photogrammetron goes a little beyond what a mapping agency would require (''primary tasks of Photogrammetron for a surveillance application include: (1) to report when one or more targets move into or out of the area ... (6) to assess the intention of targets; (7) to assess the situation and (8) to remind the supervisor in case certain threats appear and certain actions should be taken.''). However such a 'visioning' paper is useful for setting research sights...Search google for Pan Photogrammetron and follow on papers will come up.},
  creationdate = {2005/01/01},
  crossref     = {PCV02},
  owner        = {izzy},
  wherefind    = {in TRIM},
  year         = {2002},
}

@InProceedings{Wallace85,
  author    = {Richard S Wallace},
  title     = {A modified {H}ough transform for lines.},
  year      = {1985},
  pages     = {665--667},
  comment   = {In TRIM
Review:
The Muff transform is simply a different parameterisation of lines from the standard m-c or \rho-\theta. This creates a bounding rectangle around the image and lines are parameterised by the two points at which they cross this rectangle. Specifically, these points are defined by the distance around the rectangle that they fall. Points are still collected in an accumulator array. There is some discussion about the resolution of lines that can be detected - point out that a lower resolution exists in the \rho-\theta parameterisation with increasing \rho. This method (s_1-s_2 parameterisation) has a finer angular resolution for lines located near the corners of the image. Also discuss compaction of results - the Muff results can be more easily compacted. Not sure how valuable this really is. As far as resolution goes, I dont think it is an issue if the need for an accumulator array is avoided. As for compaction, this may have been necessary with less processing power - but is does just add an extra step in the calculation.},
  crossref  = {CVPR85},
  haveiread = {Y},
  creationdate = {2005/01/01},
}

@InBook{Brunn01,
  author           = {Brunn, A},
  title            = {Statistical Interpretation of DEM and Image Data for Building Extraction},
  pages            = {171-180},
  comment          = {Use statistics to find buildings in DEMs. Bayesian nets and Markov-Random-Fields used to build graphs, or something.},
  creationdate     = {2008/02/13},
  keywords         = {morphology},
  modificationdate = {2022-10-30T14:45:31},
  owner            = {izzy},
  year             = {2001},
}

@InProceedings{ChowdhuryC02,
  author           = {M Sharif Chowdhury and David A Clausi},
  title            = {Shape preserving edge enhancement in remote sensing imagery.},
  comment          = {In TRIM. Uses a modified Canny edge detector and then uses several rules to join up edges. Claims to be very effective but looking at results (Sea-ice imagery) it seems that a simple threshold would have worked as well.},
  creationdate     = {2005/01/01},
  modificationdate = {2022-10-30T14:45:31},
  wherefind        = {Izz},
  year             = {2002},
}

@InBook{HeuelF01,
  author           = {Heuel, S and F\''{o}rstner, W},
  title            = {Automatic {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages ({III})},
  chapter          = {Topological and geometrical models for building reconstruction from multiple images},
  editor           = {Emmanuel P Baltsavias and Armin Gr\''{u}n and Van Gool, Luc},
  pages            = {13-24},
  publisher        = {A A Balkema},
  comment          = {Best read once a good knowledge has been gained of the field! Quite difficult to read. Describes a system by which geometric and topological tools are used to reconstruct buildings in 3D. The geomtric tools find points, lines and planes in the data, match these to each other (or match image points to object points and image lines to object lines), the reconstruction and grouping of these (not really sure about this bit). The topological tools allow topology to be constructed between points, lines and planes and queried. This can be used to constrain the extraction (two planes meet at a line, for instance). No indication of accuracy or other quality measures (except that modesl meet constraints). Uses a polyhedral (not CSG) model. Based on feature extraction, they found that pixel sized of 15-20 cm were good (smaller pixels exibited distracting features such as tiles). ``Matching algorithms are avilable at all levels: pixels, features and feature aggregates. Area based techniques obviously have proven to yield 3D information which has the highest density. Feature based matching techniques have proven to be most robust. Matching on the feature aggregate level leads to highly information structures, but is error prone to missing features. There is obviously not a single appropriate level .. multiple views seem to be required: intensities should be visitble in at least two images, points in at least three images and lines in at least four images.'' Present 13 relationships between points, line and planes that can be constrained. Would like to know what became of this work.},
  creationdate     = {2005/11/25},
  keywords         = {3D, quality, epipolar},
  modificationdate = {2022-10-30T14:45:31},
  owner            = {izzy},
  whotorecommendto = {Jon H, Dave C},
  year             = {2001},
}

@InBook{Niederost01,
  author           = {M Nieder\''{o}st},
  title            = {Automated update of building information in maps using medium scale imagery},
  pages            = {161-170},
  comment          = {Want to improve 1:25k maps, fitting to real landscape, increase planimetric accuracy to 1m and derive height information with 1-2m accurace. Use aerial colour imagery of 1:15,800 scale. Do not go into detail about methods in this paper but discuss problems with original vector data, ways of assessing its accuracy etc. Find that vegetation can be automatically detected using isoclustering of image with the 2 channels: GR, PC2 and PC3 where GR=(green-red)/(green+red) and PC2 and PC3 are the second and third principle components, respectively. This paper is fairly scathing of other stufies that do not discuss cases of failure or do not test techniques on other data sets.},
  creationdate     = {2005/01/01},
  haveiread        = {y},
  modificationdate = {2022-10-30T14:45:31},
  wherefind        = {in book},
  year             = {2001},
}

@InBook{ZhangBG02,
  author           = {C Zhang and E Baltsavias and A Gruen},
  title            = {Updating of cartographic road databases by image analysis},
  comment          = {''Since road marks are usually white, the image is first segmented by thresholding in R, G, B channels. The road marks are then extracted using an image line model and the geometrical description of each road mark is obtained. The shape of a image line can be presented as a second order polynomial (HaralickWL83. Busch, A. 1994. Fast Recognition of Lines in Digital Images without User-Supplied Parameters. International Archives of Photogrammetry and Remote Sensing, vol. 30, part 3/1, 91-97) it is fitted to the grey values G(x,y) as a function of the pixel's row and column coordinates (x,y). We can compute the line local direction a using this model. We then get the profile in the direction perpendicular to a. The profile can be described as a parabola. Thus, the precise position of each line point is obtained from the profile. The detected line points with similar direction and second directional derivative are linked. The details of the algorithm and implementation can be found in Zhang et al. (2001). Straight lines are obtained by least squares fitting. The 3D lines are generated by our developed structural matching method. The 3D lines are then evaluated using knowledge. Only those on the ground (as defined by DSM-DTM), belonging to road region (as determined by the classification) and in the buffer defined by VEC25 are kept as detected road marks.''},
  creationdate     = {2005/01/01},
  keywords         = {DeepLEAP1},
  modificationdate = {2022-10-30T14:45:31},
  owner            = {izzy},
  year             = {2002},
}

@InProceedings{DAngeloW06,
  author       = {Pablo d'Angelo and Christian W\''{o}hler},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Image-based 3{D} {S}urface {R}econstruction by {C}ombination of {S}parse {D}epth {D}ata with {S}hape from {S}hading and {P}olarisation},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Defect detection for rough metallic structures using shape from shading and shape from polarisation. Test on artificial images with noise added. Real world examples also. Compare to laser profile along a transect. Good results from shape from polarisation but if this is not available shape from shading is OK. Also applied to lunar crater images from the internet. The crater was found to be deeper than previous estimate but there is not real ground truth...After paper was given ther author was asked if there was a CAD model to do the comparison to. However, such objects never exactly fit the design but this is not always a fault. Results could be improved y using multiple light sources.},
  creationdate = {2006/09/27},
  keywords     = {shape from polarisation, shape from shading, image matching},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{dAngeloW05,
  author    = {Pablo d'Angelo and Christian Wahler},
  title     = {3{D} surface reconstruction by combination of photopolarimetry and depth from defocus},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Fault detection for strongly non-lambertian surfaces. Useful because it lists passive methods ( shape from shading, shadow or polarisation; depth from focus/defocus; stereo imaging; structure from motion) and active methods (projection of structured light; 3D sensors; interferometry).},
  keywords  = {3D, image matching},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Article{AbbasiMK99,
  Title                    = {Curvature scale space image in shape similarity retrieval},
  Author                   = {Abbasi, S and Mokhtarian, F and Kittler, J},
  Year                     = {1999},
  Number                   = {6},
  Pages                    = {467-476},
  Volume                   = {7},

  Abstract                 = {In many applications, the user of an image database system points to an image, and wishes to retrieve similar images from the database. Computer vision researchers aim to capture image information in feature vectors which describe shape, texture and color properties of the image. These vectors are indexed or compared to one another during query processing to find images from the database. This paper is concerned with the problem of shape similarity retrieval in image databases. Curvature scale space (CSS) image representation along with a small number of global parameters are used for this purpose. The CSS image consists of several arch-shape contours representing the inflection points of the shape as it is smoothed. The maxima of these contours are used to represent a shape. The method is then tested on a database of 1100 images of marine creatures. A classified subset of this database is used to evaluate the method and compare it with other methods. The results show the promising performance of the method and its superiority over Fourier descriptors and moment invariants.},
  Journaltitle             = {Multimedia Systems},
  Keywords                 = {morphology},
  Owner                    = {izzy},
  creationdate                = {2008/02/13}
}

@InBook{AdanA07,
  author       = {Adan, M and Adan, A},
  booktitle    = {PATTERN RECOGNITION AND IMAGE ANALYSIS, PROCEEDINGS},
  title        = {Solids characterization using modeling wave structures},
  pages        = {1-10},
  series       = {LECTURE NOTES IN COMPUTER SCIENCE},
  url          = {http://books.google.com/books?id=FzdsGvZOK94C&pg=PA1&lpg=PA1&dq=%22Solids+characterization+using+modeling+wave+structures%22&source=web&ots=dyzmmTgTki&sig=Qu4uOtO7WV_AG08cK7V6sYboc0g#PPA1,M1},
  volume       = {2652},
  abstract     = {This paper introduces a characterization study on solid and 3D shapes based-on the recent Modeling Wave (MW) topological organization. The MW establishes a whole n-connectivity relationship in 3D objects modeling meshes. Now an extended use of MW is carried out. Through a new feature called Cone-Curvature, which originates from the MW concept, a flexible and extended surroundings geometry knowledge for every point of the solid surface is given. No-local nor no-global but a half-connectivity has been used for defining a robust 3D similarity measure. The method presented has been successfully tested in our lab over range data in a wide variety of shapes. Consequently, extended research on 3D objects clustering will be accomplished in the near future.},
  comment      = {''Cone-curvature is defined as a new and intuitive feature based on [modelling wave] structure taking into account the location of the [wave fronts] inside the model'' Methods for determining the similarity of objects and recognising objects. ``This paper is devoted to showing a new 3D shape characterization study based on extended knowledge that goes from local to global knowledge using Modelling Wave Set (MWS). MWS is applied to mesh of object and cone curvature found along MWS. Appears to be a rather complex method to set up and seems to be focused on curved shapes.},
  creationdate = {2008/02/13},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {2003},
}

@Article{AguilarM08,
  author       = {F J Aguilar and J P Mills},
  journaltitle = {Photogrammetric Record},
  title        = {Accuracy assessment of lidar-derived digital elevation models},
  number       = {122},
  pages        = {148-169},
  volume       = {23},
  comment      = {Recognition that the use of RMSE is not enough in many cases for indicating the accuracy of a DEM. Identifies that error in lidar terrain models tends to be non-normal. Model the error to determine the 95\% confidence interval by including the skewness and kurtosis.},
  creationdate = {2008/08/12},
  keywords     = {DSM, lidar, DEM, quality},
  owner        = {izzy},
  year         = {2008},
}

@Misc{AguilarP06,
  Title                    = {GIS (Idrisi) Analysis of Digital Elevation Models for the Extraction of Drainage Basin Geomorphometric Properties.},

  Author                   = {Aguilar, J A P and Perez, J M R},
  Note                     = {From  \url{http://www.sigte.udg.es/idrisi/recursos/secundari/reunion1/htmls/14/index.htm} (last accessed 05/11/08)},
  Year                     = {2006},

  Keywords                 = {Geomorphometry},
  Owner                    = {izzy},
  creationdate                = {2008/11/05},
  Url                      = {http://www.sigte.udg.es/idrisi/recursos/secundari/reunion1/htmls/14/index.htm}
}

@InProceedings{AhlbergSEP04,
  author       = {Ahlberg, Simon and S\''{o}nderman, Ulf and Elmqvist, Magnus and Persson, {\AA}sa},
  booktitle    = {Geoinformatics 2004 {P}roceedings of the 12th {I}nternational {C}onference on {G}eoinformatics - {G}eospatial information research, {B}ridging the {P}acific and {A}tlantic},
  title        = {On modelling and visualisation of high resolution virtual environments using {L}i{DAR} data},
  url          = {http://www.hig.se/geoinformatics/proceedings/files/p299.pdf},
  address      = {University of G\''{a}vle, Sweden},
  comment      = {Also SondermanAEP04 and SondermanAPE04. All three papers give an overview of how airborne laser scanning works and then describe (not in detail) three uses of these data - classification, 3D building reconstruction and environment modelling and visualisation. The 3D building reconstruction involves first locating the footprint of the building (by classification for example) then clustering the normals to the surfaces found in these data points to find the faces of the roof. Intersections of planes are then found (or 'height jump' sections) and vertices identified in order to describe the topology. Would be interesting to know more about their method. Quality assessment?},
  creationdate = {2005/01/01},
  groups       = {lidar},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2004},
}

@TechReport{Akca07,
  author      = {Devrim Akca},
  title       = {Accuracy concept for 3{D} building reconstruction},
  institution = {ETH Zurich},
  year        = {2007},
  type        = {Internal Technical Report},
  comment     = {I have a hard copy in desk. Report on progress in contract between ETH Zurich and Ordnance Survey on determining the quality of 3D building models by comparing to lidar point clouds using least squares matching.},
  keywords    = {quality, 3D},
  owner       = {Izzy},
  creationdate   = {2009.03.09},
}

@Article{AkcaFGS08,
  Title                    = {Quality Assessment of 3{D} Building Data by 3{D} Surface Matching},
  Author                   = {Devrim Akca and Mark Freeman and Armin Gruen and Isabel Sargent},
  Year                     = {2008},
  Number                   = {B2},
  Pages                    = {771-778},
  Volume                   = {XXXVII},

  Journaltitle             = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  Keywords                 = {3D, quality, 3DCharsPaper},
  Owner                    = {izzy},
  creationdate                = {2008/09/11},
  Url                      = {http://www.isprs.org/proceedings/XXXVII/congress/2_pdf/7_WG-II-7/01.pdf}
}

@Article{AlamusK08,
  author       = {Ramon Alam\'{u}s and Wolfgang Kornus},
  title        = {{DMC} Geometry analysis and virtual image characterisation},
  journaltitle = {The Photogrammetric Record},
  year         = {2008},
  volume       = {23},
  number       = {124},
  pages        = {353-371},
  comment      = {Determines the theoretical accuracy given influence of base-to-height ratio (which is compensated by pointing accuracy - I think this is the accuracy of pointing the camera in the direction intended), observation accuracy (I'm not sure what this is), GPS observations and image point density. Then perform tests with DMC imagery and find that unexpectedly large hieght errors are obtained (especially in blocks where there are a large number of observations for a corresponding object). This can be improved with self-calibration. Could be useful for information about the DMC and about testing for error and self-calibration.},
  keywords     = {image geometry},
  owner        = {Izzy},
  creationdate    = {2009.01.16},
}

@Article{AlamusKT06,
  author       = {R Alam\'{u}s and W Kornusa and J Talaya},
  title        = {Studies on {DMC} geometry},
  journaltitle = {ISPRS journal of photogrammetry and remote sensing},
  year         = {2006},
  volume       = {60},
  number       = {6},
  pages        = {375-386},
  abstract     = {Since the ISPRS Congress 2000 in Amsterdam, there are great expectations in matrix-CCD based digital cameras for aerial photogrammetry and mapping applications. During the last two years the number of DMC cameras in the market has raised significantly (32 cameras were sold until March 2006). This paper discusses the DMC accuracy focusing on the role of self-calibration parameters and the assessment of automatic DEM quality. This investigation concluded that under the current status of DMC an appropriate set of self-calibration parameters is necessary in order to achieve theoretical accuracy and precision, which were discussed in early literature. In the following discussions, the accuracy of the DMC is analyzed comparing its performance in automatic DEM generation to that of an analog camera using a Lidar DEM as reference. Despite the fact that the higher image quality of the DMC should overcome the poorer base-to-height ratio, the presented results did not reach the expected accuracies. However, our current study is not yet conclusive on this topic because the DMC, the analog images and the LIDAR data have not been acquired at the same time.},
  booktitle    = {ISPRS journal of photogrammetry and remote sensing},
  comment      = {In TRIM},
  owner        = {Izzy},
  creationdate    = {2009.03.09},
}

@Unpublished{AlexanderSTJT06,
  author    = {Cici Alexander and Sarah Smith-Voysey and Nicholas J. Tate and Claire Jarvis and Kevin Tansey},
  title     = {3-D Visualisation of Urban {OS} {MasterMap} using {LiDAR} Height Data},
  note      = {Paper has come out of Cicimol's work. Not sure where it is to be published.},
  abstract  = {Three-dimensional urban models are increasingly needed for applications as varied as urban planning and design, microclimate investigation and tourism. {OS} {M}aster{M}apÃ‚Â® provides topographic information which includes footprints of buildings. {H}owever, this is a two-dimensional data product. {R}esearch is on-going to determine how best to capture height data and integrate such data with {OS} {M}aster{M}ap. {L}ight {D}etection {A}nd {R}anging ({L}i{DAR}) data are considered to be highly suitable for the threedimensional reconstruction of urban features such as buildings. {T}his paper reports research on combining data from {OS} {M}aster{M}ap and {L}i{DAR} to visualise an urban area - {P}ortbury near {B}ristol, {E}ngland - with emphasis on representing buildings in an {ESRI} {A}rc{GIS}* environment. {T}he main emphasis here is on the employment of a vector model that is more suitable for representing regular man-made structures like buildings. {A} novel approach contrasting this research with earlier work is the classification of roof types of buildings into flat and pitched before visualisation. {L}i{DAR} data at three point densities: 1 (low), 16 (medium) and 40 (high) points per m2, were compared in terms of successful building type detection and visualisation, as there are important data acquisition cost issues at each of these resolutions. {H}igh density {L}i{DAR} produced the highest overall accuracy of building type detection and proved useful for identifying features associated with the roof, yet lower densities proved more useful for revealing overall roof morphology.},
  comment   = {in share_library and have hardcopy in file.},
  groups    = {lidar},
  owner     = {izzy},
  creationdate = {2007/01/08},
  year      = {2006},
}

@InProceedings{AlharthyB03,
  author    = {Alharthy, A and Bethel, J},
  title     = {HEURISTIC FILTERING AND 3D FEATURE EXTRACTION FROM LIDAR DATA},
  booktitle = {Proceedings of {ISPRS} {C}ommission {III}/{WG}3 3{D} {R}econstruction from {L}aser {S}canning and {I}n{SAR}},
  year      = {2002},
  month     = {October},
  url       = {http://www.ISPRS.org/commission3/proceedings/papers/paper061.pdf},
  address   = {Dresden, Germany},
  comment   = {Uses difference between first and last return of laser scanning data to extract buildings.},
  groups    = {lidar},
  keywords  = {3D},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{AmiriParianS07,
  author    = {Amiri Parian, Jafar and Isabel Sargent},
  title     = {Automatic height attribute assignment for building polygons: City modeling with level of detail zero},
  booktitle = {Proceedings of the 8th Conference on Optical 3-{D} Measurement Techniques},
  year      = {2007},
  url       = {file://os2k17\Research\Resources\ConferenceProceedings\Optical3D2007\pdf\Parian_Sargent.pdf},
  comment   = {TRIM Record Number: RESD/09/157},
  keywords  = {3DCharsPaper},
  owner     = {Izzy},
  creationdate = {2007/05/18},
}

@Article{GisProfessional04,
  author       = {Anon},
  journaltitle = {G{IS} {P}rofessional},
  title        = {Visualising the true scale of 3{D} {GIS}},
  number       = {1},
  url          = {http://www.pvpubs.com/read_article_gis.asp?ID=34&article_id=191},
  volume       = {1},
  comment      = {''Conclusion While everyone is in agreement on the demand for 3D GIS, not everyone agrees on the direction. Sanderson doubts that heavyweight GIS systems will ever be developed to deal with these data, but expects this technology to be seamlessly integrated into relational databases like Oracle. Ostyn, though, concluded: ``The 2D thematic map may have been the core of GIS analysis for a decade and more, but the time is almost upon us when this evolves into 3D visualisation.''},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {2004},
}

@Misc{NoiseDirective02,
  Title                    = {D{IRECTIVE} 2002/49/{EC} {OF} {THE} {EUROPEAN} {PARLIAMENT} {AND} {OF} {THE} {COUNCIL}},

  Author                   = {Anon},
  HowPublished             = {Internet},
  Month                    = {June},
  Note                     = {\url{http://europa.eu.int/eur-lex/pri/en/oj/dat/2002/l_189/l_18920020718en00120025.pdf}},
  Year                     = {2002},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@InProceedings{AplinATCI99,
  Title                    = {{SAR} imagery for flood monitoring and assessment.},
  Author                   = {Aplin, P and Atkinson, P M and Tatnall, A R and Cutler, M E and Sargent, I},
  Booktitle                = {Proceedings of {RSS}99 Earth Observation - from Data to Information},
  Year                     = {1999},

  Address                  = {Nottingham, UK},
  Organization             = {Remote Sensing Society},
  Pages                    = {557-563},

  Owner                    = {Izzy},
  creationdate                = {2009.02.11}
}

@Article{AriasG09,
  author       = {Benjam\'{i}n Arias and Javier G\'{o}mez-Lahoz},
  journaltitle = {The Photogrammetric Record},
  title        = {Testing the stereoscopic precision of a large-format digital camera},
  number       = {126},
  pages        = {157-170},
  volume       = {24},
  comment      = {Focuses on the precision of measures made by human operators between a film camera and Vexcel UltraCamD. Also compare scanned film with original image. Quite a detailed effort to try to rule out learning by operators, ability of operators, location of point in image (account for modular component of digital cameras) and a number of other factors. Points that were measured were: well-defined points on the terrain, easy urban points (roofs) and difficult urban points (ground points close to buildings). Operators were classed as of high experienced (10 years), of medium experience (5 years) and of low experience (1 to 2 years). ``Today, in addition to modern automatic measurements, stereoscopic measurements are still performed by human operators and it is likely that photogrammetric production will continue to rely on the latter for some time to come.'' ``It should be borne in mind that the variability between operators may be greater than the variability between the cameras.'' Statistical analysis of results appears to find that in planimetry there is no significant difference between cameras although the film camera is better, probably due to the better B/H (base/height) ratio. There is a significant difference in Z where the film camera is worse . There also seems to be significant differences between operators in Z but not in planimetry (I may not have understood this).},
  creationdate = {2010.06.04},
  owner        = {Izzy},
  year         = {2009},
}

@Article{AsifC01,
  author       = {Muhammad Asif and Tae-Sun Choi},
  title        = {Shape from focus using multilayer feed-forward neural networks},
  journaltitle = ieip,
  year         = {2001},
  volume       = {10},
  number       = {10},
  pages        = {1670--1675},
  comment      = {shape from focus (SFF) uses a sequence of images taken by a single camera at different focus levels to comute depth of objects. Any use to us with image-sets?},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
}

@InProceedings{AthanasiadisM04,
  author       = {I N Athanasiadis and P A Mitkas},
  booktitle    = {International {E}nvironmental {M}odelling and {S}oftware {S}ociety 2004 {I}nternational {C}ongress: ``{C}omplexity and {I}ntegrated {R}esources {M}anagement''},
  title        = {Applying agent technology in {E}nvironmental {M}anagement {S}ystems under real-time constraints},
  editor       = {C Pahl and S Schmidt and A Jakeman},
  organization = {iEMSs},
  pages        = {46},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/AthanasiadisM04.pdf},
  address      = {Osnabrueck, Germany},
  comment      = {Layla highlighted this paper has having a good explanation of real-time},
  creationdate = {2005/01/01},
  file         = {AthanasiadisM04.pdf:\url{file\://///os2k17/r&i_data6/lammergeier/share_library/AthanasiadisM04.pdf:PDF}},
  month        = {June},
  owner        = {izzy},
  year         = {2004},
}

@Unpublished{IGARSS02,
  author       = {Peter Atkinson},
  title        = {Optimal spatial information extraction for remote sensing classification},
  note         = {Loughborough Feature Extraction Workshop: commercial in confidence},
  abstract     = {Accurate information on land cover is required for both scientific research (e.g., climate change modelling, flood prediction) and management (e.g., city planning, disaster mitigation). {R}emote sensing has the potential to provide this information. {H}owever, there exist several practical limitations to the remote sensing of land cover. {T}he particular problem that provides the impetus for this paper is that within remotely sensed images, a significant proportion of pixels may be of mixed class composition ({F}isher, 1997). {F}or example, a {L}andsat {T}hematic {M}apper ({TM}) image (with a spatial resolution of 30 m by 30 m) of an urban scene may contain many pixels that represent more than one land cover class. {T}his is because the spatial frequency of land cover variation in urban areas is high relative to the pixel size. {E}ven in rural areas a {L}andsat {TM} scene may contain mixed pixels at the boundaries between land cover types, for example, between agricultural fields. {T}raditionally, hard classification has been used to assign each pixel in a remotely sensed image to a single, most likely, class. {H}owever, where mixed pixels are present, hard classification is inappropriate: it does not make sense to allocate a single pixel to, say, woodland when the pixel actually represents 50\% woodland, 30\% heathland and 20\% water. {T}he solution to the mixed pixel problem typically centres on soft classification. {S}oft classifiers such as the spectral mixture model ({G}arcia-{H}aro et al., 1996), the nearest neighbour classifier ({S}chowengerdt, 1997), the multi-layer perceptron ({A}tkinson et al., 1997) and the support vector machine ({B}rown et al., 1999) may be used to estimate the proportion of each class within each pixel. {I}n most cases, soft classification results in a more informative and appropriate representation of land cover than that produced using hard classification. {H}owever, while the class composition of every pixel is predicted, the spatial distribution of these class components within each pixel remains unknown ({A}tkinson, 1997). {T}his paper describes an extension of an approach first introduced by {A}tkinson (1997) and an alternative to the approach developed by {T}atem et al. (2001). {I}t uses the output from a soft classification to constrain a simple pixel-swapping algorithm that has not previously been introduced. {B}y utilizing information contained in surrounding pixels, the land cover within each pixel is mapped using a simple spatial clustering function. {T}he result is a map of land cover with a pixel size that is much smaller than that of the remotely sensed imagery. {T}his paper demonstrates also how this approach can be extended to multiple land cover class mapping at the sub-pixel scale. {T}his and related approaches represent an important step forward in remote sensing classification research from (i) hard classification, through (ii) soft classification to (iii) super-resolution classification. {R}eferences {A}tkinson, {P}.{M}., 1997, {M}apping sub-pixel boundaries from remotely sensed images, {I}nnovations in {GIS} {IV}. {T}aylor and {F}rancis, {L}ondon, pp.166-180. {B}rown, {M}., {G}unn, {S}.{R}., and {L}ewis, {H}.{G}., 1999, {S}upport vector machines for optimal classification and spectral unmixing. {E}cological {M}odelling, 120:167-179. {F}isher, {P}., 1997, {T}he pixel: a snare and a delusion, {I}nternational {J}ournal of {R}emote {S}ensing.18:679-685. {G}arcia-{H}aro, {F}.{J}., {G}ilabert, {M}.{A}., and {M}elia, {J}., 1996, {L}inear spectral mixture modelling to estimate vegetation amount from optical spectral data. {I}nternational {J}ournal of {R}emote {S}ensing, 17:3373-3400. {S}chowengerdt, {R}.{A}., 1997, {R}emote {S}ensing: {M}odels and {M}ethods for {I}mage {P}rocessing, {A}cademic {P}ress, {S}an {D}iego. {T}atem, {A}.{J}., {L}ewis, {H}.{G}., {A}tkinson, {P}.{M}., and {N}ixon, {M}.{S}., 2001, {S}uper-resolution target identification from remotely sensed images using a {H}opfield neural network, {IEEE} {T}ransactions on {G}eoscience and {R}emote {S}ensing ({I}n {P}ress).},
  address      = {Department of Geography,University of Southampton,Highfield Southampton,SO17 1BJ,UK},
  creationdate = {2005/01/01},
  year         = {2002},
}

@Article{AtkinsonSFW07,
  Title                    = {Exploring the geostatistical method for estimating the signal-to-noise ratio of images.},
  Author                   = {Atkinson, P M and Sargent, I M and Foody, G M and Williams, J},
  Year                     = {2007},
  Number                   = {7},
  Pages                    = {88-104},
  Volume                   = {73},

  Journaltitle             = {Photogrammetric Engineering and Remote Sensing},
  Owner                    = {Izzy},
  creationdate                = {2009.02.11}
}

@InBook{AtkinsonS01,
  author       = {Peter M Atkinson and Isabel M J Sargent},
  title        = {{OEEPE}-Project on Topographic Mapping from High Resolution Space Sensors},
  chapter      = {Annexe 4: High Resolution Sensor data for Automatic Change Detection},
  editor       = {David Holland and Bob Guilford and and Keith Murray},
  pages        = {71-90},
  publisher    = {European Organization for Experimental Photogrammetric Research},
  url          = {http://bono.hostireland.com/~eurosdr/publications/44.pdf},
  comment      = {Overview: Outlines the possible ways that change between two data sets can be undertaken. These are either raster to raster comparison ('rasterizing' vector data if necessary) or vector to vector comparison ('vectorizing' raster data if necessary). It also points out that equivalent data should be compared (reflectance values to reflectance values, for instance, rather than image values to reflectance values). This project classifies Ikonos imagery using two unsupervised approaches (one using spectral values alone the other using spectral and spatial information). This information was then compared to rasterised topographic data. The unique identifier for each polygon in the topographic data was assigned to each pixel in its rasterized version. The comparison was performed using local statistics that reset the pixel values in each data set to binary values depending on whether or not they were a memebr of the current class. Comments: Despite undertaking this research myself, I can't actually remember the intricasies of the comparison method. This could be a useful method of comparing two differing data sets. How could report be updated: There may be some scope for using a segmentation technique such as eCognition for the classification stage of this research. Also, it would be interesting to attempt comparisons between data sets in the vector domain. Relevance to/of current or proposed activities: The comparison method may be worth returning to in future research into automatic change detection methods. Reviewer: Isabel Sargent. Date: June 2005},
  howpublished = {OEEPE Project report},
  keywords     = {Izzypub},
  month        = {September},
  owner        = {Izzy},
  creationdate    = {2005/01/01},
  year         = {2002},
}

@Article{AtkinsonSFW05,
  Title                    = {Interpreting image-based methods for estimating the signal-to-noise ratio.},
  Author                   = {Atkinson, P M and Sargent, I M J and Foody, G M and Williams, J},
  Year                     = {2005},
  Number                   = {20},
  Pages                    = {5099-5115},
  Volume                   = {26},

  Journaltitle             = {International Journal of Remote Sensing},
  Owner                    = {Izzy},
  creationdate                = {2009.02.11}
}

@InProceedings{AvrahamiRD05,
  author       = {Avrahami, Yair and Raizman, Yuri and Doytsher, Yerach},
  title        = {Extraction of 3{D} spatial polygons based on the overlapping criterion for roof extraction from aerial images},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {http://www.commission3.isprs.org/cmrt05/papers/CMRT05_Avrahami_et_al.pdf},
  comment      = {Use two aerial images. The operator points within an area to be extracted from the left image. Then find edges around the point and find the pixels with similar values. Next region growing, raster to vector conversion and then height. Match the images using epipolar lines. Problems exist but are overcome with overlapping criterion - pass left polygon over the right image space along the epipolar line and find the location of maximum overlap to achieve coarse matching. Then something else. For roof extraction have a generic model (see log book p116) and there are a vairety of options for planes for the operator to point at. This is done in matlab currently. The options allow the choice of non-occluded planes to fit the model to. Quality assessment entails comparing the Maybe something that could be tested?},
  keywords     = {3D, epipolar},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Article{Axelsson99,
  Title                    = {Processing of laser scanner data - algorithms and applications},
  Author                   = {Axelsson, Peter},
  Year                     = {1999},
  Number                   = {2-3},
  Pages                    = {138-147},
  Volume                   = {54},

  Journaltitle             = {#ijprs#},
  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Article{BackHS97,
  author           = {B\''{a}ck, T, and Hammel, U and Schwefel, H-P},
  date             = {1997},
  journaltitle     = {I{EEE} {T}rans. on {E}volutionary {C}omputation},
  title            = {Evolutionary computation: comments on the history and current state},
  number           = {1},
  pages            = {3--17},
  url              = {http://citeseer.ist.psu.edu/cache/papers/cs/29509/http:zSzzSzls11-www.cs.uni-dortmund.dezSzpeoplezSzschwefelzSzpublicationszSzBHS97.pdf/evolutionary-computation-comments-on.pdf},
  volume           = {1},
  comment          = {Seems to be a good general reference for genetic algorithms},
  creationdate     = {2005/01/01},
  modificationdate = {2022-11-20T09:33:25},
  owner            = {izzy},
  year             = {1997},
}

@Article{BabuMadhavanWTHNYTS06,
  author       = {Babu Madhavan, B and C. Wang and H. Tanahashi and H. Hirayu and Y. Niwa and K. Yamamoto and K. Tachibana and T. Sasagawa},
  title        = {A computer vision based approach for 3D building modelling of airborne laser scanner DSM data},
  journaltitle = {Computers, Environment and Urban Systems},
  year         = {2006},
  volume       = {30},
  number       = {1},
  pages        = {54-77},
  bibsource    = {DBLP,  \url{http://dblp.uni-trier.de}},
  comment      = {In TRIM. Capturing 3D building models automatically from lidar DSMs. Quite a useful lit review on automatic 3D building modelling. Includes some comments on multiple image matching techniques for DSM creation. Also a useful list of the pros and cons of using lidar for 3D building extraction. Test area is Japan, where buildings are densely packed. Method is 'computer vision-based'. The stages are: 1 enhance DSMs spatial resolution and noise removal - this appears to add in posts and assign their height using the median-SUSAN filter which obtains heights only from posts that fall on the same 'object'; 2 Plane fitting and extraction of stable planar regions - the stable planar regions are computed from the histogram of the normals to the local planes, assuming a Gaussian distribution of normal directions the plane with the majority normals is identified; 3 jump and boundary edge detection - a Sobel directional filter is applied to the gridded DSM to identify edges, edges are thinned to one pixel width and Hough transform is used to identify the major straight lines and their intersections and thus start and ends are calculated; 4 roof edge computation - the roof planes are intersected to identify the edges in the roof, the building itself is bounded by the jump edges identified in 3; 5 polygon description of DSM - using the roof edges and jump edges the building polygon is identified. Quality assessment involved comparing the 3D models to 2D map data and also comparing the building model heights to the original lidar data.},
  ee           = {http://dx.doi.org/10.1016/j.compenvurbsys.2005.01.001},
  keywords     = {3D, quality, lidar, DSM},
  owner        = {Izzy},
  creationdate    = {2007/11/16},
}

@InProceedings{BacherM05,
  author       = {Uwe Bacher and Helmut Mayer},
  title        = {Automatic road extraction from multispectral high resolution satellite images},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {http://www.isprs.org/proceedings/XXXVI/3-W24/papers/CMRT05_Bacher_Mayer.pdf},
  address      = {Vienna, Austria},
  comment      = {In central Europe almost all roads are in databases, however road detection is necessary in other parts of the world. The paper classifies images on spectral information to find roads and background classes. Looked a bit like thresholding would achieve a similar result. They then look for lines and create road hypotheses based on the length and average width of these lines. Somewhere in here is the homogeniety of the grey value and the membership of the road hypothesis to the road class. Effectively use a set of heuristics to find roads. They close the gaps between lines. Compared to reference to data. The comparison was made up of a) minum reference roads (what must be included - completeness) and b) maximum reference roads (what could be included - sort of correctness).},
  keywords     = {DeepLEAP1},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Article{BaillardD00,
  Title                    = {A stereo matching algorithm for urban digital elevation models},
  Author                   = {Baillard, C And Dissard, O},
  Year                     = {2000},
  Number                   = {9},
  Pages                    = {1119-1128},
  Volume                   = {66},

  Abstract                 = {A stereo matching algorithm dedicated to complex urban scenes is described. It relies on successive complementary matching steps, based on dynamic programming. First, intensity edges of both images are matched, which produces piecewise continuous 3D chains. This provides a description of the scene structure containing the highest elevation of most height discontinuities. Then the interval pairs defined by the matched edges are matched in a hierarchical way, by a radio-metrically constrained process followed by a geometrically constrained one. The novelty of the approach lies in the use of several successive steps appropriate to different kinds of pixels. It provides dense disparity maps with less noise, while preserving discontinuities, which are a characteristic of urban digital elevation models. The method has proved reliable (producing few noisy and altimetrically accurate 3D data) and fast, and is robust to image variability. Perspectives within an industrial production context are discussed.},
  Journaltitle             = {Photogrammetric Engineering and Remote Sensing},
  Keywords                 = {3D, getacopy},
  Owner                    = {Izzy},
  creationdate                = {2007/11/16}
}

@Article{BaillardDJM98,
  author       = {Baillard, C. and Dissard, O. and Jamet, O. and Maitre, H.},
  journaltitle = {ISPRS Journal of Photogrammetry and Remote Sensing},
  title        = {Extraction and Textural Characterization of Above-ground Areas from Aerial Stereo Pairs: A Quality Assessment},
  number       = {2},
  pages        = {130-141},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/BaillardDJM98.pdf},
  volume       = {53},
  abstract     = {Above-ground analysis is a key point to the reconstruction of urban scenes, but it is a difficult task because of the diversity of the involved objects. We propose a new method to above-ground extraction from an aerial stereo pair, which does not require any assumption about object shape or nature. A Digital Surface Model is first produced by a stereoscopic matching stage preserving discontinuities, and then processed by a region-based Markovian classification algorithm. The produced above-ground areas are finally characterized as man-made or natural according to the grey level information. The quality of the results is assessed and discussed. (C) 1998 Elsevier Science B.V. All rights reserved.},
  comment      = {Ordered from library 2008/02/13
Review:
Seems to be about classifying regions on a DSM. Not terribly well written. A DSM is created using image matching. The points are then clustered into regions of different heights. Regions are classified as ground or above ground and adjacent above ground regions are grouped together into blobs. These blobs are then 'characterized' as man-made or natural (I think this should be classified). Image matching involves edge and area matching. Unmatched areas have their heights interpolated as part of the next step. 'Markovian modelling' is used to classify the regions (that is, it is not single points but the hole regions that are classified as ground or above-ground according to the nature of the regions. Error in the classification of these regions tends to occur with small objects and because the discontinuities in the DSM are planimetrically incorrect. Above ground features then to be classified. A histogram of local values such as slope is created for each pixel. The variability of this can be used to say if a region is structured and infer if it is man-made. Blobs are classified as built areas, vegetated areas and mixed areas. The final classification is useful to determine which 'reconstruction' (capture) algorithm/method should be aplied to the data in that region. A good e.g. for roof characterisation.},
  creationdate = {2008/02/13},
  keywords     = {morphology},
  month        = {April},
  owner        = {izzy},
  year         = {1998},
}

@InProceedings{BaillardSZF99,
  author      = {Baillard, Caroline and Schmid, Cordelia and Zisserman, Andrew and Fitzgibbon, Andrew},
  title       = {Automatic line matching and {3{D}} reconstruction of buildings from multiple views},
  booktitle   = {I{SPRS} {C}onference on {A}utomatic {E}xtraction of {GIS} {O}bjects from {D}igital {I}magery},
  year        = {1999},
  volume      = {32},
  number      = {3-2 W5},
  pages       = {69--80},
  url         = {http://citeseer.ist.psu.edu/cache/papers/cs/16114/ftp:zSzzSzftp.inrialpes.frzSzpubzSzmovizSzpublicationszSzBaillardSchmid-isprs99.pdf/baillard99automatic.pdf},
  citeseerurl = {http://citeseer.ist.psu.edu/cache/papers/cs/16114/ftp:zSzzSzftp.inrialpes.frzSzpubzSzmovizSzpublicationszSzBaillardSchmid-isprs99.pdf/baillard99automatic.pdf},
  comment     = {In TRIM. Referenced by BaltsaviasH00. Instead of computing a dense DSM from images, this method starts by finding 3D lines and matching them across images. It then performs matching to determine the planes that are defined by the lines and finally groups the lines and planes to create the 3D models of roofs. This is part of the IMPACT (IMage Processing for Automatic Cartographic Tools) project that includes groups from Bonn, ENST (France), Eurosense, Leuwen and this group in Oxford.The data used contain at least three views of any object. The line matching used here is based on that proposed by Schmid and Zisserman 1997 for grouping lines in 3 images. This work extends it to n images. A line found in one image can be used to define an epipolar 'beam' in another by finding the epipolar lines corresponding to the ends of the found line. The line will then be found in the second image within the epipolar beam. A triple tensor is used to transfer the matched lines into the third image. This allows geometric (a line is in the predicted position in the third image) and photometric (the is strong correlation in the predicted position between the second and third image) verification. If the first test is passed or the second test is passed with a high confidence then the line is verified. This is repeated using the second and third image as the initial pair. Matched lines are improved in quality by merging segments together or growing lines to best fit the multiple views. This is extended to n images by finding triples as above and matching these according to some stated criteria. I imagine this can get very heavy going with more than 6 images. The planar models are fitted based on the lines. The more lines that are hypothesised, the more likely that planes will be found. A similarity score is computed between the proposed plane and the surface model (I think) to determine the angle of the plane and decide whether to accept or reject a plane. An example is given of a similarity score that changes with angle but does not reach a notable peak and is therefore reqjected. This change of similarity, as well as the similarity itself could be a useful self-assessment test. Finally, the model is built by assembling the planes and lines that are consistent with each other. The equations used throughout the paper seem logical and could be useful. There is masses in this paper that could be useful, it would also be useful to know where this work has gone to now.},
  keywords    = {quality 3D, image matching},
  owner       = {izzy},
  creationdate   = {2005/10/14},
}

@InProceedings{BaillardZ00,
  author    = {Baillard, C. and Zisserman, A.},
  title     = {A plane-sweep strategy for the 3{D} reconstruction of buildings from multiple images},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2000},
  volume    = {XXXIII},
  url       = {http://citeseer.ist.psu.edu/cache/papers/cs/16753/http:zSzzSzimogen.robots.ox.ac.uk:20000zSz~vggzSzvggpaperszSzBaillard2000.pdf/baillard00planesweep.pdf},
  comment   = {In TRIM. Interesting and readable paper. Starts with a short but comprehensive overview of 3{D} reconstruction to date. The method presented comprises: 1) computing reliable half-planes defined by one 3d line and similarity scores computed over all the views, 2) line grouping and completion based on the computed half-planes, 3) plane delineation and verification. In this case the lines are first computed on 2D images using Canny edge detection. Straight lines are identified and then matched between three images to produce 3D lines.},
  keywords  = {3D, quality},
  owner     = {izzy},
  text      = {C. Baillard and A. Zisserman. A plane-sweep strategy for the 3{D} reconstruction of buildings from multiple images. In Proc. 19th {ISPRS} Congress and Exhibition, 2000.},
  creationdate = {2005/01/01},
}

@InProceedings{BaillardZ99,
  author    = {Baillard, C and Zisserman, A},
  title     = {Automatic reconstruction of piecewise planar models from multiple views},
  booktitle = {Proceedings {IEEE} {C}omputer {V}ision and {P}attern {R}ecognition},
  year      = {1999},
  volume    = {2},
  pages     = {599-565},
  url       = {Automatic reconstruction of piecewise planar models from multiple views},
  comment   = {Not read but according to Kim01 they use six or more images to find 3D matched lines},
  keywords  = {3D, quality, toread},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{BajramovicGD05,
  author       = {Bajramovic, Ferid and Gr\''{a}{\ss}l, Christoph and Denzler, Joachin},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Efficient combination of histomgrams for real-time tracking using mean-shift and trust-region optimization},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Histogram trackers are robust and can handle occlusions. But there is a choice of trackers and not always clear which to choose. This paper proposes a weighted combinationj of histograms. Runs in real-time on PC hardware and has imprived tracking precision. Found that the colour and gradient histogram seems better than the colour and corner or colour alone histogram.},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{BaltsaviasH00,
  author       = {Baltsavias, Emmanuel And Hahn, Michael},
  booktitle    = {IAPRS},
  title        = {Integrating Spatial Information and Image Analysis - One Plus One Makes Ten},
  url          = {http://e-collection.ethbib.ethz.ch/ecol-pool/inkonf/inkonf_97.pdf},
  volume       = {Vol. XXXIII},
  address      = {Amsterdam},
  comment      = {''Photogrammetry and remote sensing have proven their efficiency for spatial data collection in many ways...In the field of image analysis, it has become evident that algorithms for scene interpretation and 3D reconstruction of topographic objects, which rely on a single data source, cannot function efficiently...Research in two directions promises to be more successful. Multiple, largely complementary, sensor data like range data from laser scanners, SAR and panchromatic or multi-/hyper-spectral aerial images have been used to achieve robustness and better performance in image analysis. On the other hand, given GIS databases, e.g. layers from topographic maps, can be considered as virtual sensor data which contain geometric information together with its explicitly given semantics...This paper is intended to give an overview and the state-ofthe-art on topics related to the terms of references of the IC WG ``Integration of Image Analysis and GIS''...we will concentrate on 3 topics on which most activities were observed: (a) use of GIS data and models to support image analysis; (b) matching of image features and GIS objects for change detection and database revision; (c) use of image analysis techniques to extract height information for 2D databases.'' ``Examples of approaches that incorporate a priori knowledge for object extraction are given: (a) for buildings in BaillardSZF99, HaalaB99, StillaJ99, Niederost00'' Useful text for references (if it gives them) and summarises work to date clearly.},
  creationdate = {2005/01/01},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2000},
}

@Article{Baltsavias04,
  author       = {E. P. Baltsavias},
  title        = {Object extraction and revision by image analysis using existing geodata and knowledge: current status and steps towards operational systems},
  journaltitle = {I{SPRS} {J}ournal of {P}hotogrammetry and {R}emote {S}ensing},
  year         = {2004},
  volume       = {58},
  number       = {3-4},
  pages        = {129-151},
  comment      = {A more comprehensive version of Baltsavias99.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  wherefind    = {In share_library},
}

@Article{Baltsavias99,
  Title                    = {A comparison between photogrammetry and laser scanning},
  Author                   = {E P Baltsavias},
  Year                     = {1999},
  Pages                    = {83-94},
  Volume                   = {54},

  Journaltitle             = {#ijprs#},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01},
  Url                      = {http://www.cnr.colostate.edu/~lefsky/ISPRS/1139.pdf}
}

@InBook{BaGr03,
  Title                    = {Remotely {S}ensed {C}ities},
  Author                   = {E P Baltsavias and A Gruen},
  Chapter                  = {Resolution convergence: A comparison of aerial photos, {L}i{DAR}, and {IKONOS} for modelling cities},
  Editor                   = {V Mesev},
  Pages                    = {47-82},
  Publisher                = {Taylor and Francis},
  Year                     = {2003},

  Address                  = {London},

  Groups                   = {lidar},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@InProceedings{BalzH05,
  author       = {Balz, Timo and Haala, Norbert},
  title        = {Interpretation of high resolution {SAR} data using existing {GIS} dat in urban areas},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {SAR data for 3D city models. Requires georeferncing of SAR with existing GIS. Tried matching against street vectors but shadows and layover gave an apparent shirt in position of streets but maybe 6 meters. Therefore matched to 3D models This was achieved by modelling how the SAR data would look given 3D model and maching this. Suggested use for change detection. (given by Haala)},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Article{BandyopadhyayM01,
  author       = {Sanghamitra Bandyopadhyay and Ujjwal Maulik},
  title        = {Nonparametric Genetic Clustering: Comparison of Validity Indices},
  journaltitle = iesmc,
  year         = {2001},
  volume       = {31},
  number       = {1},
  pages        = {120-125},
  comment      = {In TRIM. Genetic algorithm performs clustering with no a priori number of clusters.},
  keywords     = {clustering},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Unpublished{BarrB02,
  Title                    = {Deriving {B}uilt-{F}orms from {R}emotely {S}ensed {D}ata for the {I}nference of {U}rban {L}and {U}se {I}nformation: {P}reliminary {R}esults and {F}uture {R}esearch {I}ssues},
  Author                   = {Stuart Barr and Mike Barnsley},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {Accurate information on the morphology and spatial composition of urban built-forms have been shown to provide a plausible means by which urban land use information (e.g., residential, commercial and industrial land) may be inferred. {V}ery high spatial resolution remotely sensed images have long been considered an ideal means by which to derive information on the physical extent of urban built-forms. {H}owever, and particularly in relation to the task of inferring urban land use, the accuracy of built-form information derived from such data is often disappointing. {I}n order to address this issue, we discuss two approaches currently under investigation for the derivation of built-form morphology and spatial composition for the inference of urban land use. {T}he first approach involves a combined use of very high spatial resolution multispectral {IKONOS} images and {L}ight {D}etection and {R}anging ({LIDAR}) data. {O}n the basis of a standard classification and {NDVI} ratio of the multispectral image, and the utilisation of a empirically a-priori derived building height threshold of the {LIDAR} data, we demonstrate that sufficiently accurate building outlines can be derived that allow a broad range of urban land use types to be discriminated on the basis of building morphology and spatial composition. {A} comparison with digital map data highlights, however, that errors which correlate to building size exist in the derived buildings. {T}he second approach relates to very high spatial resolution {E}arth observed multispectral image data alone. {W}e postulate that the poor accuracy traditionally achieved for the inference of built-forms using such data is a function of the complex 3-{D}imensional built-form geometry (e.g., gable roofs with different principle axis orientations) of urban areas, which under certain illumination and viewing conditions can result in both the multispectral and hyperspectral response of buildings of the same size, shape and roofing material varying significantly. {I}n order to address this point, we present the results of a preliminary study into the utility of multiple view angle data in order to improve the determination of urban built-forms. {S}pectroscopy measurements over scaled physical models of typical gable-roofs of different roofing material reveal that roof orientation, and illumination and view angle parameters result in considerable variance and overlap in recorded spectral response. {A} sampling of the roof-models for changing view angle shows, however, a significant improvement in spectral discrimination, suggesting that the acquisition of very high spatial resolution multispectral multiple view-angle images may facilitate a more consistent and objective inference of urban built-forms than single-look multispectral or hyperspectral images. {I}n light of findings presented for each approach, a suggested programme of future research into the derivation of urban built-forms for the inference of urban land use using remotely-sensed data is presented.},
  Address                  = {Stuart Barr,School of Geography,University of Leeds,Leeds,LS2 9JT,UK;Mike Barnsley,Department of Geography,University of Wales Swansea,Swansea SA2 8PP,UK},
  Groups                   = {lidar},
  Keywords                 = {morphology},
  creationdate                = {2005/01/01}
}

@InProceedings{BauckhageT05,
  author    = {Christian Bauckage and John K Tsotsos},
  title     = {Separable linear discriminant classification},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Linear discrimiant analysis using tensor decomposition. Consider a 2-class problem.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Article{BellAS03,
  author       = {A Bell and A F Ayoub and P Siebert},
  journaltitle = {Journal of {O}rthodontics},
  title        = {Assessment of the accuracy of a three-dimensional imaging system for archiving dental study models},
  number       = {3},
  pages        = {219-223},
  url          = {http://jorthod.maneyjournals.org/cgi/content/full/30/3/219},
  volume       = {30},
  comment      = {''Design: A comparative assessment between direct measurements of dental study models and measurements of computer generated 3D images of the same study models was performed. Materials and methods: Twenty-two dental study models stored at Glasgow Dental Hospital and School for the purposes of research were used in the study. The models were captured in three dimensions using a photostereometric technique and stored in digital format. Main Outcome Measures: Measurements were conducted directly on dental study models and on the computer generated 3D images using Euclidean Distance Matrix Analysis.2 The difference between the two sets of measurements was statistically analysed using a two-sample t-test. Results: The average difference between measurements of dental casts and 3D images was 0.27 mm. This difference was within the range of operator errors (0.10-0.48 mm) and was not statistically significant (P < 0.05). Conclusion: This study shows that it is possible to use 3D imaging to store dental study models for treatment monitoring and research with a satisfactory degree of accuracy.'' ``On each model six anatomical dental points were marked. Using Euclidean Distance Matrix Analysis,2 the linear distances between the points were measured with an Orthomax Vernier calliper. A total of 15 measurements were made on each cast (Figure 1). The same points on each cast were measured eight times with at least a 1-day interval between measurements. The mean differences in measurements were calculated to assess intra-operator error in manual measurement.'' ``Images were digitized and automatically loaded into the computer memory. The C3D-builder processed the texture-projected pair of images to produce a 3D surface reconstruction of the study model. A polygon mesh represented this....This allows direct measurement of real distances, areas, volumes, and angles. A computer automated measuring tool was used to make the same measurements that had been carried out manually. The points on each cast were digitized and the distances between the points were calculated. This was carried out eight times for each cast, with at least a 1-day interval between measurements. The mean differences in measurements were calculated to assess the error of the method.'' Slight but non-significant differences between measurements of the same points on the cast (at different times, one operator) and even smaller difference between measurements of the same points on the 3D model of the cast (at different times, one operator). The differences between the cast and the model measurements were also not statistically significant (using two-sample t-test).},
  creationdate = {2005/08/08},
  keywords     = {3D, quality, image matching},
  owner        = {izzy},
  wherefind    = {url},
  year         = {2003},
}

@Article{BeSh00,
  Title                    = {Early {S}tage {O}bject {R}ecognition {U}sing {N}eural {N}etworks},
  Author                   = {C Bellman and M Shortis},
  Year                     = {2000},
  Number                   = {Supplement B3},
  Pages                    = {20-26},
  Volume                   = {Vol XXXIII},

  Journaltitle             = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@InProceedings{BellmanS04,
  author    = {Bellman, C J and Shortis, M R},
  title     = {A {C}lassification {A}pproach {T}o {F}inding {B}uildings {I}n {L}arge {S}cale {A}erial {P}hotographs},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.ISPRS.org/istanbul2004/comm3/papers/291.pdf},
  comment   = {Support Vector Machines (SVM) find optimal separation between classes and allow for an increase in the dimensionality of the data. This work preprocessed the data using simple wavelet transform. The SVM was train on small portions of images contain either complete buildings or no building. Buildings filled whole portions according to example figures. Results OK but problem very simplified.},
  keywords  = {Building Recognition, Classification, Learning, Neural Networks},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{BevanM94,
  author       = {Bevan, N and Macleod, M},
  journaltitle = {Behaviour and {I}nformation {T}echnology},
  title        = {Usability {M}easurement in {C}ontext},
  pages        = {132-145},
  volume       = {13},
  comment      = {Not read, but this paper describes the ESPRIT MUSiC project ``has developed tools which can be used to measure usability in the laboratory and the field'' Also ``Unproductive periods of the task are periods during which users are seeking help (Help Time), searching hidden structures of the product (Search Time) and overcoming problems (Snag Time). Productive Time is therefore defined as the Task Time remaining after Help, Search, and Snag Times have been removed.''. These are measures of duration. HCI92, added to this performance metric `` Measures of learning The rate at which a user learns how to use particular products in specified contexts, can be measured by the rate of increase exhibited by individual metrics when the user repeats evaluation sessions. Alternatively the efficiency of a particular user relative to an expert provides an indication of the position on the learning curve that the user has reached.''},
  creationdate = {2006/02/01},
  file         = {music94.pdf:http\://www.usability.serco.com/papers/music94.pdf:PDF},
  keywords     = {usability, RapidDC},
  owner        = {izzy},
  year         = {1994},
}

@Misc{BevingtonLA06,
  author       = {J Bevington and H Lewis and P Atkinson},
  title        = {Quantitative and qualitative measurements of planned and unexpected change using remotely sensed imagery},
  year         = {2006},
  howpublished = {draft document},
  month        = {October},
  comment      = {Have hardcopy in file. Description of conceptual model involving object recognition and change detection and results of first part of this work into object recognition.},
  keywords     = {change detection},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Article{Bian03,
  Title                    = {Retrieving urban objects using a wavelet transform approach},
  Author                   = {Ling Bian},
  Year                     = {2003},
  Number                   = {2},
  Pages                    = {133-141},
  Volume                   = {69},

  Journaltitle             = {Photogrammetric Engineering and Remote Sensing},
  Keywords                 = {wavelets urban},
  Owner                    = {izzy},
  creationdate                = {2008/02/04}
}

@Article{BimboP06,
  Title                    = {Content-based retrieval of 3D models},
  Author                   = {Alberto Del Bimbo and Pietro Pala},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {20--43},
  Volume                   = {2},

  Abstract                 = {In the past few years, there has been an increasing availability of technologies for the acquisition of digital 3D models of real objects and the consequent use of these models in a variety of applications, in medicine, engineering, and cultural heritage. In this framework, content-based retrieval of 3D objects is becoming an important subject of research, and finding adequate descriptors to capture global or local characteristics of the shape has become one of the main investigation goals. In this article, we present a comparative analysis of a few different solutions for description and retrieval by similarity of 3D models that are representative of the principal classes of approaches proposed. We have developed an experimental analysis by comparing these methods according to their robustness to deformations, the ability to capture an object's structural complexity, and the resolution at which models are considered.},
  Address                  = {New York, NY, USA},
  Comment                  = {Get a copy?},
  Doi                      = {http://doi.acm.org/10.1145/1126004.1126006},
  ISSN                     = {1551-6857},
  Journaltitle             = {ACM Trans. Multimedia Comput. Commun. Appl.},
  Keywords                 = {morphology},
  Owner                    = {izzy},
  Publisher                = {ACM},
  creationdate                = {2008/02/21}
}

@Article{BlackFY00,
  author       = {M J Black and D J Fleet and Y Yacoob},
  title        = {Robustly estimating changes in image appearance},
  journaltitle = {Computer {V}ision and {I}mage {U}nderstanding},
  year         = {2000},
  volume       = {78},
  number       = {1},
  pages        = {8--31},
  comment      = {cited by RadkeAKR05},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@Article{BlottP08,
  author       = {Blott, Simon J and Pye, Kenneth},
  title        = {Particle shape: a review and new methods of characterization and classification},
  journaltitle = {SEDIMENTOLOGY},
  year         = {2008},
  volume       = {55},
  number       = {1},
  pages        = {31-63},
  abstract     = {Shape is a fundamental property of all objects, including sedimentary particles, but it remains one of the most difficult to characterize and quantify for all but the simplest of shapes. Despite a large literature ?on the subject, there remains widespread confusion regarding the meaning and relative value of different measures of particle shape. This paper re-examines the basic concepts of particle shape and suggests a number of new and modified methods which are widely applicable to a range of sedimentological problems; it is shown that the most important aspects of particle form are represented by the I/L ratio (elongation ratio) and S/I ratio (flatness ratio). A combination of these two ratios can be used to classify particles in terms of 25 form classes. A method of obtaining a quantitative measure of particle roundness using simple image analysis software is described, and a new visual roundness comparator is presented. It is recommended that measurements of both roundness and circularity (a proxy measure of sphericity) are made on grain images in three orthogonal orientations and average values calculated for each particle. A further shape property, irregularity, is defined and a classification scheme proposed for use in describing and comparing irregular or branching sedimentary particles such as chert and coral.},
  comment      = {Morphology analysed w.r.t. sedimentary particles},
  keywords     = {morphology},
  owner        = {izzy},
  creationdate    = {2008/02/13},
}

@InProceedings{BoudetPJMP06,
  author       = {Laurence Boudet and Nicolas Paparoditis and Franck Jung and Gilles Martinoty and Marc Pierrot-Deseilligny},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {A supervised classification approach towards quality self-diagnosis of 3{D} building models using aerial digital imagery},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. ``The self-diagnosis [not self-assessment, which is dependant on the method of capture] process of 3D roof facet quality is based on aerial images and does not depend on the level of automation involved in the reconstruction stage (none, semi or complete) or on the specific algorithm used to produce the building models. Avoiding the reference need, (SchusterW03, MeidowS05) proposed to use another reconstructed scene to compute either absolute or relative quality measures.'' ``Quality criteria are based on completeness, robustness, geometric accuracy, and shape similarity according to the reference, in addition to those proposed in (McKeownBCHMS00). These empirical evaluations showed the capabilities of semi-automated and automated systems for the production of 3D building models.'' ``Another approach of evaluation in computer vision is the algorithm performance characterisation in terms of internal evaluation and error propagation. (Foerstner94, Foerstner96, ThackerCBBCCCR05) give useful guidelines on this topic.'' In the data used, ``each roof facet is described by geometrical properties (a set of 3D vertices, 3D edges and a normal direction) and topological relations (3D connexity and 2D planimetric connexity between the facets).'' Undertake 3D ROOF FACET QUALITY ANALYSIS. A median difference is calculated between the position of pixels in a DEM and their projected position on a facet in Facet Elevation Consistency Analysis (CD). Then Correlation Function Profile Analysis (CP) seems to be some scoring of correlations along the facet. Edgel Extraction then finds the main structures in the scene, whether or not they are present in the model. These edges are categorised into segments (3D Segment Detection) near edges or corners or in the middle of a roof. Analysis is then performed: Facet Edge Analysis (ES), Facet Corner Analysis (CS) and Inner Facet Analysis (IS). The indices derived for CD, CP, ES,CS and IS for each facet are used to classify the facet into four categories: false, generalised, acceptable and correct. KNN is used as the classifier (they suggest trying other classifiers e.g. NN) and the combination and proportion of neighbours is used to determine whether the model should be accepted, rejected or undecided (traffic lights).},
  creationdate = {2006/09/27},
  keywords     = {Self-diagnosis, Consistency, Image-based measures, Performance evaluation, Classification, 3D, City Models, quality},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{Brenner05,
  author       = {Brenner, Claus},
  title        = {Constraints for modelling complex objects},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Most algorithms fit then snap. That is fit the model to the data then snap using constraints but snap (e.g. constraining to right angles or parallel lines) can destroy the fit. This paper is all about constraints and groups these so that they can be solved in order.},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{BrennerR06,
  author       = {Claus Brenner and Nora Ripperda},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Extraction of {F}acades using rj{MCMC} and {C}onstraint {E}quations},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Poster presentation. Scene grammar of facades. Can it be applied to 2D aerial views? Brenner wants to extend to 3D case.},
  creationdate = {2006/09/27},
  keywords     = {facade extraction},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InBook{Brooke96,
  author       = {J Brooke},
  title        = {Usability {E}valuation in {I}ndustry.},
  chapter      = {SUS: A 'quick and dirty' usability scale.},
  editor       = {Jordan PW and Thomas B and Weerdmeester B and McClelland I},
  pages        = {189-194},
  publisher    = {Taylor \& Francis},
  address      = {London},
  comment      = {in share_library. WongR90 concludes ``SUS is a relatively short questionnaire (10 questions) and is therefore simple and quick for users to complete. The scoring procedure is also simple to apply and provides a single, easy to understand measure. If the application only demands a reliable overall measure of user-satisfaction then SUS is to be recommended.},
  creationdate = {2006/02/01},
  keywords     = {usability, RapidDC},
  owner        = {izzy},
  year         = {1996},
}

@InProceedings{BroxBPW04,
  author    = {Thomas Brox and Andr\'{e}s Bruhn and Nils Papenberg and Joachim Weickert},
  title     = {High {A}ccuracy {O}ptical {F}low {E}stimation {B}ased on a {T}heory for {W}arping},
  booktitle = {Proc. 8th {E}uropean {C}onference on {C}omputer {V}ision, {S}pringer {LNCS} 3024},
  year      = {2004},
  editor    = {T Pajdla and J Matas},
  volume    = {4},
  pages     = {25-36},
  url       = {http://www.mia.uni-saarland.de/Publications/brox_eccv04_of.pdf},
  address   = {Prague, Czech Republic},
  comment   = {Main reference from SlesarevaBW05.},
  keywords  = {toread},
  owner     = {izzy},
  creationdate = {2005/09/12},
}

@InProceedings{BuchholzDNK05,
  author       = {Buchholz, H. and D\''{o}llner, J. and Nienhaus, M. and Kirsch, F.},
  booktitle    = {Proceedings of the 1st {I}nternational {W}orkshop on {N}ext {G}eneration 3{D} {C}ity {M}odels},
  title        = {Real-{T}ime {N}on-{P}hotorealistic {R}endering of 3{D} {C}ity {M}odels},
  editor       = {Gr\''{o}ger and Kolbe},
  url          = {file://///randi01/r%20and%20i/ConferenceProceedings/Lammergeier/NextGen3DCity05/paper14_Buchholz.pdf},
  comment      = {3D city modelling usually attempts to achieve ever more realistic results, often by applying photographic 'textures' to models to indicate, for example, how the walls of a building look. The paper presented by Buchholz (Buchholz et al., 2005) dispensed with this quest for 'photorealism' arguing that despite ever more complex methods available, there can still be a lot of criticism that a model is not realistic due to very small aberrations. Instead, Buchholz presented 'non-photorealism', a method of rendering buildings according to some graphical style that does not attempt to mimic reality. This method was inspired by the historic and cartographic depictions that can date from 16th Century. Very difficult effects can be achieved using a simple library of images (for windows or wall textures, for instance) and a simple set of colours to indicate differences in shading. The example shown didn't apply textures to all parts of a building, but used the method from cartoon drawing that only indicates the texture in some parts of an object. Shadows were also modelled and edges were stylised to look like sketched lines of various types. Such rendering shown here can be designed by the data user and requires only basic information about the nature of different parts of objects - perhaps how many storeys a building has or the labelling of roofs or other buildings features. Therefore, if OS is to consider capturing 3D data, this method indicates the minimum attribution required by users of 3D data for visualisation. Thesis: http://www.hpi.uni-potsdam.de/fileadmin/hpi/Forschung/Publikationen/Dissertationen/Nienhaus/Diss_Nienhaus.pdf Presentation: http://www.ikg.uni-bonn.de/fileadmin/nextgen3dcity/pdf/NextGen3DCity2005_Buchholz.pdf},
  creationdate = {2005/01/01},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2005},
}

@Article{BustosKSS07,
  Title                    = {Content-based 3D object retrieval},
  Author                   = {Bustos, B and Keim, D and Saupe, D and Schreck, T},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {22-27},
  Volume                   = {27},

  Abstract                 = {Methods for automatically extracting descriptors from 3D objects are key to searching and indexing techniques in their growing repositories. The authors present two recently proposed approaches and discuss methods for benchmarking the 3D retrieval systems' qualitative performance.},
  Comment                  = {get a copy?},
  Journaltitle             = {IEEE COMPUTER GRAPHICS AND APPLICATIONS},
  Keywords                 = {morphology},
  Owner                    = {izzy},
  creationdate                = {2008/02/21}
}

@InProceedings{Butenuth06,
  author       = {Matthias Butenuth},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Segmentation of {I}magery {U}sing {N}etwork {S}nakes},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  url          = {http://www.isprs.org/proceedings/XXXVI/part3/singlepapers/O_01.pdf},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Network contours. Active contours have been used for finding objects that are not represented by rigid primitives. They can combine image features with shape contraints. But previously only for objects with a closed boundary. Snakes are also known as parametric active contours and level sets are also known as geometric active contours. Network snakes are not constrained to closed object boundaries. In the presentation the initialisation had the same network topology as the desired result but the geometry changes. Iz: use for getting better geometry for known road networks?},
  creationdate = {2006/09/27},
  keywords     = {DeepLEAP1, ImageLearn, Feature Extraction},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{ButenuthH05,
  author    = {Mattias Butenuth and Christian Heipke},
  title     = {Network snakes-supported extraction of field boundaries from imagery},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Snakes are constrained to have straight field boundaries. Author considering using texture in later work to maybe distinuish between fields ploughed in different directions.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Misc{Capstick04,
  author       = {Dave Capstick},
  title        = {Q{UESTIONS} {FOR} {THE} {GEOUSERS} {ABOUT} 3{D} {DATA}},
  howpublished = {Internal R\&I document},
  note         = {\url{file://///os2k05/Research/Projects/GeoUsers/Goal%202+3+Orch%20work%20(Squish,%20inc%20BOD)/BOD_Users/Internal%203D%20knowledge/GUT-BOD_questions.doc}},
  abstract     = {A report detailing a series of questions that the {BOD} team need answering in order for height modelling and {BOD} to progress. {T}hese are being posed to the {GU} {T}eam who will work in conjunction with the {BOD} in order to assess what 3{D} data our customers will need and use for their visualisation, analysis and querying. {T}he ultimate aim is that we will get these answers from existing customers and potentially new customers of 3{D} data.},
  creationdate = {2005/10/03},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2004},
}

@InProceedings{CapstickHHS06,
  Title                    = {Moving Towards 3D: from a National Mapping Agency Perspective},
  Author                   = {Capstick, D and Heathcote, G and Horgan, J and Sargent, I},
  Booktitle                = {3rd International Conference on the Virtual City and Territory},
  Year                     = {2006},

  Address                  = {Palacio de Congresos Y de la Musica, Euskalduna, Bilbao, Spain},
  Month                    = {25--27 October},

  Keywords                 = {3D, quality, 3DCharsPaper},
  Owner                    = {Izzy},
  creationdate                = {2009.02.11},
  Url                      = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.7883&rep=rep1&type=pdf}
}

@TechReport{Carroll01,
  author       = {Jeremy J Carroll},
  title        = {Matching {RDF} {G}raphs},
  institution  = {Information Infrastructure Laboratory, HP Laboratories Bristol},
  year         = {2001},
  number       = {HPL-2001-293},
  note         = {\url{http://www.hpl.hp.com/techreports/2001/HPL-2001-293.pdf}},
  month        = {November},
  comment      = {Interesting and fairly readable document on the comparison of graphs using Resource Description Framework (RDF). it has been suggested that 3D topology may be described using RDF, and if so, quality assessment of the topology may be possible using the techniques described here and in cited documents.},
  file         = {HPL-2001-293.pdf:http\://www.hpl.hp.com/techreports/2001/HPL-2001-293.pdf:PDF},
  howpublished = {Internet},
  keywords     = {quality},
  owner        = {izzy},
  creationdate    = {2006/02/07},
}

@InProceedings{CastelO08,
  author    = {Thierry Castel and Pascal Oettli},
  title     = {Sensitivity of the {C}-band {SRTM} {DEM} Vertical Accuracy to Terrain Characteristics and Spatial Resolution},
  booktitle = {Headway in Spatial Data Handling - 13th International Symposium on Spatial Data Handling},
  year      = {2008},
  series    = {Lecture Notes in Geoinformation and Cartography},
  pages     = {163-176},
  comment   = {IGN paper. Compare IGN terrain model to GCPs to verify that IGN data is a good verification data for other data sets. Compared IGN to SRTM DEM for different land cover types. Found overall elevation accuracy was OK but in certain areas it was very variable and sometimes below the stated accuracy of the SRTM data. This was caused by land cover type and nature of geomorphology wrt the direction of the radar beam. Talk about comparing slope and aspect data but I didn't find that in my skim-read.},
  keywords  = {DEM, SAR, DTM, quality, DSM},
  owner     = {izzy},
  creationdate = {2008/08/12},
}

@InProceedings{ChampionB06,
  author       = {Nicolas Champion and Didier Boldo},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {A Robust Algorithm for Estimating Digital Terrain Models from Digital Surface Models in Dense Urban Areas},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. DTM from a DSM by masking out outliers. Can use cadastral data for building masks and NDVI on orthos for vegetation masks but other outliers still exist. Uses elastic grid to remove these and shows how resulting terrain fits neatly to the lowest points in a profile.},
  creationdate = {2006/09/27},
  keywords     = {terrain, DEM, quality, image matching},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Article{ChapuisGJA91,
  author       = {R Chapuis and J Gallice and F Jurie and J Alizon},
  title        = {Real time road mark following},
  journaltitle = {Signal {P}rocessing},
  year         = {1991},
  volume       = {24},
  pages        = {331--343},
  comment      = {This method predicts the road mark (centre and edge line) positions, detections them, updates the prediction model and finds new bands based on this. The prediction/detection occurs over a row in the image - it seems that each row has a different prediction (as would be expected) though Im not sure if the method actually predicts for all lines or just for particular ones. The method is tried without and with a smoothing constraint over time. The smoothing constraint allowed for better results.},
  creationdate    = {2005/01/01},
}

@InProceedings{ChenTSLR04,
  author    = {Chen, Liang-Chien and Teo, Tee-Ann and Shao, Yi-Chen and Lai, Yen-Chung and Rau, Jiann-Yeou},
  title     = {F{USION} {OF} {L}i{DAR} {DATA} {AND} {OPTICAL} {IMAGERY} {FOR} {BUILDING} {MODELING}},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.ISPRS.org/istanbul2004/comm4/papers/445.pdf},
  comment   = {OK more about detection that extraction - only flat-roofed models},
  groups    = {lidar},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{ChenDB04,
  Title                    = {Building footprint simplification techniques and their effects on radio propagation predictions},
  Author                   = {Chen, ZQ and Delis, A and Bertoni, HL},
  Year                     = {2004},
  Number                   = {1},
  Pages                    = {103-133},
  Volume                   = {47},

  Abstract                 = {Building footprint simplification is of critical importance to radio propagation predictions in wireless communication systems as the prediction time is closely related to the number of both buildings and vertices involved. Intuitively, if the complexity of footprints (i.e. the number of vertices in the footprints) is reduced, predictions can be generated more quickly. However, such reductions often affect the accuracy of results as the simplification error constrains the efficiency that can be achieved. To achieve a good vertex reduction rate for the footprints involved and at the same time preserve the shapes of footprints in terms of their areas, orientations and centroids, we propose a number of efficient single-pass methods to simplify building footprints. To satisfy constraints on edges, areas and centroids of simplified footprints, multi-pass methods are suggested. Hybrid methods take advantage of complementary properties exhibited by different footprint simplification methods. We assess the baseline effectiveness of our proposed techniques, and carry out an extensive comparative evaluation with real geographic information system data from different municipalities. Through experimentation, we find that hybrid methods deliver the best performance in both vertex reduction rate and simplification error. We examine the effects that these footprint simplification methods have on the ray-tracing based radio propagation prediction systems in terms of processing time and prediction accuracy. Our experiments show that footprint simplification methods indeed reduce prediction time up to three-fold, and maintain prediction accuracy with high confidence as well. We also investigate the relationship between footprint simplification error and the prediction accuracy. We find that the prediction accuracy is sensitive to the distortion (i.e. change of shape) of building footprints. This helps us to better understand the trade-off between precision of the building database and the accuracy of predictions generated by ray-tracing based radio propagation prediction systems.},
  Journaltitle             = {COMPUTER JOURNAL},
  Keywords                 = {quality},
  Owner                    = {izzy},
  creationdate                = {2008/05/28}
}

@Article{Cheng95,
  author       = {Yizong Cheng},
  title        = {Mean Shift, Mode Seeking, and Clustering},
  journaltitle = iepami,
  year         = {1995},
  volume       = {17},
  pages        = {790-799},
  comment      = {Have hardcopy on file. Revisits mean shift work of FukunagaH75},
  keywords     = {clustering},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Misc{Chikomo04,
  author       = {Freeman Chikomo},
  title        = {Automatic Extraction of Building Data by Synergistic Fusion of Remote Sensing Systems},
  year         = {2004},
  howpublished = {PhD Proposal},
  comment      = {In filing cabinet},
  owner        = {izzy},
  creationdate    = {2008/02/04},
}

@Article{ChiltonJP99,
  author       = {Chilton, T D and Jaafar, J and Priestnall},
  journaltitle = {International Archives of ISPRS},
  title        = {The use of Laser Scanner data for the extraction of building roof detail using standard elevation derived parameters},
  number       = {3W14},
  pages        = {137--143},
  url          = {http://www.isprs.org/commission3/lajolla/pdf/p137.pdf},
  volume       = {32},
  address      = {La Jolla, California},
  comment      = {in filing cabinet
Review:
''This paper has assessed the use of relatively low resolution LIDAR data for the extraction of roof detail from buildings, primarily for 3D city modelling. A 2D spatial database of vector building outlines was used to locate the roof extents. Two study areas were used to test the LIDAR data, an industrial area with large simple roofed buildings, and a residential area with smaller buildings and more complex roof structures. Through the use of LIDAR elevation, aspect and slope parameters, attempts were made to extract the main roof ridge of a building. Results suggest that it is possible to extract general roof detail using this data, especially for large buildings with simple roof structures. The aspect parameter performed best, extracting the largest majority of ridges from the buildings.'' As with JaafarPM99, this is an early example of morphological analysis of roof DSMs.},
  creationdate = {2008/02/25},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {1999},
}

@InProceedings{ChoJCL04,
  author    = {Cho, Woosug and Jwa, Yoon-Seok and Chang, Hwi-Jeong and Lee, Sung-Hun},
  title     = {Pseudo-{G}rid {B}ased {B}uilding {E}xtraction {U}sing {A}irborne {L}i{DAR} {D}ata},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.ISPRS.org/istanbul2004/comm3/papers/298.pdf},
  comment   = {Bin laser scanning points into a grid and perform detection and extraction on this},
  groups    = {lidar},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Misc{CohenOrLR99,
  author    = {Daniel Cohen-Or and David Levin and Offir Remez},
  title     = {Progressive compression of arbitrary triangular meshes},
  year      = {1999},
  url       = {http://www.math.tau.ac.il/~levin/vis99-dco.pdf},
  comment   = {In TRIM},
  owner     = {izzy},
  creationdate = {2008/02/04},
}

@Misc{ComaniciuMXX,
  author       = {Dorin Comaniciu and Peter Meer},
  title        = {Robust Analysis of Feature Spaces: Color Image Segmentation},
  howpublished = {unknown},
  comment      = {In TRIM. More stuff on mean shift},
  keywords     = {clustering},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Article{ComaniciuM02,
  author       = {Dorin Comaniciu and Peter Meer},
  title        = {Mean shift: A robust approach toward feature space analysis},
  journaltitle = iepami,
  year         = {2002},
  volume       = {24},
  number       = {5},
  pages        = {603--619},
  comment      = {In TRIM. A method by which clusters are identified within feature space. This paper looks like a valuable technique but it will require some working out - first I shall read the following references: Recent survey of such methods can be found in section 3.2 of JainD88. This method is based on FukunagaH75 and Cheng95. See also Silverman86 for a discussion of FukunagaH75.},
  haveiread    = {Y},
  keywords     = {clustering},
  creationdate    = {2005/01/01},
}

@Article{ComaniciuM99,
  author       = {Dorin Comaniciu and Peter Meer},
  title        = {Distribution Free Decomposition of Multivariate Data},
  journaltitle = {Pattern Analysis \& Applications},
  year         = {1999},
  volume       = {2},
  pages        = {22-30},
  comment      = {In TRIM. mean shift to identify clusters in data.},
  keywords     = {clustering},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Misc{ComaniciuRMXX,
  author       = {Dorin Comaniciu and Visvanathan Ramesh and Peter Meer},
  title        = {The Variable Bandwidth Mean Shift and Data-Driven Scale Selection},
  howpublished = {unknown},
  comment      = {In TRIM. More stuff on mean shift. ``Employing the sample point estimator, we define the Variable Bandwidth mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure. The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information''.},
  creationdate = {2007/06/22},
  keywords     = {clustering},
  owner        = {Izzy},
}

@Article{ComberFW04,
  author       = {Alexis Comber and Peter Fisher and Richard Wadsworth},
  title        = {Assessment of a semantic statistical approach to detecting land cover change using inconsistent data sets.},
  journaltitle = pers,
  year         = {2004},
  volume       = {70},
  number       = {8},
  pages        = {931-938},
  comment      = {Apparently an advance on the methodology of ComberFW03b by 'eliminating anomalous parcels from the analysis'. Difficult to understand alone - perhaps reading the earlier papers by these authors will help. Also, there is information here: http://www.geog.le.ac.uk/staff/ajc36/revigis_leicester.html},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@InProceedings{ComberFW03a,
  Title                    = {A semantic statistical approach for identifying change from ontologically diverse land cover data.},
  Author                   = {A J Comber and P F Fisher and R A Wadsworth},
  Booktitle                = {6th {AGILE} {C}onference on {G}eographic {I}nformation {S}cience},
  Year                     = {2003},

  Address                  = {Lyon, France},
  Editor                   = {Michael Gould and Robert Laurini and StÃƒÂ©phane Coulondre},
  Pages                    = {123-131},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@InProceedings{ComberFW03,
  author    = {A J Comber and P F Fisher and R A Wadsworth},
  title     = {Identifying Land Cover Change Using a Semantic Statistical Approach: First Results},
  booktitle = {Geocomputation},
  year      = {2003},
  url       = {http://www.geocomputation.org/2003/Papers/Comber_Paper.pdf},
  comment   = {Referenced by ComberFW04.},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{CroitoriD04,
  Title                    = {Right-angle rooftop polygon extraction in regularised urban areas: {C}utting the corners},
  Author                   = {Croitori, A and Doytsher, Y},
  Year                     = {2004},
  Number                   = {108},
  Pages                    = {311--341},
  Volume                   = {19},

  Journaltitle             = {The {P}hotogrammetric {R}ecord},
  Owner                    = {izzy},
  Text                     = {Croitori, A and Doytsher, Y, 2004. Right-angle rooftop polygon extraction in regularised urban areas: Cutting the corners. The Photogrammetric Record, 19(108):311-341},
  creationdate                = {2005/01/01},
  Wherefind                = {izzy}
}

@Misc{CyberCity06CCEdit,
  Title                    = {User {G}uide {CCE}dit},

  Author                   = {{CyberCity AG}},
  HowPublished             = {Provided by CyberCity AG},
  Month                    = {April},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02}
}

@Misc{CyberCity06CCModeler,
  Title                    = {User {G}uide {CCM}odeler},

  Author                   = {{CyberCity AG}},
  HowPublished             = {Provided by CyberCity AG},
  Month                    = {May},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02}
}

@Misc{CyberCity06CCVisualStar,
  Title                    = {User {G}uide {F}ull {D}igital {P}hotogrammetry {S}ystem ``{{V}isual{S}tar}''},

  Author                   = {{CyberCity AG}},
  HowPublished             = {Provided by CyberCity AG},
  Month                    = {April},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02}
}

@Misc{CyberCity05,
  Title                    = {Press {R}elease: {C}yber{C}ity {AG} awarded contract to generate a 3{D} city model of parts of the {C}ity of {M}unich from the {B}avarian {S}tate {M}apping {A}gency},

  Author                   = {{CyberCity AG}},
  HowPublished             = {www.cybercity.tv/pressemitteilungen/2005/{\linebreak}PressRelease\_Feb05\_low.pdf},
  Year                     = {2005},

  Keywords                 = {3D},
  Owner                    = {izzy},
  creationdate                = {2005/01/01},
  Url                      = {http://www.cybercity.tv/pressemitteilungen/2005/PressRelease_Feb05_low.pdf}
}

@InProceedings{DalPozGD06,
  author       = {Dal Poz, Aluir Porfirio and Gallis, de Araujo Rodrigo and da Silva, Jo\~{a}o Fernando Custodio},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Semiautomatic {R}oad {E}xtraction by {D}ynamic {P}rogramming {O}ptimisation in the {O}bject {S}pace: {S}ingle {I}mage {C}ase},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Wasn't presented.},
  creationdate = {2006/09/27},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Article{Davies98,
  author       = {Clare Davies},
  title        = {Analysing `work' in complex system tasks: an exploratory study with {GIS}},
  journaltitle = {Behaviour \& Information Technology},
  year         = {1998},
  volume       = {17},
  number       = {4},
  pages        = {218-230},
  comment      = {Have hardcopy in file. Separating human computer interaction into `enabling' and `work' actions for study.},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Article{DaviesM96,
  Title                    = {{GIS} users observed},
  Author                   = {C Davies and D Medyckyj-Scott},
  Year                     = {1996},
  Number                   = {4},
  Pages                    = {363-384},
  Volume                   = {10},

  Abstract                 = {As a follow-up to a previously reported postal questionnaire survey of GIS usability issues, a workplace observation study was conducted to clarify the earlier results. Visits were made to 21 user sites in the U.K. and involved structured interviews, checklists and video recordings of users at work with their GIS. Timing extracted from the videotapes were analysed alongside more sujective measures. Error messages and other feadback, and user docuemtntation, wee poorly rated by usersr as in the previous study. Comparison of objective and subjective measures showing a strong relationship between the amount of time wasted on errors and problems, and compatibility of the user's and system's conceptural models.},
  Comment                  = {In TRIM},
  Journaltitle             = {International Journal of Geographical Information Systems},
  Keywords                 = {RapidDC, usability},
  Owner                    = {Izzy},
  creationdate                = {2007/06/22}
}

@Unpublished{DCMOpPlan0203,
  author    = {DC\&M},
  title     = {D{C}\&{M} {O}perating {P}lan 2002-2003},
  year      = {2002},
  comment   = {Overview: I have only seen a small part of this document. This gives an Acceptible Quality Level and the following information for the National Sweep Programme, Topo QIF, Imagery and Integrated Transport Network: * Requirement * What we will deliver 2002-03 * Capture method * Measure/monitor. How could report be updated: It would be interesting to see the most recent operating plan. Relevance to/of current or proposed activities: Change detection research need to be focused of the business plan so such information is vital to current research. Reviewer: Izzy. Date: June 2005},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Unpublished{NatCurrencyAudit02,
  author       = {DCM},
  title        = {National {C}urrency {A}udit - {N}ovember 2002 sample},
  note         = {Internal Audit},
  comment      = {Overview: This document summarises the results of the 2001 (?) audit of data currency. It is largely a set of (not very well annotated) graphs and portrays only results of the survey, no recomendations. Comments: There seem to be two different targets. The first in the document is ``An average of 0.6 Cat A HUs per DMU over 6 months old remains unrevised''. It appears that more that this proportion of HUs were unrevised. However, the quoted Agency Performance Target for DC\&M is ``99.5\% of significant real-world feature are represented in the database within 6 months of their completion (which was met). In section 1.2 there are plots showing the total number of missing HUs grouped into age groups. The peak occurs within the first 3 months (it seems reasonable that there is a delay in completion of build and capture of data). After this there is then a drop in missing HUs in the 3-4, 4-5 and 5-6 months age groups. However, there is overall a slight increase in the number of missing HUs (it is hard to compare the older age groups because these have larger age ranges). This raises the question of whether older features are harder to detect and if so, why this is. How could report be updated: The above report is several years old, the most recent version would be of value. Relevance to/of current or proposed activities: These audits indicate if and where we are failing to keep our data current and as such are of interest to the current change detection research. Reviewer: Izzy. Date: June 2005},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {2002},
}

@Article{DellaRoccaFFP04,
  author    = {Della Rocca, M R and Fiani, M and Fortunato, A and Pistillo, P},
  title     = {Active Contour Model to Detect Linear Features in Satellite Images},
  journal   = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.isprs.org/proceedings/XXXV/congress/comm3/papers/311.pdf},
  comment   = {Use active contours (snakes) to find coastline in SAR image. Contour fits to progressively higher resolution. Not verified against other data. May be useful for references and algorithms.},
  keywords  = {DeepLEAP1},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{DevillersJ05,
  author       = {Devillers, Rodolphe and B\'{e}dard, Yvan and Jeansoulin, Robert},
  title        = {Multidimensional Management of Geospatial Data Quality Information for its Dynamic Use Within {GIS}},
  journaltitle = pers,
  year         = {2005},
  volume       = {71},
  number       = {2},
  pages        = {205-215},
  url          = {http://www.marinegis.com/rapport/Devillers_PERS.pdf},
  comment      = {Paper about meta data and data quality. Some useful tables and diagrams showing different data standards (e.g. ISO) and different quality types.},
  keywords     = {quality toread},
  owner        = {izzy},
  creationdate    = {2005/11/17},
}

@InProceedings{DevillersJ06,
  author       = {Devillers, R and Jeansoulin, R},
  title        = {Spatial Data Quality: Concepts},
  booktitle    = {Fundamentals of {S}patial {D}ata {Q}uality},
  year         = {2006},
  editor       = {R Devillers and R Jeansoulin},
  organization = {ISTE},
  pages        = {31-42},
  address      = {London},
  comment      = {Reference from Jenny H},
  owner        = {izzy},
  creationdate    = {2007/01/09},
}

@Article{DiasCV06,
  author       = {Jos\'{e} Miguel Sales Dias and Rafael Bastos and Jo\~{a}o Correia and Rodrigo Vicente},
  title        = {Semi-Automatic 3D Reconstruction of Urban Areas Using Epipolar Geometry and Template Matching},
  journaltitle = {Computer-Aided Civil and Infrastructure Engineering},
  year         = {2006},
  volume       = {21},
  number       = {7},
  pages        = {466-485},
  abstract     = {Abstract: In this work we describe a novel technique for semi-automatic three-dimensional (3D) reconstruction of urban areas, from airborne stereo-pair images whose output is VRML or DXF. The main challenge is to compute the relevant information, building's height and volume, roof's description, and texture, algorithmically, because it is very time consuming and thus expensive to produce it manually for large urban areas. The algorithm requires some initial calibration input and is able to compute the above-mentioned building characteristics from the stereo pair and the availability of the 2D CAD and the digital elevation model of the same area, with no knowledge of the camera pose or its intrinsic parameters. To achieve this, we have used epipolar geometry, homography computation, automatic feature extraction and we have solved the feature correspondence problem in the stereo pair, by using template matching.},
  comment      = {In TRIM},
  keywords     = {3D},
  owner        = {Izzy},
  creationdate    = {2007/11/16},
}

@InProceedings{DickTRC01,
  Title                    = {Combining single view recognition and multiple view stereo for architectural scenes.},
  Author                   = {A. R. Dick and P. H. S. Torr and S. J. Ruffle and R. Cipolla.},
  Booktitle                = {Proc. {I}nt. {C}onf. on {C}omputer {V}ision ({ICCV})},
  Year                     = {2001},
  Pages                    = {268-274},
  Volume                   = {I},

  Owner                    = {izzy},
  creationdate                = {2005/01/01},
  Url                      = {http://mi.eng.cam.ac.uk/reports/svr-ftp/dick_iccv01.pdf}
}

@InProceedings{Dickinson05,
  author    = {Sven Dickinson},
  title     = {Object categorisation and the need for many-to-many matching},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {The invted talk. Categoristaion started in 70s with matching to models that was very specific to obects. This has become more relaxed over the decades to the 1990 where matching is more about the image data and more of a recognition problem - e.g. faces or vehicles. Now we are starting to move back to a categorisation task. However, which different designs possible for the same type of object e.g. a cup, need to consider not 1-to-1 matching of object parts for matching groups of parts to groups of parts (e.g. limbs that have been articulated and therefore are not always in same formation) (and exclude spurious features e.g. design on the mug).There are three frameworks for many-to-many matching. Model-based, spectral abstraction and the geometric domain. Basically graph-based approach. Need to find important part of graphs. The assumption is the the adjacency graph is oversegmented. The eigen vavlues of this are found and these are used to determine the salient parts. Not too sure how this is acfhieved.Seems to be iterative. Staed that successful categorisation with require segementation, perceptual grouning and image abstraction.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{DidasWB05,
  author    = {Stephan Didas and Joachim Weickert and Bernhard Burgeth},
  title     = {Stability and local feature enhancement of higher order nonlinear diffusion filtering},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Using forward and backward diffusion both noise removal and edge enhancement can be achieved at the same time. however, with current methods 'staircasing' (stepping of gray valuse) tends of occur.This paper combines second order (edge enhancement) and fourth order (curvature enhancement) diffusion and achieves better results.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{DomkeA06,
  author       = {Justin Domke and Yiannis Aloimonos},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {A {P}robabilistic {N}otion of {C}amera {G}eometry: {C}alibrated vs. {U}ncalibrated},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  url          = {http://www.cs.umd.edu/~domke/egomotion},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Work on 2 frame 3D motion estimation. Why is it so difficult ot estimate geometry from images. The image input to vector output is difficult. Usually there is something in the middle such as correspondences from imeages to geometry. It is not easy to get correspondences from image. This paper suggests something instead of correspondences. Traditionally: a point on a line can be contrained to the line called 'normal flow'. The point could correspond to one or many other points. However, real points in real images do not fall onto these very cleanly. Therefore propose correspondence probability distributions. These may correspondence to geometry harder perhaps by a bit. They use tuned Gabor filters at many phases. These filters have scale and orientation. They filter corresponence with different filters and combine the distributions. Use addition instead of integration for simplicity I think ``if you thikn this should be an integral, you have my sympathies''. Need to optimise to find the most probable correspondence. Requires a nonlinear search with multiple restarts. Used the Nelder-Mead simplex search and found taht this had an equal accuracy but was quicker than more complex optimisation schemes. Correspondences - if you have lots get them because they are better. However, correspondence distributions are much easier to compute. Go to www.cs.umd.edu/~domke/egomotion for the matlab code. Only works for short baseline scenes.},
  creationdate = {2006/09/27},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Unpublished{Dowman99,
  author    = {I Dowman},
  title     = {A study on feature extraction and change detection from high resolution satellite images (part 3) final report by {U}niversity {C}ollege {L}ondon},
  year      = {1999},
  note      = {Internal OS report},
  comment   = {Overview: The report starts with a literature review that covers previous related report from DERA, BNSC/Ordnance Survey as well as published literature. The four topic areas covered are 1) using 2D and 3D information to reconstruct buildings in urban areas, 2) using shadows to determine height information, 3) obtaining Digital Terrain Models (DTMs) and Digital Surface Models (DSMs) using digital photogrammetric workstations and 4) using high resolution and multispectral imagery to detect 'shacks'. The second half of the report describes a feature extraction and change detection method devised by the project. The broad principle of this method is to 1) generate a DTM and a DSM from the stereo imagery, 2) use these to identify object by finding the difference between the DTM and the DSM, 3) classify multispectral data to identify 'buildings', 4) generate building hypotheses by combining the difference data with the classification and 5) identify changes by comparing the hypotheses to land-line data. Comments: The literature review seems rather confused and lacks content. For example, the section on using high resolution and multispectral imagery to detect 'shacks' discusses the sufficiency and otherwise of different types of data for feature extraction without actually identifying how the data would be used to extract features. This is very frustrating to read. However, the research that is reported on is clear. Aspects of the method are rather crude - for example the DTM and DSM generation each used a different strategy but there is no indication of whether these were derived from detailed research or were just chance discoveries. The classification is a very basic 3 classes + other maximum likelihood classification which would be expected achieve poor results for a 'building' class given the variability of this class (which would be similar to the 'other' class). How could report be updated: The method would be updated if more intelligence were put into the strategies chosen for DTM and DSM generation (see below). Also, the classification is very crude and would do better to include spatial and contextual information available in the image as well as a more flexible classifier. This classification was trained for the test area only - it is extremely likely that in a new region that classification would be very unsuccessful. A classification that is robust to changes in illumination, viewing and environmental condition is required. It goes without saying that in any future such research, OS MasterMap topography polygons should be used. Finally, automatic change detection would require that the comparison of building hypotheses and land line data were an automatic process - it appears to be based purely on visual inspection. Relevance to/of current or proposed activities: Research undertaken by Barbara Haebler, under the supervision of David Holland and Jon Horgan has looked into the value of different strategies available within SOCET set for Digital Elevation Model creation. Also, Research is proposed that will use multispectral information to determine the best strategy for Digital Elevation Model creation - this would be a huge improvement on the method in the current report. Change detection work in Research \& Innovation is currently undertaking a literature review that is looking at change detection by comparing 2D raster and vector data, change detection using 3D information and change detection using annotated image data. Reviewer: Izzy Date: March 2005},
  keywords  = {image matching},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{DrauschkeSF06,
  author       = {Martin Drauschke and Hanns-Florian Schuster and Wolfgang F\''{o}rstner},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Detectability of Buildings in Aerial Images over Scale Space},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Perform segmentation in 'scale space' i.e. image pyramids. This way, scale persistent features are identified. buildings are detected. The stability of shapes segmented over a range of scales is investigated. ``There is no single scale at which all roof parts are observable''.},
  creationdate = {2006/09/27},
  keywords     = {ImageLearn, Spatial Scale},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{DuruptT06,
  author       = {M\'{e}elanie Durupt and Franck Taillandier},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Automatic {B}uilding {R}econstruction from a {D}igital {E}levation {M}odel and {C}adastral {D}ata : {A}n {O}perational {A}pproach},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. This research is aimed at ``massive production'' of 3D models. It should operate in real time an be robust and automatic. Use cadastral limits (work is based on Taillandier05). The drawback to the previous work was that the operator has to define the focal area. There was a lack of rebustness in primitive detction and it was not in real time. Now they use only the cadastral data and DSM. Create all possible solutions as before. The best model is chosen with similarity score as before. The results look good. Acceptible means the model is correct (wihout dormer or chimey). Can model 1 building in <= 1 second. A second method extracts the plane directly. RANSAC is performed for every primitive direction and choose 2 3D point in the DEM to compute corresponding planes. Count the number of points near this plane. Choice of best model uses Bayes. This method is judged to be 89\% acceptible which is better than the 1st method. However the execution takes 1-5 seconds per building due to RANSAC. After the presentation there was a comment from Hans-Peter Baehr that there is a need to create standards for a product. Comment from the author that it is not very interesting for the operator to refine the building. Iz: clearly lots of need for user research into what the operator and the customer actually want!!},
  creationdate = {2006/09/27},
  keywords     = {3D, buildings},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{EbnerH05,
  author    = {Ebner, Marc and Herrmann, Christian},
  title     = {On determining the color of the illuminent using the dichromatic reflection model},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Aiming for colour constancy no matter what the colour of the illunination. So need to mimic this ability of human eye. Reference finlayson and shaefer 2001. Assume very narrow response functions for each colour channel - while this is not often the case it seems to work well (see finlayson paper?).Previous assumptons that illumination is constant over scene or black body radiator model do not seem to be advantageous.},
  keywords  = {ImageLearn},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{Ehlers05,
  author       = {Ehlers, Manfred},
  booktitle    = {I{SPRS} {H}annover {W}orkshop 2005 - {H}igh- {R}esolution {E}arth {I}maging for {G}eospatial {I}nformation},
  title        = {B{EYOND} {PANSHARPENING}: {ADVANCES} {IN} {DATA} {FUSION} {FOR} {VERY} {HIGH} {RESOLUTION} {REMOTE} {SENSING} {DATA}},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/Ehlers05.pdf},
  comment      = {Useful for information about pansharpening and more generally the specification and uses of digital aerial cameras such as the DMC, ADS...},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {2005},
}

@Article{EhlersGJ06,
  Title                    = {Automated techniques for environmental monitoring and change analyses for ultra high resolution remote sensing data},
  Author                   = {Ehlers, M and Geehler, M and Janowsky, R},
  Year                     = {2006},
  Number                   = {7},
  Pages                    = {835-844},
  Volume                   = {72},

  Abstract                 = {For monitoring environmental changes, new digital remote sensors have become available that allow monitoring and change detection analyses at resolutions and scales that were deemed impossible just a few years ago. The advent of airborne stereo scanners of ultra high spatial resolution offers the possibility of a complete digital remote sensing processing system. Current sensors include the High-resolution Stereo Camera (HRSC), the ADS-40, and the Digital Mapping Camera (DMC). For automated analysis, however, the new sensors require also new processing techniques. This paper presents results of change monitoring analyses for areas along the shorelines of the Elbe and Weser rivers in North Germany using integrated HRSC and GIS datasets. An automated procedure for highly accurate mapping was developed which is based on a hierarchical stepwise approach integrating GIS methods and digital surface information in this process. This approach allows the production of GIS maps that are more detailed and accurate than those that were previously produced by conventional means. Within the GIS environment, the multitemporal analysis also allows the exact quantification and location of changes of the protected biotope types.},
  Comment                  = {Get a copy?},
  Journaltitle             = {Photogrammetric Engineering and Remote Sensing},
  Keywords                 = {DSM accuracy},
  Owner                    = {izzy},
  creationdate                = {2008/03/06}
}

@InProceedings{EladTA01,
  author       = {Elad, M and Tal, A and Ar, S},
  booktitle    = {The 6th Eurographics Workshop in Multimedia},
  title        = {Content based retrieval of {VRML} objects - an iterative and interactive approach.},
  url          = {file://///os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers\EladTA01.pdf},
  address      = {Manchester, U.K},
  comment      = {''We will show that the moments of the three-dimensional objects' surfaces, up to some orefer, are a relevant choice for features as only a handful of the are needed to represent the essence of the data. We will also show that the weighted Euclidean distance leads to an efficient and effective adaptation scheme, based on the user's feadback...Using ideas based on Support Vector Machine learning algorithms...''. The first moments represent the centre of mass of the object, the second moments represent the scale and rotation of the object. Approximate the moments by $m_{pqr} = 1/n \sum_{i=1}^{N} x_i^p y_i^q z_i^r$ where the sum is over a number of uniformly-spaced points on the surface of the object.},
  creationdate = {2008/03/10},
  owner        = {izzy},
  year         = {2001},
}

@InProceedings{EngelsSN06,
  author       = {Chris Engels and Henrik Stew\'{e}nius and David Nist\'{e}r},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Bundle {A}djustment {R}ules},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  url          = {http://www.vis.uhy.edu/~dnister.},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. As in bundle adjustment rules OK. State that bundle adjustment is a real-time method and not an offline batch method. Implement carefully using slideing windows in the case of camera tracking. Bundle adjustment won't save you from a error that you already made, but could save you from an error in the future. Pseudo code provided in paper. Voting: ``its like electing a president and having the president go out and kill al those who didn't vote for him''. An alternative to this is image residuals robustified. Works on a 5 point algothm of nister pami 04. See www.vis.uhy.edu/~dnister for something that makes the 5 point algorithm very easy to use. Demonstrated using a rotating cylinder with a scene from star wars on it. They would like to bundle adjust and bring it into the geographical frame so that reconstructed views can be put into Google Earth. Scalable recognition with a vocabulary tree (CVPR paper). Demonstrated the whole thing with a mini camera and matching CD covers to a library - playing album once matching occurred. There are 10 camera positions in adjustment all the time.},
  creationdate = {2006/09/27},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{ErnstHTRBZ05,
  author       = {Ernst, I and Hetscher, M and Thiessenhusen, K and Ruh\'{e} and B\''{o}rner, A and Zuev, S},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  title        = {New approaches for real time traffic data acquisition with airborne systems},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  organization = {Joint workshop of ISPRS and DAGM},
  volume       = {XXXVI},
  comment      = {(Given by Ruhe).Find cars in infrared and CCD image scenes to calculate the velocity. From this calculation the traffic parameters density and velocity. Use airship as platform.},
  creationdate = {2005/09/05},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{Foerstner99,
  author       = {Wolfgang F\''{o}rstner},
  booktitle    = {Proceedings of Photogrammetric Week '99},
  title        = {3{D}-city models: Automatic and semiautomatic acquisition method},
  editor       = {D Fritsch and R Spiller},
  publisher    = {Wichmann Verlag},
  url          = {http://www.ifp.uni-stuttgart.de/publications/phowo99/foerstner.pdf},
  address      = {Heidelberg},
  comment      = {A review of acquisition methods as they were in 1999. Divides models into ``parametric models. Parametric models describe the form by a usually small but fixed set of variable parameters.'' and generic models. Generic models break down to ``prismatic models assume the building to be specified by a polygonal ground plan, vertical walls and a p lanar, usually horizontal roof'' and ``polyhedral models assume the building to be bounded by planar surfaces.''. A sub-class of generic models is also given as ``CSG-models. M odels from constructive solid geometry allow the composition of complex models from simp le parts. `` Describes two approaches to building model acquisition. Oxford's approach finds edges in multiple images and Bonn's approach seems to do the same. ``3D-city models are becoming an importantn tool for town planning''.},
  creationdate = {2007/06/22},
  keywords     = {3D buildings},
  owner        = {Izzy},
  year         = {1999},
}

@InProceedings{Foerstner96,
  author       = {F\''{o}rstner, W},
  booktitle    = {Workshop on {P}erformance {C}haracteristics of {V}ision {A}lgorithms},
  title        = {10 pros and cons against performance characterization of vision algorithms},
  url          = {http://www.ipb.uni-bonn.de/fileadmin/publication/pdf/Forstner199610.pdf},
  address      = {Cambridge},
  comment      = {Not read. Mentioned in BoudetPJMP06 with reference to internal evaluation and error propagation. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.4351. mention in Mayer2008 and possibly a good reference for traffic light system of self-diagnosis.},
  creationdate = {2006/09/08},
  keywords     = {quality, computer vision},
  owner        = {izzy},
  year         = {1996},
}

@InProceedings{Foerstner94,
  author       = {F\''{o}rstner, W},
  booktitle    = {Performance versus {M}ethodology in {C}omputer {V}ision, {NSF}/{ARPA} {W}orkshop},
  title        = {Diagnotics and performance evaluation in computer vision.},
  organization = {IEEE Computer Society},
  address      = {Seattle},
  comment      = {Not read. Mentioned in BoudetPJMP06 with reference to internal evaluation and error propagation},
  creationdate = {2006/09/08},
  keywords     = {quality},
  owner        = {izzy},
  year         = {1994},
}

@Article{Foerstner82,
  author       = {Wolfgang F\''{o}rstner},
  journaltitle = {International {A}rchive of {P}hotogrammetry and {R}emote {S}ensing},
  title        = {On the geometric precision of digital correlation},
  number       = {3},
  pages        = {176-189},
  volume       = {XXIV},
  comment      = {dont have this but have a note to read it},
  creationdate = {2005/10/14},
  keywords     = {toread},
  owner        = {izzy},
  year         = {1982},
}

@Article{rfabbri2002,
  author       = {Fabbri, R. and Estrozi, L.F. and F. Costa, L.},
  title        = {On Voronoi Diagrams and Medial Axes},
  journaltitle = {Journal of Mathematical Imaging and Vision},
  year         = {2002},
  volume       = {17},
  number       = {1},
  month        = {July},
  pages        = {27-40},
  url          = {http://citeseer.ist.psu.edu/fabbri02voronoi.html},
  comment      = {What happen moocow?},
  creationdate    = {2005/01/01},
}

@Misc{FairchildJ,
  author    = {Fairchild, Mark D and Johnson, Garrett M},
  title     = {Image {A}ppearance {M}odeling},
  url       = {citeseer.ist.psu.edu/603994.html},
  comment   = {In TRIM. This paper presents the iCAM model for colour or image appearance modelling. This is useful for image difference and image quality metrics, rendering of image data on different media etc. May be applicable to research into viewing our imagery on DPWs etc...},
  creationdate = {2005/01/01},
}

@Misc{Faulk02,
  author       = {Matthew Faulk},
  title        = {Magrathea -- 3{D} {D}ata {M}odels -- {M}an-made structures},
  howpublished = {Internal R\&I document},
  note         = {\url{file://///os2k17/r\&i_data6/Magrathea2/Matt%20Faulk/Projects/Magrathea/3D%20Capture%20Spec/3D%20Man%20Made%20Structures%20Report%20-%20Version%202.doc }},
  creationdate = {2005/10/03},
  keywords     = {3D},
  month        = {December},
  owner        = {izzy},
  year         = {2002},
}

@Misc{Felsberg05,
  author       = {Michael Felsberg},
  title        = {The monogenic framework: a retrospective},
  year         = {2005},
  howpublished = {Presentation to DAGM 2005 following receipt of Olypus Award},
  note         = {see also log book},
  comment      = {Phase based reconstruction - the effect of shadow is removed. Edge, line, corner and disparity detection from phase. Look up the actual paper (previous DAGM or some other event?) for more information.},
  owner        = {izzy},
  creationdate    = {2005/09/03},
}

@InProceedings{Felsburg05b,
  author       = {Michael Felsburg},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Wiener {C}hannel {S}moothing: {R}obust {W}iener {F}iltering of {I}mages},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {The Wiener filter averages away noise, removes salt and pepper noise while preserving image discontinuities. This method improves the basic filter by taking the image features as channels. The channels are smoothed by decoding tham to produce a smoothed image map. The orienattion inforamtion is extracted and then encoded in the channels. Kernal density / probability density function estimation is achieved by convolving with a kernal function. For more information look up F\''{o}rstner 1998 Proceeding of the internation Summer School. The different in the results between the channel method and the linear method only occurs at the edges of features where sharpness is preserved. This method removes, not averages, noise.Interesting stuff.},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@Misc{FerreiraXX,
  Title                    = {Resources for AFJ's PhD},

  Author                   = {Alfredo Ferreira},
  HowPublished             = {Internet - last viewed 2008-03-10},

  Keywords                 = {morphology},
  Owner                    = {izzy},
  creationdate                = {2008/03/10},
  Url                      = {http://immi.inesc-id.pt/~afj/resources/retrieval3d.xml}
}

@Misc{FisherXX,
  author       = {Peter Fisher},
  title        = {Quality Metadata to Address Semantic Uncertainty and Fitness for Use},
  howpublished = {in a book},
  comment      = {Have hardcopy in file. Short piece on metadata about data quality. Suggests a refereed web site where interested parties can post information about data as a solution to problem of ownership of and responsibility for metadata.},
  keywords     = {quality},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@InProceedings{FlamancM05,
  author    = {Flamanc, D and Maillet, G},
  title     = {Evaluation of 3{D} city model production from pleiades-{HR} satellite images and 2{D} ground plans.},
  booktitle = {3rd {I}nternational {S}ymposium {R}emote {S}ensing and {D}ata {F}usion over {U}rban {A}reas},
  year      = {2005},
  address   = {Tempe, USA},
  comment   = {Unread, cited in Boudet as way of collecting 3D data},
  keywords  = {3D},
  owner     = {izzy},
  creationdate = {2006/09/08},
}

@Article{FoodySAW04,
  Title                    = {Thematic labelling from hyperspectral remotely sensed imagery: trade-offs in image properties.},
  Author                   = {Foody, G M and Sargent, I M and Atkinson, P M and Williams, J},
  Year                     = {2004},
  Number                   = {12},
  Pages                    = {2337-2363},
  Volume                   = {25},

  Journaltitle             = {International Journal of Remote Sensing},
  Owner                    = {Izzy},
  creationdate                = {2009.02.11}
}

@InProceedings{FoodySAW01,
  Title                    = {Land cover classification from hyperspectral data: an investigation of spectral, spatial and noise issues.},
  Author                   = {Foody, G M and Sargent, I M J and Atkinson, P M A and Williams, J L},
  Booktitle                = {Geoscience and Remote Sensing Symposium, IGARSS '01},
  Year                     = {2001},

  Address                  = {Sydney, Australia},
  Organization             = {IEEE 2001 International},
  Pages                    = {2728-2730},

  Owner                    = {Izzy},
  creationdate                = {2009.02.11}
}

@Article{Forberg07,
  author       = {Forberg, Andrea},
  title        = {Generalization of 3D building data based on a scale-space approach},
  journaltitle = {Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year         = {2007},
  volume       = {62},
  number       = {2},
  pages        = {104-111},
  url          = {http://www.isprs.org/proceedings/XXXV/congress/comm4/papers/341.pdf},
  abstract     = {In image analysis, scale-space theory is used, e.g., for object recognition. A scale-space is obtained by deriving coarser representations at different scales from an image. With it, the behaviour of image features over scales can be analysed. One example of a scale-space is the reaction-diffusion-space, a combination of linear scale-space and mathematical morphology. As scale-spaces have an inherent abstraction capability, they are used here for the development of an automatic generalization procedure for three-dimensional (3D) building models. It can be used to generate level of detail (LOD) representations of 3D city models. Practically, it works by moving parallel facets towards each other until a 3D feature under a certain extent is eliminated or a gap is closed. As not all building structures consist of perpendicular facets, means for a squaring of non-orthogonal structures are given. Results for generalization and squaring are shown and remaining problems are discussed. The conference version of this paper is Forberg [Forberg, A., 2004. Generalization of 3D Building Data Based on a Scale-Space Approach. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences 35 (Part 134) http://www.isprs.org/istanbul2004/comm4/papers/341.pdf},
  booktitle    = {Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  comment      = {A paper on generalising 3D buildings to produce different levels of detail. Presented at ISPRS congress 2004 in Istanbul},
  keywords     = {3D, Scale},
  owner        = {Izzy},
  creationdate    = {2008/01/09},
}

@Article{FraserBG02,
  author       = {C S Fraser and E Baltsavias and A Gr\''{u}n},
  journaltitle = ijprs,
  title        = {Processing of {IKONOS} imagery for submeter 3{D} positioning and building extraction},
  pages        = {177-194},
  volume       = {1209},
  comment      = {Mostly focuses on the accuracy of point positioning with Ikonos imagery, a little but on 3D building reconstruction at the end. At the time of this study Ikonos was available in a range of flavours: Geo, Reference, Pro, Precision and Precision Plus each with supposedly increasingly accuracy (and hence price). Only the Geo product was not orthorectified using a DTM, it also did not some with any orientation information. Platform and camera characteristics were not available with any product, but for some stereo products rational coefficients (rational polynomials or RPCs) are supplied. GPCs were obtained within the test site. Several ways of determining the image orientation are discussed (see Downman and Dolloff 2000) and the Direct Linear Transformation (DLT) and affine projection are used in this paper. Found that, despite having no sensor information with the Geo data, it is possible to capture points of reasonably high accuracy - around 0.5m in Xy and less that 1m in Z. The biggest variation seems to be due to the quality of individual images, for example when the view and sun azimuth are very different there can be a lot of shadow in non-occluded areas.},
  creationdate = {2007/11/19},
  file         = {FraserBG02.pdf:\\\\Os2k17\\Research Labs\\Lammergeier\\Common\\Library\\ExternalPapers\\FraserBG02.pdf:PDF},
  keywords     = {3D, quality},
  optnote      = {check details of this reference},
  owner        = {Izzy},
  year         = {2002},
}

@InProceedings{FraserBG01,
  author       = {C S Fraser and E Baltsavias and A Gr\''{u}n},
  booktitle    = {Automatic {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages ({III})},
  title        = {3{D} building reconstruction from high-resolution {I}konos stereo imagery},
  comment      = {''it has been necessary to examine essentially three salient aspects when evaluating the use of 1m stereo imagery for 3D city modelling. These comprise the geometric accuracy of geopositioning ? from stereo and multi-image coverage; the radiometric quality, with an emphasis on characteristics to support automatic feature extraction (e.g. noise content, edge quality and contrast); and attributes of the imagery for the special application of building extraction and visual reconstruction.''},
  creationdate = {2005/11/17},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2001},
}

@InProceedings{FreemanI08,
  Title                    = {Quantifying and visualising the uncertainty in 3D building model walls using terrestrial lidar data.},
  Author                   = {Freeman, M and Sargent, I},
  Booktitle                = {Proceedings of the Remote Sensing and Photogrammetry Society Conference 2008: `Measuring change in the Earth system'},
  Year                     = {2008},

  Address                  = {University of Exeter, UK},
  Month                    = {15-17 September},

  Keywords                 = {3D, quality, 3DCharsPaper},
  Owner                    = {Izzy},
  creationdate                = {2009.02.11},
  Url                      = {file://os2k17\Research\Resources\ConferenceProceedings\RSPSoc08\RSPSocCD\docs\132_FreemanSargent_RSPSoc2008.pdf}
}

@InProceedings{FrintopBR05,
  author    = {Simone Frintop and Gerriet Backer and Erich Rome},
  title     = {Goal-directed search with a top-down modulated computational attention system},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Finding salient points. Claims the difference here is that it uses a top-down and bottom up approch. The bottom up part uses basic image characteristics such as colour but could include other according to author in poster session.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{FuS04,
  author    = {Fu, Chiung-Shiuan and Shan, Jie},
  title     = {3-{D} {B}uilding {R}econstruction {F}rom {U}nstructured {D}istinct {P}oints},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  pages     = {553},
  url       = {http://www.ISPRS.org/istanbul2004/comm3/papers/330.pdf},
  comment   = {Points are manually defined for all corners of roof and for building foot print. Algorithm then 'rectangulates' these points and builds roof structure up from several roof shape primitives. Resulting model is in CSG form.},
  keywords  = {3D},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@TechReport{FuaH86,
  author       = {Fua, P and Hansen, A J},
  institution  = {Artificial intelligence centre, SRI International},
  title        = {Resegmentation using generic shape: locating general cultural objects.},
  comment      = {From ShufeltM93: ``described a system that used generic geometric mdoels and noise-tolerant geometry parsing rules to allow semantic information to interact with low-level geometric information, producing segmentations of objects in the aerial image. The system used region-based segmentations as input and applied the geometry rules to connect simple image tokens such as edges into more complex rectilinear structures.''},
  creationdate = {2005/09/09},
  month        = {May},
  owner        = {izzy},
  wherefind    = {don't have},
  year         = {1986},
}

@InProceedings{Fuchs96,
  Title                    = {O{EEPE} survey on 3{D} city models},
  Author                   = {C Fuchs},
  Booktitle                = {Report of the {I}nstitute of {P}hotogrammetry},
  Year                     = {1996},

  Address                  = {University of Bonn},

  Keywords                 = {3D},
  Optmonth                 = {October},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@Article{FukunagaH75,
  author       = {K Fukunaga and Hostetler},
  title        = {The estimation of the gradient of a density function, with applications in pattern recognition},
  journaltitle = ieit,
  year         = {1975},
  volume       = {21},
  pages        = {32--40},
  comment      = {Original article on mean shift (see ComaniciuM02).},
  haveiread    = {N},
  keywords     = {clustering},
  creationdate    = {2005/01/01},
}

@Misc{Fyall05,
  author       = {Richie Fyall},
  title        = {E{XTERNAL} {LITERATURE} {RESEARCH}: {THE} {FUTURE} {USER} {OF} 3{D} {GEOGRAPHIC} {INFORMATION}},
  howpublished = {Internal R\&I document},
  note         = {\url{file://///os2k05/Research/Projects/GeoUsers/Goal%202+3+Orch%20work%20(Squish,%20inc%20BOD)/BOD_Users/External%203D%20knowledge/Research%20report.doc}},
  creationdate = {2005/10/03},
  month        = {April},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{GuelchML99,
  author       = {E G\''{u}lch and H M\''{u}ller and T L\''{a}be},
  booktitle    = {Proceedings of {ISPRS} {C}onference {A}utomatic {E}xtraction {O}f {GIS} {O}bjects {F}rom {D}igital {I}magery},
  title        = {Integration of {A}utomatic {P}rocesses {I}nto {S}emi-{A}utomatic {B}uilding {E}xtraction},
  comment      = {From LeeHN00: ``the system handles complex building structures by using constructive solid geometry. This system uses an image correlation method to fit a primitive to the image; however, this method is computationally expensive when modeling urban sites, where many building have complex shapes.''},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {1999},
}

@Article{GalC06,
  Title                    = {Salient geometric features for partial shape matching and similarity},
  Author                   = {Ran Gal and Daniel Cohen-Or},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {130--150},
  Volume                   = {25},

  Abstract                 = {This article introduces a method for partial matching of surfaces represented by triangular meshes. Our method matches surface regions that are numerically and topologically dissimilar, but approximately similar regions. We introduce novel local surface descriptors which efficiently represent the geometry of local regions of the surface. The descriptors are defined independently of the underlying triangulation, and form a compatible representation that allows matching of surfaces with different triangulations. To cope with the combinatorial complexity of partial matching of large meshes, we introduce the abstraction of salient geometric features and present a method to construct them. A salient geometric feature is a compound high-level feature of nontrivial local shapes. We show that a relatively small number of such salient geometric features characterizes the surface well for various similarity applications. Matching salient geometric features is based on indexing rotation-invariant features and a voting scheme accelerated by geometric hashing. We demonstrate the effectiveness of our method with a number of applications, such as computing self-similarity, alignments, and subparts similarity.},
  Address                  = {New York, NY, USA},
  Comment                  = {get a copy?},
  Doi                      = {http://doi.acm.org/10.1145/1122501.1122507},
  ISSN                     = {0730-0301},
  Journaltitle             = {ACM Trans. Graph.},
  Keywords                 = {morphology},
  Owner                    = {izzy},
  Publisher                = {ACM},
  creationdate                = {2008/02/21}
}

@Unpublished{GambaDLT05,
  author    = {P Gamba and F {Dell'Acqua} and G Lisini and G Trianni},
  title     = {Rapid delineation of objects in a large high resolution scene},
  year      = {2005},
  comment   = {Progress report. In filing cabinet.},
  owner     = {izzy},
  creationdate = {2008/02/04},
}

@Article{GambaH00,
  author       = {Gamba, P and Houshmand, B},
  journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
  title        = {Digital surface models and building extraction: A comparison of IFSAR and LIDAR data},
  number       = {4},
  pages        = {1959-1968},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/GambaH00.pdf},
  volume       = {38},
  abstract     = {In this paper, the task of extracting significant built structure in digital surface models (DSM) is analyzed. The original data are obtained by means of interferometric SAR or LIDAR techniques and have different resolution and noise characteristics. This work aims to make a comparison of what (and how precisely) it is possible to detect and extract starting from these models, taking into account their differences but applying to them the same planar approximation approach. To this aim, data over Los Angeles and Denver is considered and evaluated, The results show that LIDAR data provide a better shape characterization of each building, and not simply because of their higher resolution. Indeed, less accurate results obtained starting from radar data are mainly due to shadowing/layover effects, which can be only partially corrected by means of the segmentation procedures. However, better results than those already presented in the literature could be achieved by using the IFSAR data correlation map.},
  comment      = {Ordered from library 2008/02/13
Review:
Do a sort of plane fitting/edge detection on lidar and ifsar data to 'characterise' buildings - really this is finding buildings. Not terribly interesting - finds that lidar data are better for this.},
  creationdate = {2008/02/13},
  keywords     = {lidar, 3D},
  owner        = {izzy},
  year         = {2000},
}

@Article{Gaetal00,
  Title                    = {Detection and {E}xtraction of {B}uildings from {I}nterferometric {SAR} data},
  Author                   = {P Gamba and B Houshmand and M Saccani},
  Year                     = {2000},
  Number                   = {1},
  Pages                    = {611-618},
  Volume                   = {38},

  Journaltitle             = {I{EEE} {T}ransactions on {G}eoscience and {R}emote {S}ensing},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@Misc{Gardiner08,
  Title                    = {Liverpool Building Height Trial},

  Author                   = {Andy Gardiner},
  HowPublished             = {Internal Ordnance Survey document},
  Month                    = {March},
  Note                     = {TRIM Record Number: DCD/08/5878},
  Year                     = {2008},

  Owner                    = {Izzy},
  creationdate                = {2009.04.08}
}

@InProceedings{GerhardingerEP05,
  author       = {A Gerhardinger and D Ehrlich and M Pesaresi},
  title        = {Vehicles detection from very high resolution satellite imagery},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Vehicle detection and enumeration. Baghdad pre (2000) and during (2003) war ikonos and ikonos and QB data. Geometric recitification is relative to other images. Radiometric rectification is applied to images affected by smoke plumes. Inductive learning technique - model of target created and an iterative process improves the model. They are able to stretch data to view through smoke except in the thickest areas. Mean and standard deviation caculated within a local window and this is used for enhancement. Had to digitise their own road polygons because the available road centrelines were not good enough. Use Feature Analyst for inductive learning of models.},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{Gerke05,
  author       = {Gerke, Markus},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  title        = {Automatic quality assessment of {GIS} road data using aerial imagery - comparison between bayesian and evidential reasoning},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {file://///randi01/r%20and%20i/ConferenceProceedings/Lammergeier/CMRT05/Papers/CMRT05_Gerke.pdf},
  volume       = {XXXVI},
  comment      = {Uses rows of trees to help verify road detection in the absence of verification data.},
  creationdate = {2005/09/05},
  keywords     = {quality},
  owner        = {izzy},
  year         = {2005},
}

@Unpublished{Gerke,
  Title                    = {Scene {A}nalysis in {U}rban {E}nvironments {U}sing a {K}nowledge-{B}ased {I}mage {I}nterpretation {S}ystem},
  Author                   = {Markus Gerke},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  creationdate                = {2005/01/01}
}

@InProceedings{GoldT05,
  author       = {Christopher Gold and Rebecca O C Tse},
  title        = {Quad-edges and {E}uler operators for automatic building extrusion using {{L}i{DAR}} data},
  booktitle    = {Seminar {G}eo-information and {C}omputational {G}eometry},
  year         = {2005},
  organization = {Utrecht University},
  month        = {November},
  address      = {The Netherlands},
  comment      = {Cited in proposal for continuation of Rebecca Tse's work},
  groups       = {lidar},
  owner        = {izzy},
  creationdate    = {2006/12/11},
}

@PhdThesis{Goodhall07,
  author       = {Simon Goodall},
  title        = {3-D Content-Based Retrieval and Classification with Applications to Museum Data},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/Goodall07.pdf},
  comment      = {See also GoodallLM05. Looks like an excellent reference for all things 3D retrieval. 22 algorithms described and compared.},
  creationdate = {2008/03/03},
  keywords     = {morphology},
  owner        = {izzy},
  school       = {Faculty of Engineering, Science and Mathematics, School of Electronics and Computer Science, University of Southampton},
  year         = {2007},
}

@InProceedings{GoodallLM05,
  author    = {Simon Goodall and Paul Lewis and Kirk Martinez},
  title     = {Towards Automatic Classification of 3-{D} Museum Artifacts using Ontological Concepts},
  booktitle = {Proceedings of The 4th International Conference on Image and Video Retrieval ({CIVR}2005)},
  year      = {2005},
  editor    = {Leow, W K and Lew, M S and Chua, T S and Chaisorn, M Y and Bakker, L},
  pages     = {435-444},
  address   = {National University of Singapore, Sinagpore},
  comment   = {In share_library. Practical application of shape descriptors - SCULPTEUR, a system for classifying museum artifact and determining how they may be distinguished. Contains short review of other shape descriptors. System is designed to be used by experts and non-experts. Features/descriptors to use for classifying 3D objects. Uses a load of descriptors from other's research to identify objects in museum's catalogue (e.g. from Princetown's work: http://www.cs.princeton.edu/gfx/proj/shape/). Also use different distance metrics to determine how close the two objects are in descriptor space. Finally have architecture such that are specialised to disctinguish say between different broad classes or within classes. Reduced the number of classifiers for non-expert users and also introduced automatic parameter selection for these users. Could be useful for simplifying matching between 3D models? See also Goodall07 for more detail.},
  file      = {civr.pdf:http\://eprints.ecs.soton.ac.uk/10366/01/civr.pdf:PDF},
  keywords  = {3D, quality, morphology},
  owner     = {izzy},
  creationdate = {2006/03/07},
}

@InBook{Gruen96,
  author       = {Armin Gr\''{u}n},
  title        = {Close range photogrammetry and machine vision},
  chapter      = {8},
  comment      = {I have a note to read this...not sure why...},
  creationdate = {2005/10/14},
  keywords     = {toread},
  owner        = {izzy},
  year         = {1996},
}

@Article{GruenA05,
  author       = {Armin Gr\''{u}n and Devrim Akca},
  journaltitle = {Photogrammetry and {R}emote {S}ensing},
  title        = {Least squares 3{D} surface and curve matching},
  pages        = {151-174},
  volume       = {59},
  comment      = {I have a hard copy in desk. Co-registration of point clouds. Use a generalised Gauss-Markoff model.},
  creationdate = {2006/09/04},
  keywords     = {quality, DEM, image matching},
  owner        = {izzy},
  year         = {2005},
}

@InBook{GruenD97,
  author       = {Gr\''{u}n, A and Dan, H},
  booktitle    = {Automatic {E}xtraction of {M}an {M}ade {O}bjects from {A}erial and {S}pace {I}mages ({II})},
  title        = {Automated {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages ({II})},
  chapter      = {TOBAGO - a topology builder for the automated generation of building models},
  editor       = {Gr\''{u}n, A and Baltsavias, E and Henricsson, O},
  pages        = {149-160},
  publisher    = {Birkhauser Verlag, Berlin},
  comment      = {From LeeHN00: ``an automatic system constructs topological relations among 3D roof points collected by a user for each roof; this system can work with several types of complex roofs.'' Buildings are constructed by defining roofs and projecting the edges of these down to DTM. Thus eaves are not included in this case. Operator captures points in roofs and the TOBAGO system then classifies these points to determine whether they are 'ridge points' (where ridges meet not at the eaves) or otherwise. This is then used to classify the roof. Once the roof has been classified, the geometric parser completes the roof structure. This parser uses constraints such as parallelism and orthogonality of straight lines. Either the classifier or the geometric parser can flag roofs that don't seem correct and these are passed back to the operator to handle. Focus is on models for CAD which can't handle non-convex hulls for instance and so an extra stage that sorts the data for CAD is employed. Also assert that the model is improved by adding texture and mention that this is captured from video imagery. Testing gave good results. Geometric tests didnt seem to exist, main criteria were how many roof units were handled by TOBAGO (rather than being passed back to the operator). Main factor in this seemed to be experience of operator and how much they understand the automatic structuring functioning. The average operator took about 0.5 minutes / unit including interpreting the scene, measurement and corrections. The roof structuring took around 5 mseconds which meant the operator could check this and update measured points where necessary.},
  creationdate = {2005/10/14},
  keywords     = {3D, quality},
  owner        = {izzy},
  wherefind    = {In TRIM},
  year         = {1997},
}

@Article{GrenzdorfferGF08,
  author       = {G\''{o}rres J. Grenzd\''{o}rffer and Markus Guretzki and Ilan Friedlander},
  journaltitle = {Photogrammetric Record},
  title        = {Photogrammetric image acquisition and image analysis of oblique imagery},
  number       = {124},
  pages        = {372-386},
  volume       = {23},
  comment      = {Write about flying oblique imagery and the special requirements for orientating it. Also talk about MultiVision software for viewing images. Possibly useful if ever need to understand the orientation equations for oblique imagery. Doesn't go into detail on how to use imagery, but suggests some uses (texturing 3D model).},
  creationdate = {2009.01.16},
  keywords     = {oblique imagery},
  owner        = {Izzy},
  year         = {2008},
}

@InProceedings{GrossT06,
  author       = {Hermann Gross and Ulrich Thoennessen},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Extraction of {L}ines from {L}aser {P}oint {C}louds},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Extract lines from point clouds (rather than grids). The results look good. The next step is to reconstruct planes.},
  creationdate = {2006/09/27},
  keywords     = {laser scanning, 3D, buildings},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{GrossTV05,
  author       = {Gross, H and Thoennessen, U and van Hansen, W},
  title        = {3{D}-modeling of urban structures},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {They create ground plans from lidar data by adding and subtracting rectangles. Create histogram of orientations but this doesn't work well with complex buildings. Therefore use an orientation sphere. Find planes with the same orientation. From this intersection lines leads to 3D buildings. Put textures on from ground based and aerial photos.},
  groups       = {lidar},
  keywords     = {3D},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Article{GruenW98,
  Title                    = {CC-Modeler: a topology generator for 3-D city models},
  Author                   = {Gruen, A and Wang, XH},
  Year                     = {1998},
  Number                   = {5},
  Pages                    = {286-295},
  Volume                   = {53},

  Abstract                 = {In this paper, we introduce a semi-automated topology generator for 3-D objects, CC-Modeler (CyberCity Modeler). Given the data as point clouds measured on Analytical plotters or Digital Stations, we present a new method for fitting planar structures to the measured sets of point clouds. While this topology generator has been originally designed to model buildings, it can also be used for other objects, which may be approximated by polyhedron surfaces. We have used it so far for roads, rivers, parking lots, ships, etc. The CC-Modeler is a generic topology generator. The problem of fitting planar faces to point clouds is treated as a Consistent Labelling problem, which is solved by probabilistic relaxation. Once the faces are defined and the related points are determined, we apply a simultaneous least-squares adjustment in order to fit the faces jointly to the given measurements in an optimal way. We first present the processing flow of the CC-Modeler. Then, the algorithm of structuring the 3-D point data is outlined. Finally, we show the results of several data sets that have been produced with the CC-Modeler. (C) 1998 Elsevier Science B.V. All rights reserved.},
  Journaltitle             = {ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING},
  Keywords                 = {3D},
  Owner                    = {izzy},
  creationdate                = {2008/05/28}
}

@Article{Gruen85,
  author       = {A W Gruen},
  title        = {Adaptive least squares correlation: A powerful image matching technique},
  journaltitle = {South African Journal of Photogrammetry, Remote Sensing and Cartography},
  year         = {1985},
  volume       = {14},
  number       = {3},
  pages        = {175-187},
  url          = {http://www.photogrammetry.ethz.ch/general/persons/AG_pub/ALSM_AWGruen.pdf},
  abstract     = {The Adaptive Least Squares Correlation is a very potent and flexible technique for all kinds of data matching problems. Here its application to image matching is outlined. It allows for simultaneous radiometric corrections and local geometrical image shaping, whereby the system parameters are automatically assessed, corrected, and thus optimized during the least squares iterations. The various tools of least squares estimation can be favourably utilized for the assessment of the correlation quality. Furthermore, the system allows for stabilization and improvement of the correlation procedure through the simultaneous consideration of geometrical constraints, e.g. the collinearity condition. Some exciting new perspectives are emphasized, as for example multiphoto correlation, multitemporal and multisensor correlation, multipoint correlation, and simultaneous correlation/triangulation.},
  comment      = {I've not read this. In TRIM},
  owner        = {Izzy},
  creationdate    = {2008/02/04},
}

@InProceedings{GuarnieriVR04,
  author       = {Alberto Guarnieri and Antonio Vettore and Fabio Remondino},
  booktitle    = {F{IG} {W}orking {W}eek 2004},
  title        = {Photogrammetry and Ground-based Laser Scanning: Assessment of Metric Accuracy of the 3{D} Model of {{P}ozzoveggiani} {C}hurch},
  url          = {http://www.photogrammetry.ethz.ch/general/persons/fabio/fig_atene.pdf},
  volume       = {TS26 Positioning and Measurement Technologies and Practices II - Laser Scanning and Photogrammetry},
  address      = {Athens, Greece},
  comment      = {''Most effort has been spent to achieve visually pleasant 3D models, mainly for VR applications, but only a few works addressed the metric and geometric accuracy of generated 3D models.''''in this paper we report the results from the comparison between digital photogrammetry and laser scanning techniques applied to the survey of the outside of the ancient church of Pozzoveggiani'' Used PhotoModeler to generate the model from the images and Polyworks to generate the model from the laser scanning data. Measured a set of ``check points'' on the church using a total station. ``This little church boasts a simple geometry composed by both planar and curved surfaces, allowing to compare easily the results about the application of different surveying techniques'' ``The methods to recover 3D shapes and models can be generally divided into two classes: ? systems based on objects measurements; ? systems that do not use measurements.''The former methods are employed for capture from both active sensors such as laser scanners and passive sensors such as imagers. The latter methods ``generally subdivide and smooth polygons using 3D splines; no measurements are employed at all''. Packages for photogrammetric reconstruction include PhotoModeler (http://www.photomodeler.com), ShapeCapture(http://www.shapecapture.com), Australis (http://www.sli.unimelb.edu.au/australis/). Automatic image matching techniques can provide a fairly dense point cloud but these do not necessarily correspond to the salient points required for a 3D model and smoothing will have occurred. On the other hand, and operator can define the 3D points and form a more useful model, but there will be fewer points and the operator needs to understand how the model is constructed to build the model effectively. The model produced from the image data took 10 hours and was found to be of good accuracy when measurements were compared to the check points. With the laser scanner, it was more difficult to find the check points in the data, and many were not found. They recommend using artificial targets in this case. The model produced from these data took 7-8 hours. Also lists different methods for suface registration from point clouds.},
  creationdate = {2005/08/08},
  keywords     = {3D, quality, image matching},
  owner        = {izzy},
  year         = {2004},
}

@Article{GuptaH97,
  author       = {R Gupta and R I Hartley},
  title        = {Linear pushbroom cameras},
  journaltitle = {I{EEE} {T}rans. {PAMI}},
  year         = {1997},
  comment      = {Mentioned in HirschmuellerSH05.},
  keywords     = {toread},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Misc{GuriesXX,
  author       = {Guries, Nicholas},
  title        = {Considerations for {D}igitizing {A}ccuracy {A}ssessment},
  howpublished = {Internet presentation},
  url          = {http://www.ersc.wisc.edu/academics/courses/Seminar/Spring2002/Nick%20Guries/guries_seminar.pdf},
  comment      = {The main reasons for measuring digitizing error are to provide Metadata to our product or to compare methods. Uncertainty can be due to systematic or random error, blunders or to generalisation for scale/resolution requirements or data storage requirements. Can measure error in geometry, i.e. the difference between two measurements, e.g. displacement vectors and polygons can represent the difference between two vectors, or by assessing whether measurements fall within a buffer, e.g. the epsilon model puts a buffer that represents a confidence level around vectors (also Buffer-Overlay-Statistics).},
  creationdate = {2005/01/01},
  owner        = {izzy},
}

@Misc{Hohle02,
  author       = {Joachim H\''{o}hle},
  title        = {Automated orientation of aerial images},
  abstract     = {Methods for automated orientation of aerial images are presented. They are based on the use of templates, which are derived from existing databases, and area-based matching. The characteristics of available database information and the accuracy requirements for map compilation and orthoimage production are discussed on the example of Denmark. Details on the developed methods for interior and exterior orientation are described. Practical examples like the measurement of rÃƒÂ©seau images, updating of topographic databases and renewal of orthoimages are used to prove the feasibility of the developed methods.},
  creationdate = {2008/02/04},
  owner        = {izzy},
  year         = {2002},
}

@Article{Hohle97,
  author       = {Joachim H\''{o}hle},
  journaltitle = {Photogrammetrie, Fernerkundung, Geoinformation},
  title        = {The automatic measurement of targets},
  pages        = {13-21},
  volume       = {1},
  abstract     = {The automatic measurement of targets is demonstrated by means of a theoretical example and by an interactive measuring program for real imagery from a rÃƒÂ©seau camera. The used strategy is a combination of two methods: the maximum correlation coefficient and the correlation in the subpixel range. Furthermore, a variable template is interactively derived at the beginning in order to eliminate some unknowns which ensures a more stable solution. Various possibilities are outlined how blunders can be detected and how the results concerning accuracy and speed can be further improved. The produced interactive software is also part of a computer-assisted learning program on digital photogrammetry.},
  creationdate = {2008/02/04},
  owner        = {izzy},
  year         = {1997},
}

@Unpublished{Haala02,
  Author                   = {Norbert Haala},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {Within the presentation the integration of {LIDAR} data and existing {GIS} for building extraction will be described exemplary on the basis of a system developed at ifp during the last years. {M}ain emphasis will be given on the demonstration of future developments aiming on data collection for location based applications. {I}n this context current projects at ifp i.e. aim on the refinement and update of existing 3{D} city models based on terrestrial images. {T}his data has to be used for automatic texture mapping and collection of geometric details for building facades. {A}nother topic of interest is the generalisation of {D}igital {S}urface {M}odels and 3{D} building models for visualization, i.e. the use of existing {GIS} data for extraction of relevant object representations.},
  Groups                   = {lidar},
  Owner                    = {Izzy},
  creationdate                = {2005/01/01}
}

@InProceedings{HaalaBK06,
  author       = {Norbert Haala and Susanne Becker and Martin Kada},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Cell {D}ecomposition for the {G}eneration of {B}uilding {M}odels at {M}ultiple {S}cales},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Cell decomposition. Hints that this is not the same as B-REP or CSG but appears to be a restricted CSG in which only union is possible. Start with 3D model and reduced to simple cells. Starting model could be ground plan extruded using laser scanner data. Also did this with facade - working out where the windows are.},
  creationdate = {2006/09/27},
  keywords     = {facade extraction},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Article{HaalaB99,
  author       = {N Haala and C Brenner},
  title        = {Extraction of buildings and trees in urban environments},
  journaltitle = ijprs,
  year         = {1999},
  volume       = {54},
  pages        = {130-137},
  url          = {http://www.cnr.colostate.edu/~lefsky/ISPRS/1135.pdf},
  abstract     = {In this article, two methods for data collection in urban environments are presented. {T}he first method combines multispectral imagery and laser altimeter data in an integrated classification for the extraction of buildings, trees and grass-covered areas. {T}he second approach uses laser data and 2{D} ground plan information to obtain 3{D} reconstructions of buildings.},
  comment      = {Contains: classification using DSM and colour imagery},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@Article{HaalaBA98,
  author       = {N Haala and C Brenner and K Anders},
  journaltitle = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  title        = {3{D} {U}rban {GIS} from {L}aser {A}ltimetry and 2{D} {M}ap {D}ata},
  number       = {3/1},
  pages        = {339-346},
  volume       = {32},
  comment      = {''We provide the required constraints by the assumption that the coordinates of the given ground plan are correct and the borders of the roof are exactly defined by this ground plan. This supplies sufficient restrictions to enable the reconstruction of buildings without loosing the possibility to deal with very complex buildings.''},
  creationdate = {2005/01/01},
  keywords     = {3D, toread},
  owner        = {slsmith},
  year         = {1998},
}

@Article{HafnerZS00,
  author       = {Hafner, BJ and Zachariah, SG and Sanders, JE},
  journaltitle = {Medical \& Biological Engineering \& Computing},
  title        = {Characterisation of three-dimensional anatomic shapes using principal components: application to the proximal tibia},
  number       = {1},
  pages        = {9-16},
  volume       = {38},
  abstract     = {The objective of the research is to determine if principal component analysis (PCA) provides an efficient method to characterise the normative shape of the proximal tibia. Bone surface data, converted to analytical surface descriptions, are aligned, and an auto-associative memory matrix is generated. A limited subset of the matrix principal components is used to reconstruct the bone surfaces, and the reconstruction error is assessed. Surface reconstructions based on just six (of 1452) principal components have a mean root-mean-square (RMS) reconstruction error of 1.05\% of the mean maximum radial distance at the tibial plateau. Surface reconstruction of bones not included in the auto-associative memory matrix have a mean RMS error of 2.90%. The first principal component represents the average shape of the sample population. Addition of subsequent principal components represents the shape variations most prevalent in the sample and can be visualised in a geometrically meaningful manner. PCA offers an efficient method to characterise the normative shape of the proximal tibia with a high degree of dimensionality reduction.},
  comment      = {In TRIM
Review:
CT scans of tibia and scaled using B-spline surface representation. PCA performed on the resulting points that fall on tubular surface. This is applied to U_i' this is the normalied version of U-i=[x_{i1},y_{i1},z_{i1},x_{i2},...,z_{in}] where i is the bone model and n is the number of 3D points measured on i - U_i' is therefore 3n long. I think each model (i) has the same number of points (n) and, due to alignment, each point represents corresponding locations on each tibia. PCs are calculated from all r vectors together. A=\sigma{i=1,r}U_i'U_i'^t the variance-covariance matrix. Eigenvector decomposition of A then dtermines the PCs. Could be useful if applied to roofs of similar type? Would need to align all first and find points all at the same locations. Alignment may be possible with PCA using XYZ as 3 features? This could create an automatic means of fitting data to models? Could align my taking the convex hull of footprint and aligning to longest edge of convex hull. Centre data at u=midway along longest edge v= mideway along longest line that is perpendicular to longest edge? More thoughts in log book... Is their alignment method similar to using moments as in ELAD, M., TAL, A., AND AR, S. 2001. Content based retrieval of VRML objects - an iterative and interactive approach. The 6th Eurographics Workshop in Multimedia, Manchester, U.K.?},
  creationdate = {2008/02/13},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {2000},
}

@Misc{HaimesCV03,
  author       = {Haimes, Robert and Connell, Stuart D and Vermeersch, Sabine A},
  title        = {Visual grid quality assessment for {3{D}} unstructured meshes},
  howpublished = {CiteSeer},
  note         = {American Institute of Aeronautics and Astronautics},
  citeseerurl  = {http://citeseer.ist.psu.edu/cache/papers/cs/1157/http:zSzzSzraphael.mit.eduzSzvisual3zSzcfd93.pdf/visual-grid-quality-assessment.pdf},
  comment      = {Curious one this. Seems to be about assessing the quality of cells in tetrahedral meshes that are used for flow simulation, e.g. over aircraft. I think CFD stands for computational fluid dynamics. There are different kinds of grids - both structured and unstructured (not clear what the difference is but its easier to quality assess structured meshes) that are derived using different techniques. Quadtrees and Delauney tetrahedration are mentioned. ``One useful cell quality [metric is cell aspect ratio]. This is the ratio of the radii of the circumscribed sphere to the inscribed sphere. This ratio is then normalised so that an equilateral tetrahedra has an aspect ratio of one. The grid quality measure used in this example to display poorly formed cells is skewness, calculated in degrees. For this paper, skewness is defined as the maximum angle that a face normal deviates from the vector between the node of the trahedron not on the face and the centroid of the face. A value of zero degrees would indicate an equilateral tetrahedron. A value close to 90 degrees would indicate a cell far from equilateral. These distroted tetrahedra haveg three forms: needle, cap and sliver.'' These methods of quality assessment may be worth noting as I am not sure that anyone has done any assessment on the quality of faces in 3D models - either for self-diagnosis (e.g. to detect slithers) or for comparison between captured data and the verification data set. This copy does not show all the figures - which may provide more insight into the assessment methods.},
  creationdate = {2005/08/08},
  keywords     = {3D, quality, morphology},
  owner        = {izzy},
  year         = {1993},
}

@TechReport{HaithcoatSH01,
  author       = {Haithcoat, Tim and Song, Wenbo and Hipple, James},
  institution  = {Interdisciplinary Center for Research in Earth Science Technologies},
  title        = {Building Extraction - {LIDAR} {R}\&{D} Program for {NASA}/{ICREST} Studies Project Report 09/16/01},
  comment      = {In TRIM. Method of extracting 3D buildings from laser scanning data. Doesn't describe the method. Also tested extraction from DEMs available in ENVI software. Comparison is against digitised building footprints and identified roof shape: ``We compare the automatically extracted buildings with reference data manually digitized from aerial photograph with 0.25m resolution. The reference data contain building outlines and roof type information. We can get the completeness and correctness measure by comparing number of extracted buildings with reference data. Horizontal RMS error can be obtained by calculating the distance between corresponding building corners. Overlaying extracted building with reference data will lead to the overlay error as well as area and perimeter difference measure. Due to lack of height information of reference data, we cannot assess the vertical geometric accuracy. We compare extracted roof types with reference data to obtain classification accuracy. The seven quality measures (completeness, correctness, classification accuracy, RMS error, area difference, perimeter difference, and overlay error) are used to access accuracy Normalized DSM of a downtown area 3D view of extracted buildings draped on DEM for the two tested data sets.'' ``A publication is underway for peer reviewed journal publication.'' See also http://icrest.missouri.edu/Projects/NASA/FeatureExtraction-Buildings/Building%20Extraction.pdf},
  creationdate = {2005/08/08},
  groups       = {lidar},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2001},
}

@InProceedings{HaithcoatSH01a,
  author       = {Haithcoat, Tim and Song, Wenbo and Hipple, James},
  booktitle    = {Remote Sensing and Data Fusion over Urban Areas, IEEE/ISPRS Joint Workshop 2001},
  title        = {Building footprint extraction and 3-{D} reconstruction from {LIDAR} data},
  pages        = {74-78},
  abstract     = {Building information is extremely important for many applications within the urban environment. Automated techniques and user-friendly tools for information extraction from remotely sensed imagery are urgently needed. This paper presents an automatic approach for building footprint extraction and 3-D reconstruction from airborne light detection and ranging (LIDAR) data. First a digital surface model (DSM) is generated from the LIDAR point data. The approach then extracts objects higher than the ground surface. Based on general knowledge about building geometric characteristics such as size, height and shape, buildings are separated from other objects (trees, etc.). The extracted building footprints are then simplified using an orthogonal algorithm to obtain better cartographic quality. Watershed analysis is conducted to extract the ridgelines of building roofs. The ridgelines as well as slope information are used to classify building roof types. The buildings are reconstructed using three basic parametric building models (flat, gabled, hipped) common to the study area. Finally, the results of extraction are compared with manually digitized building reference data to conduct an accuracy assessment},
  comment      = {From Sadhvi's thesis: ``Haithcoat et al uses information on slope and watershed analysis to understand the roof type and reconstruct the buildings using three parametric models: flat, hipped, gable (Haithcoat 2001). A greyscale magnitude image is used to mask tree from buildings from an nDSM data. The building outlines are refined and simplified based on orthogonal simplification algorithm. During the reconstruction process of a flat roof, the slope is computed from the DSM data and binarised with a threshold value. A zone layer is created from the building outlines where each building is a zone. The area for each building is computed from the binarised slope image using zonal statistics. Flat buildings are determined by comparing the area calculated with the whole area of each building. By calculating the average height of pixels within each pixel boundary gives the height of those flat buildings. Gabled and hipped buildings can be identified by a straight line running parallel to the long side of building and a straight line with fork segments. DSM explains the 3D view of the buildings and the direction of water flow down the steepest slope. It is possible to determine the number of cells flowing into a given cell. This is very helpful in determining the watershed boundaries. If the flow accumulation is zero it is identified as ridge. Further, with the help of shape characteristics, the buildings can be distinguished. After extracting the ridgelines, eave height and ridge height are determined. Eave height is the mean height of the corner points in a building and ridge height is the average height of roof ridgelines. These building extractions are compared with the manually digitised data for accuracy assessment. The roof classification obtained from this method has 90.9\% correctness ``},
  creationdate = {2008/09/25},
  keywords     = {3D, roofs, roof type},
  owner        = {izzy},
  year         = {2001},
}

@Misc{HalkidiVXX,
  author       = {M Halkidi and M Vazirgiannis},
  title        = {Quality assessment in the clustering process},
  howpublished = {unknown},
  comment      = {In TRIM. About assessing how good clustering algorithms are under different circumstances. Gives useful overview of different clustering methods.},
  keywords     = {clustering},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@InProceedings{VonHansen06,
  author       = {von Hansen, Wolfgang},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Robust {A}utomatic {M}arker-free {R}egistration of {T}errestrial {S}can {D}ata},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Co-registering multiple scans from a terrestrial laser scanner. Create raster cell in 3D that have approximately 1 meter sides. Planes identified and matched. Uses something called barycentres. The paper has pseudo code.},
  creationdate = {2006/09/27},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Article{HaralickWL83,
  author       = {Robert M Haralick and Layne T Watson and Thomas J Laffey},
  title        = {The Topographic Primal Sketch},
  journaltitle = {International {J}ournal of {R}obotics {R}esearch},
  year         = {1983},
  volume       = {2},
  number       = {1},
  pages        = {50--72},
  url          = {http://haralick.org/journals/topographic_primal_sketch.pdf},
  comment      = {A way of processing images so that they are invariance to changes in illumation (not direction, however). Using the first and second order directional derivatives (finds slope direction and magnitude at each location) each pixel is classified as one of peak, pit, ridge, ravine, saddle, flat or hillside. The directional derivative are determined by first modelling the local surface around a pixel using a bicubic function (has 10 parameters). I have tried this technique on remote sensing imagery and modelling the surface within a 5 by 5 window, however the results seem very noisey and of little use. The authors suggest that a larger window would smooth out noise although this will also remove important structure from the image. Another problem with the method is that it relies on the zero crossing points of the various directional derivative-derived parameters. Zero values for these parameters do not tend to occur in the descretised image case and so I found that I had to round off the parameter values before classifying the image. However, its a different take on images and indicates a method by which the changing greylevels in an image can be catergorised if necessary. Iz: if taken as a literal interpretation of a DSM does this produce geomorphons?},
  haveiread    = {Y},
  keywords     = {DeepLEAP1},
  creationdate    = {2005/01/01},
  wherefind    = {Izz},
}

@InProceedings{Harding06,
  author       = {Harding, J},
  title        = {Vector data quality: A data provider's perspective},
  booktitle    = {Fundamentals of {S}patial {D}ata {Q}uality},
  year         = {2006},
  editor       = {R Devillers and R Jeansoulin},
  organization = {ISTE},
  pages        = {141-159},
  address      = {London},
  comment      = {Reference from Jenny H. useful for elements of data quality: lineage. currency, positional accuracy, attribute accuracy, logical consistency, completeness.},
  keywords     = {3DCharsPaper},
  owner        = {izzy},
  creationdate    = {2007/01/09},
}

@Misc{HardingW05,
  Title                    = {Assessing planning applications with relation to {L}isted {B}uildings: {R}\&{I} {F}uture {U}sers {R}esearch: {U}ser-task {I}nterview {R}ecord 5},

  Author                   = {J Harding and L Wood},
  HowPublished             = {R\&I internal document},
  Year                     = {2005},

  Owner                    = {izzy},
  creationdate                = {2006/09/28}
}

@Article{HardingP07,
  Title                    = {Spatial Information Usability: Towards a usability assessment framework based on usability factors in contexts of use.},
  Author                   = {Harding, Jenny L and Pickering, Emma K},
  Year                     = {2007},
  Pages                    = {\url{http://www.cybergeo.presse.fr/}},
  Volume                   = {in press},

  Journaltitle             = {Cybergeo},
  Keywords                 = {usability, RapidDC},
  Owner                    = {Izzy},
  creationdate                = {2007/05/31}
}

@TechReport{HarrisB96,
  author      = {Christoper Harris and Bernard Buxton},
  title       = {Evolving edge detectors},
  institution = {UCL},
  year        = {1996},
  type        = {Research Note},
  number      = {RN/96/3},
  url         = {ftp://cs.ucl.ac.uk/genetic/papers/edgegp.ps},
  abstract    = {Edge detection is the process of detecting discontinuities in signals and images. {W}e apply {G}enetic {P}rogramming techniques to the production of high-performance edge detectors for 1-{D} signals and image profiles. {T}he method, which it is intended to extend to the development of practical edge detectors for use in image processing and machine vision, uses theoretical performance measures as criteria for the experimental design},
  address     = {Gower Street, London, WC1E 6BT, UK},
  comment     = {Use genetic programming to evolve appropriate functions for edge detection. The candidate detection functions were assessed using the three criteria outlined by Canny. These are (i) the signal-to-noise ratio of the operator, that is the response of the operator to the edge as opposed to the rest of the signal (ii) localisation or the closeness of the detected edge to the actual edge as determined manually and (iii) single response - only one edge is detected for each edge on the data. Each edge detection operator was constructed over a series of generations using + - / * and ln, exp, sin, cos and pow. Training for performed using a set of one dimensional synthetic edges and one dimensional profiles from images. During evolution, the operators were tested against the canny operator. On the whole operators that resulted were similar in shape to Canny's but some out-performed it using these data). The authors intend to extend the technique to 2-d signals. This paper is useful for a consise background to edge detection.},
  keywords    = {genetic algorithms, genetic programming, Edge Detection},
  creationdate   = {2005/01/01},
}

@Book{HartleyZ00,
  author    = {R Hartley and A Zisserman},
  title     = {Multiple view geometry},
  year      = {2000},
  publisher = {Cambridge University Press},
  comment   = {Look up RANSAC in here},
  keywords  = {toread},
  owner     = {izzy},
  creationdate = {2005/09/05},
}

@TechReport{HCI92,
  author      = {{{HCI} Group {DITC}}},
  title       = {M{IS}i{C}: {T}he performance {M}etrics {T}oolkit {U}ser {G}uides},
  institution = {National Physical Laboratory},
  year        = {1992},
  comment     = {Clare has hardcopy. Added to BevanM94 with count measures: the number of core activities plus the number of extra activities (as the result of an inefficient task proceedure perhaps) gives the number of activities required to do a task. These are measured for each task by analysing the video recordings of the evaluation sessions.},
  keywords    = {usability, RapidDC},
  owner       = {izzy},
  creationdate   = {2006/02/01},
}

@InProceedings{HeierKZ02,
  author    = {Helmut Heier and Michael Keifner and Wolfgang Zeitler},
  title     = {Calibration of the {D}igital {M}odular {C}amera},
  booktitle = {FIG XXII Internation Conference},
  year      = {2002},
  address   = {Washington, D.C. USA},
  comment   = {In TRIM},
  keywords  = {DMC, calibration, digital camera},
  owner     = {Izzy},
  creationdate = {2009.03.09},
}

@InProceedings{HeilerKS05,
  author       = {Matthias Heiler and Jens Keuchel and Christoph Schn\''{o}rr},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Semidefinate clustering for image segmentation with a-priori knowledge},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Claims that transduction is a method between supervised and unsupervised learning as it uses both labelled and non-labelled data. There are 3 main types - graph-based clustering, transductive inference and convex optimisation. Graph based clustering has problems and needs relaxation which led to the N-cut algorithm (ShiM00) An alternative to this is presented in this paper - semi-definate programming (which is apparently much more general than linear programming). WagstaffCRS01 constrained the k-means method with v simple contraints. Where the solution is unsatisfactory, more constraints are added leading to a perfection of the classification. This paper's method has very similar results. The constraints used are that image location I is equal to image location j, or that they are not equal. As many of these constraints as are required can be iteratively added. The most amazing this about this presentation is the noiselessness of the segmentation - would like to know why.},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@Misc{Heipke02,
  author       = {Christian Heipke},
  title        = {Overview of image matching techniques},
  year         = {2002},
  howpublished = {Internet},
  note         = {Last visited 04/02/2008},
  url          = {http://phot.epfl.ch/workshop/wks96/art_3_1.html},
  comment      = {In filing cabinet},
  owner        = {izzy},
  creationdate    = {2008/02/04},
}

@Unpublished{Heipke02a,
  author       = {Christian Heipke},
  title        = {Automatic road data verification and update by digital imagery},
  note         = {Loughborough Feature Extraction Workshop: commercial in confidence},
  abstract     = {Describing the quality of digital geodata in a geodatabase is required for many applications. {W}e present our developments for automated quality control of the {G}erman topographic vector data set {ATKIS} using images. {T}he automation comprises automatic cartographic feature extraction and comparison with {ATKIS} data, which both are triggered by additional knowledge derived from the existing scene description. {T}o reach an operational solution the system is designed as an automated system which admits user interaction to perform a final check of the fully automatically derived quality description of the data. {T}he project is carried out in co-operation with the {I}nstitut f\''ur {T}heoretische {N}achrichtentechnik, {U}niversit\''at {H}annover, and the {B}undesamt f\''ur {K}artographie und {G}eod\''asie, {F}rankfurt/{M}.},
  address      = {University of Hannover, Nienburger Str. 1, 30167 Hannover},
  creationdate = {2005/01/01},
  email        = {heipke@ii.uni-hannover.de},
  keywords     = {Quality, Updating, GIS, Automation, Knowledge-Base, Imagery, Acquisition, System feature},
  organisation = {Institute for Photogrammetry and GeoInformation (IPI)},
  year         = {2002},
}

@Article{Helava88,
  author       = {U V Helava},
  title        = {Object space least-squares correlation},
  journaltitle = pers,
  year         = {1988},
  volume       = {54},
  number       = {6},
  pages        = {711-714},
  comment      = {Define groundels (ground elements) as a unit in object space which has information about refletance, colour, etc. Describes transform between image space (pixel) geometric and radiometric information to object space (groundel) information. Formulates the least-squares correlation between groundels in different images. Says that this can be used to refine the results of image space results.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@InProceedings{HellerP05,
  author       = {J Heller and K Pakzad},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  date         = {August 29-30},
  title        = {Scale-dependant adaptation of object models for road extraction},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {http://www.isprs.org/proceedings/XXXVI/3-W24/papers/CMRT05_Heller_Pakzad.pdf},
  volume       = {XXXVI},
  comment      = {Heller is now Heuwald. Object models must allow for showing how object looks in images e.g. resolution. Use semantic nets manually created - can reduce the resolution of these.},
  keywords     = {ImageLearn, Spatial Scale},
  owner        = {izzy},
  creationdate    = {2005/09/05},
  year         = {2005},
}

@InBook{HenricssonB97,
  author       = {Henricsson, O and Baltsavias, E},
  booktitle    = {Automatic {E}xtraction of {M}an {M}ade {O}bjects from {A}erial and {S}pace {I}mages ({II})},
  title        = {Automated {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages ({II})},
  chapter      = {3-{D} building reconstruction with {ARUBA}: A qualitative and quantitative evaluation},
  editor       = {Gr\''{u}n, A and Baltsavias, E and Henricsson, O},
  pages        = {65-76},
  publisher    = {Birkhauser Verlag, Berlin},
  comment      = {In SchusterW03 say that they measure type-2 error (omission?), shape dissimilarity and RMS/distance},
  creationdate = {2005/10/18},
  keywords     = {3D, quality, toread},
  owner        = {izzy},
  year         = {1997},
}

@InProceedings{HenricssonBWAKBMG96,
  author       = {Henricsson, O. and Bignone, F. and Willuhn, W. and Ade, F. and K\''ubler, O. and Baltsavias, E. and Mason, S. and Gr\''un, A.},
  booktitle    = {18th {ISPRS} {C}ongress, {P}roc. {C}omm. {III} {WG} 2},
  title        = {Project {AMOBE}, {S}trategies, {C}urrent {S}tatus, and {F}uture {W}ork},
  pages        = {321-30},
  url          = {http://e-collection.ethbib.ethz.ch/ecol-pool/inkonf/inkonf_119.pdf},
  address      = {Vienna, Austria},
  comment      = {Lots of different strategies for finding buildings. A review document.},
  creationdate = {2005/01/01},
  keywords     = {remote sensing, grouping, matching, reconstruction, segmentation, color, DEM/DTM, multispectral, man-made objects, stereo, 3D},
  owner        = {izzy},
  year         = {1996},
}

@Misc{HertzmannJOCSXX,
  author       = {Aaron Hertzmann and Charles E Jacobs and Nuria Oliver and Brian Curless and David H Salesin},
  title        = {Image Analogies},
  howpublished = {Internet?},
  comment      = {In TRIM},
  owner        = {izzy},
  creationdate    = {2008/02/04},
}

@InProceedings{HeuelN96,
  author       = {S. Heuel and R. Nevatia},
  booktitle    = {Proceedings of {T}he {DARPA} {I}mage {U}nderstanding {W}orkshop},
  title        = {Including {I}nteraction in an {A}utomated {M}odeling {S}ystem},
  pages        = {429-434},
  address      = {Palm Springs, CA},
  comment      = {From LeeHN00: ``the authors suggest providing just an approximate building location to extract a building but the quality of the final result is completely dependent on the automatic analysis.'' Set up for interaction between computer and operator such that operator does those jobs most appropriate - that is qualitative information without the need for precision. This includes indicating whether there is an undetected building and the class of problem with building detection (shadow, dark building, etc). All work is in monocular framework using view angle and illumination information. Hypotheses are created and selected. Evaluation focuses on the number of cases that required interaction and the number of these required (per building? - it doesn't actually say!)},
  creationdate = {2005/10/14},
  keywords     = {quality, 3D},
  owner        = {izzy},
  wherefind    = {In TRIM},
  year         = {1996},
}

@InProceedings{HinzDH01,
  author       = {Alexander Hinz and Christoph D\''{o}rstel and Helmut Heier},
  booktitle    = {Photogrammetric {W}eek 2001},
  title        = {D{MC} - {T}he digital sensor technology of {{Z}/{I}-{I}}maging},
  editor       = {D Fritsch and R Spiller},
  pages        = {93-103},
  comment      = {Probably a useful paper for referencing for the DMC camera},
  creationdate = {2005/01/01},
  keywords     = {DMC, digital camera},
  owner        = {izzy},
  wherefind    = {in share_library},
  year         = {2001},
}

@Article{HinzH00,
  author       = {Hinz, A and Heier, H},
  title        = {The Z/I imaging digital camera system},
  journaltitle = {Photogrammetric Record},
  year         = {2000},
  volume       = {16},
  number       = {96},
  pages        = {929-936},
  abstract     = {Market needs for airborne and spaceborne imagery used in photogrammetry and GIS applications are changing. Fundamental changes in sensors, platforms and applications are currently taking place. Most recently, new high resolution spaceborne sensors have become available. Besides classical photogrammetry, new thematic applications will drive the future image marker. Savings in cost and time, together with the need for higher and reproducible radiometric resolution or spectral information will push forward the change from analogue to digital imagery. High resolution satellites will compete with airborne film-based photography and digital camera systems. With the availability of a digital airborne camera, it is possible to completely close the digital chain from image acquisition to exploitation and data distribution. The key decision regarding the camera design in this case is whether a linear or area array sensor should be used. In view of the high geometric accuracy requirements in photogrammetry, Z/I Imaging has focused development on a digital camera based on an area sensor. An essential aspect of this decision was not only the aerial camera system, but also the entire photogrammetric process to the finished photographic or mapping product. If this point of view is adopted, it becomes clear that the development of a digital camera involves more than simply exchanging film for silicon. Aspects such as data transfer rates, in-flight data processing and storage, image archiving, georeferencing, colour fusion, calibration and preprocessing hale the same influence on the economic assessment of a digital camera system. This paper describes current development activities and application aspects of a digital modular airborne camera system.},
  comment      = {Similar to HinzDH01 - about the DMC},
  keywords     = {digital camera},
  owner        = {izzy},
  creationdate    = {2008/03/06},
}

@InBook{Hinz01,
  author      = {Stefan Hinz},
  title       = {Using context as a guide for automatic object extraction in urban areas},
  booktitle   = {Remote {S}ensing of {U}rban {A}reas},
  year        = {2001},
  editor      = {C Juergens},
  series      = {Regensburger Geographische Schriften (35)},
  isbn        = {3-88246-222-1},
  comment     = {Context used was derived from a DSM - found like areas of occlusions and shadow to select non-occluded and unshadowed regions. Also used cars and road markings to give road direction, but i don't think they say how they detected these. Started by segmenting into rural, urban and forested regions. This used the DSN edge frequency and roughness and the image edge frequency, straighness and amplitude and the frequency of rectangular and parallel edge pairs.},
  infile      = {H},
  institution = {Institut fuer Geographie, Universitaet Regensburg},
  keywords    = {road, cars},
  creationdate   = {2005/01/01},
  wherefind   = {In TRIM},
}

@InProceedings{HinzB02,
  author    = {Stefan Hinz and Albert Baumgartner},
  title     = {Urban road net extraction integrating internal evaluation models},
  booktitle = {ISPRS Commission III Symposium on Photogrammetric Computer Vision},
  year      = {2002},
  editor    = {Rainer Kalliany and Franz Leberl and Fritz Fraundorfer},
  volume    = {XXXIV},
  number    = {3-A},
  url       = {http://www.isprs.org/proceedings/XXXIV/part3/papers/paper140.pdf},
  address   = {Graz, Austria},
  comment   = {In TRIM},
  keywords  = {DeepLEAP},
  owner     = {izzy},
  creationdate = {2008/02/04},
}

@InProceedings{HinzB01,
  author    = {Stefan Hinz and Albert Baumgartner},
  title     = {Vehicle detection in aerial images using generic features, grouping, and context},
  booktitle = {DAGM Symposium on Pattern Recognition. Lecture Notes in Computer Science 2191},
  year      = {2001},
  editor    = {B Radig and S Florcyk},
  volume    = {45},
  number    = {52},
  publisher = {Springer Verlag, Berlin},
  comment   = {In TRIM},
  owner     = {izzy},
  creationdate = {2008/02/04},
}

@Article{HinzB03,
  author       = {Stefan Hinz and Albert Baumgartner},
  title        = {Automatic extraction of urban road networks from multi-view aerial imagery},
  journaltitle = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year         = {2003},
  volume       = {5888},
  pages        = {83-98},
  comment      = {In filing cabinet and library folder. Local context is used to find roads e.g. buildings are often paralell to roads, the discovery of shadow in DSM tells the algorithm to alter parameters and discoery of occlusion in DSM tells algorithm to find another view.},
  keywords     = {DeepLEAP1},
  owner        = {izzy},
  creationdate    = {2008/02/04},
}

@Article{HinzW04,
  author       = {Hinz, Stefan and Wiederman, Christian},
  journaltitle = pers,
  title        = {Increasing efficiency of road extraction by self diagnonsis},
  number       = {12},
  pages        = {1457-1466},
  volume       = {70},
  comment      = {''Internal evaluation (self-diagnosis) and external evaluation of the obtained results are essential for automatic systems in practical applications''. ``The aim of self diagnosis is to determine the geometric and semantic accuracy of the extracted objects during the extraction process. This information must be derived from redundancies within the underlying data of the incorporated object knowledge.'' ``...important if extraction results are combined with other data ... also useful for guiding a human operator...'' ``External evaluation is independant of the extraction approach ... results used for comparison of different extraction approaches ... a useful tool to characterise the performance of self-diagnosis''. Useful for accuracy assessment generally and assessment part of 3D buildings work.},
  creationdate = {2005/01/01},
  keywords     = {quality, feature, 3D},
  owner        = {izzy},
  wherefind    = {library},
  year         = {2004},
}

@Article{HiranoWL03,
  author       = {Akira Hirano and Roy Welch and Harold Lang},
  journaltitle = {I{SPRS} {J}ournal of {P}hotogrammetry \& {R}emote {S}ensing},
  title        = {Mapping from {ASTER} stereo image data: {DEM} validation and accuracy assessment},
  pages        = {356--370},
  volume       = {57},
  comment      = {''The cost and difficulty of obtaining cloud-free, cross-track SPOT stereo coverage for many areas of the world has limited the possibilities for producing DEMs of large, contiguous areas.'' Rather than waiting for the next pass of the satellite for sidelapping stereo pairs, ASTER allows along-track overlapping pairs which are taken within seconds of each other and therefore have similar scene conditions such as lighting. Compared captured height with height from topographic maps or in some cases with ground measurements. Conclude that height measurements using ASTER stereopairs is adequate for purpose.},
  creationdate = {2005/01/01},
  owner        = {izzy},
  wherefind    = {share_library},
  year         = {2003},
}

@InProceedings{Hirschmueller05,
  author       = {H Hirschm\''{u}ller},
  booktitle    = {Proceedings of the 2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
  title        = {Accurate and efficient stereo processing by semi-global matching and mutual information},
  url          = {http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&arnumber=1467526&isnumber=31473},
  address      = {San Diego, USA},
  comment      = {In TRIM. HirschmuellerSH05 refer to this as using Mutual Information for image matching (rather than intensity values).},
  creationdate = {2005/09/05},
  keywords     = {toread, DSM, image matching},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{HirschmuellerSH05,
  author       = {Heiko Hirschm\''{u}ller and Frank Scholten and Gerd Hirzinger},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Stereo {V}ision based reconstruction of huge urban areas from an airborne pushbroom camera ({HRSC})},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Data from the High Resolution Stereo Camera produced by DLR. Epipolar lines are assumed to be linear however this is often not the case. Thus a 2D search along the expected line is often used for matching. This paper uses the work of LeePKL99 to define a 1D search space along non-linear epipolar lines.Semi-global matching is then used to determine the disparity image by minimising a cost function. Mutual Information (Hirschmueller05) is used in the matching rather than intensity differences. Achieve reconstruction of 110km^2 of berlin at a resolution of 20cm/pixel in about 18days on a 2.8 GHz Xeon computer. Well worth reading the references for this.},
  creationdate = {2005/09/03},
  keywords     = {epipolar, 3D},
  owner        = {izzy},
  year         = {2005},
}

@Unpublished{Hofmann02,
  Author                   = {Alexandra Hofmann},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {Toward an automatic extraction of detailed building information. {T}his presentation will point out the way we have found to locate the buildings and the method we are developing to obtain detailed informtaion of the buildings.},
  creationdate                = {2005/01/01}
}

@InProceedings{Hoetal02,
  Title                    = {Knowledge-based building detection based on laser scanner data and topographic map information},
  Author                   = {A Hofmann and H-G Maas and A Streilein},
  Booktitle                = {I{SPRS} {C}ommission {III} {S}ymposium: {P}hotogrammetric {C}omputer {V}ision},
  Year                     = {2002},

  Address                  = {Graz, Austria},
  Month                    = {September 9-11},

  Owner                    = {slsmith},
  creationdate                = {2005/01/01},
  Url                      = {http://www.ISPRS.org/commission3/proceedings/papers/paper025.pdf}
}

@Unpublished{HollandBMXX,
  author    = {D.A. Holland and D. Boyd and P. Marshall},
  title     = {Updating {T}opographic {M}apping in {G}reat {B}ritain using {I}magery from {H}igh-{R}esolution {S}atellite {S}ensors},
  note      = {Submitted to ISPRS Journal of Photogrammetry and Remote Sensing},
  comment   = {Report on results of assessing hi res satellite data for use in topographic mapping. Very valuable reference. Also useful overview of OS requirements and processes.},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{HongjianaS05,
  Title                    = {3D building reconstruction from aerial {CCD} image and sparse laser sample data},
  Author                   = {You Hongjian and Zhang Shiqiang},
  Year                     = {2005},
  Number                   = {6},
  Pages                    = {555-566},
  Volume                   = {44},

  Abstract                 = {An approach for 3D building reconstruction automatically based on aerial CCD image and sparse laser scanning sample points is presented in this paper. The geometry shape of a building is shown very clearly in the aerial high-resolution CCD image, so we use Laplacian sharpening operator and threshold segmentation to extract the edges of CCD image first, and then pixel connectivity is used to extract the linear features in the CCD image. Bi-direction projection histogram and line matching are proposed to extract the contours of buildings. The height of the building is determined from sparse laser sample points which are within the contour of the buildings extracted from CCD image; therefore the 3D information of each building is reconstructed. We reconstruct 3D buildings correctly by this approach using real aerial CCD and sparse laser rangefinder data.},
  Journaltitle             = {Optics and Lasers in Engineering},
  Keywords                 = {3D},
  Owner                    = {Izzy},
  creationdate                = {2007/11/16}
}

@Misc{Hough62,
  Title                    = {A method and means for recognizing complex patterns},

  Author                   = {P. V. C. Hough},
  HowPublished             = {U.S. Patent No. 3,069,654},
  Year                     = {1962},

  creationdate                = {2005/01/01}
}

@Unpublished{HowardR00,
  author    = {D Howard and S Roberts},
  title     = {Evolution of {A}utomatic {D}etectors to {A}ssist {I}mage {A}nalysts},
  year      = {2000},
  note      = {Internal DERA report. DERA\/KIS/SEC/CR000199/1.0},
  comment   = {Overview: This is a full report on the use of genetic programming to evolve object detection algorithms. It takes the standard format of background, methods and their development, discussion and conclusion. The research is for military applications and has the intention of cueing targets for human image analysts to then interpret. The system is designed to find 'suspicious objects', in this case vehicles in infrared (thermal) imagery. Description of interesting aspects of research: The fundamental premise of this research is that genetic programming is used to evolve effective and robust algorithms for object detection. This evolution takes the form of exchange and mutation of genetic material and, in some cases, killing off less 'fit' genetic material. The genetic material (chromosomes) are trees representing a series of basic functions such as addition, subtraction, multiplication, division, minimum and maximum the order of which in the final algorithm is determined as part of the evolutionary process. Using this methodology, an empirical/inductive algorithm is defined. However, unlike other empirical methods such as neural networks, it is easier to scrutinize the resulting algorithm to determine what features of the imagery and ways of combining these were of use. Genetic algorithms and programming have often been considered to be computationally intensive. This research attempts to minimise computation time and memory usage so that the resulting algorithm can be applied in near-real time. This is achieved by having a two- or multi-stage algorithm. The first stage of this algorithm finds all suspicious objects, including many false positives. This stage is optimised to find all the actual objects. The second stage then only searches the outputs from the first stage to determine which are truly the objects. Multiple stages were also developed to be specialists for different classes of vehicle object. The training data used several different definitions of the objects - either one point per object or various combinations of multiple points. At each of these points, 'statistics' were derived to define the spectral information in this area. This input information was necessarily rotation invariant and took two forms - simple statistics or Discrete Fourier Transform (DFT) statistics. The simple statistics at each point were calculated for a series of rings of different diameters around the point. These statistics were average value, number of edges found, standard deviation of values and a measure that indicated how the edges were distributed around the ring. The DFT statistics were the highest frequency coefficients derived by the DFT of values within disks of different diameters defined around the points. Additionally, because data of different spatial resolutions and which different viewing properties was used, these features where scaled by both altitude and perspective (resulting in ellipses in some cases). Suggested improvements to the research included the creation of an 'ant' which would wander around a 2D image 'feeling' the 3D information and context. A new way of determining object orientation was also devised and compared to second order central moments method. Other improvements were aimed at speeding up the genetic program and using less memory (which are interrelated concepts). One of the final chapters describes how the automatic object detectors where used in a practical application. This used a number of techniques including having the different stages of detector running one after the other along the lines of the image and also describes how the minimum of pixels were processed by only sampling every nth pixel in every nth row. Comments: Despite the application of this research not being directly relevant to OS, this detailed and interesting report provides plenty of information that could be followed up in further research. We would do well to model other research reports upon its structure and depth so that they continue to be of value even when the author is no longer a member of OS staff. There were a number of aspects of this research of direct interest to OS (see below). Although describing a highly technical subject, the report is largely understandable. I did get a little lost in parts describing memory usage and databasing, but this was towards the end of the report. It wasn't clear that by 'infrared', the report meant thermal infrared, however, I have assumed this from the example imagery which shows dark vegetation and bright roads. Thermal imagery has some different characteristics to optical data including different shadow characteristics (not necessarily related to illumination angle) and more noise and so a little caution should be exercised when relating the described techniques. For instance, the statistics of pixels values in the rings may be more variable for objects in optical imagery because of the variability of the position of shadow. I would like to know in what context we have been given this report - it does not seem to be research undertaken in collaboration with OS. Also of interest - apparently, for 'esoteric reasons' the same sensor can produce significantly different results in different aircraft. How could report be updated: I would be very interested to know what the researchers have done since this work, it could be of great value to us. Additionally, results of any research into the context-feeling 'ant' would be of interest. Relevance to/of current or proposed activities: The use of genetic programming to evolve algorithms, or at least to determine what features could be of value in algorithms is a area we should consider researching. This work particularly lends itself to the next stage of the Image Primitives (now HICCS) research where a method of combining the various primitives is to be devised. Also, the research describes what could be further primitives in the form of simple statistics and DFT statistics. The methods to speed up processing, including multiply-staged algorithms, are of interest to all our research as is the processing of lines of data with each stage of the algorithm in parallel. Reviewer: Izzy Date: March 2005},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{Hsieh96a,
  author       = {Hsieh, Y},
  booktitle    = {A{RPA} {I}mage {U}nderstanding {W}orkshop},
  title        = {Design and evaluation of a semi-automated site modeling system.},
  pages        = {435-459},
  volume       = {1},
  abstract     = {This paper describes the design and evaluation of {SITECITY}, a semi-automated building extraction system integrating photogrammetry, geometric constraints, image understanding and user interfaces. {E}xisting automated building extraction systems often produce mixed results and it is clear that human intervention is required to correct mistakes from fully automated systems. {SITECITY} gives human operators the ability to construct and manipulate three dimensional building objects using multiple images. {I}mage understanding algorithms are integrated into {IDLSITE} to assist users. {T}hese automated processes are selected and integrated based on methods and criteria derived from the {GOMS} ({G}oals, {O}perators, {M}ethods and {S}election {R}ules) human-computer interaction principle. {T}he performance of these automated processes are rigorously evaluated. {T}welve human subjects were used to evaluate the usability of the semi-automated system in comparison with the fully manual version. {T}he methodology for the usability evaluation is described and the result of this evaluation shows that automated processes in {SITECITY} enhance the overall usability of the system and reduce the complexity of manual mensuration of three dimensional building objects.},
  comment      = {In TRIM. Referenced by Shufelt99 - ``In SiteCity experiments with 12 subject the average measurement uncertainty was found to be in the order of 1 pixel''. Will be available from http://www.maps.cs.cmu.edu/papers/papers.html if they fix the login glitch. Shuflet96 says: ``uses rigorous photogrammetric solutions and semi-automated feature extraction techniques to aid in site model compilation''. This is a fantastic paper giving more description of quality assessment than I have encoutered so far. Firstly, it discusses the choice between machine-driven (fully automated) and operator-driven (semi-automated) approaches adn provides some useful references for both. The semi-automated approach is chosen for this research - resulting in SiteCity. ``While experimental result and performance analysis on some existing systems have been obtained, a discussion of formal methods to assess the performance and usability of these interactive systems has been lacking.'' Discuss the cost of problem solving and identify the user cost as the amount of work required by the user to solve a problem. ``One way to quantify user cost is to use the Goals, Operators, Methods and Selection Rules model of human-computer interaction (Card et al, 1983, John and Kieras 1994).''This allows the comparison of a semi-automated system with a fully manual system. The problem is decomposed into tasks and the elapsed time and user cost (number of operations) required are used to assess the cost. Argue that automated processes should not decrease the ease and effectiveness of the system. An automated process is potentially usable if it reduces the overall user cost and usable ir it reduces both the user cost and the elapsed time. An automated algorithm must there fore have speed and robustness (reduce the idle time of the user and not be affected by variations in scene, image, user - robustness is more importnant), must be non-intrusive (failure should not add to user cost, problem solving strategy should be same with or without automated processes), not have too many parameters to be adjusted by the user (otherwise time spent setting parameters could be better spent manually capturing data) and be flexible (not constraint to a few scenarios, models etc). Using these criteria, decide which of the manual tasks can be automated - choose floor detection, peak edge detection and epipolar matching. These are broken down into three component processes - verification, edge estimation and object matching (see also Hsieh96b but described better in this paper). These three components are then reassembled to enable the estimation of the peak edge, the estimation of the building height, epipolar matching and automatic copying (when similar buildings exist in an area). Previous research into quantifying image measurement precision (gives refs) show that this depends on SNR, quantisation level and pixel size. Limit the number of parameters to be set by the operator to expected error in user measurements, sensitivity to error due to camera parameters, minimum and maximum elevation. The fully manual system in this case is constrained to be the same as the semi-automatic system except that the automatic processes are turned off. This allows direct comparison. However, I can't see why user cost and time elapsed can't be compared between different systems. The evaluation should use as many subjects and different types of data as possible to avoid bias.The system was set up to record each operation (type and time) so that full evaluation can occur. Subjects used for the analysis must all be given the exact same instructions/training. 12 subjects were used and given 30 mins training. They were to capture data for two different scenes using both the semi-automatic and the fully manual system. Therefore, they were divided into 4 different to ensure that each group used a different system on a different scene first. In other studies, the ground truth is generated by one user. In this work it was taken to be the mean measurement from the fully manual system. The standard deviation of the measurements was also used to quantify the measurement uncertainty.Tested whether there was bias in the semi-automated process by plotting direction of vectors between manual and semi-automatic points (found no bias). Tested the ability of the verification component to discriminate by comparing its performance for ground truth and randomly genated building hypotheses. Descrimination was clear and they were able to define the ideal range of confidence values for this component using this. Tested the sensitivity of the verification component to measurement error by randomly offsetting ground truth points and comparing confidence values. Similarly tested sensitivity of this component to dispacement of whole building (I can't quite see why). The performance evaluation is not at building object level(eg McgloneS94) but on individual building vertices (using also the standard deviation). ``Currently, the automated processes are affected by a combination of scene complexity, image contrast, view angles and users.'' The experiment did not show a clear advantage for oblique images, perhaps because the search areas in these images are greater and result on more error.Point out that users can ``often perform building delineation within subpixel accruacies by adjusting the display resolution''. In 9 out of the 24 cases the semi-automatic task took more time and required more operations, mainly in one particular image. Broke down tasks into type, measurement, modification, deletion. Modification too a lot of time and teneded to involve fine-tuning edge and corner positions - whether semi-automatic or manual method. Discuss productivity as the amount of work required to achieve a benefit. In this case, it could be a function of the number of point measurements and the accuracy of these measurements. If the desired error is e and the desired throughput is N, there is a limit to the amount of work that is considered to be productive. A useful way of assessing an methodology. Gives some future improvements - would be interesting to see what happened to SiteCity.},
  creationdate = {2005/08/12},
  keywords     = {3D, quality, usability, RapidDC},
  owner        = {izzy},
  wherefind    = {izzy},
  year         = {1996},
}

@InProceedings{Hsieh96b,
  author       = {Hsieh, Y},
  booktitle    = {1996 {IEEE} {C}omputer {S}ociety {C}onference on {C}omputer {V}ision and {P}attern {R}ecognition},
  title        = {Site{C}ity: {A} Semi-Automated Site Modelling System},
  pages        = {499-506},
  address      = {San Francisco, CA},
  comment      = {From LeeHN00: ``interactive tools are described including methods for replicating model buildings that are identical or very similar to others.'' Details a system for semi-automatic 3D buildings capture. Seems to focus on capturing vertices as accuracy (''precision'') tests are on vertices alone. States ``most research has focused on fully automated feature extraction systems'' - not sure that this is true for 3D feature extraction, but perhaps it has been in the US unlike in Europe? ``SiteCity uses rigrous photogrammetric principles and multiple images to accurately determine 3D locations of objects, such as buildings or roads in the scene.'' There are ``three image understanding components are used to support building measurement tasks: a verification component, an object matching component and an edge estimation component.'' The verification component seems to provide a confidence or other value for the existence of a hypothesised building in an image. This determines how the visible edges and shadows of hypothesised building object should look in the scene an matches this to the image. The edge estimation component uses the Hough transform to determine edges. The object matching component searches for a hypothesised object within a defined constrained region of an image. These components are described well in Hsieh96a. The process is initiated by the operator who provides an estimate of the roof outline. This is then used to constrain an automatic process that finds posible roof geometries. It appears that only a peak roof model is available for this, although it is not made clear what the assumptions are for the roof design. The possible floor positions of the building are also detected. This indicates, but it is not stated, that no terrain model is used in the process. Both of these automatic searches use the edge estimation component. The estimated building hypotheses (roof and floor geometries) are then processed by the verification component to find a best hypothesis. This hypothesised building is then searched for in all the other images using the object matching component constrained by epipolar geometry. This results in another set of building hypotheses, from which one is selected using the confidence values from the verification component. Strictly, this is a 2D process as the best hypothesis is being derived from one image only, not multiple image geometry. One other process that is described, but I'm not sure where it applies is that of automatically copying the point, line and area characteristics from nearby building objects in the scene. It appears more information on this can be found in Hsieh96a. Previous ``reports show that the measurement precision on a digital image depends on signal to noise ratio, quantization level and pixel size of the digital image''. Because ``the three dimensional object calculated by triangulating multiple image measurements often does not conform to our precise expectations for the real 3D object'' (no indication of why) and occlusions or shadows made some points impossible to measure. Therefore, geometric constraints are introduced. However, what these are and how they are introduced is described in other reports. For performance evaluation, ground truth dervied from the measurements of 12 operators. This allows an average standard deviation to be determined for each point. ``Using the number of standard deviations [rather than the Euclidean distance] to compare the accuracy treats the automated processes with the same standard as human subjects; the automated processes need to perform as well as humans.'' There is no discussion of how images are oriented. Interest paper with a more automated process than many. I think this work is related to PIVOT (Shufelt96).},
  creationdate = {2005/01/01},
  keywords     = {3D, quality, epipolar},
  owner        = {izzy},
  wherefind    = {in share_library},
  year         = {1996},
}

@TechReport{HsiehMP90,
  author      = {Hsieh, Yuan C and McKeown, David M and Perlant, Frederic P},
  title       = {Performance Evaluation of Scene Registration and Stereo Matching for Cartographic Feature Extraction},
  institution = {Cargenie Mellon University},
  year        = {1990},
  number      = {CMU-CS-90-193},
  month       = {November},
  address     = {School of Computer Science},
  comment     = {A really clear report detailing research into stereo matching techniques and their qualitative and quantitative assessment. A useful paper for learning about stereo matching techniques in general. I understand from this paper that 'disparity' is the term used for 'height' extracted from relatively orientated images. Emphasis is on matching for extraction of 3D data models. Sites used in test included two urban areas - one industrial and one residential in which terrain areas were higher than nearby buildlings. Also a non-built-up rural area was used for terrain extraction testing alone. Work previous to this has been on scenes with isolated builidngs and nearly homogreneous texture. First describes image registration using two methods. The first of these is coarse registration that registers images to features taken from a database (containing x,y,z values for significant objects?) The second is fine registration that matches certain features between the images - shadow corners, buildings and others. Registration only performs translation and rotation. In order to determine the surface model/disparity map, stereo matching needs to be performed. Describe two types of matching technique. Area-based techniques match image areas within windows to each other. The method descibed in this paper is hierarchical, matching more finely with each iteration. Area-based matching ensures that every image pixel is matched. Its hierarchical nature means that it can overcome errors in the registration. However, matching can sometimes fail in featureless areas and smoothing of sharp features occurs. The second matching method is feature-based. Here 'features' extracted from the scene are matched. The method described in this paper extracts the 'waveform' (the intesity transect) along the epipolar scanline, breaks these down into pre-defined features such as 'peak' and 'upward slope' and matches these between the images. Again, this method is hierachical, the early matches are performed on smooth waveforms, the final being performed on the original waveform. The actual technique is fairly involved. Feature-based matching work well for identifying large disparity jumps (such as happens at the edges of buildings) but does not provite depth estimates for every point in the scene therefore these need to be interpolated. The paper therefore also suggests a method by which the two techniques can be combined. In previous work this has been done by using one technique to refine the other. In this paper, with the recognition that both techniques are advantageous under different conditions, both are applied simmultaneously. Performance evaluation is first undertaken by visual analysis. However, they point out that a false impression can easily be given by the qualitative methods that much similar research has used. One method is to compare disparity values with the 'truth' generated from a stereo display monitor. The results of this however (because they were global summaries of error) did not reflect the local effects of different scene features on the different techniques. Therefore they also studied for all building the effect of building disparity (height) on the accuracy of its predicted disparity. Also, the prediction of edge location and edge sharpness at disparity jumps was also assessed by looking at the gradients in disparity maps. The feature-based matching performed better for defining the disparities. The area-based matching performs as well as the feature-based techniques with buildings of low disparity. Little is said about the merged result so it is not clear that it is much better than the feature-based technique when it comes to defining disparity. Comment that the actual accuracy of the reference data should be considered - microscale features that are not included in the reference data may indicate error when there isn't any. This may be similar to the paper with the same name published in PAMI in 1992.},
  keywords    = {quality, epipolar, image matching},
  owner       = {izzy},
  creationdate   = {2005/01/01},
  wherefind   = {Izzy has copy},
}

@InProceedings{HuTX05,
  author       = {Hu, Yong and Tao, Vincent and Xu, Zhizhong},
  booktitle    = {A{SPRS} 2005 {A}nnual {C}onference},
  title        = {Accuracy assessment of mapping results produced from single imagery},
  url          = {http://www.geoict.net/Resources/Publications/ASPRS2005_SI54393.pdf},
  address      = {Baltimore, Maryland},
  comment      = {Premise if this research is that stereo pairs are hard to come by. ``A suite of tools and procedures for 3D mapping from single images have been developed for different use cases in the commercial software - SilverEye - to perform a full spectrum of 2D/3D measurements on single images with or without the use of DTMs. These tools all utilize the rational function model (RFM) as the internal imaging geometry model for various photogrammetric mapping tasks. SilverEye provides both mono and stereo working environments. In each of these environments users are able to collect 2D data and 3D data and organize it in a GIS-style layer format.'' Uses the Rational Function Model (rational polynomials) to extract 3D scene information from single images. DEM can be included. Results: I. The same set of building dimensions, such as building width and length, road width and airport runway length were measured using the single image, DTM and GCPs in SilverEye and stereo images in SilverEye, PCI Geomatica and ERDAS IMAGINE. A set of buildings were selected and four height measurements were made for each building. Able to predict what the error in height measurement without the DTM would be very well - though I can't really understand the reasoning behind these equations. Also use shadow to capture height. Not brilliantly written but contains some interesting stuff.},
  creationdate = {2005/08/08},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{HuertasN98,
  author       = {Andres Huertas and Ramakant Nevatia},
  booktitle    = {International {C}onference on {C}omputer {V}ision},
  title        = {Detecting changes in aerial views of man-made structures},
  pages        = {73-80},
  comment      = {In TRIM. ``We believe that the solution to finding sturctural changes lies in not comparing images taken at different times directly but rather in comparing new images (or descriptions dervied from them) to an abstract model derived from previous observations''. Assume that buidlings are rectilinear (compostie shapes such as L and T are possible) and have either flat or simple gable roofs. Do not include vegetation in the site model. System has four steps: site model to image registration, site model validation, structural change detection and site model updating. The comparison involves projecting the 3D site model to 2D image domain and matching features such as edges, junctions and shadows.},
  creationdate = {2005/09/09},
  howpublished = {internet I think must look up url},
  keywords     = {change},
  owner        = {izzy},
  year         = {1998},
}

@Article{HuertasN88,
  author       = {A Huertas and R Nevatia},
  journaltitle = {cvgip},
  title        = {Detecting buildings in aerial images},
  pages        = {131-152},
  volume       = {41},
  comment      = {From ShufeltM93: ``discuss a technique for detecting buildings in aerial images. Their method detected lines and corners in an image and labeled these corners based in dtected shadows. Then, object boundaries were traced by grouping corners that shared line segments. The position and orientation of these chains of segments were then examined, and the appropriately laigned chains were connected to form boxes representing the structures in the image. Shadow analysis was used to verify the remaining chains by adding lines as necessary.''},
  creationdate = {2005/09/09},
  owner        = {izzy},
  wherefind    = {don't have},
  year         = {1988},
}

@InBook{HulinT06,
  Title                    = {Chordal Axis on weighted distance transforms},
  Author                   = {Hulin, Jerome and Thiel, Edouard},
  Pages                    = {271-282},
  Year                     = {2006},
  Series                   = {LECTURE NOTES IN COMPUTER SCIENCE},
  Volume                   = {4245},

  Abstract                 = {Chordal Axis (CA) is a new representation of planar shapes introduced by Prasad in [1], useful for skeleton computation, shape analysis, characterization and recognition. The CA is a subset of chord and center of discs tangent to the contour of a shape, derivated from Medial Axis (MA). Originally presented in a computational geometry approach, the CA was extracted on a constrained Delaunay triangulation of a discretely sampled contour of a shape. Since discrete distance transformations allow to efficiently compute the center of distance balls and detect discrete MA, we propose in this paper to redefine the CA in the discrete space, to extract on distance transforms in the case of chamfer norms, for which the geometry of balls is well-known, and to compare with MA.},
  Booktitle                = {DISCRETE GEOMETRY FOR COMPUTER IMAGERY, PROCEEDINGS},
  Owner                    = {izzy},
  creationdate                = {2008/02/13},
  Url                      = {http://pageperso.lif.univ-mrs.fr/~edouard.thiel/print/2006-dgci13-hulin-thiel.pdf}
}

@Book{Ince92,
  author    = {A Ince},
  title     = {Mechanical intelligence: {C}ollected works of {A}lan {M}. {T}uring.},
  year      = {1992},
  publisher = {North Holland, Amsterdam},
  comment   = {Got this from DERA report into Evolution of Automatic Detectors - apparently this document says that Alan Turing was amoung the first to postulate that genetics and Darwinian evolution could be used to develop machine intelligence - useful quote for genetic programming reports.},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Manual{ISO1911302,
  Title                    = {{ISO} 19113:2002 Geographical Information -- Quality Principles},

  Address                  = {Geneva},
  Author                   = {ISO},
  Organization             = {International Organization for Standardization},
  Year                     = {2002},

  Owner                    = {izzy},
  creationdate                = {2007/01/09}
}

@Article{IyerJLKR05,
  author       = {Natraj Iyer and Subramaniam Jayanti and Kuiyang Lou and Yagnanarayanan Kalyanaraman and Karthik Ramani},
  journaltitle = {Computer-Aided Design},
  title        = {Three-dimensional shape searching: state-of-the-art review and future trends},
  number       = {5},
  pages        = {509-530},
  volume       = {37},
  abstract     = {Three-dimensional shape searching is a problem of current interest in several different fields. Most techniques have been developed for a particular domain and reduce a shape into a simpler shape representation. The techniques developed for a particular domain will also find applications in other domains. We classify and compare various 3D shape searching techniques based on their shape representations. A brief description of each technique is provided followed by a detailed survey of the state-of-the-art. The paper concludes by identifying gaps in current shape search techniques and identifies directions for future research.},
  comment      = {Hardcopy in filing cabinet
Review:
A really valuable paper that describes the basic methods used for representing and comparing shapes and well as providing masses of references. Largely based around industrial engineering requirements - so fully 3D models. Similarity metrics are first described. These compare shape feature vectors. L_p Minkowski distance is basically the extension of the Manhattan and Euclidean distances.The Hausdorff distance describes the distance between two non-matched (not the same set of features) data sets. The correlation metric (or cosine metric) is a measure of the angle between two data sets. Quote a big chunk of Loncaric98 that could be worth referring to for the difference between the processes of shape representation and shape description. Gives 7 criteria for shape representation - with descriptions - scope, uniqueness, stability, sensitivity, efficiency, multi-scale support and local support. Next describes techniques for shape searching which really break down into a number of different features: Global feature-based recognition using: moments, spherical harmonics, geometric parameters. Manufacturing feature recognition (I'm not certain how/if this applies to roof characterisation but maybe useful for comparing parts. E.g. this can be done using 7 characteristics - feature existence, feature count, feature direction, feature size, directional distribution, size distribution and relative orientation). Graph-based recognition: spectral graph theory, Reeb graphs, skeletal graphs (useful for topological comparisons). Histogram-based recognition: shape histograms (only shell model seems easily applicable in 3D), shape distributions (OsadaFCD02). Product-information-based recognition (part dsigned are described either based on their manufacturing attributes or on their geometry - could be applied to roof parts). 3D object recognition (basically stores a number of features that describe the 3D object, such as images from different aspects, for matching): aspect graphs, extended Gaussian images, geometric hashing. The following section discusses the use of each of these techniques in the published literature - useful to refer to if any techniques are tried. The discussion is valuable (as is the table of techniques): ``global feature-based methods, while being computationally efficient are unable to disciminate among dissimilar shapes. Manufacturing feature recognition based methods do not decompose shapes uniquely. Additionally, they may require human intervention. Topological graph-based technuqes are intractable for large graphs because of the high complexity of graph/subgraph matching problems. Skeletal graph based methods are not applicatble to all kinds of shapes. Histogram-based methods have a tradeoff between computational cost and number of sampled points...Three-dimensional object recognition technques have been tested for limited shapres and have high storage/computation costs.''},
  creationdate = {2008/02/21},
  keywords     = {morphology, 3D, quality},
  owner        = {izzy},
  year         = {2005},
}

@Article{JaafarPM99,
  author       = {Jaafar, J and Priestnall, G and Mather, P. M},
  title        = {The effects of {LIDAR} {DSM} grid resolution on categorising residential and industrial buildings},
  journaltitle = {International Archives of ISPRS},
  year         = {1999},
  volume       = {32},
  number       = {3W14},
  pages        = {151--157},
  address      = {La Jolla, California},
  comment      = {in filing cabinet
Review:
In TRIM. Looking at the differences between DSMs of residential and industrial buildings in terms of their RMSEs (from a extruded footprint building model) and the standard deviation of the differences between the DSM and the extruded footprint building model. Use 2m grid (from EA) as base data. Find differences as data degrade that seem to be characteristic of type of building. Not terribly useful, but really an early paper looking at characterising and perhaps classifying roofs using DSMs.},
  keywords     = {morphology},
  owner        = {izzy},
  creationdate    = {2008/02/25},
}

@Article{JacksonL02,
  author       = {Qiong Jackson and David A Landgrebe},
  title        = {Adaptive {{B}ayesian} contextual classification based on {{M}arkov} random fields},
  journaltitle = iegrs,
  year         = {2002},
  volume       = {40},
  number       = {11},
  pages        = {2454--2463},
  comment      = {Seems very similar to Ashton 1998 but initial classification is supervised.},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
}

@InBook{JainD88,
  author    = {A K Jain and R C Dubes},
  title     = {Algorithms for clustering data},
  year      = {1988},
  publisher = {Prentice Hall},
  chapter   = {Clustering methods and algorithms},
  pages     = {55-89},
  comment   = {Chapter 3 In filing cabinet},
  keywords  = {clustering},
  creationdate = {2005/01/01},
}

@Article{JainDM00,
  author       = {Anil K Jain and Robert P W Duin and Jianchange Mao},
  journaltitle = {IEEE transactions on pattern analysis and machine intelligence},
  title        = {Statistical pattern recognition: a review},
  number       = {1},
  pages        = {4-37},
  volume       = {22},
  comment      = {In TRIM
Review:
A comprehensive overview of pattern recognition. Well worth dipping into to refresh the memory. Very clearly written. On clustering: ``...a user of a clustering algorithm should keep the following issues in mind: 1) every clustering algorithm will find clusters in a given dataset whether they exist or not; the data shoule, therefore, be subjected to tests for clustering tendency before applying a clustering algorithm, followed by a validation of the clusters generated by the algorithm; 2) there is no 'best' clustering algorthm. Therefore, a user is advised to try several clustering algorjthms on a given dataset. Further, issues of data collection, data reprsentation, normalization, and cluster validity are as important as the choice of clusterin strategy.'' Probably little need for anything else in this review than a contents listing: 1 Introduction 1.1 What is pattern recognition? 1.2 Template matching 1.3 Statistical approach 1.4 Syntactic approach 1.5 Neural networks 1.6 Scope and organization 2 Statistical pattern recognition 3 The curse of dimensionality and peaking phenomena 4 Dimensionality reduction 4.1 Feature extraction 4.2 Feature selection 5 Classifiers 6 Classifier combination 6.1 Selection and training of individual classifiers 6.2 Combiner 6.3 Theoretical analysis of combination schemes 6.4 An example 7 Error estimation 8 Unsupervised classification 8.1 Square-error clustering 8.2 Mixture decomposition 9 Discussion 9.1 Frontiers of pattern recognition 9.2 Concluding remarks},
  creationdate = {2008/02/04},
  keywords     = {classification clustering feature extraction feature selection},
  owner        = {izzy},
  year         = {2000},
}

@InBook{JametDA95,
  author       = {Jamet and Dissard and Airault},
  title        = {Automatic Extraction of Man-Made Objects from Aerial and Space Images.},
  chapter      = {Building extraction from stereo pairs of aerial images: accuracy and productivity constraint of a topographical production line.},
  editor       = {Gr\''{u}n and K\''{u}bler and Agouris},
  pages        = {231-240},
  publisher    = {Birkhaeuser Verlag},
  comment      = {Work performed at IGN. Development from paper mapping to digital data is described. This should result in each point being stored in 3D with a Z accuracy of 1m rmse. Product is called BDTopo. Want to develop automatic techniques to save time transcribing from hardcopy to softcopy. Describe constraints to this. Also discuss choice between machine- and operator-driven processing. ``in both cases, the main issue remains the auto-diagnosis ability of the automatic techniques. In the case of preprocessing, a complete scanning and correction of the data is generaly less efficienct and yields more errors than manual plotting. The operator intervention should be guided by the internal confidence in the results, i.e. by a confidence level given by the automatic process itself. In the second alternative, the help provided by the machine should preferable be able to require on line operator intervention in case of possible error, rather than imporse an a posteriori correction of the result.'' The automatic building extraction approach chosen relies on a model of simple isolated buidlings with planar roofs. Take techniqes from previous work by Ma\^{i}tre and Luo 1992, Dang 1994 and Dissard 1995. Edge detection is applie to both images separately, stereo matching is applied to each image I think using both area matching and feature maching of the detected edges. Disparity (is this height? - see HsiehMP90) is approximated, edges are then grouped (into building hypotheses?) and the final disparity map is created. The 3D polygons are extracted from this. Clearly, I don't fully understand what is going on in this paper. Quality assessment was performed on 41 buildings by comparing the XY location of the corners of the buildings extracted using monoscopic process to the manually digitised buildings (from the ongoing process to digitise the paper maps). The XYZ of the corners of the buildings was also compared to something. 30 buildings were correctly plotted, 7 weren't and 4 were unrecognised. Conclude that this process is not enough to become operational since it only works with very simple buildings - which are easily plotted manually anyway - and correcting error from the automatic techniques is extremely tedious. Suggest some form of confidence measure (e.g. comparing measurements to shadow information, Irvin and McKeown 1989) to reduce the failure rate. Consider that for this resolution of imagery (30-40cm) feature matching is not precise enough and a short study indicates that area matching creates a more accurate Z value. The matching algorithm uses epipolar lines. Comment that ``the behavior of this kind of algorithm on the building roofs highly depends on the direction of the computation (right to left or reverse along the epipolar line), due to the propagation effect induced by the order constraint (the match for the point is to be looked for after the match of its predecesor)''. Maybe I'll understand this better later. ``The topographic application we are aiming at place the real bottlenecks of automatic building extraction techniques on their reliability and geometrical accuracy.},
  creationdate = {2005/08/12},
  keywords     = {3D, quality, epipolar},
  owner        = {izzy},
  wherefind    = {izzy},
  year         = {1995},
}

@Article{JurieG95,
  author       = {Frederic Jurie and Jean Gallice},
  title        = {A recognition network model-based approach to dynamic image understanding},
  journaltitle = {Annals of {M}athematics and {A}rtificial {I}ntelligence},
  year         = {1995},
  volume       = {13},
  pages        = {317--345},
  comment      = {Intention of this work is to interpretate image dynamically - therefore extract only that information that is relavent and time is a dimension. Create hypotheses networks in which a number of hypotheses of what the data represent are linked eg 3 segment hypotheses can be linked together in a triangle hypothesis. There is a great deal of set theory required to understand this paper. How exactly this is implemented to videos taken from moving autonomous vehicles is difficult to determine but there is some input from past inpretation outputs. They use the technique to identify left, centre and right lane markings.},
  creationdate    = {2005/01/01},
}

@InBook{JurischM08,
  author       = {Jurisch, B A and Mountain, D M},
  booktitle    = {Computational Science and Its Applications},
  title        = {Evaluating the Viability of Pictometry Imagery for Creating Models of the Built Environment.},
  editor       = {Gervasi, O and Gavrilova, M L},
  pages        = {663-677},
  publisher    = {Springer},
  series       = {Lecture Notes in Computer Science},
  address      = {Berlin / Heidelberg},
  comment      = {MSc thesis (summary submitted to AGI student awards). Produced a 3D model using Pictometry with textures applied. ``The visual appearance of the model and suitability for purpose are assessed by expert interviews which identify the importance of roof structures derived from PictometryÃ‚Â® for realistic representation.''},
  creationdate = {2008/10/27},
  owner        = {izzy},
  year         = {2008},
}

@InProceedings{JutziS06,
  author       = {Boris Jutzi and Uwe Stilla},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Precise {R}ange {E}stimation on {K}nown {S}urfaces by {A}nalysis of {F}ull-{W}aveform {L}aser},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. 'Boris's spheres'. This paper describes the effect on waveform lidar of different surface features. Different beam distributions also have an effect. Compare the transmitted and receive waveform. The shape of the received waveform is mainly affected by the laser system the reflectance surface. Mostly about spheres...},
  creationdate = {2006/09/27},
  groups       = {lidar},
  keywords     = {waveform lidar},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{Kaartinen05a,
  author       = {Kaartinen, H. and Hyypp\''{a}, J. and G\''{u}lch, E. and Vosselman, G. and Hyypp\''{a}, H. and Matikainen, L. and Hofmann, A.D. and M\''{a}der, U. and Persson, \AA and S\''{o}derman, U. and Elmqvist, M. and Ruiz, A. and Dragoja, M. and Flamanc, D. and Maillet, G. and Kersten, T. and Carl, J. and Hau, R. and Wild, E. and Frederiksen, L. and Holmgaard, J. and Vester, K.},
  booktitle    = {Proceedings of the 1st {I}nternational {W}orkshop on {N}ext {G}eneration 3{D} {C}ity {M}odels},
  title        = {{E}uro{SDR} building extraction comparison},
  editor       = {Gr\''{o}ger and Kolbe},
  url          = {file://///randi01/r%20and%20i/ConferenceProceedings/Lammergeier/NextGen3DCity05/BuildingExtraction_Kaartinen.pdf},
  comment      = {Isabel made several attempts to contact Juha Hyypp\''a from the Finnish Geodetic Institute over the last year regarding the EuroSDR Commission 3 Evaluation of Building Extraction project. From a long established web page: ``The objective of the Building Extraction project is to evaluate the quality, accuracy, feasibility and economical aspects of 1. Semi-automatic building extraction based on photogrammetric techniques with the emphasis on commercial and/or operative systems. 2. Semi-automatic and automatic building extraction techniques based on high density laser scanner data. 3. Semi-automatic and automatic building extraction techniques based on integration of laser scanner data and aerial images'' This piece of research is of enormous relevance to Ordnance Survey if we are to consider capturing a 3D product. The Capture of 3D Building Data project has outlined a research programme to develop and test systems for capturing data and discussions have already taken place with some of the main researchers in this field. Thus, the reporting of results of the EuroSDR project are extremely timely. Within the EuroSDR test (Kaartinen et al., 2005), 11 participants from academia, industry and national mapping agencies applied different building extraction systems to 4 test sites. The results were compared for ability to capture the building outline and length and the height and inclination of the roof. The different systems included both commercial systems and those being developed within research institutions. Data available included aerial imagery, laser scanning data and some basic ground plans. The test sites we chosen to represent different environments: a) complex buildings, b) large buildings and little vegetation on a flat terrain c) variable buildings and many trees on moderate relief and d) many linked buildings of similar height. For the systems tested, more automation was achieved using laser scanning data rather than imagery. The techniques using only image data (CyberCity-Modeler and one other) were more reliable accurate with determining the building outline (ground plan) and building length. Results of a similar accuracy were obtained using laser scanning for some systems, but other laser scanning and image and laser scanning-only systems produced considerably lower accuracy results. The difference may have been down to the degree of automation. The laser scanning methods were better at predicting the height of buildings, particularly using data with a higher point density. The degree of automation of the system did not have an impact on this accuracy. The predictions of the roof inclination varied with the site and degree of automation. The more automated methods resulted in a higher error, as did predictions for the sites with the steep and short roofs. One of the final conclusions was that CyberCity-Modeler should be used as a baseline for accuracy assessments. The study still needs to assess the results on time taken to run each system. Unfortunately, the presented results give little away about the methods used to extract the 3D data, the data used to verify these and the method of verification. Certainly, it does not appear that any 3D reference data were used. Therefore, it is not possible to determine how well the systems captured the geometry and topology of the buildings. My impression is that the means by which the research results were to be assessed where not clearly set out in advance. As a result, the different sets of captured data showed differences in detail and completeness. It is difficult to assess relative accuracy of data that display different levels and types of detail. The full report is yet to be published, but is eagerly anticipated. The Capture of 3D Building Data research programme has already identified CC-Modeler as something we need to test and so I was disappointed that the word from some researchers before the conference was that CC-Modeler it wasn't very useful. However, the EuroSDR capture test (see above, Kaartinen et al., 2005) identified CC-Modeler as the benchmark standard. See also Kaartinen05b.},
  creationdate = {2005/01/01},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{Kaartinen05b,
  author       = {H Kaartinen and J Hyypp\''{a} and E G\''{u}lch and G Vosselman and H Hyypp\''{a} and L Matikainen and A D Hofmann and U M\''{a}der and \AA Persson and U S\''{o}derman and M Elmqvist and A Ruiz and M Dragoja and D Flamanc and G Maillet and T Kersten and J Carl and R Hau and E Wild and L Frederiksen and J Holmgaard and K Vester},
  booktitle    = {I{SPRS} {WG} {III}/3, {III}/4, {V}/3 {W}orkshop ``{L}aser scanning 2005''},
  title        = {Accuracy of 3{D} city models: {E}uro{SDR} comparison},
  url          = {http://www.commission3.isprs.org/laserscanning2005/papers/227.pdf},
  address      = {Enschede, the Netherlands},
  creationdate = {2005/01/01},
  keywords     = {toread, 3D},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{KalisperakisKG06,
  author       = {Ilias Kalisperakis and George Karras and Lazaros Grammatikopoulos},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {3{D} {A}spects of 2{D} {E}pipolar {G}eometry},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Relative orientation is either 5 parameter orientation task with the essential matrix (for calibrated cameras) or epipolar geometry with 7 parameters and epipolar lines and the fundamental matrix (for uncalibrated cameras). Its useful to view the 3D image geometry embedded in 2D epipolar geometry in a Euclidean framework. We have to assume that planes are not parallel and g is not at infinity. Also, no image should be parallel to the baseline because there can be no epipole at infinity. Created circular foci of the 2nd epipole in 2D. Every point on the circle is related to a specific direction on...This paper had some very cool slides with animatable diagrams but wasn't easy to follow. Perhaps read the paper!},
  creationdate = {2006/09/27},
  keywords     = {epipolar geometry},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{KazhdanFR04,
  author       = {Michael Kazhdan and Thomas Funkhouser and Szymon Rusinkiewicz},
  title        = {Shape {M}atching and {A}nisotropy},
  booktitle    = {A{CM} {T}ransactions on {G}raphics ({SIGGRAPH} 2004)},
  year         = {2004},
  url          = {http://www.cs.princeton.edu/~funk/sig04b.pdf},
  comment      = {In share_library. Princeton University. Similar to the work of OsadaFCD01 but using anisotropy rather than shape descriptors maybe.},
  howpublished = {not sure - check internet},
  journaltitle = {A{CM} {T}ransactions on {G}raphics ({SIGGRAPH} 2004)},
  keywords     = {3D, matching, quality},
  owner        = {izzy},
  creationdate    = {2006/09/29},
}

@PhdThesis{Kazhdan04,
  author       = {Michael M. Kazhdan},
  title        = {Shape Representations and Algorithms for 3D-shape Model Retrieval},
  url          = {http://www.cs.jhu.edu/~misha/MyPapers/Thesis.pdf},
  comment      = {Extensive study of the use of symmetry to describe shape. From Goodhall07: ``The Reflective Symmetry descriptor ... is a descriptor that measures the amount of symmetry (or not) in an object. In the 2-D case, it works by averaging an image against itself reflected along a line of symmetry. The descriptr is defined for all planes that go through the centre of mass. To do this efficiently, the fast Fourier Transform is used to calculate the symmetry. Extended to the 3-D case, ``slices'' or prjection of a sphere are used to make into multiple 2-D problems. Visually, this is represented by deforming a unit sphere. Areas of higher symmetry cause the sphere to extend outwards, whereas areas of lower symmetry will not...The 3-D object is converted to a voxel representation and domposed into a series of concentric spheres. A Fourier Transform is then applied. The use fo a FT defined on a sphere allows for rotation invariance.''},
  creationdate = {2008/03/10},
  keywords     = {morphology},
  owner        = {izzy},
  school       = {The Faculty of Princeton University},
  year         = {2004},
}

@Article{KerekesB02,
  author       = {John P Kerekes and Jerrold E Baum},
  title        = {Spectral imaging system analytical model for subpixel object detection},
  journaltitle = iegrs,
  year         = {2002},
  volume       = {40},
  number       = {5},
  pages        = {1088--1101},
  comment      = {Seems to be a very comprehensive look at the effect that various scene, sensor and processing configurations have of subpixel detection. Use a modelled image (based on HYDICE spectra) and vary number of channels, noise object pixel fraction as well as meteorological conditions and much more. Image is of subpixel roads on a grass background. Highest ranking parameters were object pixel fraction, background variability scaling factor, meteorological range, number of spectral channels and sensor nadir view angle.},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
}

@Unpublished{KeyesW01,
  author    = {Laura Keyes and Adam Winstanley},
  title     = {Technical {R}eport: {T}opographic object recognition through shape},
  year      = {2001},
  note      = {NUI Maynooth},
  comment   = {Overview: A report details methods and results of describing the shape of vector objects. The methods used included Fourier descriptors, moment invarients and scalar descriptors and methods for using these for classification. The different types of descriptors and classifiers are fused to try to improve the classification. The research used Ordnance Survey data, and I assume that is why we have a copy of the report. Comments: I only skimmed this report. It contains some very interesting work and references that may be useful to some future research. I don't think it is of immediate value to change detection research. How could report be updated: Relevance to/of current or proposed activities: Reviewer: Izzy Date: June 2005},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{KhoshelhamL04,
  author       = {Khoshelham, Kourosh and Li, Zhilin},
  title        = {A model-based approach to semi-automated reconstruction of buildings from aerial images},
  journaltitle = {Photogrammetric {R}ecord},
  year         = {2004},
  volume       = {19},
  number       = {108},
  pages        = {342--359},
  comment      = {Create 3{D} (well wire-frame) models of buildings and fit these to lines found in images. Images are small segments of aerial photography within which buildings seems to sit centrally with very little background. Because only one image used, method is not so effective with nadir imagery.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  wherefind    = {Izzy},
}

@Misc{Kieras01,
  author       = {David Kieras},
  title        = {Using the {K}eystroke-{L}evel {M}odel to {E}stimate {E}xecution {T}imes},
  year         = {2001},
  howpublished = {Internet},
  note         = {\url{ftp://www.eecs.umich.edu/people/kieras/GOMS/KLM.pdf}},
  url          = {ftp://www.eecs.umich.edu/people/kieras/GOMS/KLM.pdf},
  comment      = {Estimate how long a task will take by assigning times to each keystroke, thought-process etc and adding up for different types of user.},
  owner        = {izzy},
  creationdate    = {2005/12/20},
}

@Article{KimM99,
  author       = {Taejung Kim and Jan-Peter Muller},
  title        = {Development of a graph-based approach for building detection},
  journaltitle = {Image and {V}ision {C}omputing},
  year         = {1999},
  pages        = {3--14},
  comment      = {Detect lines and then find connections between them. A building is when a loop of lines is found, or when a U-shaped group is found. Also detected lines in the direction of shadows to find buildings and detected lines that would be vertical to find buildings.},
  haveiread    = {ish},
  creationdate    = {2005/01/01},
  wherefind    = {Izz},
}

@Article{KimM98,
  Title                    = {A technique for 3D building reconstruction},
  Author                   = {Kim, T and Muller, J-P},
  Year                     = {1998},
  Number                   = {9},
  Pages                    = {923-930},
  Volume                   = {64},

  Abstract                 = {An approach to tackle the problem of three-dimensional (3D) building reconstruction in urban imagery is presented. For 3D building reconstruction, there is a need to combine 2D (such as grouping) and 3D analysis (such as stereo matching). A good strategy for the combination is essential for success. A simple but robust combination strategy is proposed. Combination is carried out only after a 2D building detection technique and a 3D height extraction technique are applied completely independently. The 2D building detection technique does not use any information generated from the height extraction technique, nor vice versa. Moreover, any assumptions or conditions derived in the course of 2D building detection or height extraction are not used for combination. 3D building reconstruction is done by interpolating heights into the area covered by 2D building boundaries using the 3D height information. In this way, results from the 2D building detection technique and 3D height extraction technique can be meaningful by themselves. This also can make the process of 3D building reconstruction simple and applicable to a wide range of images. This approach is tested with airborne images, and the results show that 3D building reconstruction can be achieved successfully.},
  Journaltitle             = {Photogrammetric Engineering and Remote Sensing},
  Keywords                 = {3D, getacopy},
  Owner                    = {Izzy},
  creationdate                = {2007/11/16}
}

@PhdThesis{Kim01,
  author       = {Kim, ZuWhan},
  title        = {Multi-view 3-{D} object description with uncertain reasoning and machine learning},
  url          = {http://citeseer.ist.psu.edu/cache/papers/cs/29723/http:zSzzSziris.usc.eduzSzOutlineszSzpaperszSz2001zSzzuwhan-thesis.pdf/kim01multiview.pdf},
  comment      = {In TRIM
Review:
Chapter 5: ``in most building description systems, building models are constru ted by extruding polygonal roof tops''. BaillardZ99 use six or more images to find 3D matched lines. For ``DEMs ... computed from high resolution ... images... underlying correlations methods has inherent limitations and produce errors at or near ... depth discontinuities'' VestriD00 did research into increasing the quality of DEMs using 10 or more images. Multiple images are better then pairs because occlusions are mitigated, epipolar alignments are overcome, wrong line or junction matches are elimated. This paper finds 2D lines and junctions in images and matches them between multiple images to identify 3D featrues. These hypotheses are then verified. A number of checks are used to elimated bad matches and enhance the final hypotheses. First, the DEM is smoothed and possible object boundaries are identified. The images for each calculation are then chosen as those with the greatest angles between epipolar lines. Line and junction extraction is done using the work of Noronha (PhD). Only lines that fall near the possible objects in the DEM are accepted. A number of techniques are used to matched 2D features to find 3D features, in turn: 1) pairwise epipolar matching (see NoronhaN01) 2) combining height estimates of pairwise matching 3) feature grouping (groups features to find junctions or lines) 4) 3D selection with DEM (by which the feature is projected onto the DEM and must fall within a tolerance of the height). Hypotheses are then generated (quite complicated) and verified using supporting evidence such as line support, wall vertical line support, darkness of shadow region and closeness of hypotheses to boundary of DEM. This involves an expandable Bayesian network but I'm confused by this. Flat roofs are roofs with hips are dealt with - the letter after the flat-roof building hypothesis has been verified. Quality assessment is based purely on time taken to perform the analysis per buidling and visual inspection.},
  creationdate = {2005/01/01},
  keywords     = {3D, quality, epipolar},
  school       = {Faculty Of The Graduate School, University Of Southern California},
  year         = {2001},
}

@InProceedings{KirchhofMJ05,
  author       = {Kirchhof, M and Michaelsen, E and J\''{a}ger, K},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  title        = {Motion detection by classification of local structures in airborne thermal videos},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  organization = {Joint workshop of ISPRS and DAGM},
  volume       = {XXXVI},
  comment      = {Homographies and RANSAC. Use 3 frames to calculate homographies which reduces the degrees of freedom (from 2 frames I guess). Reduces the problem from 27 degrees of freedom to 17. The classes are car, T, L and rejection. Sample circulatory around a point and at a range of radii to get signature. Can then remove vehicle objects from creating homographies but still need to detect motion due to false alarms. ?Use homographies to register images so that difference can be found?},
  creationdate = {2005/09/05},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{KirsteinWK05,
  author       = {Stephan Kirstein and Heiko Wersing and Edgar K\''{o}rner},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Rapid online learning of objects in a biologically moivated recognition architecture},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Based on the process stages that are believed to occur in the humjan visual system (AIT <-> ITC <-> V4 <-> V2 <-> V1 whatever that means). The first layers of the model are general feature representation laters. After that they are tuned to particular objects. The system is capable of recognising hand drawn sketches but these need to be aligned to the orginal figures on which the model was trained. Somme interesting stuff on human perception and translation invariance. Apparently, for online approaches, segmentation is usually required. They consider short tem memory as a input buffer for long term memory. Global learning methods such as MLPs and SVMs do not tend to be robust to a change in data. Local leaning methods such as LVQ and growing neural gas are more suitable for incremental leaning but can have convergence problems in hi dimensional feature space. This paper has developed a version of the local learning methods.. (Given by Wersing)},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@Article{KocamanZGP06,
  author       = {S Kocaman and L Zhang and A Gruen and D Poli},
  title        = {3D city modeling from high-resolution satellite images},
  journaltitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year         = {2006},
  volume       = {36},
  number       = {Commission I, WG 1/5, WG 1/6},
  comment      = {Using CyberCity with Ikonos data.},
  keywords     = {3D},
  owner        = {Izzy},
  creationdate    = {2009.03.09},
}

@InCollection{KolbeGP2005,
  author       = {Kolbe, T. H. and Gr\''{o}ger, G. and Pl\''{u}mer, L.},
  booktitle    = {Geo-information for disaster management},
  title        = {City{GML} -- Interoperable Access to 3D City Models},
  editor       = {van Oosterom, P. and Zlatanova, S. and Fendel, E. M.},
  note         = {Presentation at 1st International Workshop on Next Generation 3D City Models},
  pages        = {883--899},
  publisher    = {Springer-Verlag, Berlin, Heidelberg},
  comment      = {CityGML (Kolbe, 2005) is an open data model and XML-based format for the storage and exchange of virtual 3D city models. It is realised as an application schema for GML3, the extendible international standard for spatial data exchange issued by the Open Geospatial Consortium (OGC) and the ISO TC211. CityGML is intended to become an open standard and therefore can be used free of charge. It is being developed by members of the Special Interest Group 3D (SIG3D) of the initiative Geodata Infrastructure North-Rhine Westphalia (GDI NRW) in Germany, which is a consortia of 70 companies, municipalities and research organisations. The aim of the development of CityGML is to reach a common definition of the basic entities, attributes, and relations that can be shared over different applications. The targeted application areas explicitly include city planning, architectural design, tourist and leisure activities, environmental simulation, mobile telecommunication, disaster management, homeland security, vehicle and pedestrian navigation, and training simulators. CityGML not only represents the graphical appearance of city models but especially takes care of the representation of the semantic, especially the thematic properties, taxonomies and aggregations of Digital Terrain Models, sites (including buildings, bridges, tunnels), vegetation, water bodies, transportation facilities, and city furniture. The underlying model differentiates five consecutive levels of detail (LODs), where objects become more detailed with increasing LOD regarding both geometry and thematic differentiation. CityGML files can - but don't have to - contain multiple representations for each object in different LOD simultaneously. Until recently, the CityGML project has comprised almost exclusively of German organisations (Snowflake being the only UK contributor). This has changed somewhat and Ordnance Survey have been invited to become members of SIG3D. This is an opportunity which must be taken up at the earliest opportunity.},
  creationdate = {2005/01/01},
  keywords     = {3D, 3DCharsPaper},
  owner        = {izzy},
  year         = {2005},
}

@Article{KontosM05,
  author       = {Kontos, D and Megalooikonomou, V},
  journaltitle = {Pattern Recognition},
  title        = {Fast and effective characterization for classification and similarity searches of 2D and 3D spatial region data},
  number       = {11},
  pages        = {1831-1846},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/KontosM05.pdf},
  volume       = {38},
  abstract     = {We propose a method for characterizing spatial region data. The method efficiently constructs a k-dimensional feature vector using concentric spheres in 3D (circles in 2D) radiating out of a region's center of mass. These signatures capture structural and internal volume properties. We evaluate our approach by performing experiments on classification and similarity searches, using artificial and real datasets. To generate artificial regions we introduce a region growth model. Similarity searches on artificial data demonstrate that our technique, although straightforward, compares favorably to mathematical morphology, while being two orders of magnitude faster. Experiments with real datasets show its effectiveness and general applicability. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
  comment      = {In TRIM
Review:
''Shape is the geometrical information that remains when location, scale and rotational effects are filtered out from an object.''. Perform pixel or voxel 'counting' within concentric circles or spheres on homogeneous (each pixel/voxel has the same values) and non-homogeneous (each pixel/voxel has a value within a range) pixels/voxel. The counting for non-homogeneous pixels/voxels is a density count. Aimed at characterising the internal structure of the region of interest. Two radius signatures are obtained - they are the volume or density of the ROI as the concentric circle/sphere's radius increases normalised by the area/volume of the increasing circle/sphere or the area/volume of the total region of interest. ``Other techniques, such as morphology, wavelets and Fourier transform operate either on a 2D basis, or require significant computational overhead in order to operate directly in 3D''. ``The morphological distance between two objects $x_1$ and $x_2$ is defined as $d_{morph}^E(x_1, x_2) = (\Sum_{m=-M}^{M}|d*{f_m^E(x_1), f_m^E(x_2)}|^p)^{\frac{1}{p}} (see paper for some more badly reproduced maths) where E is some structuring element, M is the maximum radius used to construct E (circle or sphere), d* is the area of the symmetric set difference distance measure. Read this paper for roof DSM characterisation for which the homogeneous case _may_ be valid but this may have more value to waveform lidar if volumes of lidar points with intensity values are sampled into a non-homogeneous voxel structure.},
  creationdate = {2008/02/13},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {2005},
}

@Book{Kraus93,
  author       = {Kraus, K},
  title        = {Photogrammetry},
  publisher    = {Duemmler, Bonn},
  volume       = {1},
  comment      = {p231 - from AvrahamiRD05 ``The accuracy of the manual mapping can be evaluated according to Kraus (1993) using Equations 2 and 3, where: m is the image scale, mq is an estimation of the photogrammetric measurement's accuracy (10Ã‚Âµm), Z is the flight height, and B is the base line.''},
  creationdate = {2005/11/11},
  keywords     = {toread},
  owner        = {izzy},
  year         = {1993},
}

@Article{KrausKBM06,
  author       = {K Kraus and W Karel and C Briese and G Mandlburger},
  title        = {Local accuracy measures for digital terrain models},
  journaltitle = {The Photogrammtric Record},
  year         = {2006},
  volume       = {21},
  number       = {116},
  pages        = {342-354},
  comment      = {When deriving a DTM from DSM the quality of each point is determined. The result is relative accuracy (iz: this allows us to assess the accuracy of secondary data such as slope). Accuracy is influenced by a) number and alignment of neighbouring original points from which the DTM is calculated b) distance to the grid point (from...?) c) terrain curvature in the neighbourhood of the grid point and d) accuracy of the height of the original points. This method calculates a) the location of points used (i.e. excluding areas of drop out and non-terrain points) b) point density of original points - from a) c) minimum distance between grid points and its nearest data point and identification of point where nearest point is greater than a threshold d) maximum curvature at the grid point e) height accuracy of original points and f) spatial variation of height accuracy. There are combined to calculate accuracy for each grid point. See also the EuroSDR publication: Quality parameters of digital terrain models. Seminar on Automatic Quality control of Digital Terrain Models. Karel and Kraus.},
  keywords     = {DTM, quality, DEM},
  owner        = {Izzy},
  creationdate    = {2007/09/17},
}

@Article{KumarM97,
  author       = {Vinay P Kumar and Elias S Manolako},
  journaltitle = iesp,
  title        = {Unsupervised statistical neural networks for model-based object recognition},
  number       = {11},
  pages        = {2709--2718},
  url          = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=650097},
  volume       = {45},
  comment      = {Example of unsupervised feature learning from imagery. Used a network hierarchy (tree) with 3 levels: object, scale and translation. I think, in effect, for each object at a range of scales, templates were created for all(?) translations. Each pixel in the image is assigned a tree with this three level structure. A recursive algorithm (based on expectation-minimisation) is then used to find posterior probabilities of each subclass/template at that pixel - thus a mixture model is defined for the pixel. The weighting in the corresponding nodes in trees of neighbouring pixels is used in determining posterior probability. Input activations are derived from a problem-specific error database. Apparently it is scale invariant (iz: proportions defined at this level in the tree indicat scale intermediate to those defined?) Could be worth a revisit but I suspect it is computationally intensive.''The resulting recursive scheme for estimating the posterior probabilities of an object's presence in an image corresponds to an unsupervised feedback neural network architecture. We present here the results of experiments involving recognition of traffic signs in natural scenes using this technique.''},
  creationdate = {2005/01/01},
  haveiread    = {Y},
  keywords     = {ImageLearn, Spatial Scale},
  year         = {1997},
}

@MastersThesis{La01,
  Title                    = {Directing {P}hotogrammetry to 3{D} {C}ity {M}odelling},
  Author                   = {L-K Lai},
  School                   = {University College London},
  Year                     = {2001},

  Keywords                 = {3D},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@Misc{Leberl05,
  author       = {Franz Leberl},
  title        = {Frame camera (UCD) versus ``Push-Brooming''},
  howpublished = {Don't know},
  comment      = {See also PetrieW07},
  creationdate = {2008/02/04},
  month        = {December},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{LeePKL99,
  author    = {Lee, H Y and W K Park and T Kim and H K Lee},
  title     = {Accurate {DEM}lk extraction from {SPORT} stereo pairs: {A} stereo matching algorithms based on the geometry of the satellite},
  booktitle = {Asian {C}onference on {R}emote {S}ensing},
  year      = {1999},
  url       = {http://www.gisdevelopment.net/aars/acrs/1999/ts4/ts4028.shtml},
  comment   = {Used by HirschmuellerSH05 as a method for refining 2D matching along expected epipolar lines to a 1D search by better predicting the non-linearity of the epipolar lines.},
  keywords  = {Stereo matching, toread, 3D, height, epipolar},
  owner     = {izzy},
  creationdate = {2005/09/05},
}

@InProceedings{LeeHN00,
  author       = {Lee, S C and Huertas, A and Nevatia, R},
  booktitle    = {In {P}roceedings of {IEEE} {W}orkshop on {A}pplications of {C}omputer {V}ision},
  title        = {Modeling 3-{D} complex buildings with user assistance},
  pages        = {170-177},
  url          = {http://iris.usc.edu/Outlines/papers/2000/sungchul-wacv-00.pdf},
  comment      = {This systems requires one, two or three (depending on ambiguity) mouse clicks to create a starting rectangular 3D buildings hypothesis. The user can then add or subtrack rectangles or trangles by clicking the mouse near the appropriate vertices or edges and the automatic routines fine the best fit to the data. When multiple hypotheses are created two criteria are used to determine the best hypothesis. 1) Hypotheses that exhibit self intersections are topologically incorrect and are discarded. 2) Hypotheses are judged according to the balance of positive evidence (such as lines in the image that near or parellel to the hypothesised line) and negative evidence (such as lines in the image that intersect the hypothesised line). The system assumes flat roofed models but can be used to construct fairly complex models including buildings with layers of different shapes or sizes. Again, like Hsieh96b and others, requires some initial identification of the location of the building (we have OS MasterMap polygons!) This paper bases a lot of the quality assessment on number of clicks required by operator, as well as time taken. This could be a useful aspect to quality assessment. There is no assessment of positional accuracy etc. ``The results that can be achieved automatically [in other systems] are not completely accurate although significant progress has been made in recent years [1, 2, 3, 4]. On the other hand completely manual systems require an unacceptable amount of effort of time and cost.''},
  creationdate = {2005/01/01},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2000},
}

@InProceedings{LeitloffHS05,
  author       = {Leitloff, J and Hinz, S and Stilla},
  title        = {Automatic vehicle detection in space images supported by digital map data},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Quickbird imagery. Similar to Hinz model for aerial imagery. Contrast junction and width function meaasured along road. Fit model to these because they are noisey to identify local maxima and therefore cars.},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{LeitloffHS06,
  author       = {Jens Leitloff and Stefan Hinz and Uwe Stilla},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Automatic {V}ehicle {D}etection in {S}atellite {I}mages},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Optical imagery. Want to determine the traffic density per segment of road and the traffic situation of entire road network. The resolution is fairly low. In urban areas there are many object classes, which results in occulusions and shadow. Previous authors have used implicit and explicit modelling of vehicles. This uses global modelling. Cars are rarely isolated in urban areas. grouping show regularities (see Hinz's previous work). Working with ATKIS, although there are problems with the geographic accuracy of these data (Iz: perhaps fix this with Buthenuth's network snakes?). They exlude non-road data. Line extraction is performed according to Steger IEPAMI'98. Lines are filtered using several criteria. They analyse the width and contrast along the line and find concurrent peaks in these (by least squares matching of Gaussians to the wdith and contrast curves). The appraoch is not designed to extract grey vehicles but bright of dark (c.f. the road). The iterative contrained search performed better than the least squares. They are looking for queuea and need to improve the single car detection. The maximum gap length between cars is 1.5 cars, otherwise lines of cars are separated.},
  creationdate = {2006/09/27},
  keywords     = {road},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@TechReport{Lewis06,
  author      = {High G Lewis},
  title       = {Ontologies for Geographical Applications},
  institution = {Unversity of Southampton},
  year        = {2006},
  number      = {SESA-HGL-0601},
  comment     = {In TRIM. Start of the discussion into use of ontologies in geography. Bona fide and fiat boundaries discussed.},
  owner       = {Izzy},
  creationdate   = {2007/06/22},
}

@Article{Lewis94,
  author       = {James R Lewis},
  title        = {Sample sizes for usability studies: additional considerations},
  journaltitle = {Human {F}actors},
  year         = {1994},
  volume       = {36},
  number       = {2},
  pages        = {368-378},
  comment      = {Clare has hardcopy. Refutes some of claims of Virzi92 saying that there is no correlation between problem severity and the rate of discovery.},
  keywords     = {usability, RapidDC},
  owner        = {izzy},
  creationdate    = {2006/02/01},
}

@Article{LiL02,
  author       = {Liyuan Li and Maylor K H Leung},
  title        = {Integrating intensity and texture differences for robust change detection},
  journaltitle = ieip,
  year         = {2002},
  volume       = {11},
  number       = {2},
  pages        = {105--112},
  comment      = {Texture difference measure is a gradient value that defines how grey level changes within a neighbourhood. The partial derivative for this is defined using the Sobel operator. These are compared between images and are shown to be robust to changes in illumination and noise. This is integrated with an intensity measure using two methods. Implemented in a real-time technique.},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
}

@Misc{Li00,
  Title                    = {Modeling {I}mage {A}nalysis {P}roblems {U}sing {M}arkov {R}andom {F}ields},

  Author                   = {Stan Z. Li},

  creationdate                = {2005/01/01},
  Url                      = {citeseer.nj.nec.com/li00modeling.html}
}

@InBook{LiBD01,
  author       = {Li, Xiaopeng and Baker, A Bruce and Dickson, George},
  title        = {G{IS} for {M}odeling {C}artographic {D}esign},
  chapter      = {ACCURACY ASSESSMENT OF MAPPING PRODUCTS PRODUCED FROM THE STAR3i`AIRBORNE IFSAR SYSTEM},
  editor       = {Alexander Martyneko and Tamara Nyrtsova and Sergei Glazov},
  url          = {http://www.intermap.com/images/papers/STAR3iaccuracyassessmentICC2001.pdf},
  comment      = {Briefly describes how Digital Elevation Models (DEMs), Digital Ortho Images (DOIs) and Topographic Line Maps (TLMs) can be created suing IFSAR data. Ground truth took the form of check points collected from photogrammetric data. ``Using 1:24,000 photogrammetric data set as .base data. and for the given terrain situations, the findings from the accuracy assessment studies are as followings:* DOI accuracy - The mean offset between the horizontal locations of DOI image points and checkpoints is 2.4m (less than one pixel) with a 1.3m standard deviation. * DEM accuracy - STAR-3i DEM is about a half meter higher than the comparative photogrammetric data. There could be some minor uncompensated systematic effect in the DEM data. The RMSE value of 1.2m is close to the claimed 1m value. STAR-3i GT1 DEM can be used for orthorectifying aerial photographs with 1:5,000 or smaller scale in order to meet the National Mapping Accuracy Standard. The feasibility of applying STAR-3i generated DEM for orthorectifying IKONOS images is also well demonstrated. * TLM accuracy - Generally, the contour lines on the TLM are a very good characterization of the surface. The interpolation process of the contour lines from the DEM and the breaklines introduce extra error budget. Even so, it is still well within one-third of the 10m contour. Smaller contour intervals are also possible based on''},
  creationdate = {2005/01/01},
  institution  = {Intermap},
  keywords     = {quality, DEM},
  owner        = {izzy},
  year         = {2001},
}

@Article{LiG04,
  author       = {Zhang Li and Armin Gruen},
  title        = {Automatic {DSM} generation from linear array imagery data},
  journaltitle = {The International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year         = {2004},
  volume       = {XXXV},
  number       = {Part B3, Commission III},
  pages        = {128-133},
  comment      = {Description of work into image matching to produce DSMs. Uses feature point matching, edge matching and grid point matching.},
  keywords     = {DSM, image matching},
  owner        = {Izzy},
  creationdate    = {2009.03.09},
}

@InProceedings{LinN96,
  author    = {Chungan Lin and Ramakant Nevatia},
  title     = {Buildings detection and description from monocular aerial images},
  booktitle = {A{RPA} {I}mage {U}nderstanding {W}orkshop},
  year      = {1996},
  url       = {http://iris.usc.edu/Outlines/papers/1996/lin-iuw96.pdf},
  comment   = {In TRIM
Review:
Many other systems (gives refs) use shadow evidence to infer height. In this research buildings modelled from monocular views (mainly oblique). The system detects edges and then these are grouped hierarchically to form parallel features, then U-contour features and then parallelograms. THese are roof hypotheses. Camera model is used to compute skewness of reoof hypothesis in oblique views. Hypotheses are selected using local selection (for example do lines, corners and their spatial relations support the hypothesis?) and then global selection (for example do locally supported hypotheses NOT overlap?). Shadow and wall evidence is then used for verification. The possible position of shadow is computed using sun and view angles (gives equations!) and roof hypothesis. If candidate shadows are found these are given confidence values and the highest confidence value is taken as the roof shadow and used to calculate height. Wall evidence is then collected for verification. Again, possible positions of wall verticals are calculated from orientation inforamtio and confixence measures are calculated for each possibility. The two sets of confidence scores (or only one if necessary) are used to give overall confidence (using the stated equation). A threshold is used to determine which hypotheses are retained. Assessment is visual and uses detection percentage and brach factor of Shufelt as well as correct building pixel percetnatge and correct background pixel percentage which is based on classifying pixels in the image using derived models (also in Shufelt apparently). Better results were achieved for the nadir view. Missed biuldings tended to be small (correct building pixel percentage >> detection percentage). Many buildings in scenes - little background. Errors tended to be with dark roofs (difficult to detect shadows). Compare confidence values with results and find some good correlation and state therefore tha confence / self-evaluation is useful to the interactive environemnt (assist operator).},
  keywords  = {3D, quality},
  creationdate = {2005/01/01},
  wherefind = {Have hardcopy},
}

@Article{LiowP90,
  author       = {Y-T Liow and T Pavlidis},
  journaltitle = {cvgip},
  title        = {Use of shadows for extracting buildings in aerial images},
  pages        = {242-277},
  volume       = {49},
  comment      = {From ShufeltM93: ``described two shadow-based analysis systems based on a combination of region growing and edge detection for extracting buildings from aerial imagery. One system employed edge detection to locate shadow boundaries, followed by region growing and morphological analysis to form biudling hypotheses. The other employed region segmentation to generate hypotheses, using shadow and contour adjustment to refine the hypotheses.''},
  creationdate = {2005/09/09},
  keywords     = {DeepLEAP},
  owner        = {izzy},
  wherefind    = {don't have},
  year         = {1990},
}

@Article{LiuKD04,
  author       = {Liu, X and Kim, W and Drerup, B},
  title        = {3D characterization and localization of anatomical landmarks of the foot by FastSCAN},
  journaltitle = {Real-time Imaging},
  year         = {2004},
  volume       = {10},
  number       = {4},
  pages        = {217-228},
  url          = {http://www.kpal.co.uk/particle_shape_info.htm},
  abstract     = {The landmarks on the body surface are important to shape and motion analysis. It is much better if the landmarks are anatomical ones, which are independent of position and coordinate system. The objective of this method is to present an easy-implemented method for extracting anatomical landmarks on the cylindraceous body surface which could be used in motion analysis or in medical treatment. The surface is scanned by FastSCAN (Polhemus, Colchester, Vermont, USA) and described by scattered three-dimensional surface points. The method provides the estimation of second-order derivatives by way of least-squares surface fitting to calculate the Gaussian curvature and mean curvature. To separate convexity from concavity, the Koenderink shape index maps of foot and leg are given as examples. The landmarks formed by underlying muscles and skeletal structures such as the malleoli distinguish themselves clearly on the Koenderink shape index maps. Minutes after the foot and leg are scanned, the curvature maps of the foot and leg provide the shape information and the loci of landmarks avail the statistical shape analysis as well as foot underside deformation analysis. Furthermore, the anatomical landmarks around the knee and ankle, defining the transcondylar and transmalleolar axis, make it possible to calculate the tibial torsion by this non-invasive way. Generally, this method is fast and accurate. However, it gives some inaccurate results on the patch edge, which should be interpreted with caution, when it is applied on a surface patch in other occasions because of a small number of points unevenly distributed in the operator. Presently, the method is computationally intensive although the time can be reduced to a few seconds at the sacrifice of image resolution. Further efforts will be made to get the real-time information.},
  comment      = {Fit Gaussian curves to scans of feet, ankles and knees to determine convexity and concavity for using in motion analysis or medical treatment.},
  keywords     = {morphology},
  owner        = {izzy},
  creationdate    = {2008/02/13},
}

@Article{Loncaric98,
  author       = {S. Loncaric},
  journaltitle = {Pattern Recognition},
  title        = {A survey of shape analysis techniques},
  number       = {8},
  pages        = {983--1001},
  volume       = {31},
  comment      = {In filing cabinet.
Review:
Starts by overviewing the different classifications of shape analysis techniques. Methods can be based on the boundary of the shape or the whole shape. They can result in numeric (scalar transform) or non-numeric (space-domain) outputs. Finally they can be information preserving or not - this is some results allow the original shape to be reconstructed whereas others don't. There are also a number of criteria set out for shape description methods. The article then outlines human visual perception.Then the techniques are divided into four sections - boundary scalar (e.g. centroid to boundary distance), boundary space-domain (e.g polygonisation), global scalar (e.g. shape matrices) and global space-domain (e.g. medial axis transform). A useful overview. Solely focussed on 2D shapes but it may be possible to translate some things to 3D? From this paper but copied from IyerJLKR05: ``Shape representation methods result in a non-numeric representation of the original shape (e.g. a graph) so that the important characteristics of the shape are preserved...Shape description refers to the methods that result in a numeric descriptor of the shape and is a step subsquent to shape representation. A shape description method generates a shape descriptor vector (also called a feature vector) from a given shape. The goal of description is to uniquely characterize the shape using its shape description vector''.},
  creationdate = {2007/11/16},
  keywords     = {shape},
  owner        = {Izzy},
  year         = {1998},
}

@Book{Mantyla88,
  author       = {M\''{a}ntyl\''{a}, M},
  title        = {An introduction to solid modelling},
  publisher    = {Computer Science Press},
  series       = {Principles in Computer Science},
  address      = {Maryland, USA},
  comment      = {Seems to be the book referenced by everone when talking about choices of models for solid objects},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {1988},
}

@InProceedings{MuehlichM05,
  author       = {Matthias M\''{u}lich and Rudolf Mester},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {A fast algorithm for statistically optimized orientation estimation},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Work to estimate the orientation of a pattern. Actually the pattern is stripes which is then resampled.Mpstly maths.},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{MuellerZ05,
  author       = {S\''{o}nke M\''{u}ller and Zaum, Daniel Wilheim},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  title        = {Robust building detection in aerial images},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {http://www.commission3.isprs.org/cmrt05/papers/CMRT05_Mueller_Zaum.pdf},
  volume       = {XXXVI},
  comment      = {RGB images converted to HSI. Seed points evenly spaced over image at distance that should ensure all images are hit. Region growing segments the image. Red channel histogram used to determine likely roof regions. Opening and closing removes ragged edges of regions. Adjacent regions are merged. Area and mean hue angle are used to find likely roof regions. a whole stack of geometric and structural features are then used to model the roofs. Quality assessment is detection percentage and branch factor of buildings (not pixels or voxels in buildings).},
  creationdate = {2005/11/25},
  keywords     = {3D, quality, DeepLEAP},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{Maas99,
  author       = {Maas, H-G},
  booktitle    = {International {A}rchives of {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation {S}ciences},
  title        = {Fast determination of parametric house models from dense airborne laser scanner data},
  pages        = {245-53},
  url          = {http://www.tu-dresden.de/fghgipf/forschung/material/publ_maas/Maas_Bangkok99.pdf},
  volume       = {XXXII-2-5-3/W10},
  address      = {Bangkok, Thailand},
  comment      = {''The point density to be aspired for the reconstruction of buildings should be at least one point per square meter. If building details such as dorms on roofs are to be modeled, a point density in the order of five points per square meter should be provided. This data density allows an accuracy potential in the order of 10 - 20 cm. Despite this stand-alone potential of laserscanning, a high-resolution digital camera integrated on a laserscanner platform remains desirable. Besides image information to be used for texture mapping, it may provide valuable information on edges, thus forming a perfect complement to laserscanning data. Moreover, data from an integrated multispectral sensor might also be used to strengthen the segmentation process and to widen the range of objects, which can be detected and modeled.''},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {1999},
}

@Article{MaasV99,
  author       = {Maas, H-G and Vosselman, G},
  journaltitle = ijprs,
  title        = {Two algorithms for extracting building models from raw laser altimetry data},
  pages        = {153-63},
  volume       = {54},
  comment      = {''Dense laser altimetry datasets with a point density of 1 point/m^2 or higher depict a very valuable source of data for the automatic generation of 3-D city models. Based on the computation of invarient moments, closed solutions can be formulated for the detemination of the parameter of simple building models, yielding a precision of 0.1-0.2 m for the building dimensions and 1-2 degrees for the building orientation and the slope of roofs. Going beyond primitive house models, techniques based on the analysis of moments do also allow for modelling asymmetric deviations like dorms on roofs. Using a data driven technique based on the intersection of planes fitted into trigulated point cloulds, models of more complex buildings can be determined....Besides fusion with avilable GIS data, future work should concentrate on the fusion with photogrammetric imagery for a sharper modelling of edges and the fusion with multispectral imagery to support the segmentation process.''},
  creationdate = {2005/01/01},
  keywords     = {morphology, lidar},
  owner        = {izzy},
  text         = {Maas, H-G and Vosselman, G, 1999. Two algorithms for extracting building models from raw laser altimetry data. {ISPRS} Journal of Photogrammetry and Remote Sensing, 54:153-63},
  wherefind    = {slsmith},
  year         = {1999},
}

@Unpublished{Mayer02,
  author       = {Helmut Mayer},
  title        = {Automated {R}oad {E}xtraction from {A}erial and {S}atellite {I}magery},
  note         = {Loughborough Feature Extraction Workshop: commercial in confidence},
  abstract     = {This presentation summarizes the work on road extraction developed over the last decade in Munich. It emphasizes the importance of multiple scales as well as context and shows how roads are extracted in rural areas based on (perceptual) grouping and so-called ``snakes''. The extracted roads and crossings are then connected by a global grouping step taking into account the network character of roads. Additionally, recent developments on road extraction in urban areas are sketched. The evaluation of road extraction results has led to the formation of an OEEPE working group.},
  creationdate = {2005/01/01},
  year         = {2002},
}

@Article{Mayer99,
  author       = {Mayer, Helmut},
  title        = {Automatic {O}bject {E}xtraction from {A}erial {I}magery - {A} {S}urvey {F}ocusing on {B}uildings},
  journaltitle = {Computer {V}ision and {I}mage {U}nderstanding},
  year         = {1999},
  volume       = {74},
  number       = {2},
  pages        = {138--149},
  url          = {\\os2k17\r&i_data6\Lammergeier\share_library\Mayer99.pdf},
  comment      = {Great paper that structures work into building e},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@InProceedings{MayerHBB06,
  author       = {Helmut Mayer and Stefan Hinz and Uwe Bacher and Emmanuel Baltsavias},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {A {T}est of {A}utomatic {R}oad {E}xtraction {A}pproaches},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. The EuroSDR test. Fully automatic approaches. Questionnnaires were sent to researchers and manufactureres and also producer but only one of the latter responded (IZ: what about users?)Data used included aerial images, satellite images with different complexities. Most groups modelled the road axes and the width, not lanes or markings. Complex junctions were not modelled. Most undertook feature extraction then generated the network. There is still plenty of room for improvement of the results especially as these don't seem to match the stated desires of the producer. Compared to reference data from a human operator. There is no weighting for major and minor roads. Comment from Heipke is that the entire scene, not just the roads, should be modelled, especially in urban areas. Hans-Peter Baehr alter pointed out that existing data should be used. Iz: this is a peculiar study. The sorts of training sites being used already have road data existing - so why not use. Other areas without road data could hae a different problem when it comes to extracting roads from images.},
  creationdate = {2006/09/27},
  keywords     = {road extraction, DeepLEAP},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{MayerR06,
  author       = {Helmut Mayer and Sergiy Reznik},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {M{CMC} {L}inked {W}ith {I}mplicit {S}hape {M}odels and {P}lane {S}weeping for 3{D} {B}uilding {F}acade {I}nterpretation in {I}mage {S}equences},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. 3D reconstruction includes windows etc. Approach is fully automatic. ``More scientific than practical like Fabio''. (RemondinoZ06) Foerstner point are least-squares matched. Do lots of bundle adjustments (very important). Plane hypotheses are derived from matching and RANSAC. Train the model using window corner pathces at the same scale as the data plus vectors from the centre of the window to its corner. At this stage the Foerstner points are found. A gaussian kernal is used to integrate and determine the wondow centre. Delineation of windows uses MCMC. They combine this with implicit shape information. Once the windows are found, they are 'cut out' and positioned at a range of distances behind the plane of the wall until they best fit all the views, thus finding the location of the plane of the window.At question at the end of this presentation asked if MCMC was necessary and perhaps a simple gradient descent could have been used. Response was that MCMC gets around the problem of local minima.},
  creationdate = {2006/09/27},
  keywords     = {facade extraction},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{MayerR05,
  author       = {Mayer, Helmut and Reznik, Sergiy},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  title        = {Building fa\c{c}ade interpretation from image sequences},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  organization = {Joint workshop of ISPRS and DAGM},
  volume       = {XXXVI},
  comment      = {In TRIM
Review:
point extraction and sub-pixel least squares matching. See also Hartley and Zisserman 2003. Some intersting work into finding windows in ground based views of buildings. Since the paper was written they have looked into row hypotheses - so that they can assume similar wondows in a row. Mumford 2000 ``The dawning of the age of stochasticity'' - check through the references for this.},
  creationdate = {2005/09/05},
  keywords     = {facade extraction},
  year         = {2005},
}

@InProceedings{McGloneS94,
  author       = {McGlone, J.C. and Shufelt, J.},
  booktitle    = {Proc. {IEEE} {C}omputer {V}ision and {P}attern {R}ecognition},
  title        = {Projective and Object Space Geometry for Monocular Building Extraction},
  pages        = {54-61},
  comment      = {A building detection system based on line-corner analysis of monocular imagery. ``The paper describes the current status of the BABE system, starting with the extraction of horizontal and vertical edges and a brief description of the BABE system.'' Vanishing point geometry, as used by other researchers, not very appropriate for aerial imagery because the perspective effects are small and the edges are only a few pixels long. Lines are identified and labelled as vertical, horizontal or neither. Corners between lines are identified creating sequences of edges forming boxes. Given two basic building models - flat roofed and gable-roofed, the 2D expressions of these from different angles are calculated including the labeling of horizontal, vertical and neither. The boxes found in the image are compared to these 2D models to form building hypotheses where the correct sequences of line directions are found. These partial hypotheses are then extrapolated to full building hypotheses. To determine the building height, the location of building roof corners is located in the image and a search is performed to find high gradient in the pixel values in the direction orthogonal to the direction of the vertical vanishing point. This is performed for all pixels within a window of the building roof corner to generate a set of vertical edge hypotheses. The line with the greatest confidence (as determined by the line length and the image gradient) is chosen as the building vertical. The height for each building vertical (that would be visible in the image) is calculated and the height for the building is calculated as the same as the building vertical with the highest product of confidence and vertical length. This building height is used to fit a 3D building model in the scene. Quality assessment is performed in the image (pixel) and object (voxel) space using the measures from ShufeltCh699. They discuss simply comparing correctly classified pixels to number of pixels overall instead of current measures, but consider this latter method insensitive to error because nonstructured hypotheses could get a high score even though they are meaningless. Would like to develop system to work with 3D hypotheses rather than 2D boxes.},
  creationdate = {2005/08/12},
  keywords     = {3D, quality},
  owner        = {izzy},
  wherefind    = {izzy},
  year         = {1994},
}

@Article{McKeownBCHMS00,
  Title                    = {Performance Evaluation for Automatic Feature Extraction},
  Author                   = {David M McKeown and Ted Bulwindle and Steven D Cochran and Wilson A. Harvey and Chris McGlone and Jefferey A. Shufelt},
  Year                     = {2000},
  Number                   = {Part B2},
  Pages                    = {379-394},
  Volume                   = {Volume XXXIII},

  Journaltitle             = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  Keywords                 = {3D, toread},
  Owner                    = {izzy},
  creationdate                = {2005/01/01},
  Url                      = {http://www-2.cs.cmu.edu/afs/cs/usr/sdc/www/papers/paper-0007.html}
}

@InProceedings{MeidowS05,
  author       = {Meidow, Jochen and Schuster, Hanns-Florian},
  title        = {Voxel-based quality evaluation of phtogrammetric building acquisitions},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {http://www.ipb.uni-bonn.de/fileadmin/publication/pdf/Meidow2005Voxel.pdf},
  comment      = {Single test data set with no redundancy therefore reference data set is required for quality assessment. base all quality measures on this. If reference data set is error free can get accuracy. If it is high qulaity cfan get approximate accurancy. Have formulated criteria to select the measures. These are that the measures must be reliable computable, require moderate technical effort, be usable both planimetrically and volumetrically, they must be locally and globally identical, they must be easily interpreted, they must be invariable to the concept used to capture the data. The measures remaining after applying these criteria include: the qulaity rate, the branch factor (false positive), the miss factor (false negative), and the detection rate (true positive). The internal represention of buildings - different operators interpret the builsing in terms of unit (eg buildings in a terrace) differently. How to compute? Vectors are complex (eg R intersect T) and so an error free represnttaiotn is time consuming therefore a volumetric grid is used. A B-REP is used for evaluation. They count the intersections of the rays with boundaries to determine if the point is inside or outside the model.I shoudl look into 'hashing'. This work tested InJect against CC-Modeler. Meta data should be included with the model and this should include the purpose of acquisition, date of overflight to allow better decision making on the results of the qulaity assessment. Have to set the resolution of the volume grid depnding on the point accuracy og the measurment system. The reference data used in this test was provided to the authors so no real idea of its qulaity, specification, etc. Should read the paper.},
  keywords     = {3D, quality, 3DCharsPaper},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{MeyerHLB05,
  author       = {Meyer, Franz and Hinz, Stefan and Laika, Andreas and Bamler, Richard},
  title        = {A-priori information driven detection of moving objects for traffic monitoring by spaceborne {SAR}},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Some cunning stuff detecting moving vehicles in SAR.Need to know orientation of direction and speed to determine the offset of car manifestation in the image. Can get orientation from road information (Navtech). A priori information to predict probability density function of vehicle. Need brightness and velocity. Couldnt quite figure where this came from but it gave improved ROCs.},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{MeyerHLSB06,
  author       = {Franz Meyer and Stefan Hinz and Andreas Laika and Steffen Suchandt and Richard Bamler},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Performance {A}nalysis of {S}paceborne {SAR} {V}ehicle {D}etection and {V}elocity {E}stimation},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Vehicle detection in SAR. The displacement of the vehicles' signals is proportional to their velocity and the angle of the signal. Interferometry is also possible (using a signal that is split along track). This uses a two step appraoch. They detect vehicles and then estimate the velocity. Use NAVTEQ data for road orientation and position. The magnitude and phase plotted against each other show the PDF of different features. Detection increases with brighter vehicles and faster vehicles. Artificially added vehicles to SAR data to test. Different estimators for different road headings.},
  creationdate = {2006/09/27},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{MichaelsonST05,
  author       = {Michaelson, E and Soergel, U and Thoennessen, U},
  title        = {Potential of building extraction from multi-aspect high-resolution amplitude {SAR} data},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Extract building outlines from data of about 1meter resoltuion. PAMIR-FGAN.},
  keywords     = {building},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{MindruMV99,
  author       = {F Mindru and T Moons and Van Gool, L},
  title        = {Recognizing color patterns irrespective of viewpoint and illumination},
  booktitle    = {Proceedings of the {IEEE} conference on computer vision and pattern recognition ({CVPR}99)},
  year         = {1999},
  organization = {IEEE},
  month        = {June},
  pages        = {368-373},
  address      = {Fort William, Colorado},
  comment      = {In TRIM
Review:
Similarly to StepanMC03 I wish I understood this. Generates a whole stack of moments and defines invariants based on these...?},
  creationdate    = {2005/01/01},
}

@InProceedings{Minut00,
  Title                    = {Face {R}ecognition {U}sing {F}oveal {V}ision},
  Author                   = {Silviu Minut and Sridhar Mahadevan and John M. Henderson and Fred C. Dyer},
  Booktitle                = {Biologically {M}otivated {C}omputer {V}ision},
  Year                     = {2000},
  Pages                    = {424--433},

  Comments                 = {In humans the fovea covers about 2 degrees of the FOV. The human vision system rapidly reorients the eyes using very fast eye movements called saccades which are up to 900 degree per second (see paper for refs). An eyetracker was used to determine where human subjects looked on an image of a face in order to learn it. A high correlation was found between subjects of the the patterns of eye movements, fixation points and fixation durations. Hidden Markov Models (HMM) were used to generate the scan patterns - the model is defined by a transition probabilities (between states) and observation densities (at each state) and that is as far as i can understand. Look at Rabiner, L, 1989. A tutorial in hidden markov models and selected applications in speech recognition. In this case these scan patterns are fixed (they intend to generalise to Partially Observable Markov Decision Processes which will allow for individual optimtisations in scan patterns across different faces). Used 2 different types of foveal processing - super pixels where groups of pixels (super pixels) all contained the average of the corresponding pixels in the original image and the groups became larger towards the edge of the image. The other method was log-polar transform. A set of observation vectors was created using 10 predefined regions (defined using the eyetracker data) from each image from the library and each region was foveated. The recogniser was trained using a predefined number of states to generate a HMM for each face. In the testing phase the classifier matched each image to the HMMs. This method does not require retraining on the whole set with every new image added to the library. It was more successful that other previous HMM methods that had more arbitrary division of faces but it performed less well compared to 'eigen faces'.},
  creationdate                = {2005/01/01},
  Url                      = {citeseer.nj.nec.com/439709.html}
}

@Article{ModestinoZ92,
  author       = {James W Modestino and Jun Zhang},
  title        = {A {{M}arkov} random field model-based approach to image interpretation},
  journaltitle = iepami,
  year         = {1992},
  volume       = {14},
  number       = {6},
  pages        = {606--615},
  url          = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=37888},
  abstract     = {In this paper, a Markov random field (MRF) model-based approach to automated image interpretation is described and demonstrated as a region-baaed scheme. In this approach, an image is first segmented into a collection of disjoint regions which form the nodes of an adjacency graph. Image interpretation is then achieved through assigning object labels, or interpretations, to the segmented regions, or nodes, using domain knowledge, extracted feature measurements and spatial relationships between the various regions. The interpretation labels are modeled as a MRF on the corresponding adjacency graph and the image interpretation problem is formulated as a maximum a posteriori (MAP) estimation rule. Simulated annealing is used to find the best realization, or optimal MAP interpretation. Through the MRF model, this approach also provides a systematic method for organizing and representing domain knowledge through the clique functions of the pdf of the underlying MRF. Results of image interpretation experiments performed on synthetic and real-world images using this approach are described and appear promising.},
  comment      = {Gives a reasonable explanation of MRF on graphs. Use MRF on a pre-segmented image to label the regions.},
  haveiread    = {Y},
  keywords     = {ImageLearn},
  creationdate    = {2005/01/01},
}

@TechReport{Mohan99,
  author      = {Mohan, Anuj},
  title       = {Object detection in images by components},
  institution = {Massachusetts Institute of Technology, Artificial Intelligence Laboratory},
  year        = {1999},
  type        = {A.I. Memo No. 1664},
  number      = {C.B.C.L. Paper No. 178},
  month       = {June},
  comment     = {Reallly clearly written. Outlines three basic object detection approaches: model-based (the model is defined for the object of interest), image invariance methods which uniquely detemine the objects being searching for and example-based learning algorithms. This work uses the latter in the following manner. The human body is seen as made up of components - arms, legs and head. Wavelets are used to detect these components and then SVM are used to classify them. People were then considered to have been found if all the components are found in the right locations to make up a body. Use ROC curves.},
  haveiread   = {ish},
  creationdate   = {2005/01/01},
  wherefind   = {In TRIM},
}

@Article{MohanN89,
  author       = {R Mohan and R Nevatia},
  journaltitle = {iepami},
  title        = {Using perceptual organization to extract 3-{D} structures},
  number       = {11},
  pages        = {1121-1139},
  volume       = {11},
  comment      = {From ShufeltM93: ``present a method by which simple image tokens such as lines or edges could be clustered into more complex geometric features consisting of parallelopipeds. They used constraint-satisfaction networks to decide which features were mutually supportive and which features subsumed or elimintated other features. They also applied set operations to the segments of features to merge pairs of features.''},
  creationdate = {2005/09/09},
  keywords     = {toread, 3D},
  owner        = {izzy},
  wherefind    = {don't have},
  year         = {1989},
}

@Article{Monga07,
  author       = {Monga, Olivier},
  journaltitle = {Image and Vision Computing},
  title        = {Defining and computing stable representations of volume shapes from discrete trace using volume primitives: Application to 3D image analysis in soil science},
  number       = {7},
  pages        = {1134-1153},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/Monga07.pdf},
  volume       = {25},
  abstract     = {This paper presents an innovative approach for defining and computing stable (intrinsic) representations describing volume shapes from discrete traces without any a priori information. We assume that the discrete trace of the volume shape is defined by a binary 3D image where all marked points define the shape. Our basic idea is to describe the corresponding volume using a set of patches of volume primitives (bowls, cylinders, cones...). The volume primitives representation is assumed to optimize a criterion ensuring its stability and including a characterization of its scale (trade-off. fitting errors/number of patches). Our criterion takes also into account the preservation of topological properties of the initial shape representation (number of connected components, adjacency relationships...). We propose an efficient computing way to optimize this criterion using optimal region growing in an adjacency valuated graph representing the primitives and their adjacency relationships. Our method is applied to the modelling of porous media from 3D soil images. This new geometrical and topological representation of the pore network can be used to characterize soil properties. (C) 2006 Elsevier B.V. All rights reserved.},
  comment      = {Data are 3D tomography images of soil - ie voxels - and purpose is to define shapes from which volume is built, e.g. finding cylinders that describe wormholes. Not very well written and not very relevant.},
  creationdate = {2008/02/13},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {2007},
}

@Article{MoonCR02,
  author       = {Hankyu Moon and Rama Chellappa and Azriel Rosenfeld},
  journaltitle = ieip,
  title        = {Optimal edge-based shape detection},
  number       = {11},
  pages        = {1209--1227},
  volume       = {11},
  comment      = {Define edge operators based on derivative of double exponential (DODE) which they find is better than the derivative of Gaussian (DOG). I think they define the edge detector to look for the prefefined shape at the same time. E.g. if looking for cars, edge detection looks for parallelogram made up of 4 elongated edge operators. Could be owrth a try. DODE is described by J Ben-Arie and K R Rao:Optimal edge detection using expansion matching and restoration. iepami:16''1169--1182},
  creationdate = {2005/01/01},
  haveiread    = {Y},
  keywords     = {DeepLEAP1},
  year         = {2002},
}

@InProceedings{MorganH03,
  author    = {Morgan, Michel and Habib, Ayman},
  title     = {Interpolation of Lidar Data and Automatic Building Extraction},
  booktitle = {ACSM-ASPRS 2002 Annual Conference Proceedings},
  year      = {2002},
  comment   = {Haven't read it all so read properly before citing. Seems that the breaklines in the data are extracted before the data are filtered so that the edges of objects are obtained. This uses region growing and merging which finds regions of similar characteristics. Looks interesting, but examples are only small areas. Would be interesting to see more recent work.},
  keywords  = {3D, DSM, lidar},
  owner     = {Izzy},
  creationdate = {2009.03.09},
}

@InProceedings{MorganKJH04,
  author    = {Morgan, M and K Kim and S Jeong and A Habib},
  title     = {Epipolar geometry of linear array scanners moving with constant velocity and constant altitude},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  comment   = {In TRIM
Review:
Mentioned in HirschmuellerSH05. Paper is about shape analysis of epipolar lines. Defines epipolar lines in two ways. The traditional way is to described it as the intersection of the spipolar plane with the image. The other way given is that it is the locus of all possible conjugate points of a point in the first image one the other image by changing the height of that point. Also gives two ways of calculating the epipolar lines (from Kraus 1993). Defines the image as the recorded sensory data associated with one exposure station and the scene as the recorded sensory data or one or more exposure stations (which is not the usual definition). This means that a set of line scanner images makes up a scene. Stereo coverage in linear array scanners can be achieved in three ways - by adjusting the roll angle for the second image (e.g. SPOT), by adjusting the pitch angle for the second image (e.g. IKONOS) or by scanning three lines simultaneously (e.g. ADS40). It has already been shown that, because the external orientation parameters are different for each scanned line, the epipolar lines for scanned scenes are not linear. This paper investigates whether this is the case for the constant velocity constant altitude model. It finds that epipolar lines are still non-linear but are straighter at higher altitudes. Curvature is also less with the three-line scanner and the adjusted pitched scenes than with the adjusted rolls scenes.},
  keywords  = {epipolar},
  creationdate = {2005/10/14},
}

@Book{MoserK71,
  Title                    = {Survey Methods in Social Investigation},
  Author                   = {Moser, C A and Kalton, G},
  Publisher                = {Gower},
  Year                     = {1971},

  Address                  = {Aldershot, UK},

  Owner                    = {Izzy},
  creationdate                = {2007/05/31}
}

@Article{NicolinG87,
  author       = {B Nicolin and R Gabler},
  journaltitle = {iegrs},
  title        = {A knowledge-based system for the analysis of aerial images.},
  number       = {3},
  pages        = {317-329},
  volume       = {GE-25},
  comment      = {From ShufeltM93: ``described a system for analysis of aerial images. The system had four component: a method-base of domain-independant processing techniques, a long-term memory containng a priori knowledge about the problem domain, a short-term memory containing intermediate results from the image analysis process, and a control module responsible for invocation of the various procsesing techniques. Gray-level analysis was applied to a resolution pyramid of imagery to suggest segmentation techniques, and structural analysis was performed after segmentation to provide geometric interpretations of the image. These interpretations were then given confidence values based on their similarity to known image features such as roads and houses.''},
  creationdate = {2005/09/09},
  keywords     = {quality},
  owner        = {izzy},
  wherefind    = {don't have},
  year         = {1987},
}

@InProceedings{Niederost00,
  author       = {Nieder\''{o}st, M},
  booktitle    = {I{APRS}},
  title        = {Reliable {R}econstruction of {B}uildings for {D}igital {M}ap {R}evision},
  url          = {http://e-collection.ethbib.ethz.ch/ecol-pool/bericht/bericht_90.pdf},
  volume       = {33},
  address      = {Amsterdam},
  comment      = {Haven't read - referecned by BaltsaviasH00},
  creationdate = {2005/01/01},
  keywords     = {3D, quality, toread},
  owner        = {izzy},
  year         = {2000},
}

@Misc{NielsenXX,
  author       = {Jakob Nielsen},
  title        = {How to {C}onduct a {H}euristic {E}valuation},
  howpublished = {internet},
  note         = {Last modified: 29 April 2005. \url{http://www.useit.com/papers/heuristic/heuristic_evaluation.html}},
  url          = {http://www.useit.com/papers/heuristic/heuristic_evaluation.html},
  comment      = {''It is certainly true that some usability problems are so easy to find that they are found by almost everybody, but there are also some problems that are found by very few evaluators. Furthermore, one cannot just identify the best evaluator and rely solely on that person's findings. First, it is not necessarily true that the same person will be the best evaluator every time. Second, some of the hardest-to-find usability problems (represented by the leftmost columns in Figure 1) are found by evaluators who do not otherwise find many usability problems. Therefore, it is necessary to involve multiple evaluators in any heuristic evaluation (see below for a discussion of the best number of evaluators). My recommendation is normally to use three to five evaluators since one does not gain that much additional information by using larger numbers.''},
  creationdate = {2005/12/20},
  keywords     = {usability, RapidDC},
  owner        = {izzy},
  year         = {2005},
}

@Misc{NixonXX,
  author       = {Mark Nixon},
  title        = {Computer Vision Lecture 6: The Hough Transform},
  year         = {1997},
  howpublished = {Lecture notes},
  comment      = {In filing cabinet},
  owner        = {izzy},
  creationdate    = {2008/02/04},
}

@Article{NoronhaN01,
  author       = {Noronha, Sanjay and Nevatia, Ramakant},
  title        = {Detection and modeling of buildings from multiple aerial images},
  journaltitle = iepami,
  year         = {2001},
  volume       = {23},
  number       = {5},
  pages        = {501-518},
  comment      = {In TRIM. Kim01 references with respect to epipolar modelling. Useful for a list of methods using monocular images, multiple images and range data. Use the hypothesise and verify approach with decisions being delayed until all the information is available. Lines are matched between images using epipolar and height constraints (the latter being set by the operator). This forms a quadrilateral within which the corresponding line in the next image must fall. Find junctions in lines and match these across using epipolar constraints, line match constraints (the lines that connect at the junction must match), orthogonality (the 3D angle between the lines but be roughly orthogonal) and the tinocular constraint (the junction appears in a third image at the intersection of the epipolar lines for that junction found in the first and second images. Parallel lines and u-contours are also found based on sets of constraints. Flat-roof and gable roof hypotheses are then formed and selected and finally these hypotheses are verified using roof, wall and shadow evidence. Quality is assessed as the running time (the time it took to undertake each stage) and the detection ability in the form of detection percentage and branch factor of buildings (from paper that probably follows LinN96). Correct building pixel, incorrect building pixel and correct nonbuilding pixel percentages (from ShufeltM93) were also computed. More than two views increased the quality of the assessment. The site seems very simple compared to European regions as the roads are in a grid form and buildings simple in shape and in line with the grid. Also the terrain is very flat (shadow verification would not be possible otherwise).},
  keywords     = {3D, quality, epipolar},
  creationdate    = {2005/10/14},
  wherefind    = {izzy - hardcopy},
}

@Article{Norvelle92,
  author       = {F Raye Norvelle},
  title        = {Stereo correlation: {W}indow shaping and {DEM} corrections},
  journaltitle = pers,
  year         = {1992},
  volume       = {58},
  number       = {1},
  pages        = {111-115},
  comment      = {Performing area-based matching between two images with regularly-spaced points chosen in left image. The local points that have been already matched are used to predict the likely location of the next point for matching in the right image. Furthermore, this prediction is used to change the shape of the window used over the left image so that it corresponds to a rectangle defined in the right image. Finally, iterative orthophoto refinements are undertaken. Here a left and right orthophoto is creted using the disparity map. These are compared and the differences are used to upate the disparity map. This continues until the two images are equal.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@MastersThesis{Nwankwoeze07,
  author       = {Chijioke Williamson Nwankwoeze},
  title        = {Roof classification from aerial photography},
  comment      = {In filing cabinet
Review:
The literature review covers clearly everything that's relevant to the work, the methods chosen were well-considered and implemented and the analysis too thorough. Much of the classification is on spectral characteristics and finding roof materials, which actually seems to work rather well. Its not completely clear how the field work data were used, but the images from the field are interesteding. Some work using the image matching DSM to classifiy by morphology was attempted - the classification is by eye using transects but proves a simple point. Notes that the DSM from lidar would be better. Accuracy assessment is based on visually identified training data and uses error matrices and kappa coefs. Some useful listings of classes - different types of roof shapes - flat, mansard, plain pitch, pavillion, catslide (that one isn't in wikipedia), gable, gambrel, hipped, dutch-hip, roof with parapet, barrel, dome and lean-to. ``Roof profiles are usually the most distinguishing features of an architectural style''. ``Given that most aluminum and asbestos roofs found on site were industrial or commercial buildings while concrete tile and clay tile materials dominated the residential buildings blocks, it could be inferred to a reasonable extent which buildings were commercial or industrial and which ones were residential, etc, by looking at the materials represented in the classification results.''},
  creationdate = {2008/02/06},
  keywords     = {roof, morphology},
  owner        = {izzy},
  school       = {School of Geogr?aphy, University of Nottingham},
  year         = {2007},
}

@MastersThesis{Nyaruhuma07,
  Title                    = {Performance analysis of algorithms for detection roof faces in airborne laser scanner data},
  Author                   = {Adam Patrick Nyaruhuma},
  School                   = {International Institute for Geo-informational Science and Earth Observation},
  Year                     = {2007},

  Keywords                 = {roof shape},
  Owner                    = {Izzy},
  creationdate                = {2010.08.19},
  Url                      = {http://www.itc.nl/library/papers_2007/msc/gfm/nyaruhuma.pdf}
}

@InProceedings{OsullivanBS08,
  author    = {Liam O'Sullivan and St\'{e}phane Bovet and Andr\'{e} Streilein},
  title     = {{TLM} - The {S}wiss 3{D} Topographic Landscape Model},
  booktitle = {The International Archives of the Photogrammetry, Remote Sensing And Spatial Information Sciences, ISPRS Congress Beijing 2008, Commission IV},
  year      = {2008},
  volume    = {Volume XXXVII},
  number    = {Part B4},
  pages     = {1715-1719},
  comment   = {Describes how Swisstopo originally captured data - a disparate set of processes for each different product - and how these were integrated into a new update process and a new base data set, the Topographic Landscape Model of Switzerland (TLM). The solution, TOPGIS, is all ESRI and resulting data includes DTM, roads and tracks, public transport, buildings, and more (there are 10 'topics'). Among components of software and hardware are stereo analyst for ArcGIS, 3D and field editing environment, Photogrammetric 3D roof extrqaction emplates, 3D TIN based automatic roof Multipatch generator and 'extensive quality assurance tools, even in 3D'. There is automatic generalisation for creation of products from the TLM. Roofs are captured using a library of shapes or as a series of 'breaklines' so almost any shape roof can be collected. Linear features can be extracted semi-automatically - the operator indicates some points on the route of the feature and the tool finds the feature in the imagery (in mono). If the software is able to fine feature, operator can step in and manually capture parts. DTM editor allows points (but inclear about breaklines) to be edited in stereo. Points or multipoints can carry attributes. Terrain build occurs overnight so that new DTM is available next day. Only roofs are captured for modelling 3D buildings. No indication of customer requirements gathering. 3D model is multipatch. No indication that DTM is updated directly from vector capture (some features such as tracks are captured in mono and heighted from DTM).},
  file      = {:R\:\\Lammergeier\\Common\\Library\\ExternalPapers\\OsullivanBS08.pdf:PDF},
  keywords  = {3D},
  owner     = {izzy},
  creationdate = {2009/02/02},
}

@InProceedings{StepanMC03,
  author       = {\v{S}t\v{e}p\'{a}n Obdr\v{z}\'{a}lek and Ji\v{r}\'{i} Matas and Ond\v{r}ej Chum},
  booktitle    = {The {I}nternational {C}onference on {C}omputer {V}ision ({ICCV}03)},
  title        = {On the interaction between object recognition and colour constancy},
  organization = {IEEE},
  address      = {Nice, France},
  comment      = {I wish i understood this. The maths in in matrix form, which helps a little. Does photometric and geometric normalisation. Conclusion says ``we have demonstrated that for many objects a recognition method relying mainly on geometry and invariant representation of local colour appearance can be successful even under severe and unknown changes of illumination.''},
  creationdate = {2005/01/01},
  month        = {October},
  owner        = {izzy},
  year         = {2003},
}

@InProceedings{OhlhofGMWT04,
  author       = {Ohlhof, T and G\''ulch, E and M\''uller, H and Wiedemann, C and Torre, M},
  booktitle    = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  title        = {Semi-automatic extraction of line and area features from aerial and satellite images},
  editor       = {M Orhan {ALTAN}},
  url          = {http://www.icc.es/pdf/bienni0304/ii_fotogrametria/12_paper_istanbul_ohlhof_et_al.pdf},
  volume       = {XXXV},
  comment      = {Testing (salespitch?) of inJECT, inpho's software platform for semi-automatic feature extraction. Extract homogeneous parcels by describing a triangle within the area thus defining the stats of that class - active contour is then generated and smoothed. Example of this isn't so good however. Also, line extraction where user gives the starting point, the starting direction, and the width of the linear feature. The software then follows the line. The software has been extended to extract 3D buildings. Worth investigating this software further.},
  creationdate = {2005/01/01},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2004},
}

@Misc{OSFramework04,
  Title                    = {Ordnance Survey Framework Document},

  Author                   = {{Ordnance Survey}},
  HowPublished             = {Published by Ordnance Survey, UK},
  Note                     = {\url{http://www.ordnancesurvey.co.uk/aboutus/reports/frameworkdocument/docs/frameworkdocument2004.pdf}},
  Year                     = {2004},

  Owner                    = {Izzy},
  creationdate                = {2007/05/31}
}

@Article{OsadaFCD02,
  author       = {Robert Osada and Thomas Funkhouser and Bernard Chazelle and David Dobkin},
  journaltitle = {A{CM} {T}ransactions on {G}raphics},
  title        = {Shape {D}istributions},
  number       = {4},
  pages        = {807-832},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/OsadaFCD02.pdf},
  volume       = {21},
  abstract     = {Measuring the similarity between 3D shapes is a fundamental problem, with applications in computer graphics, computer vision, molecular biology, and a variety of other fields. A challenging aspect of this problem is to find a suitable shape signature that can be constructed and compared quickly, while still discriminating between similar and dissimilar shapes.In this paper, we propose and analyze a method for computing shape signatures for arbitrary (possibly degenerate) 3D polygonal models. The key idea is to represent the signature of an object as a shape distribution sampled from a shape function measuring global geometric properties of an object. The primary motivation for this approach is to reduce the shape matching problem to the comparison of probability distributions, which is simpler than traditional shape matching methods that require pose registration, feature correspondence, or model fitting.We find that the dissimilarities between sampled distributions of simple shape functions (e.g., the distance between two random points on a surface) provide a robust method for discriminating between classes of objects (e.g., cars versus airplanes) in a moderately sized database, despite the presence of arbitrary translations, rotations, scales, mirrors, tessellations, simplifications, and model degeneracies. They can be evaluated quickly, and thus the proposed method could be applied as a pre-classifier in a complete shape-based retrieval or analysis system concerned with finding similar whole objects. The paper describes our early experiences using shape distributions for object classification and for interactive web-based retrieval of 3D models.},
  comment      = {In Cite seer and also share_library.
Review:
Appears to be the full report of OsadaFCD01. Very readable paper about translation and rotation invariant shape descriptors - shape distributions - that are also robust to noise, cracks and occlusions in the data. Data are 3D models drawn from WWW defined by polygons. ``In general, 3D models will be acquired with scanning devices, or output from geometric manipulation tools (file format conversion programs), and thus they will have only geometric and appearance information, usually completely devoid of structure or semantic information.'' ``Unlike images and range scans, 3D models do not depend on the configuration of cameras, light sources, or surrounding objects (e.g., mirrors). As a result, they do not contain reflections, shadows, occlusions, projections, or partial objects. This greatly simplifies finding matches between objects of the same type.'' Define 5 shape distributions (see also Goodall07): A3: Measures the angle between three random points on the surface of a 3D model; D1: Measures the distance between a fixed point and one random point on the surface. We use the centroid of the boundary of the model as the fixed point; D2: Measures the distance between two random points on the surface; D3: Measures the square root of the area of the triangle between three random points on the surface; D4: Measures the cube root of the volume of the tetrahedron between four random points on the surface. Samples are random and unbiased by triangulating polygons and then weighting samples according to area of triangle. Need to find the happy medium between resolution of distribution and getting enough data for each bin to create representative distribution. Dissimilarity first is investigated. Have references for Minkowski L_N norms, Kolmogorov-Smirnov distance, Kullback-Leibler divergence distances, match distances, earth mover's distance and and Bhattacharyya distance for determining dissimilarity. Compare chi-squared, Bhattacharyya and Minkowski L_N norms of the probability distribution function (PDF) and comulative distribution function (CDF). Differences in scale also needs to be accounted for - in this case by normalisation using the mean distribution value. Test robustness of measures by scaling isotropicall and anisotropically, rotating, mirroring, shearing, adding noise and adding and deleting polygons. Finally, also similarity and therefore ability to classify shapes is investigated. This is compared to using surface moments Elad et al. [2001] (the first 3 of which are used to translate, rotate and scale the data). This all looks very interesting w.r.t. analysing the shapes of roofs - perhaps by determining the distributions for some primative roof shapes and testing if these can be identified in real roof shape distributions - and perhaps if several different primatives can be detected when tesselated into a single roof.},
  creationdate = {2006/09/29},
  keywords     = {3D, comparison, quality, morphology},
  owner        = {izzy},
  year         = {2002},
}

@Article{OsadaFCD01,
  author       = {Robert Osada and Thomas Funkhouser and Bernard Chazelle and David Dobkin},
  journaltitle = {Shape {M}odeling {I}nternational},
  title        = {Matching 3{D} {M}odels with {S}hape {D}istributions},
  pages        = {154--166},
  comment      = {In share_library. A number of measures are defined for 3D models. ``A3: Measures the angle between three random points on the surface of a 3D model; D1: Measures the distance between a fixed point and one random point on the surface. We use the centroid of the boundary of the model as the fixed point; D2: Measures the distance between two random points on the surface; D3: Measures the square root of the area of the triangle between three random points on the surface; D4: Measures the cube root of the volume of the tetrahedron between four random points on the surface'' The distribution of measures of these can then be compared between two models.},
  creationdate = {2006/09/29},
  howpublished = {not sure - search internet},
  keywords     = {3D, comparison, quality},
  owner        = {izzy},
  year         = {2001},
}

@InProceedings{OudeElberinkV06,
  author       = {Oude Elberink, Sander and George Vosselman},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Adding the {T}hird {D}imension to a {T}opographic {D}atabase {U}sing {A}irborne {L}aser {S}canner {D}ata},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Dutch national laser scanning data (AHN) and the national topo data (TOP10NL). The topo data adds semantic information to laser scanning and laser scanning gives height to topo. They preprocess the laser scanning data using a 3D Hough transform to identify smooth surfaces and therefore remove small surfaces. Use the semnatic information to constrain the heighting of the topo data. For example, laser scanning points are applied to the whole of the polygon if its a field but for water the heights must result in a flat surface. Boundaries of roads only have laser scanning points applied. Next step is to work on ``invisitble'' features. Or rather, obscured features such as those underneith flyovers.},
  creationdate = {2006/09/27},
  keywords     = {laser scanning, height},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{OverbyBKI04,
  author    = {Overby, Jens and Bodum, Lars and Kjems, Erik and IlsÃƒÂ¸e, Peer M},
  title     = {Automatic 3{D} {B}uilding {R}econstruction {F}rom {A}irborne {L}aser {S}canning {A}nd {C}adastral {D}ata {U}sing {H}ough {T}ransform},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.ISPRS.org/istanbul2004/comm3/papers/284.pdf},
  comment   = {Very straight-forward paper with great illustrations. A modification of the Hough transform is used to fit planes to 1m laser scanning data. Some useful ways of overcoming problems of low-density points and multiple planes.},
  keywords  = {3D},
  owner     = {Izzy},
  creationdate = {2005/01/01},
}

@Article{ParkPK03,
  author       = {Park, S C and Park, M K and Kang, M G},
  title        = {Super-resolution image reconstruction: A technical overview},
  journaltitle = {IEEE SIGNAL PROCESSING MAGAZINE},
  year         = {2003},
  volume       = {20},
  number       = {3},
  pages        = {21-36},
  comment      = {Have requested on ILL.},
  owner        = {Izzy},
  creationdate    = {2009.03.11},
}

@Article{Parker04,
  author       = {Chris Parker},
  title        = {Research challenges for a {G}eo-{I}nformation business},
  journaltitle = {The {C}artographic {J}ournal},
  year         = {2004},
  volume       = {41},
  number       = {2},
  pages        = {131-141},
  comment      = {Chris's summary of where we were at in early 2004. Could be useful for referencing when writing about OS.},
  owner        = {izzy},
  creationdate    = {2005/09/09},
  wherefind    = {hardcopy},
}

@Misc{Payne98,
  author       = {S Payne},
  title        = {Feature {E}xtraction {T}echnical {R}eport},
  year         = {1998},
  howpublished = {Internal R\&I document},
  note         = {Change history: OS 75/57/826 Pt1},
  comment      = {Overview: This document reports on feature extraction techniques in the literature by giving a brief description and assessing the technique's advantages and disadvantages. It covers two main areas: 1) 'image segmentation', in which techniques for extracting points, edges and regions are discussed and 2) 'polymorphic methods', in which it is claimed that methods that use a mixture of techniques are discussed. In addition, a section on 'reconstruction techniques' very briefly overviews how the 3D geometry and topology of objects is obtained and another section indicates 5 areas that should be monitored for future use in feature extraction. Comments: Whilst this is a usefully-structured document, it gives the impression that not enough time was given for a thorough literature review. Many description are not clear enough to determine if the algorithms are of value to us. There appear to be some misunderstandings (I would have put Hough transform into the section under edge extraction, for instance) and some omissions (not all methods of reconstruction are covered, template matching is only mentioned for point features, for instance). This is compounded by the lack of referencing in the document - it would take further digging around to find from which report/article/document the description was derived. The report wavers between 2D and 3D features and it isn't always clear which type of feature is being reported on. This is a serious drawback to the report because it is difficult to determine whether a described techniques should be investigated for application to a particular circumstance. Much of the problem probably lies in the different uses of the phrase 'feature extraction' in different research communities. Five techniques are recommended for further consideration. Two of these, 'descriminative analysis' (presumed to be discriminant analysis) and 'principal component analysis', were well established at the time the report was written and should have either been included in this report or dismissed as not relevant enough. One of these recommended 5 techniques is a 3D geometry extraction tool (PIVOT) developed at CMU but there is no reference to this in the report, and I suspect that other such tools were/are also available to be evaluated alongside PIVOT. The two remaining recommended techniques, '2D and 3D grouping' and 'object colour modelling' are not described well enough to be able to investigate further. How could report be updated: It is difficult to recommend updating this report - really it should be rewritten following a comprehensive literature review if we require this information. Relevance to/of current or proposed activities: Again, difficult to determine. There are some useful references that we should investigate further and decide whether these are relevant to our research. Reviewer: Izzy Date: March 2005},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@InProceedings{PerwassGS05,
  author       = {Christian Perwass and Christian Gebken and Gerald Sommer},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Estimation of geometric entities and operators from uncertain data},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Builds on work of F\''{o}rstner into uncertain projective geometry (which I think is a form of geometric algebra or clifford algebra). They combine uncertain pose estimation and uncertain geometry. Basic entities are described by vectors and other are described by a product of these. Other operators are geometric product of vectors. A rotation can be produced by combining these (including creating a reflection). The basis of this approach has 35 elements and there is a set of 13 entities including points, lines, circles, reflection, invesrsion, motor, rotor...which I think are defined by sets from the basis.some visualisation s/w seems to be available at www.clucalc.info},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@Article{PeteriCR04,
  author       = {Renaud Peteri and Isabelle Coubigner and Thierry Ranchin},
  title        = {Quatitatively assessing roads extracted from high-resolution imagery},
  journaltitle = pers,
  year         = {2004},
  volume       = {70},
  number       = {12},
  pages        = {1449-1456},
  comment      = {Discusses how to define a suitable reference again which to compare extracted roads then describes two sets of criteria by which these vectors are evaluated. These are the planimetric accuracy of the road (is the road in the right place) and the spatial characteristics of the network (considering numebr of roads, intersections, connectivity, complexity, ...). Could be useful for comparing extracted vectors with existing vectors e.g. in change detection.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  wherefind    = {library},
}

@Article{PetrieW07,
  author       = {Gordon Petrie and A Stewart Walker},
  journaltitle = {The Photogrammetric Record},
  title        = {Airborne Digital Imaging Technology: A New Overview},
  number       = {119},
  pages        = {203-225},
  volume       = {22},
  comment      = {Useful overview of digital cameras. First section is current technologies, explanation of CMOS and CCD arrays and how colour is detected, divided into sections on small, medium and large format cameras and pushbroom line scanners. CMOS arrays up to 16.7 megapixels while CCD arrays much more than this - CMOS arrays are currently only used in small format airborne cameras. Small format airborne cameras are mainly used for agricultural and environmental monitoring but also include oblique cameras such as that used by Pictometry. Medium format airborne cameras are mainly from modified professional film cameras for which digital backs have been developed. These are also often used with laser scanners. Large format airborne cameras are either single cameras producing monochrome images (usually for surveillance/reconaissance) or multiple medium format cameras such as with the DMC and UltraCam. UltraCam-X is quite a change from UltraCam-D - 60\% increase in pixel count. DMC has seen less development but it has received a Type Certification from USGS. Also in this category is the DiMAC camera which comprises two vertical cameras with no need for separate colour cameras and the only merging is of the two side by side images. This system has been prototype until now. Line-scanners can produce monochrome or colour strips and, with more than one scanner, stereo strips. The ADS40 is the best known of the latter, and recent developments in beamsplitting have allowed a range of scanner configurations for different customers. Owing to Trimble and Leica's rivalry, the ADS40 no longer uses the Applanix POS/AV system and instead IPAS10 system from Terramatics (now owned by Leica). There is also the 3-DAS-1 and the 3-OC but it seems Leica has the advantage when it comes to resources to design, buld, test and market a large-format pushbroom scanner. Other companies have gone out of business. The current trends section discusses aerial film versus airborne digital imagery (just about no contest), GPS/IMU sub-systems, calibration (seems to be improving), software (this has favoured frame cameras until recently), colourising (Bayer interpolation, different cameras, beamsplitting as well as pansharpening - which is slightly simply with pushbrooms), performance and applications. In the latter section, it is noted that line-scanners better for orthorectification and there no longer seems to be doubt about the resolution of these imagers. Also noted the popularity of oblique imagers owing to users' preferences. See also Leberl05.},
  creationdate = {2007/11/16},
  owner        = {Izzy},
  year         = {2007},
}

@Unpublished{Petrucco,
  author    = {Ray Petrucco},
  title     = {House {D}iff supplier project report},
  year      = {2004},
  comment   = {Overview: This report give method, results and conclusion of a project lokking at the value of the Hitachi product House Diff for finding in current imagery buildings that are different from those in the vector database. Detailed comments are given for most of the buildings in the study, particular those ones that House Diff failed to identify as changed. I do not have a complete copy of this report. Comments: This methodology could be useful for current change intelligence/detection activities to find out what are the main failings of our current system. It could also be used to evaluate any future change detection techniques. How could report be updated: I'd like to see the final version. Relevance to/of current or proposed activities: The methodology and perhaps the data set used could be useful for a) determining failings of our current processes and b) evaluating any new processes. Reviewer: Izzy . Date: June 2005},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{PeuquetD94,
  author       = {Donna J Peuquet and Niu Duan},
  journaltitle = {International {J}ournal of {G}eographical {I}nformation {S}cience},
  title        = {An {E}vent-{B}ased {S}patiotemporal {D}ata {M}odel ({ESTDM}) for {T}emporal {A}nalysis of {G}eographical {D}ata.},
  number       = {1},
  pages        = {7--24},
  volume       = {9},
  comments     = {Peter Halls mentioned Donna Peuquet as one of the few people truly looking into representing spatiotemporal data. Also Donna Peuquet and Elizabeth Wentz. An Approach for Time-Based Analysis of Spatiotemporal Data. In Proc. SDH 94 (I), pages 489-504. Taylor \& Francis, 1994. (also P.J. McBrien? and work by Yeh, Tsin-Shu and de Cambray, B\'eatrix)},
  creationdate = {2005/01/01},
  year         = {1994},
}

@InProceedings{PlagemannMB05,
  author       = {Christian Plagemann and Thomas M\''{u}ller and Wolfram Burgard},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Vision-based 3{D} object localization using probabilistic models of appearance},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Pope took the iterative alignment approach which is to match features to object and iteratively align.The major limitation of this is that it is in 2D. That paper takes it to 3D. A 3D model of the object is created and this is used to create 3D training views (by rotating model). These are then used for matching by allowing rotation in x-y plane in then on z axis. I think these are fixed ojects (not types of objects).},
  creationdate = {2005/09/03},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{PoliLG04,
  author       = {Daniela Poli and Zhang Li and Armin Gr\''{u}n},
  booktitle    = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  title        = {S{POT}-5/hrs stereo images orientation and automated {DSM} generation},
  editor       = {M Orhan {ALTAN}},
  volume       = {XXXV},
  comment      = {Paper includes work on Rational Polynomial Coefficients. Prof Gruen sent it to me because I was interested in the part on quality assessment of the model. Paper illustrates how 2.5D quality assessment, that is, assessment of the accuracy of the height of the model at an XY location, is prone to error. Instead, they recommend using a 3D assessment that determine the accuracy of a point on the model by comparing it to the point in 'reality' that is orthogonal to the model at that point. For this they used ``Geomatic Studio v.4.1 by Raindrop'' (I think they mean GeoMagic).},
  creationdate = {2005/11/30},
  owner        = {izzy},
  wherefind    = {in share_library},
  year         = {2004},
}

@PhdThesis{Pollefeys,
  author    = {Pollefeys, M},
  title     = {self-calibration and metric 3{D}-reconstruction from uncalibrated image sequences},
  year      = {1999},
  comment   = {Lots of people reference this guy, the thesis could be very useful to read.},
  keywords  = {toread, 3D},
  owner     = {izzy},
  school    = {K U Leuven},
  creationdate = {2005/09/05},
}

@Article{PollefeysVVVCT04,
  author       = {Pollefeys, M and Van Gool, L and Vergauwen, M and Verbiest, F and Cornelis, K and Tops, J},
  title        = {Visual {M}odeling with a {H}and-{H}eld {C}amera.},
  journaltitle = {International {J}ournal of {C}omputer {V}ision},
  year         = {2004},
  volume       = {59},
  number       = {3},
  pages        = {207--232},
  comment      = {referenced as method to obtain the internal camera parameters by MayerR05.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@Article{PoonFZ07,
  author       = {Poon, Joanne and Fraser, Clive and Zhang, Chunsun},
  title        = {Digital surface models from high resolution satellite imagery},
  journaltitle = {Photogrammetric Engineering and Remote Sensing},
  year         = {2007},
  volume       = {73},
  number       = {11},
  abstract     = {Automated processes in commercial-off-the-shelf (COTS) systems are increasingly prevalent as new technology, and new knowledge is fused to enhance accessibility to spatial information. Automated terrain extraction is becoming a standard capability implemented into photogrammetric software. This paper focuses on digital surface model (Dsm) generation from high-resolution satellite imageiy (HRSi) using three COTS systems, SOCET SET (R), ZII Imaging, and Imagine (R) OrthoBASE, which each have their own image matching strategy. By generating DSMS of a test field diverse in landcover, we assess the performance of the COTS terrain extraction methodologies. In checkpoints favorable to image matching, accuracy to a few meters in height can be achieved from COTS generated Dsms, however the isolated points are unlikely to be representative of the entire scene. Therefore, we look to alternative sources of control, such as the newly available DLR- and NASA-generated SRTM DEMs. A comparison to X-band SRTM DEMs demonstrated that height RMSE values range from 4 to 9 metres, though most of this uncertainty is attributed to the SRTM data.},
  comment      = {Get a copy?
Review:
Relates to PoonFCLG05?},
  keywords     = {DSM, accuracy, quality, DEM},
  owner        = {izzy},
  page         = {1225-1231},
  creationdate    = {2008/03/06},
}

@Article{PoonFCLG05,
  author       = {Joanne Poon and Clive S Fraser and Zhang Chunsun and Zhang Li and Armin Gr\''{u}n},
  journaltitle = {The {P}hotogrammetric {R}ecord},
  title        = {Quality assessment of digital surface models generated from {{I}konos} imagery},
  number       = {110},
  pages        = {162-171},
  volume       = {20},
  comment      = {Compared DSM to LiDAR points to compare heights. Also performed tests within land cover classes. Blunders found in central business district, park and gardens classes and where there was mixed topography. The LiDAR reference also contributed errors, for example where the surface was less reflective or where the laser hit a vertical surface and this is misinterpreted as the upper surface. Note that accuracy descreases with slope and diagram indicate a linear relationship between EMS height discrepency and slope. Looking at diagram the height discrepancy increases rapidly at 13-18 degress and then tails off. Note the surface modelling/interpolation introduces ambiguities when comparing data sets and say that interpolation should be carried out such that the modelling errors overlaying the measurement errors are minimised.},
  creationdate = {2006/02/09},
  groups       = {lidar},
  keywords     = {quality, DEM, image matching},
  owner        = {izzy},
  year         = {2005},
}

@Misc{Purdue05,
  author       = {{Purdue University}},
  title        = {File {C}ompression {C}an {E}xpand {M}ammography's {P}ower},
  year         = {2005},
  howpublished = {Internet},
  note         = {\url{http://www.sciencedaily.com/releases/2005/12/051220001738.htm}},
  month        = {December},
  url          = {http://www.sciencedaily.com/releases/2005/12/051220001738.htm},
  comment      = {Feature selection/feature extraction improves performance},
  owner        = {izzy},
  creationdate    = {2005/12/23},
}

@Misc{QSS013130,
  Title                    = {T{OPO}-96 detail catalogue},

  Author                   = {{QSS013130}},
  HowPublished             = {Quality system document},
  Month                    = {March},
  Note                     = {\url{http://intranet/intranet/edocs/docs/s013130.pdf}},
  Year                     = {2005},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Article{Quackenbush04,
  author       = {Lindi J Quackenbush},
  title        = {A review of techniques for extracting linear features from imagery},
  journaltitle = pers,
  year         = {2004},
  volume       = {70},
  number       = {12},
  pages        = {1383-1392},
  comment      = {Within the background to feature extraction there is a useful overview of human versus computer feature extraction including references that may be worth investigating - although perhaps Quackenbush could have delved deeper into psychology research ??? A useful overview of linear feature extraction. Looks at how authors have assessed their algorithms but this is often using visual assessment and/or in a small area and so is not very satisfactory.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  wherefind    = {library},
}

@InProceedings{RoosliM04,
  author       = {R\''{o}\''{o}sli, Markus and Monagan, Gladys},
  booktitle    = {I{CDAR}},
  title        = {A high quality vectorization combining local quality measures and global constraints},
  pages        = {243-},
  url          = {http://computer.org/proceedings/icdar/7128/vol_1/71280243abs.htm},
  comment      = {Finds lines and arcs in images using a combination of skeletonisation and contouring. Also find 'singular' features that could link these. Bit vague on the local quality measures or global constraints.},
  creationdate = {2005/01/01},
  keywords     = {quality},
  owner        = {izzy},
  year         = {1995},
}

@Article{RadkeAKR05,
  author       = {Richard J Radke and Srinivas Andra and Omar Al-Kofahi and Badrinath Roysam},
  journaltitle = {I{EEE} {T}ransactions on {I}mage {P}rocessing},
  title        = {Image change detection algorithms: A systematic survey},
  url          = {http://www.ecse.rpi.edu/homepages/rjradke/papers/radketip04.pdf},
  comment      = {In TRIM
Review:
Contains sections on: PRE-PROCESSING METHODS geometric and radiometric adjustments SIMPLE DIFFERENCING SIGNIFICANCE AND HYPOTHESIS TESTS here I found Multiple-Hypothesis Tests most interesting - BlackFY00 softly classified pixels ``into mixture components corresponding to different generative models of change. These models included (1) parametric object or camera motion, (2) illumination phenomena, (3) specular reflections and (4) ``iconic/pictorial changes'' in objects such as an eye blinking or a nonrigid object deforming (using a generative model learned from training data). A fifth outlier class collects pixels poorly explained by any of the four generative models...The approach is notable in that image registration and illumination variation parameters are estimated in-line with the changes, instead of beforehand. This approach is quite powerful, capturing multiple object motions, shadows, specularities, and deformable models in a single framework.'' PREDICTIVE MODELS look at different between neighbouring pixels over space (usu. when only 2 or 3 images to compare) and time (when long image sequences are available) THE SHADING MODEL - This is based upon the concept that the intensity at a pixel can be modelled as the product of two components: the illumination from the light source(s) in the scene and the reflectance of the object surface to which the pixel belongs. Only the reflectance component contains information about the objects in the scene. A type of illumination-invariant change detection can hence be performed by first filtering out the illumination component from the image. I understand the principle of this, but its practical application isn't so clear. BACKGROUND MODELLING is a method of determining the background and looking for change in the foreground (or the foreground is the change) - mainly used for video sequences and a little inprecise about what is background. CHANGE MASK CONSISTENCY ensures that the output of change detection is not noisey - as would be the case with per-pixel change detection. WHile some authors have applied filters after change detection, Markov-Gibbs Random Fields (MRF) have been used during change detection. Also, segementation of images has been applied before change detection. The section on PRINCIPLES FOR PERFORMANCE EVALUATION AND COMPARISON is also very valuable - robust quantitative tests are hard to come by perticularly given that change can be percieved differently by different operators and at different times. A few options are given (getting different opinions of operators and working with the intersection, mode or union of these are asking them to come to a collective consensus) and ways of then arriving at indices of success are given. Includes info about 3 software packages including ENVI and the Matlab change detection suite (S. Andra and O. Al-Kofahi, 2004. Rensselaer Polytechnic Institute, Troy, NY, USA. http://www.ecse.rpi.edu/censsis/papers/change/).},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {in press},
}

@Article{Rafailidis97,
  author       = {Rafailidis, S},
  title        = {Influence of building areal density and roof shape on the wind characteristics above a town},
  journaltitle = {Boundary-Layer Meteorology},
  year         = {1997},
  volume       = {85},
  number       = {2},
  pages        = {255-271},
  abstract     = {Flow characteristics in the lower part of the atmospheric boundary layer developing immediately above building roofs have been studied by physical modelling under neutral stratification conditions. The vertical profiles of velocity, turbulence intensity and Reynolds stress were measured in detail above a model urban fetch consisting of parallel street canyons. Two different street densities and roof shapes were tested. It is found that the influence of the buildings on the oncoming wind remains confined to within three overall building heights above ground. Furthermore, the effect on the wind at roof level from the areal building density is relatively weak, but strong from the roof shape. Thus, altering roof shape can have a much more beneficial impact on urban air quality than increasing the spacing between buildings. Moreover, these findings yield a novel methodology for reliable prediction of urban air quality, by combining numerical mesoscale wind flow models with physical street canyon pollution dispersion models.},
  comment      = {From abstract more evidence that roof shapes are importance in building data for air quality modelling.},
  keywords     = {morphology, 3D},
  owner        = {izzy},
  creationdate    = {2008/02/13},
}

@TechReport{Ragia01,
  author       = {Ragia, Lemonia},
  institution  = {GMD - Forschungszentrum Informationstechnik GmbH},
  title        = {Ein {{M}odell} f\''{u}r die {{Q}ualit\''{a}t} r\''{a}umlicher {{D}aten} zur {{B}ewertung} der photogrammetrischen {{G}eb\''{a}udeerfassung}},
  number       = {RS-AiS-2001-14},
  url          = {http://www.bi.fraunhofer.de/publications/research/2001/014/Text.pdf},
  abstract     = {Geoinformation {S}ystems have gained in importance over years. {T}hese systems deal with spatial relationships and require data of high quality. {T}his work contributes to the automatic quality control of available data on spatial objects. {T}he data may be provided from different sources {T}he spatial objects can be observed in planimetry and the outlines are represented by polygons. {T}he uncertainty of their boundaries is taken into consideration {T}he objects are composed of many parts. {A} quality model is de ned to access the data quality. {I}t is based on quality descriptions parameters {I}nput to the evaluation of the parameters of the quality model are di erent descriptions of a scene. {O}ne description is used as a reference and the other for a qualitycontrol {T}he descriptions are analysed geometrically and topologically. {T}he topological analysis is based on the neighbourhood structure and the geometric analysis of the footprint structure. {T}he existence of an object is asserted by the quality parameter success. {T}he specifications of the data is also modelled in the quality model. {A}n identification and detection of topological and geometrical inconsistencies is provided {T}he metaquality is also modelled. {A} representation of complex objects with graphs has several advantages {T}he object parts neighbour hood graph represents the internal stucture the descriptions. {T}he object part correspondence graph represents the relationships of the object parts and the object correspondence graph represents the relationships of the objects. {A} zone skeleton and a distance function is used for describing the geometrical differences. {T}he proposed process is verifired on real examples {I}t was applied successfully in test areas of cities with di erent building characteristics. {A} quality protocol is generated automatically. {T}he traffic light principle is used for the evaluation of the quality parameter groups the quality parameters and the overall performances: {R}ather than binary decisions three categories are de ned accepted green rejected red and subject for review yellow: {T}hresholds and weights are produced in order to access the quality differences.},
  creationdate = {2005/11/21},
  keywords     = {3D, quality, toread},
  owner        = {izzy},
  wherefind    = {in share_library},
  year         = {2001},
}

@Article{RagiaF99,
  author       = {Ragia, L and F\''{o}rstner, W},
  journaltitle = {Bulletin de la {S}ociete {F}rancaise de {P}hotogrammetrie et {T}eledetection},
  title        = {Automatically Assessing the Geometric and Structural Quality of Building Ground Plans},
  pages        = {22-31},
  volume       = {153},
  comment      = {In TRIM. ``Without knowing the specification it is not clear which data set is better or good enough. If the specificatio requires a planar accuracy of 1 m, the acquisition of building with more than 100m^2 and separation of building in case of height differences larger than 3 m, the geometric differences appear acceptable. However, some small buildings appear to be superfluous and, without explicit reference to the 3D-structure, some building parts might have been better fused.'' Distinguish sevel clases of difference of two sets of regions - geometric differences and structural differences. I assume structurual is similar to topological. Geometric differencs are differences of form and of location. Form differences seem to be analysised by looking at the differences between areal intersection of two regions. Location differences are self-explanatory. Structural differences are differences in partitioning and differences in existence. These are calculated using the region adjacency graph and the region correspondence graph.},
  creationdate = {2005/11/21},
  keywords     = {quality, toread},
  owner        = {izzy},
  year         = {1999},
}

@InProceedings{RagiaW98,
  author       = {Ragia, L and Winter, S},
  title        = {Contributions to a Quality Description of Areal Objects in Spatial Data Sets},
  booktitle    = {Proceedings of {ISPRS} {C}ommission {IV} {S}ymposium},
  year         = {1998},
  pages        = {7-10},
  address      = {Stuttgart, Germany},
  comment      = {About quality assessment of 2D data but could be applicable to 3D. Talks about the ISO TC211 documents. Research into these was started with collections of quality aspects (references 2 books for this). Measure geometric and topological differences between captured data and the reference data.Topological differences are interior structure (is a region missing or spurious, is a region split or combined with another) and boundary structure (and the parts connected the same). This is analysed using region agency graphs. Geometric differences are about location - are the boundary points in different locations, are the regions different in pose, are the regions different in their form parameters (their what?). Hybrid rasters are used to measure distances and these give rise to distance histograms from which a distribution function and other measures are defined (this may relate to Soukup02). Region connecitivity graphs are used to indicate the connection between the captured and the reference data.},
  journaltitle = {I{SPRS} {J}ournal of {P}hotogrammetry and {R}emote {S}ensing},
  keywords     = {quality},
  owner        = {izzy},
  creationdate    = {2005/11/21},
}

@Article{RajanC02,
  author       = {Deepu Rajan and Subhasis Chaudhuri},
  title        = {Data fusion techniques for super-resolution imaging},
  journaltitle = {Information Fusion},
  year         = {2002},
  volume       = {3},
  pages        = {25-38},
  comment      = {In TRIM. Method of creating super resolution image by maintaining the structural properties of the image in the interpolation. Something else to do with Markov random fields and maximum a posteriori estimation.},
  owner        = {Izzy},
  creationdate    = {2007/06/22},
}

@Article{RauCC02,
  author       = {Jiann-Yeou Rau and Nai-Yu Chen and Liang-Chien Chen},
  title        = {True orthophoto generation of built-up areas using multi-view images},
  journaltitle = pers,
  year         = {2002},
  volume       = {68},
  number       = {6},
  pages        = {581-588},
  comment      = {Detects hidden areas in main image and fills them with data from other images. Detects shadow areas and enhances the histogram for these areas so that it matches unshadowed part of image. Detection is all based on projection and known geometries.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@InProceedings{ReitbergerKS06,
  author       = {Josef Reitberger and Peter Krzystek and Uwe Stilla},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Analysis of {F}ull {W}aveform {L}idar {D}ata for {T}ree {S}pecies {C}lassification},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Research into tree species classification in waveform lidar. Find peaks in the waveform to identify 3D position of objects using a Gaussian function. The waveform processing results in more point with vegetation.A problem with erroneous peaks after big peaks has been identified and they were able to determine the distance and amplitude of the erroneous peak in order to exclude it. Some peaks are not found fue to the threshold so instead they applied a stepwise change to the threshold. Different tree forms could be identified. Different 'saliency' groups were introduced - the outer tree geometry, the internal geometrical structure and the intensity-related structure. (Iz: these could be useful metrics for tree models in 3D databases). Bayes classification was performed based on these groups.After presentation Brenner suggested using a whole ray and working on the whole volume rather than the points. Comment for someone else that >= 95\% accuracy is essential to a forester.},
  creationdate = {2006/09/27},
  groups       = {lidar},
  keywords     = {waveform lider, tree species},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{RemondinoR06,
  author       = {Fabio Remondino and Camillo Ressl},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Overview and {E}xperiences in {A}utomated {M}arkerless {I}mage {O}rientation},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Orientation of terrestrial images. Usually bundle adjustment is used and this is largely solved and automated in aerial data. However, in terrestrial data this is not solved without markers because of the likelihood of massive image rotation, low texture and illumination and scale changes. This research has developed three different approaches for short, long and wide baselines. Short baseline is usually motion image sequences such as video in which that is a small parallax. They find poitn on the first image, predict these in the next and cross correlate. Finally a precise correspondence is establised using least squares matching. Long baseline is often range motion image sequences. Here they extract points, cross correlate and least squares match for pairwise relative orientation, correspondence in all consecutive triplets. The results are comparable between automated and manual approaches. The wide basline image sequences could also contain scale changes. Interest regions and descriptor (e.g. Lowe keypoints), matching correspondence (using descriptors and least squares), pairwise relative orientation. They state that it is unlikely that correspondences between more than two image will be found. They say that automation in tie-point extration is feasible with good texture and the right strategy. For this use tracking for a short baseilne, and regions for a wise baseline. User interaction is required at the start as a fully blind process is time consuming. The extracted tie points are not always useful 3D modelling, which instead requires user interation (?) Least squares matching can manage to a 30\% scale differences between images. Markerless tie point extraction is still difficult in close range and success of automation depends on image arrangement (baseline and viewing direction) and scene properties (geometry and structure).},
  creationdate = {2006/09/27},
  keywords     = {tie points},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{RemondinoZ06,
  author       = {Fabio Remondino and Li Zhang},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Surface {R}econstruction {A}lgorithms for {D}etailed {C}lose-{R}ange {O}bject {M}odelling},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Surface measurement using imagery. Multiple image matching. Preprocess using for example the Wallis filter which draws out detail whether it is in shadow or not. matching starts at low resolution and matches features, areas and edgse (after Canny edge detection). Requires that images are orientated (''quite precise'') . Area of interst defined and seed points given. Show it working with a simple example with illumination changes between images. Still need to perform quality assessment. Have compared with laser scanner data but comw to do this? Discussion included whether the results are smoothed.},
  creationdate = {2006/09/27},
  keywords     = {DSM, multi-image matching},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{ResslHBR06,
  author       = {Camillo Ressl and Alexander Haring and Christian Briese and Franz Rottensteiner},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {A {C}oncept {F}or {A}daptive {M}ono-{P}lotting {U}sing {I}mages and {L}aserscanner {D}ata},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. The operator identifies a point in a point cloud. The cone of interest is derived that contains this point and emerges from the laser scanner. Other points within this cone of interest are classified to find the plane in which the chosen point falls.},
  creationdate = {2006/09/27},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Article{Rissanen78,
  author       = {J Rissanen},
  journaltitle = {Automatica},
  title        = {Modeling by shortest data description.},
  pages        = {465--471},
  volume       = {14},
  comment      = {According to Li00 citing this paper: ``Hough transform ... is later found to be equivalent to template matching''},
  creationdate = {2005/01/01},
  year         = {1978},
}

@InProceedings{RonnebergerFB05,
  author    = {Olaf Ronneberger and Janis Fehr and Hans Burkhardt},
  title     = {Voxel-wise gray scale invariants for simultaneous segmentation and classification},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Biological application. Cells should be studied in 3D environment. Use an SVM to segment using iterative training.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{RosenhahnKSGBK05,
  author    = {Bodo Rosenhahn and Uwe G Kersting and Andrew W Smith and Jason K Gurney and Thomas Brox and Reinhard Klette},
  title     = {A system for markerless human motion estimation},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Movies of moving people are modelled in 3D using jointed models. The more joints in the more, the more complicated it is to fit - therefore need more information. Tried more cameras and it seemed to work better but improvement required (only moving elbow and shoulder joints).},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{RothGSB05,
  author    = {Peter Roth and Helmut Grabner and Danijel Sko\v{c}aj and Horst Bischof and Ale\v{s} Leonardis},
  title     = {Conservative visual learning for object detection this minimal hand labelling effort},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {A learning person detector requires a lot of training examples. In order to minise hand labelling of training samples this method starts with a simple detector, learns, combines detectors and does some jiggery pokery to come up with robust training. Key stage seems to be a PCA on appearance and shape. Updates to training set are both positive and negative or no update at all. Mention AdaBoost, haar Wavelets and local orientation histograms. The test site is a camera over a coffee dispenser in a corridor. They trained 3 classifiers and during evaluation new positive and negative examples were collected and the classifier retrained using these. The scene is actually very controlled - indoors with only movement other that people is the shadow of the people (minimal) and a short period of direct sunlight reflecting off the floor. They also used the shopping mall public domain data and a road through a tunnel for car detection. I'm not totally sure how hand labelling is avoided.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Misc{Roth05,
  author       = {Volker Roth},
  title        = {Feature selection in clustering: applications in bioinformatics and computer vision},
  year         = {2005},
  howpublished = {presentation at DAGM 2005},
  note         = {see also log book},
  comment      = {Unsupervised clustering - to find the cluster we need to find the interesting features but to find the interesting features we need to define the clusters. Usually clustering involves iterating between finding partitions and scoring observations for relevance but these are two different objective functions. This research's goal was to optimise the same objective function for both clustering and feature selection. Used a Gaussian mixure model with built-in automatic relevance determination. The classic approach is the EM algorithm where E defines class given the current parameters and M defines parameters given the current class. This paper modifies the M part to introduce a relevance parameter. Showed that feature selection increased the stability of segmentation. Presentation given after receiving a prize at DAGM 2005. See RothL2003 for previous work.},
  owner        = {izzy},
  creationdate    = {2005/09/03},
}

@InProceedings{Rottensteiner06,
  author       = {Franz Rottensteiner},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {Consistent {E}stimation of {B}uilding {P}arameters {C}onsidering {G}eometric {R}egularities by {S}oft {C}onstraints},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Geometric regularities exist in buildings. These should be considered and used to contrain reconstructions but only whre the regularities actual exist. Geomtric contrains are implicit in modelling by primities but non regular buildings can only be modelled approximately. I think here (as in ValletT05) the model has been plucked from the ether and the focus is on fitting. The contraints improve the fitting where necessary. Tested on lsaer scanning data but can also be applied to image data.},
  creationdate = {2006/09/27},
  keywords     = {3D, buildings},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@Article{Rottensteiner03,
  Title                    = {Automatic Generation of High-Quality Building Models from {LiDAR} Data},
  Author                   = {Rottensteiner, Franz},
  Year                     = {2003},
  Number                   = {6},
  Pages                    = {42--50},
  Volume                   = {23},

  Abstract                 = {This article presents a method for the automated generation of 3{D} building models from directly observed point clouds generated by {L}idar. {B}uilding regions are detected automatically, and then a curvature-based segmentation technique detects roofs. {T}hese roof planes are grouped to create polyhedral building models. {I}n this grouping process, the shapes of the roof plane boundaries are determined, and the whole model is improved by an overall adjustment using all available sensor information and, if possible, geometric constraints. {T}he article describes the existing modules and those still in the implementation phase, and discusses the issue of integrating aerial images into the reconstruction process to increase the geometric quality of the reconstructed models.},
  Groups                   = {lidar},
  Journaltitle             = {I{EEE} {C}omputer {G}raphics and {A}pplications},
  Keywords                 = {3D, building models, recognition, LIDAR processing, buildings, toread},
  Owner                    = {Izzy},
  creationdate                = {2005/01/01}
}

@InProceedings{RottensteinerJ02,
  author    = {F Rottensteiner and J Jansa},
  title     = {Automatic {E}xtraction of {B}uildings from {L}i{DAR} {D}ata and {A}erial {I}mages},
  booktitle = {Proceedings of the {S}ymposium on {G}eospatial {T}heory, {P}rocessing, and {A}pplications},
  year      = {2002},
  url       = {http://www.ISPRS.org/commission4/proceedings/pdfpapers/204.pdf},
  address   = {Ottowa, Canada},
  comment   = {Building detection (using laser scanning data), find planar patches in the DSM and these are improved using images info such as homogeneity and colour, these planes are grouped into initial polyhedral models which are verified in the images. The process then iterates to fine up on the model.},
  groups    = {lidar},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{RottensteinerSTCK05,
  author       = {Rottensteiner, F and Summer, G and J Trinder and S Clode and Kubik, k},
  title        = {Evaluation of a method for fusing lidar data and multispectral images for building detection},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Lidar provide explicit 3D information and information on planarity and roughness. MS data provides high resoltuion information and spectral content. This work uses 3 data sets - a D canopy model from lidar, height difference between the first and last pulse and the NDVI information. Use Dempster-Schaefer data fusion for a) each pixel b) each building. Classify to building, tree, grassland and bare soil classes.The D-S fusion combines the probability masses of sensors and classes. The results look good. Evaluation includes digitising the buildings and trees (trees are a single point) and measure completeness and correctness per pixel and per building.},
  groups       = {lidar},
  keywords     = {3D, quality, toread},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@InProceedings{RottensteinerTCK04,
  author    = {Rottensteiner, F and Trinder, J and Clode, S and Kubik, K},
  title     = {Fusing {A}irborne {L}aser {S}canner {D}ata {A}nd {A}erial {I}magery {F}or {T}he {A}utomatic {E}xtraction {O}f {B}uildings {I}n {D}ensely {B}uilt-{U}p {A}reas},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.ISPRS.org/istanbul2004/comm3/papers/323.pdf},
  comment   = {The use of imagery and laser scanning data to detect and extract buildings. Some useful citations. Needs more study...},
  owner     = {izzy},
  text      = {Stassopolou, A, Caelli, T and Ramirez, R, 2000. Building Detection using Bayesian Networks. International Journal of Pattern Recognition and Artificial Intelligence. 14(6)715-734},
  creationdate = {2005/01/01},
}

@Unpublished{Kidner02,
  Title                    = {A Topological Feature Extraction System from LiDAR Data with the Application of Radiowave Propagation Modelling},
  Author                   = {Antony Winston Roullier-Callaghan and Prof. M. Al-Nuaimi and Dr. D. Kidner},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {One effective solution to wireless communications systems design in urban areas is to utilise {D}igital {E}levation {M}odel ({DEM}) datasets along with {G}eographical {I}nformation {S}ystems ({GIS}) techniques within radiowave propagation models. {T}he aim of this project is to design and implement a '{R}adio {W}ave {C}overage and {P}lanning {S}ystem ({RAWCAPS}) which can predict the signal field strength from a pre-positioned transmitter in a given topographical region. {T}he emphasis of the extracted features is to identify and classify feature outlines such as building footprints and regions of vegetation as these particular features would have the maximum effect on radiowave propagation modelling. {LIDAR} dataset {A} certain constraint for the systems being developed is the sole use of {LIDAR} data as a data source. {F}igure 1. {LIDAR} {DEM} data {T}his is mainly due to the cost effectiveness of {LIDAR} as opposed to existing topological feature vector data. {T}he {LIDAR} is used in the form of {D}igital {E}levation {M}odel ({DEM}) data. {T}he {DEM}s used in this study where spaced at 1m intervals, with the extent of each site being 500m x 500m. {S}ix sites of the {C}ardiff {UK}, {LIDAR} {DEM}s were designated for their terrain specific properties. {O}ne attribute of the {LIDAR} {DEM}, that causes concern is the accuracy of it. {A}s can be seen in {F}igure 1, ground and roof levels are not separated by thin edges constituting realistic wall widths, thus the need for various processing techniques such as thinning. {T}opological {F}eature {E}xtraction ({TOFEX}) {S}ystem {T}he ultimate goal is to extract terrain features solely from the {LIDAR} dataset using {GIS} software. {T}he features would be represented within the software applications as vector polygons which can then be exported as a vector output file. {T}he vector information can be exported to an external data file for various purposes. {V}arious {GIS} software applications were used in the implementation of the features. {T}he method includes various {GIS} and image processing techniques including filtering, smoothing, edge detection, vectorisation, and feature enhancing techniques. {I}n {F}igure 2, features represented in brown, can be seen, superimposed onto a 2{D} image of the {DEM}. {F}igure 2. {E}xtracted {P}olygons with height data from {LIDAR} {DEM} data. {T}he yellow outlines depict the idealised feature outlines from the {O}rdnance {S}urvey {L}and{L}ine.{P}lus vector data. {R}eplication of these vector outlines is the ultimate goal of the {TOFEX} system. {T}he features can be classified using pattern recognition or mathematical morphology. {W}ireless {C}ommunication as an {A}pplication of the {GIS} '{TOFEX}' {S}ystem {F}igure 3. {S}ignal {S}trength {M}inus {LOS} and diffraction losses {V}arious applications of the extracted features exist. {O}ne such application is in the wireless communication systems design. {T}he extracted features can be used in existing microcell ray tracing models and propagation modelling. {W}ork in this project has involved the implementation of a visibility analysis of the {DEM} data, implementation of {LOS} and single knife edge diffraction propagation techniques as depicted in {F}igure 3.},
  Groups                   = {lidar},
  Keywords                 = {3D, quality},
  creationdate                = {2005/01/01}
}

@InProceedings{SodermanAEP04,
  author       = {Ulf S\''{o}nderman and Simon Ahlberg and Magnus Elmqvist and {\AA}sa Persson},
  booktitle    = {Proceedings of {SPIE} {D}efense and {S}ecurity {S}ymposium},
  title        = {Three-dimensional environment models from airborne laser radar data},
  volume       = {Vol 5412: Laser Radar Technology and Applications IX},
  comment      = {In TRIM
Review:
See AhlbergSEP04},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {2004},
}

@InProceedings{SodermanAPE04,
  author       = {Ulf S\''{o}nderman and Simon Ahlberg and \AA sa Persson and Magnus Elmqvist},
  booktitle    = {Second {S}wedish-{A}merican {W}orkshop on {M}odeling and {S}imulation ({SAWMAS}-2004)},
  title        = {Towards rapid 3{D} modelling of urban areas},
  url          = {http://130.243.99.7/pph/pph0220/simsafe/dok/simsafe09.pdf},
  address      = {Cocoa Beach, Florida},
  comment      = {See AhlbergSEP04},
  creationdate = {2005/01/01},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2004},
}

@InProceedings{SaksT08,
  author       = {Tauno Saks and Udo Tempelmann},
  booktitle    = {EuroCOW2008},
  title        = {{ADS40} System with New Sensor Heads -- Key to the Simplified Model for Self-Calibration and Extended User Benefits},
  comment      = {In TRIM
Review:
Paul Marshall: ``Further to the meeting with the Leica people last week and our discussions about the up-grade to the ADS40. I did pick up a paper at the EuroCOW2008 written by Tauno Saks which explains further the improvements to the ADS40.''},
  creationdate = {2008/08/08},
  file         = {:R\:\\Lammergeier\\Common\\Library\\ExternalPapers\\SaksT08.pdf:PDF},
  owner        = {izzy},
  year         = {2008},
}

@Misc{Sargent08,
  Title                    = {Building Heights using SOCET SET SDK page on Research wiki},

  Author                   = {Isabel Sargent},
  HowPublished             = {Ordnance Survey internal document},
  Note                     = {\href{http://nd22625/mediawiki/index.php/Building_Heights_using_SOCET_SET_SDK}{Web page}},
  Year                     = {2008},

  Owner                    = {Izzy},
  creationdate                = {2009.04.15},
  Url                      = {http://nd22625/mediawiki/index.php/Building_Heights_using_SOCET_SET_SDK}
}

@Misc{Sargent07,
  Title                    = {Test of Methods for Capturing Building Heights},

  Author                   = {Isabel Sargent},
  HowPublished             = {Ordnance Survey internal document},
  Month                    = {April},
  Note                     = {TRIM Record Number: RESD/09/158},
  Year                     = {2007},

  Keywords                 = {3D, height},
  Owner                    = {Izzy},
  creationdate                = {2009.04.14}
}

@Misc{CCTrialHowToSetUp,
  Title                    = {Trial of {C}yber{C}ity software: {S}etting up a {C}yber{C}ity project},

  Author                   = {Isabel Sargent},
  HowPublished             = {Internal Ordnance Survey document},
  Month                    = {May},
  Note                     = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/CyberCityTrial/Documents/CCHowToSetup.pdf}},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02},
  Url                      = {enter URL}
}

@Misc{CCTrialIssuesLog,
  Title                    = {{C}yber{C}ity Issue Log},

  Author                   = {Isabel Sargent},
  HowPublished             = {Internal Ordnance Survey Document},
  Month                    = {May},
  Note                     = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/CyberCityTrial/Documents/IssueLog.pdf}},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/1?1/02},
  Url                      = {enter URL}
}

@Misc{CCTrialTimeSheet,
  Title                    = {{C}yber{C}ity Time Sheet},

  Author                   = {Isabel Sargent},
  HowPublished             = {Internal Ordnance Survey Document},
  Month                    = {May},
  Note                     = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/CyberCityTrial/Documents/TimeSheet.pdf}},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02},
  Url                      = {enter URL}
}

@Unpublished{Sargent06,
  Title                    = {'{B}elow the {R}oof' {Q}uality {A}ssessment of 3{D} {B}uilding {D}ata {R}esearch {P}roposal},
  Author                   = {Isabel Sargent},
  Note                     = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/BelowTheRoof/3DTerrestrialQAProposal.pdf}},

  Month                    = {September},
  Year                     = {2006},

  HowPublished             = {Internal Research document},
  Keywords                 = {3D, quality},
  Owner                    = {izzy},
  creationdate                = {2006/11/20}
}

@Misc{Sargent06a,
  Title                    = {Automatic Derivation of Height Statistics for Building Polygons Research Proposal},

  Author                   = {Isabel Sargent},
  HowPublished             = {Ordnance Survey internal document},
  Month                    = {August},
  Note                     = {TRIM record number: RESD/09/156},
  Year                     = {2006},

  Keywords                 = {3D height},
  Owner                    = {Izzy},
  creationdate                = {2009.04.14}
}

@Misc{Sargent06CCOverview,
  Title                    = {Trial of {C}yber{C}ity software},

  Author                   = {Isabel Sargent},
  HowPublished             = {Internal Ordnance Survey document},
  Month                    = {May},
  Note                     = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/CyberCityTrial/Documents/CCTrialOverviewSheet.pdf}},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02},
  Url                      = {enter URL}
}

@Misc{3DMatrix05,
  author       = {Isabel Sargent},
  title        = {3{D} {S}pecification {M}atrix},
  howpublished = {Internal R\&I document},
  note         = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/3DbuildingsProject/3DSpecMatrix_v3.xls}},
  url          = {enter URL},
  keywords     = {3D},
  month        = {June},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  year         = {2005},
}

@Unpublished{Sargent05,
  author       = {Isabel Sargent},
  title        = {Quality {A}ssessment of 3{D} {B}uilding {D}ata {R}esearch {P}roposal},
  howpublished = {Internal R\&I document},
  note         = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/3DQualityAssessment/3DbuildingsQAProposal.pdf}},
  url          = {enter URL},
  keywords     = {Quality, 3D},
  owner        = {izzy},
  creationdate    = {2006/11/01},
  year         = {2005},
}

@Unpublished{Sargent05QA,
  author       = {Sargent, Isabel},
  title        = {Quality assessment of 3{D} building data},
  howpublished = {Internal R\&I Document},
  note         = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/3DQualityAssessment/QAreview.pdf}},
  url          = {enter URL},
  keywords     = {3D, quality},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  year         = {2005},
}

@Misc{Sargent04,
  author       = {I Sargent},
  title        = {Capture of 3{D} building data research proposal},
  howpublished = {Internal R\&I Document},
  note         = {\url{file://///os2k05/Research/Projects/Lammergeier/Research/ProjectPlansDocumentation/3DDataCapture/3DbuildingsProposal.doc}},
  url          = {enter URL},
  keywords     = {3D},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  year         = {2004},
}

@Misc{SargentF06CCInstructions,
  Title                    = {Trial of {C}yber{C}ity software: {W}orking instructions},

  Author                   = {Isabel Sargent and Mark Freeman},
  HowPublished             = {Internal Ordnance Survey document},
  Month                    = {May},
  Note                     = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/CyberCityTrial/Documents/CCTrialInstructions.pdf}},
  Year                     = {2006},

  Owner                    = {izzy},
  creationdate                = {2006/11/02},
  Url                      = {enter URL}
}

@InProceedings{SargentHF07,
  author       = {Isabel Sargent and Jenny Harding and Mark Freeman},
  booktitle    = {5th International Symposium on Spatial Data Quality},
  title        = {Data quality in 3D: Gauging quality measures from users' requirements},
  url          = {http://itc.nl/external/ISSDQ2007/proceedings/Session%205%20Dissemination%20and%20Fitness%20for%20Use/paper%20Sargent.pdf},
  abstract     = {Producing data of known quality is an essential operation of mapping agencies such as Ordnance Survey. For these data to be of value to our customers, we need to understand what quality measures will allow them to assess whether the data are fit for their purpose. In the case of 3-dimensional (3D) data, this is particularly important as it will inform research into capturing and modelling these data. However, for a data type in its infancy, such as 3D data, it is rare that a clear idea of quality requirements is available since the full range of uses of the data is still unknown. Instead, the potential use contexts of such data need to be investigated. To this end, we have conducted user needs research across a wide range of professional use contexts. This research has been analysed to identify measures and their required quality for use contexts where 3D information about buildings is of particular interest to the user. However, it is often the case that the user cannot realistically make explicit statements anticipating what they would require in terms of 3D data measures and quality elements such as positional accuracy. Instead, it is possible to identify 3D building data characteristics and quality tolerances from implicit statements about use context and objectives from interviews with a wide range of professionals. Characteristics identified include the highest point of a structure and the maximum height of roof ridge, and others such as the the geometric shapes of roofs, buildings and the space between them, which will clearly present some challenges for developing usable quality measures. Preliminary results of this research are presented.},
  creationdate = {2007/02/08},
  keywords     = {user needs, quality, quality measures, 3D, mapping, 3DCharsPaper},
  owner        = {Izzy},
  year         = {2007},
}

@Misc{SargentH05,
  author       = {Sargent, Isabel and David Holland},
  title        = {Provisional specification of real-world objects to be captured in 3{D}},
  howpublished = {Internal R\&I Document},
  note         = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/3DbuildingsDocumentation/3Dspecification.pdf}},
  url          = {enter URL},
  abstract     = {A specification is required for the capture and modelling 3{D} data. {S}uch a specification should be a balance between user requirements and technological constraints. {T}his will be achieved by iteratively updating the specification as user and technological information becomes available. {T}his document initiates this process by setting out three simple, user-focused 3{D} real-world object specifications. {T}hese specifications are designed to provide data required in the three scenarios: flood modelling, signal/noise propagation modelling and homeland security. {H}aving defined these scenarios and their resulting specifications, this document briefly describes the background to the work and produces a data capture specification to be used in the {C}apture of 3{D} {B}uilding {D}ata project.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
  year         = {2005},
}

@Misc{SargentHB05,
  author       = {Sargent, Isabel and Holland, David and Boyd, Doreen},
  title        = {Capture of 3{D} {B}uilding {D}ata {W}orkshop held on 4\&5 {M}ay 2005},
  howpublished = {Internal R\&I Document, also distributed to workshop attendees},
  note         = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/3DbuildingsDocumentation/3DbuildingsWorkshop.pdf}},
  url          = {enter URL},
  abstract     = {Ordnance {S}urvey's {R}esearch \& {I}nnovation group ({R}\&{I}) is to run a programme of research that will investigate how a national database of 3{D} building data may be obtained. {T}his programme will run as a series of modules addressing both capture methodologies and, importantly, the quality assessment of the capture. {W}e intend that this research will be largely undertaken by research groups already expert in the fields of 3{D} data capture from multiple image data, laser scanning data and the quality assessment of these data. {F}or this reason, a workshop was held at {O}rdnance {S}urvey headquarters in {S}outhampton, {UK} to bring together some of these experts and discuss the practicalities of the proposed research programme. {T}his report summarises the discussion held at the workshop and then identifies how these issues are to be taken forward by {O}rdnance {S}urvey.},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {2005},
}

@Misc{SargentHCS05,
  author       = {Isabel Sargent and David Holland and Dave Capstick and Sarah Smith},
  title        = {Capture of 3{D} {B}uilding {D}ata - {D}ata {C}onsiderations},
  howpublished = {Internal R\&I Document, also distributed to workshop attendees},
  note         = {\url{file://///os2k17/r\&i_data6/Lammergeier/Projects/3Dbuildings/3DbuildingsDocumentation/3DbuildingsData.pdf}},
  url          = {enter URL},
  abstract     = {Within the {C}apture of 3{D} {B}uilding {D}ata research programme, we will need to consider the specification and type of the input and output data. {T}his document describes on what basis decisions on data specification and type should be made. {F}or the purpose of initiating the research, detail is given where necessary to the specification of the input multiple image and laser scanning data, and an outline is given of specification and model of the output data.},
  keywords     = {3D},
  month        = {May},
  owner        = {izzy},
  creationdate    = {2005/10/03},
  year         = {2005},
}

@InProceedings{SargentT99,
  Title                    = {Neural networks for improved prediction of Chlorophyll in coastal waters.},
  Author                   = {Sargent, I M J and Tatnall, A R L},
  Booktitle                = {Proceedings of The 25th Conference of the Remote Sensing Society},
  Year                     = {1999},
  Pages                    = {831-838},

  Owner                    = {Izzy},
  creationdate                = {2009.02.11}
}

@Article{SarkarBKKMP02,
  author       = {Anjan Sarkar and Manoj Kumar Biswas and B Kartikeyan and Vikash Kumar and K L Majumder and D K Pal},
  journaltitle = iegrs,
  title        = {A {MRF} {M}odel-based segmentation approach to classification for multispectral imagery},
  number       = {5},
  pages        = {1102--1113},
  volume       = {40},
  comment      = {Oversegment images (unsupervised) and then define MRF on segments. A statistical model is used to compare adjacent regions to test whether they should be merged. Valuable paper for all the statistics but maybe missed a trick (iz: used MRF to add spatial info to segmentation ie group segments according to similar spatial arrangments log 1 p 58). They use segmentation with a higher level of significance in F-test (to over-segment). (iz: we could use ecognition?)},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
  year         = {2002},
}

@Article{SchmidMB00,
  author       = {Cordelia Schmid and Roger Mohr and Christian Bauckhage},
  title        = {Evaluation of Interest Point Detectors},
  journaltitle = {International {J}ournal of {C}omputer {V}ision},
  year         = {2000},
  volume       = {37},
  number       = {2},
  pages        = {151-172},
  url          = {http://www.inrialpes.fr/movi/publi/Publications/2000/SMB00},
  comment      = {In TRIM
Review:
Interest point detectors find points that may be of use in a following technique in an image. There are 3 basic categories: those that are based on extracting contours and then finding the maximal curvature or inflexion point and labelling this as the interest point, intensity-based methods use the greyvalues directly to find interest points and parametric model methods fit a parametric intensity model to the signal. This paper compares a number of methods for their repeatability - that is the ability to find the same interest point under varying conditions (illumination, scale etc). They also compared methods on the information content of the interest point by considering well-scattered points as containing more information than clustered points. The methods were applied to a Van Gogh painting and an Asterix cartoon. Difficult to determine applicability of repeatability results to real changes in image conditions.},
  haveiread    = {ish},
  creationdate    = {2005/01/01},
}

@Misc{SchulzeHorsel07,
  author       = {Schulze-Horsel, Michael},
  title        = {3D City Models:Data Generation and Applications},
  year         = {2007},
  howpublished = {Internet},
  note         = {Last accessed 26/6/08},
  month        = {April},
  comment      = {Mention of CyberCity extrusion of 2D footprint to under roof model to form walls},
  keywords     = {3D},
  owner        = {izzy},
  creationdate    = {2008/06/26},
}

@InProceedings{SchusterW03,
  author       = {Schuster, Hanns-Florian and Weidner, Uwe},
  booktitle    = {I{SPRS} {C}ommission {IV} {J}oint {W}orkshop {C}hallenges in {G}eospatial {A}nalysis, {I}ntegration and {V}isualization {II}},
  title        = {A new approach towards quantitative quality evaluation of 3{D} building models},
  organization = {{ISPRS}},
  url          = {https://www.researchgate.net/publication/228568180_A_new_approach_towards_quantitative_quality_evaluation_of_3D_building_models},
  address      = {Stuttgart, Germany},
  comment      = {In TRIM
Review:
Reviews the performance evaluations given in McKeownBCHMS00 and work by Ragia (http://www-i5.informatik.rwth-aachen.de/lehrstuhl/staff/ragia/) as well as tabularising what 8 further studies have done for quality assessment.Then identifies their own approach: building detection is evaluated according to the 2D ground plan and building reconstruction is evalutated according to comparison of voxels. The buildings only have gable roofs in the models (whatever the reality). ``Quality evaluation is important due to several reasons. First, it may give important information about deficiencies of an approach and may thereby help to focus further research activities. Second, quality evaluation is needed in order to compare the results of the different approaches and to convince a user, that an approach can be used in an operational workflow.''},
  creationdate = {2005/01/01},
  keywords     = {3D, quality, 3DCharsPaper},
  year         = {2003},
}

@Article{ShiM00,
  author       = {Shi, Jianbo and Malik, Jitendra},
  title        = {Normalized {C}uts and {I}mage {S}egmentation},
  journaltitle = iepami,
  year         = {2000},
  volume       = {22},
  number       = {8},
  pages        = {888-905},
  url          = {http://www.cs.berkeley.edu/~malik/papers/SM-ncut.pdf},
  comment      = {The paper referenced by HeilerKS05 for N-Cuts, which apparently resulted from the relaxation of graph-based clustering.},
  owner        = {izzy},
  creationdate    = {2005/09/13},
}

@Article{ShilaneF07,
  Title                    = {Distinctive regions of 3D surfaces},
  Author                   = {Shilane, P and Funkhouser, T},
  Year                     = {2007},
  Number                   = {2},
  Volume                   = {26},

  Abstract                 = {Selecting the most important regions of a surface is useful for shape matching and a variety of applications in computer graphics and geometric modeling. While previous research has analyzed geometric properties of meshes in isolation, we select regions that distinguish a shape from objects of a different type. Our approach to analyzing distinctive regions is based on performing a shape-based search using each region as a query into a database. Distinctive regions of a surface have shape consistent with objects of the same type and different front objects of other types. We demonstrate the utility of detecting distinctive surface regions for shape matching and other graphics applications including mesh visualization, icon generation, and mesh simplification.},
  Comment                  = {get a copy?},
  Journaltitle             = {ACM TRANSACTIONS ON GRAPHICS},
  Keywords                 = {morphology},
  Owner                    = {izzy},
  creationdate                = {2008/02/21}
}

@Book{Shufelt99,
  Title                    = {Geometric {C}onstraints for {O}bject {D}etection and {D}elineation},
  Author                   = {Shufelt, Jefferey A.},
  Publisher                = {Kluwer Academic Publishers},
  Year                     = {1999},

  Abstract                 = {The ability to extract generic 3{D} objects from images is a crucial step towards automation of a variety of problems in cartographic database compilation, industrial inspection and assembly, and autonomous navigation. {M}any of these problem domains do not have strong constraints on object shape or scene content, presenting serious obstacles for the development of robust object detection and delineation techniques. {T}his book addresses these problems with a suite of novel methods and techniques for detecting and delineating generic objects in images of complex scenes, and applies them to the specific task of building detection and delineation from monocular aerial imagery. {PIVOT}, the fully automated system implementing these techniques, is quantitatively evaluated on 83 images covering 18 test scenes, and compared to three existing systems for building extraction. {T}he results highlight the performance improvements possible with rigorous photogrammetric camera modeling, primitive-based object representations, and geometric constraints derived from their combination. {PIVOT}'s performance illustrates the implications of a clearly articulated set of philosophical principles, taking a significant step towards automatic detection and delineation of 3{D} objects in real-world environments.},
  Keywords                 = {3D, quality},
  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@InBook{ShufeltCh699,
  author    = {Shufelt, Jefferey A},
  title     = {Geometric {C}onstraints for {O}bject {D}etection and {D}elineation},
  year      = {1999},
  publisher = {Kluwer Academic Publishers},
  chapter   = {6: Performance evaluation and analysis},
  pages     = {143-190},
  comment   = {Chapter on quality assessment},
  keywords  = {quality, 3D},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{Shufelt96,
  author       = {Jefferey A Shufelt},
  title        = {Exploiting photogrammetric methods for building extraction in aerial images},
  journaltitle = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  year         = {1996},
  volume       = {XXXI},
  number       = {B6/S},
  pages        = {74-79},
  comment      = {In TRIM. Describes the basis behind PIVOT, the Perspective Interpretation of Vanishing points for Objects in Three dimentions. This method uses monocular imagery and a rigorous photogrammetric camera model and is fully automated. A rectacular and a prismatic 3D primitive are fitted to edges, corners, shadows and other features found in the image using principles of vanishing points. Actually, I'm not very clear on how this bit works. Fitting is constrained geometrically and by assessing the relative intensity of roof planes facing towards and away from the sun and the shadow. Assessment is in both image space (assessing the true/false positive/negativeness of pixels) and in object space performing the same assessments on voxels.},
  keywords     = {3D, quality},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@Article{ShufeltM93,
  author       = {J. Shufelt and D. McKeown},
  journaltitle = {Computer {V}ision, {G}raphics and {I}mage {P}rocessing},
  title        = {Fusion of Monocular Cues to Detect Man-Made Structures in Aerial Imagery},
  number       = {3},
  pages        = {307-330},
  volume       = {57},
  comment      = {In TRIM
Review:
Take 4 previously developed building extraction algorithms (BABE, SHADE, SHAVE and GROUPER) and fuse the resulting building hypotheses to improve detection rates. BABE uses a line-corner analysis method. SHADE is based on shadow analysis where the shadow threshold is estimated by BABE. SHAVE verifies building hypotheses by shadow analysis. GROUPER clusters fragemtns of building hypotheses. Uses monocular and stereo techniques. ``In general, the fusion of stereo information provides improved performance over monocular fusion, just as monocular fusion provides improved performanceover any individual building extraction technique''. The output seems to be 2D roof outlines and these are compared per pixel using the measures - \% buildings detected, \% background detected, \% buildings missed, \% background missed, \% false positives, \% false negatives and branch factor. Despite the paper stating that scenes are complex, they contain well spaced buildings with generally rectilinear outlines.},
  creationdate = {2005/09/09},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {1993},
}

@InProceedings{SikanetaG05,
  author       = {Sikaneta, I and Gierull, C H},
  title        = {Two-channel {SAR} ground moving target indication for traffic monitoring in urban terrain},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {3 different detection metrics - difference in position, ?product of phase, ?outer product matrix decomposed.},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Book{Silverman86,
  author    = {Silverman, B W},
  title     = {Density estimation for statistics and data analysis},
  year      = {1986},
  publisher = {Chapman and Hall},
  comment   = {Section 6.2.2 discusses FukunagaH75. ordered by ILL 29/4/03},
  keywords  = {clustering},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Misc{SimardF01,
  author       = {Philippe Simard and Frank P Ferrie},
  title        = {Online database updating by change detection},
  year         = {2001},
  howpublished = {internet need to look up url},
  url          = {http://www.cim.mcgill.ca/~apl/Papers/simard-esv2001.pdf},
  comment      = {In TRIM
Review:
Updating a 3D database whilst flying over the scene. Aircraft may use simulations of the scene built from a database. However, problems may occur if the data base is wrong and so this is a system that will detect changes and update the database. Option of detecting changes in the 2D image domain or 3D scene domain. This system claims to use both. A predicted image sensor image is rendered and then compared to the observed sensor image. Test on simulated data and say that the sensor is undergoing flight trials. Interesting concept - could be used for real-time change detection.},
  keywords     = {change},
  owner        = {izzy},
  creationdate    = {2005/09/09},
}

@Article{SitholeV04,
  author       = {Sithole, George and Vosselman, George},
  journaltitle = ijprs,
  title        = {Experimental comparison of filter algorithms for bare-{E}arth extraction from airborne laser scanning point clouds},
  number       = {1-2},
  pages        = {85-101},
  url          = {www.geo.tudelft.nl/frs/ISPRS/filtertest},
  volume       = {59},
  comment      = {Describes 8 methods of finding bare-Earth points in a lidar dataset (useful background). Identifies 7 filter characteristics: dara structure (point cloud or grid), test neighbourhhod (number of points in analysis at a time), measure of discontinuity (height diff., slope, ...), filter concept (surface, cluster, ...), single step versus iterative, replacement versus culling, first/last pulse/intesity. Using qualitative comparison based on known reasons for failure. Also, quantitative comparison based in classification of point into bare-Earth or object (omission and commision error). ``The problems that pose the greatest challengse appear to be complex cityscapes and dicontinuites in the bare-Earth''. ``It is recognised that full automation is not possible...''. Identifies several directions for future research including using a larger context (a wider area), using for information such a first return, intesity, image and map data. distinguishing between different features in the landscape, have filters report on their own anticipated quality (internal evaluation in HinzW04), and ``as has become evident ... the best filter algorithm may vary from landscape to landscape. For optimal performance, it would be preferred to select the filter algoritym depending on the landscape types. Furthermore ... optimal filter parametrs will also vary from landscape to landscape''. Algorithms are probably improved since this test. Could be a useful format for testing other terrain height capture algorithms. Very well-written paper choc full of useful stuff.},
  creationdate = {2005/01/01},
  groups       = {lidar},
  keywords     = {quality, DEM, height},
  owner        = {izzy},
  wherefind    = {library},
  year         = {2004},
}

@InProceedings{SlesarevaBW05,
  author    = {Slesareva, Natalia and Bruhn, Andr\`{e}s and Weickert, Joachim},
  title     = {Optic flow goes stereo: {A} variational method for estimating discontinuity-preserving dense disparity maps},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Stereo reconstruction and optical flow have the classifical correspondence problem in common. The reconstruction problem is restricted whereas optical flow is more general. Quote two Alvarex et al papers ( JVCIP 2002 and ICIP 1998). This paper proposed a novel variation on the stereo model and they compared it using artificial data (Bonn corridor) to correlation method and Alvarez with favourable results. Also tried on aerial stereo pair of Pentagon. interesting paper - not least because i think it was being criticised at the dinner due to suspected hidden results and not trying other methods in comparison. However it also one a prize at the end of the conference. WOuld be worth watching what comes of this research - and reading the paper. Main reference is BroxBPW04.},
  keywords  = {epipolar, 3D, toread},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{SmithKHCJ08,
  author       = {M J Smith and N Kokkas and A M Hamruni and D Critchley and A Jamieson},
  booktitle    = {EuroCOW2008},
  title        = {Investigation into the Orientation of Oblique and Vertical Digital Images},
  comment      = {Uses Pictometry - must read. Paul Marshall: ``This paper discusses the geometric properties of the Pictometry data and Nottingham University's results from aerial triangulating this data. This was presented by Martin Smith. Martin was keen to stress that he is open to any Photogrammetric collaborative research/development work we may be interested in. ``},
  creationdate = {2008/08/08},
  owner        = {izzy},
  year         = {2008},
}

@Unpublished{SmithVoysey07,
  author    = {Sarah Smith-Voysey},
  title     = {Waveform laser scanning literature review},
  year      = {2007},
  comment   = {Have hardcopy in file.},
  owner     = {Izzy},
  creationdate = {2007/06/22},
}

@Article{SoDo03,
  Title                    = {Building extraction using {L}i{DAR} {DEM}s and {IKONOS} images},
  Author                   = {G Sohn and I Dowman},
  Year                     = {2002},

  Month                    = {October 8-10},
  Note                     = {Dresden, Germany},
  Number                   = {Part 3/W13},
  Pages                    = {167-173},
  Volume                   = {XXXIV},

  Groups                   = {lidar},
  Journaltitle             = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@Unpublished{Sohn02,
  Title                    = {A building detection method using geometrically driven image space},
  Author                   = {Sohn, G and Dowman, I},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {A object detection problem from imageries can be described as several hierarchical processing steps: 1) extracting perceptual cues using low-level of vision algorithms, 2) inferring insufficient perceptual cues using object models driven by our heuristics and 3) organizing them to reconstruct the geometric shapes of real objects. {O}ne of the bottlenecks in this process is caused by the fact that perceptual cues extracted by low-level of vision algorithms are always insufficient in practice and in addition, its degree cannot be predicted in advance. {U}nder this circumstance, determining the kinds and numbers of object models used to compensate for cue insufficiency, and finally validating them, becomes more difficult. {T}o overcome this problem, we show a method to make insufficient cues denser, without using predefined object models. {T}his cue enhancing or inferring process is to transform the entire image space into a polygonal space, which is generated by a set of straight line cues using binary space partitioning tree. {T}he generic shape polygons generated are used to extract buildings boundaries. {B}ased upon this basic idea, our overall building detection process shows a focused object detection strategy, in which building blobs are extracted from {DEM}, such as {LIDAR} point dataset by using a recently developed filtering algorithm. {W}ithin each focused building blob, a polygonal space is generated using a set of straight lines extracted from {IKONOS} imagery. {T}hus, individual building outlines are extracted by the combination of 3-{D} cue from {DEM} and 2-{D} generic polygons extracted from intensity information of {IKONOS} imagery.},
  Email                    = {(gsohn, idowman)@ge.ucl.ac.uk},
  Groups                   = {lidar},
  Keywords                 = {IKONOS, LIDAR, Automation, DEM/DTM, Filtering, BSP Tree},
  Organisation             = {Dept. of Geomatic Engineering, University College London, Gower Street, London, WC1E 6BT UK},
  creationdate                = {2005/01/01}
}

@InProceedings{SohnD02,
  author    = {Sohn, G. and Dowman, I.J},
  title     = {Terrain Surface Reconstruction by the Use of Tetrahedron Model with the {MDL} Criterion},
  year      = {2002},
  pages     = {336-344},
  url       = {http://www.ISPRS.org/commission3/proceedings/papers/paper137.pdf},
  comment   = {A method for filtering out off-terrain laser scanning points to compute a more reliable dtm},
  keywords  = {DEM},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{SohnD08,
  author       = {Gunhon Sohn and Ian J Dowman},
  title        = {A model-based approach for reconstructing a terrain surface from airborne lidar data},
  journaltitle = {The Photogrammetric Record},
  year         = {2008},
  volume       = {23},
  number       = {122},
  pages        = {170-193},
  comment      = {I've only read the section on quality assessment. The QA is based on whether the filter that removes off-terrain points has classified them correctly as such. Therefore Type I error (a point is misclassified as an off terrain object) and Type II error (a point is misclassified as an on-terrain object) is investigated.},
  keywords     = {DTM, DEM, quality},
  owner        = {Izzy},
  creationdate    = {2009.02.24},
}

@Article{SongH05,
  Title                    = {Development of comprehensive accuracy assessment indexes for building footprint extraction},
  Author                   = {Song, WB and Haithcoat, TL},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {402-404},
  Volume                   = {43},

  Abstract                 = {This communication presents a suite of indexes for comprehensively evaluating the results of automated building extraction. The indexes described include detection rate, correctness, matched overlay, area omission error, area commission error, root mean square error, corner difference, area difference, perimeter difference, and shape similarity. These proposed unbiased quality measures should enable the accuracy assessment of the building extraction process to address extraction issues such as completeness, geometric accuracy, and building shape similarity.},
  Comment                  = {In file},
  Journaltitle             = {IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING},
  Keywords                 = {3D, quality},
  Owner                    = {izzy},
  creationdate                = {2008/05/28}
}

@InProceedings{SormannZB05,
  author    = {Sormann, Mario and Zach, Christopher and Bauer, Joachim and Karner, Konrad and Bischof, Horst},
  title     = {Automatic foreground propogation in image sequences for 3{D} reconstruction},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Detailed 3D reconstruction requires many imgeas and manual segmentation is time consuming so this paper wishes to automatically segment. Outlines the object in the first image manually and then uses epipolar conatraint to initiate segmentation in next image from this first outline. Do a sort of segmentation in the buffer around the outline to refine segmentation for subsequent image (mean shift? see also Fukunaga and Hostetler 1975). Where segmenation goes qrong intelligent scissors come in. Use the method to segment a gnome from a white background amoung other things. i asked H Mayer why they couldnt use the disparity map in this case and segment according that to but apparently this is often too coarse when registration is not very robust in CV applications (more robust in photogrammtery???)},
  keywords  = {epipolar, 3D},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@InProceedings{Soukup02,
  author    = {Lubom\'{i}r Soukup},
  title     = {Rigorous quality assessment of 3{D} object reconstruction for an arbitrary configuration of control points},
  booktitle = {Photogrammetric {C}omputer {V}ision ({PCV}02)},
  year      = {2002},
  pages     = {263},
  url       = {http://www.isprs.org/commission3/proceedings/papers/paper059.pdf},
  comment   = {This looks like an interesting paper, although I can't follow it all. Defines probability distribution functions for the estimation of 3D real-world co-ordinates in multiple images. Its like the pdfs are created for the estimation of the location of points in the scene and are used to estimate the error in those points - this is possible because the points appear in multiple images.The quality assessment is within the method and not testing of the method takes place. Some useful ideas that could be used if trying to implement 3D data capture techniques.},
  keywords  = {3D, quality},
  owner     = {izzy},
  creationdate = {2005/08/08},
}

@InProceedings{StuerzlS05,
  author       = {Wolfgang St\''{u}rzl and Mandyam V Srinivasan},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Omnidirectional vision with frontal stereo},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Cameras on robots. Has all-round vision and some stereo which all seemed to be obtained using mirrors.},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@InProceedings{StanskiH05,
  author    = {Adam Stanski and Olaf Hellwich},
  title     = {Spiders as robust point descriptors},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Find a salient point and connect it to the salient points around it and match this network (spide) of opints between images. Is rotation (in any direcdtion) invariant apparently. Also look into the maximum stable extreme rotation approach (suggeted to author in poster discussion).},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Article{StassopolouCR00,
  author       = {Stassopolou, A and Caelli, T and Ramirez, R},
  journaltitle = {International {J}ournal of {P}attern {R}ecognition and {A}rtificial {I}ntelligence},
  title        = {Building {D}etection using {B}ayesian {N}etworks},
  eprint       = {http://www.worldscientific.com/doi/pdf/10.1142/S0218001400000477},
  number       = {6},
  pages        = {715--733},
  url          = {http://www.worldscientific.com/doi/abs/10.1142/S0218001400000477},
  volume       = {14},
  abstract     = {In this paper a {B}ayesian {N}etwork is used to model and combine evidence for the {D}etection of buildings in orthophotos. {T}he system first segments the aerial image using an adaptive multi-scale segmenter. {C}orners of region boundaries are then registered by prediciting expert corner labeling in terms of determining the curvature scale and magnitude which produces the curvature peaks along the contour which are most consistent with expert corner annotation. {H}owever, the primary focus of this project was the development of a {B}ayesian {N}etwork to combine different sources of information and derive probabilities for segmented regions being buildings or not. {I}nformation relevant to the detection of a building in our current implementation includes geometric, radiometric and contextual sources which were combined in this probabilistic model. {T}he network was constructed from training examples and continuous variables were represented by discrete node states in the network using minimum entropy vector quantization. {R}esults demonstrate the potential of this approach.},
  comment      = {''Information relevant to the detection of a building in our current implementation includes geometric, radiometric and contextual sources which were combined in this probabilistic model.''},
  creationdate = {2005/01/01},
  keywords     = {ImageLearn},
  owner        = {izzy},
  year         = {2000},
}

@Misc{ArchitectureGlossary,
  Title                    = {Glossary of {A}rchitectural and {B}uilding terms},

  Author                   = {WANDSWORTH BOROUGH COUNCIL : CONSERVATION AREA CHARACTER STATEMENTS},

  Owner                    = {izzy},
  creationdate                = {2005/01/01},
  Url                      = {http://www.wandsworth.gov.uk/NR/Wandsworth/localpdf/planning/plothconglossarc.pdf}
}

@InProceedings{StillaJ99,
  author    = {Stilla, U and K Jurkiewicz},
  title     = {Automatic reconstruction of roofs from maps and elevation data},
  booktitle = {I{APRS}},
  year      = {1999},
  volume    = {32},
  number    = {7-4-3 W6},
  pages     = {139-143},
  address   = {Valladolid, Spain},
  comment   = {don't have copy - referenced in BaltsaviasH00},
  keywords  = {3D, quality, toread},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{StillaJ99a,
  author       = {U Stilla and K Jurkiewicz},
  booktitle    = {Integrated Spatial Databases. Digital Images and GIS: International Workshop ISD'99, Portland, ME, USA, June 1999. Selected Papers},
  title        = {Reconstruction of Building Models from Maps and Laser Altimeter Data},
  pages        = {34},
  publisher    = {Springer Berlin / Heidelberg},
  series       = {Lecture Notes in Computer Science},
  volume       = {1737/1999},
  abstract     = {In this paper we describe a procedure for generating building models from large scale vector maps and laser altimeter data. First the vector map is analyzed to group the outlines of buildings and to obtain a hierarchical description of buildings or building complexes. The base area is used to mask the elevation data of single buildings and to derive a coarse 3D-description by prismatic models. Afterwards, details of the roof are analyzed. Based on the histogram of heights, flat roofs and sloped roofs are discriminated. For reconstructing flat roofs with superstructures, peaks are searched in the histogram and used to segment the height data. Compact segments are examined for a regular shape and approximated by additional prismatic objects. For reconstructing sloped roofs, the gradient field of the elevation data is calculated and a histogram of orientations is determined. Major orientations in the histogram are detected and used to segment the elevation image. For each segment containing homogeneous orientations and slopes, a spatial plane is fitted and a 3D-contour is constructed. In order to obtain a polygonal description, adjacent planes are intersected and common vertices are calculated.},
  comment      = {In TRIM
Review:
I know its obvious, but valuable points: ``The [height] of the peak (peak area) [in the histogram] is given by the base area [of the building]. If a flat roofed building ha s falt superstructure ... the histogram shows an additional peak above the main peak. Simple gabled roofs show a rectangular histogram ... The length of the ridge determine the height of the right side of the histogram.'' Use histograms to build building hypotheses which are then confirmed or not based on the compactness of the heights. Areas that are too small are rejected. They segment the points and then dilate and erode to find the points that describe the outlines of the basic roof faces. Planes are fitted to these (or to the original points, its not clear) and these outline points (''contour chains'') then have the new z-value applied from the plane. The points that are no needed to describe the shape are removed and at the same time the points at intersections of planes are recalculated to ensure the planes intersect at a common vertex. This can result in verteces around single faces not falling on a single plane and so the data are split into planar surfaces (triangulated?).},
  creationdate = {2007/11/16},
  keywords     = {3D},
  owner        = {Izzy},
  year         = {1999},
}

@InProceedings{StreckelK05,
  author    = {Birger Streckel and Reinhard Koch},
  title     = {Lens model selection for visual tracking.},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {A comparison of perspective and fisheye lenses. Fisheye contrasts to perspective in that it has a low angular resolution but that this is constant. For structure from motion find that the fisheye lens is better.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Article{StromP08,
  author       = {Strom, K. B. and Papanicolaou, A. N.},
  title        = {Morphological characterization of cluster microforms},
  journaltitle = {SEDIMENTOLOGY},
  year         = {2008},
  volume       = {55},
  number       = {1},
  pages        = {137-153},
  abstract     = {A field study was conducted on two mountain streams in the Cascade Mountains of Washington State on the morphological characterization of cluster microforms. Morphological characterization of clusters is presented in terms of: (i) cluster shape; (ii) cluster geometric properties; and (iii) the spatial arrangement of clusters in the horizontal plane. Clusters were differentiated from other microtopography features such as reticulate structures and transverse ribs, and identified clusters were categorized by shape as being of pebble, line, comet, heap or ring type. The complex spatial arrangement of clusters at the sites was characterized by using a two-dimensional correlation function, which allowed for measurement of the average cluster-spacing properties. For the rivers examined, pebble-shaped clusters were the most frequently observed cluster shape. Cluster geometric properties were found to be controlled by particles of the largest size fraction in the bed and the projected frontal width of the cluster - with cluster length being linearly related to cluster width for cluster width-to-height ratios <3.5. Results of the cluster-spacing analysis suggest that cluster spacing increases with cluster size and decreases with local slope. Application of this principle to the available spacing data shows that cluster spacing lambda scales with the ratio of S/d(0) such that lambda S/d(0) = constant, where S is the local slope and d(0) the diameter of the largest particle in the cluster.},
  comment      = {Morphology analysed w.r.t. sedimentary particle clusters},
  keywords     = {morphology},
  owner        = {izzy},
  creationdate    = {2008/02/13},
}

@InProceedings{Taillandier05,
  author       = {Taillandier, Franck},
  title        = {Automatic building reconstruction from cadastral maps and aerial images},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  url          = {\\randi01\r and i\ConferenceProceedings\Lammergeier\CMRT05\Papers\CMRT05_Taillandier.pdf},
  comment      = {This is really really relevant. Developing a mass production line. Database for whole of French territory and 25cm imagery calibrated with a DEM. Cadastral maps - can be edited and then can slect buildinga nd use to launcha 3D reconstruction that is automatic, real-time and rebust against generality. Inside cadastral outline the proceedure infors all the possible planes given an inclinitaion of 45 degrees and planes from straight gutter edges I think.These are pruned using particular criteria.For a simple situation this can reduce 83 possibilities to 15. Using centred correlation eadh possible solution is matched to DEM. The correlation scores are summed to find the most likely. Then fitting occurs. Takes less than 1 second per normal building and less than 5 seconds for a complex building. Follow on work should look at self-assessment measures - work by Laurence Boudet. Should read actual paper. Must follow up.},
  keywords     = {3D, quality},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Misc{TaillandierPC05,
  author       = {Taillandier, F},
  year         = {2005},
  howpublished = {Personal Communication},
  month        = {August},
  comment      = {Franck sail that IGN were looking at self-assessment},
  owner        = {izzy},
  creationdate    = {2005/11/25},
}

@InProceedings{TaillandierD04,
  author       = {Taillandier, Franck and Deriche, Rachid},
  booktitle    = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  title        = {Automatic {B}uilding {R}econstruction {F}rom {A}erial {I}mages: {A} {G}eneric {B}ayesian {F}ramework},
  editor       = {M Orhan {ALTAN}},
  pages        = {343},
  url          = {http://www.isprs.org/proceedings/XXXV/congress/comm3/papers/292.pdf},
  volume       = {XXXV},
  comment      = {A system for automatic building reconstruction from multiple aerial images involving 1) primitives detection, 2) hypotheses extraction and 3) choice of the best representation together with geometric refinement. ``In the primitives detection step, starting from correlation DEM and a rough focusing zone, the algorithm extracts planar patches and oriented portions of facades that represent the base primitives. In a second step, from the arrangement of planes deduced from these base primitives, it builds up a 3D graph of facets and then a so-called ``compatibility graph'' where the nodes are the initial facets of the 3D graph and edges between two nodes state that both facets belong to at least one common hypothesis of building. In our scheme, buildings are modeled, in a very generic way, as polyhedral volumes with no overhang and it is shown that maximal cliques in the compatibility graph supply all the hypotheses of buildings that can be deduced from the arrangement of planes.''},
  creationdate = {2005/01/01},
  keywords     = {3D, quality, facade extraction, 3D buildings},
  owner        = {Izzy},
  year         = {2004},
}

@Article{TakaseSSS03,
  author       = {Y. Takase and N. Sho and A. Sone and K. Shimiya},
  journaltitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  title        = {Automatic Generation Of 3{D} City Models And Related Applications},
  note         = {Last access 26/6/08},
  url          = {http://www.photogrammetry.ethz.ch/tarasp_workshop/},
  volume       = {XXXIV-5/W10},
  comment      = {''Traditional modeling method of 3D city models had required enormous amount of time for manual works. Ordinary modeling method of 3D city used to be: 1. Scan map and get digital image, 2. Trace digital image of map with 3D CAD software resulting in 2D data of buildings outlines, 3. Manually make 3D modeling of buildings with 3D CAD by extruding 2D outlines to building height, and/or modeling manually detailed 3D geometry referring to drawings and photographs also with 3D CAD.''},
  creationdate = {2008/06/26},
  owner        = {izzy},
  year         = {2003},
}

@InProceedings{TaoY02,
  Title                    = {Combining {H}igh {R}esolution {S}atellite {I}magery {A}nd {A}irborne {L}aser {S}canning {D}ata {F}or {G}enerating {B}areland {D}em {I}n {U}rban {A}reas},
  Author                   = {Guo Tao and Yoshifumi Yasuoka},
  Booktitle                = {International {W}orkshop on {V}isualization and {A}nimation {O}f {L}andscape},
  Year                     = {2002},

  Address                  = {Kunming, China},
  Pages                    = {26 - 28},
  Volume                   = {XXX IV},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Article{TayDC07,
  author       = {Tay, L. T. and Daya Sagar, B. S. and Chuah, H. T.},
  journaltitle = {International Journal of Remote Sensing},
  title        = {Granulometric analyses of basin-wise DEMs: a comparative study},
  number       = {15},
  pages        = {3363-3378},
  url          = {file://os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers/TayDC07.pdf},
  volume       = {28},
  abstract     = {Digital elevation models (DEMs) are very useful for terrain characterization. We apply a morphological approach to characterize 14 sub-basins decomposed from interferometrically generated DEMs of Cameron Highlands and Petaling regions of Peninsular Malaysia. Physiographically, these two regions possess a distinct geomorphologic set-up as they belong to region with higher and lower altitudes, respectively. Fourteen sub-basins are extracted from the DEMs, and pattern spectra by opening and closing of these sub-basins relative to flat discrete binary patterns (square, octagon and rhombus) are computed. Pattern spectra are used to compute probability size distribution functions of both protrusions and intrusions that are conspicuous in topography, based on which shape-size complexity measures of these sub-basins are estimated by means of average roughness and size. Furthermore, fractal dimensions of channel networks derived from these 14 basins are computed by applying the box-counting method. Comparisons between shape-size complexity measures and fractal dimension are carried out.},
  comment      = {Granulometry and fractal analysis of networks is used to characterise the morphology, especially roughness, of river basins in DEMs (from interferometry). Granulometry entails combinations of opening, closing, dilation and erosion of the DEMs using a square, a octagonal and a rhombus structuring template. The results were subtracted from results at different levels to show the detail at each level. Franctal analysis was performed using box counting. Thought this may be useful for characterising roofs in DEMs but intuitively this is not of value to structured/man-made features in DEMs.},
  creationdate = {2008/02/13},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {2007},
}

@InProceedings{Te98b,
  Title                    = {Urban 3{D} topologic data and texture by digital photogrammetry},
  Author                   = {Tempfli, K},
  Booktitle                = {Proceedings of {ISPRS}},
  Year                     = {1998},

  Keywords                 = {3D},
  Optaddress               = {Tempa, Florida,USA},
  Optmonth                 = {March-April},
  Optnote                  = {CD-ROM},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@Book{ThackerCBBCCCR05,
  author    = {Thacker, N and Clark, A and Barron, J and Beveridge, R and Clark, C and Courtney, P and Crum, W and Rameh, V},
  title     = {Performance characterization in computer vision : {A} guide to best practices.},
  year      = {2005},
  comment   = {Not read. Mentioned in BoudetPJMP06 with reference to internal evaluation and error propagation},
  owner     = {izzy},
  creationdate = {2006/09/08},
}

@Book{SI03,
  Title                    = {Statutory instrument 2002 no.3113. The traffic signs regulations and general directions 2002},
  Author                   = {{The Stationery Office}},
  Publisher                = {{The Stationery Office}},
  Year                     = {2003},

  Owner                    = {izzy},
  creationdate                = {2008/02/01}
}

@Article{TheodoridisM00,
  author       = {Theodoridis, G and Moussiopoulos, N},
  title        = {Influence of building density and roof shape on the wind and dispersion characteristics in an urban area: A numerical study},
  journaltitle = {Environmental Monitoring and Assessment},
  year         = {2000},
  volume       = {65},
  number       = {1-2},
  pages        = {407-415},
  abstract     = {The Computational Fluid Dynamics code CFX-TASCflow is used for simulating the wind flow and pollutant concentration patterns in two-dimensional wind-tunnel models of an urban area. Several two-dimensional multiple street canyon configurations are studied corresponding to different areal densities and roof shapes. A line source of a tracer gas is placed at the bottom of one street canyon for modelling street-level traffic emissions. The flow fields resulting from the simulations correspond to the patterns observed in street canyons. In particular and in good agreement with observations, a dual vortex system is predicted for a deep flat-roof street canyon configuration, while an even more complex vortex system is evidenced in the case of slanted-roof square street canyons. In agreement with measurement data, high pollutant concentration levels are predicted either on the leeward or the windward side of the street canyon, depending on the geometrical details of the surrounding buildings.},
  comment      = {Perform 2D simulations of wind flow to determine pollutant spread. From abstract appear to find differences depending on the roof shape - useful evidence for including roof shape in data.},
  keywords     = {morphology, 3D},
  owner        = {izzy},
  creationdate    = {2008/02/13},
}

@InProceedings{TiedeHB05,
  author       = {Dirk Tiede and Gregor Hochleitner and Thomas Blaschke},
  title        = {A full {GIS}-based workflow for tree identification and tree crown delineation using laser scanning},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {With a lidar point density average of 10 points per square meter and first and last pulse Toposys system (although there were gaps of > 1m in the flight direction). Used on summer flight data. There is a simple relatinship between the ground width of a tree and its hight. Also reduced the point density by a) findnig the maximum value in each square meter and b) created a grid data set from this. The local maximum found was used a seed point for delinearing tree crowns.},
  groups       = {lidar},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Misc{Tompkinson03a,
  author       = {William Tompkinson},
  title        = {Evaluation of e{C}ognition image analysis software},
  howpublished = {Internal R\&I document},
  comment      = {Overview: eCognitions segments image data using a patented multi-resolution technique. Oncde the image data has been segmented, vectors defining the segments can be derived. Layers of different sized segments can be created and then associated to each other to indicate object hierachies. The report aimed to assess how eCognition could be used to a) extract the boundaries of objects in images, b) recognise the objects, c) be used for change detection and d) to identify any other uses of the software. Comments: eCognition is operated using a GUI by which the user alters many parameters to define the segmentation (such as segment dimensions). It was these many parameters that were found to be eCognitions main drawback to utilisation by Ordnance Survey because finding the appropriate parameter set represented a considerable manual effort. Other drawbacks were that the vectors derived from segment boundaries tended to follow pixel edges and that linear features such as roads tended to be segmented into more compact regions. The report finds limitations with using eCognition for object extraction but suggest that it may be used for a) 3D modelling of laser scanner data, b) land use classification and c) within a change detection system. Little information is given about these uses of eCognitions although the latter suggestion is described more in the document `` Automated change detection system (phase 1)''. The report points out htat new releases of eCognition have appeared over the yaers that may overcome some of the problems noted. However, the greatest problem remains: that of not knowing quite how the algorithms are operating and therefore being unable to fully assess the software's utility. How could report be updated: It seems that in order to fully prove eCognition's utility Ordnance Survey's processes a study would need to be undertaken that attempts to define rules (by induction or heuristics) for the values of each parameter. This would take some time and effort and may not provide very useful results. Relevance to/of current or proposed activities: Reviewer: Izzy. Date: June 2005},
  creationdate = {2005/01/01},
  month        = {January},
  owner        = {izzy},
  year         = {2003},
}

@Misc{Tompkinson03b,
  author       = {William Tompkinson},
  title        = {Automated change detection system (phase 1)},
  year         = {2003},
  howpublished = {Internal R\&I document},
  month        = {January},
  comment      = {Overview: This report describes a method of creating hypotheses of change between tow images as well as a system by which an operator is 'driven' to these locations of possible change. The emphasis of the report is on the interface which does the 'driving' (the system) although the change detector (the technique) is described in some detail. The premise of that whatever method is used to detect change, it is pertinent to have a more automatic way of taking the operator to the location of change. The change detection technique described involves segmenting two images in a temporal sequence using eCognition, finding equivalent polygons between the two sets of segments and comparing their compactness. The change detection system is a GUI written in Visual Basic with a set of display windows showing different aspects of the data set. Comments: The report is a little confusing because the division between technique and system is not entirely clear (although it is in principle). This is because the system seems to do some data processing before performing the 'driving' operation. The input to the system should be some standard probability of change value. The system is a valuable concept and, as noted in the report, it would be more useful if it were part of an editing system such as SOCET SET. How could report be updated: Relevance to/of current or proposed activities: This report suggest a useful way that change detection could in integrated into the flowline and so is relevant to current change detection research. Reviewer: Izzy. Date: June 2005},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@Unpublished{Tompkinson03c,
  author       = {William Tompkinson},
  title        = {Proposed strategy for research into change detection},
  comment      = {Overview: This document discusses the work described in the ``Automated change detection system (phase 1)'' report and proposes how research should be furthered. The report breaks down the process of change detection into identification, recognition and extraction and focuses on identification. The report recommends producing techniques to find the cues that humans use for change detection, producing a range of techniques for detecting change and also the initiation of research into the recognition of changed objects. Comments: There are useful points in the introduction that an efficient change detection system does not need to be fully automatic and that the value of experienced operators should be recognised when designing change detection systems. The recommendations for continuing change detection for the 24 months from September 2003 gives little indication of what form the proposed techniques should take. The image primitives and more recent work with the GeoUsers team has begun to address the human-computer interaction aspect of these recommendations. How could report be updated: There is a clear need for a more comprehensive plan about how change detection research should be undertaken over the coming 15 months, this is currently being addressed. Relevance to/of current or proposed activities: This is a forerunner to current change detection research and contains some useful points about the use of photogrammetric operators. Reviewer: Izzy. Date: June 2005},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {2003},
}

@InProceedings{TournairePJC06,
  author       = {Olivier Tournaire and Nicolas Paparoditis and Franck Jung and Bernard Cervelle},
  booktitle    = {The {I}nternational {A}rchives of the {P}hotogrammetry, {R}emote {S}ensing and {S}patial {I}nformation},
  title        = {3{D} {R}oad-{M}ark {R}econstruction from {M}ultiple {C}alibrated {A}erial {I}mages},
  editor       = {Wolfgang F\''{o}rstner and Richard Steffen},
  number       = {3},
  organization = {ISPRS Commission III},
  volume       = {XXXVI},
  address      = {Bonn, Germany},
  comment      = {Electronic and hardcopy proceedings with library. Oral presentation to replace one that didn't turn up. Zebra crossing and discontiniuous road marks (dashed lines). Want to provide a 3D road graph showing the different lanes. Have the specificaiton of the road marks and can match templates. Ground sample is 10, 20 and 25cm. When detected in all images use epipolar contracts to reconstruct 3D scene. Evaulate using ground surveyed points. Say that it would be useful to obtain in-flight PSF and MTF estimations. They are also trying other methods for comparison. Problems along the epipolar line. Occlusions are less of a problem due to multiple view frame. Iz - interesting that this was chosen to be a poster - is it cos it is too practical? Would be useful to return to if road markings research is revisited.},
  creationdate = {2006/09/27},
  keywords     = {road markings},
  month        = {September},
  owner        = {izzy},
  year         = {2006},
}

@InBook{ToussaintXX,
  author    = {Godfried Toussaint},
  chapter   = {7: Skeletons},
  pages     = {36-42},
  url       = {http://cgm.cs.mcgill.ca/~godfried/teaching/pr-notes/skeletons.ps},
  comment   = {In filing cabinet},
  owner     = {izzy},
  creationdate = {2008/02/04},
}

@InProceedings{Tsay02,
  author       = {Jaan-Rong Tsay},
  booktitle    = {Photogrammetric {C}omputer {V}ision {PCV}'02 {S}ymposium},
  title        = {A concept and algorithm for 3{D} city surface modeling},
  organization = {ISPRS Commission III},
  url          = {http://www.isprs.org/commission3/proceedings/papers/paper092.pdf},
  address      = {Graz, Austria},
  comment      = {Use wavelets to fit a surface to stereo imagery. List quite a number of types of roof shapes, should we ever need to know these. But these are no use in Taiwan! Therefore need a method that fits directly to the data rather than using CSG primitives. Also notes (with reference to Gruen, 2001) that ``complete 3D city models for practical use caontain not only simple buildings, but also much more complex buildings, vegetation objects, DTM, utility systems, etc''. The concept should solve the ``Gibbs phenomenon'' which is that when most surface functions are fitted to near-discontinuous surfaces (e.g. walls) a 'ripple' effect occurs either side of the discontinuity. Apparently, assuming that no discontinuity is every absolute (all walls are slightly off-vertical) means that wavelets can be fitted. Fitting occurs in windows which are then joined up to create the surface model. The choice of wavelet parameters is set by the user and its not clear how these are chosen. Would be interesting to see how this progressses - plenty of previous publications too.},
  creationdate = {2005/01/01},
  keywords     = {3D, morphology, image matching},
  owner        = {izzy},
  year         = {2002},
}

@PhdThesis{Tse08,
  author    = {Tse, Rebecca O C},
  title     = {Three dimensional building reconstruction from raw lidar data},
  year      = {2008},
  comment   = {A very useful review of different lidar point cloud to bare-earth model filtering methods. Also useful review of 3D building extraction from lidar, image and map data. Description of Euler operators.},
  keywords  = {3D, lidar},
  owner     = {izzy},
  school    = {University of Glamorgan},
  creationdate = {2008/07/02},
}

@InBook{TseG04,
  author       = {Rebecca O C Tse and Christopher Gold},
  title        = {T{IN} {M}eets {CAD} - {E}xtending the {TIN} {C}oncept in {GIS}},
  year         = {2004},
  editor       = {Yong Xue and Xiangyu Sheng and Narayana Jayaram},
  volume       = {20},
  number       = {7},
  pages        = {1171-1184},
  comment      = {Cited in proposal for continuation of Rebecca Tse's work},
  journaltitle = {Future {G}eneration {C}omputer {S}ystems ({G}eocomputation)},
  owner        = {izzy},
  creationdate    = {2006/12/11},
}

@InProceedings{TseGK06,
  author    = {Rebecca O C Tse and Christopher Gold and David Kidner},
  title     = {A {N}ew {A}pproach to {U}rban {M}odelling {B}ased on {LIDAR}},
  booktitle = {Proceedings: {W}inter {S}chool of {C}omputer {S}ciences 2006, the 14-th {I}nternational {C}onference in {C}entral {E}urope on {C}omputer {G}raphics, {V}isualization and {C}omputer {V}ision'2006},
  year      = {2006},
  pages     = {279-286},
  address   = {Plzen, Czech Republic},
  comment   = {Cited in proposal for continuation of Rebecca Tse's work},
  groups    = {lidar},
  owner     = {izzy},
  creationdate = {2006/12/11},
}

@InProceedings{TucciGOCP01,
  author       = {Tucci, G and Guidi, G and Ostuni, D and Costantino, F and Pieraccini, M and Beraldin, J-A},
  booktitle    = {Proceedings of the 2001 {W}orkshop of {I}taly-{C}anada on 3{D} {D}igital {I}maging and {M}odeling {A}pplication of: {H}eritage, {I}ndustry, {M}edicine, \& {L}and},
  title        = {Photogrammetry and 3{D} Scanning: Assessment of Metric Accuracy for the Digital Model of {D}anatello's {M}addalena},
  url          = {http://iit-iti.nrc-cnrc.gc.ca/iit-publications-iti/docs/NRC-44879.pdf},
  address      = {Padova, Italy},
  comment      = {''a measurement over well-identified features of the sculpture have been performed and the distances between couples of significant points have been calculated (see relative accuracy/precision in QSS013129) with photogrammetric operations. By repeating the same measurements on the 3D model, a corresponding set of point-to-point distances have been evaluated and compared with the photogrammetric results.''},
  creationdate = {2005/08/08},
  keywords     = {3D, quality},
  owner        = {izzy},
  year         = {2001},
}

@Article{TupinHD02,
  author       = {Florence Tupin and Bijon Houshmand and Mihai Datcu},
  title        = {Road detection and the usefulness of multiple views},
  journaltitle = iegrs,
  year         = {2002},
  volume       = {40},
  number       = {11},
  pages        = {2405--2414},
  comment      = {Apply a line detector to SAR data and then reconstruct network using MRF approach. The graph model is labelled road and not-road by minimising an energy function which used prior knowledge about road shape, curvature and probablity of crossing.},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
}

@Misc{TurnerXX,
  author       = {Andy Turner},
  title        = {Geomorphometrics},
  howpublished = {Various internet articles},
  comment      = {Various things available from the University of Leeds. Some rotation invariant metrics applied to ?DSMs. http://www.personal.leeds.ac.uk/~bs06ljc E.g. for every point, all the other points in a kernal are considered.},
  keywords     = {geomorphometry},
  owner        = {izzy},
  creationdate    = {2008/09/25},
}

@Misc{Turner06,
  author       = {Turner, A},
  title        = {Geomorphometrics: Ideas for Generation and Use.},
  note         = {http://www.geog.leeds.ac.uk/people/a.turner/research/interests/geomorphometrics/Developing%20and%20Using%20Geomorphometrics0.3.1.doc (last accessed 03/11/08)},
  url          = {http://www.geog.leeds.ac.uk/people/a.turner/research/interests/geomorphometrics/Developing%20and%20Using%20Geomorphometrics0.3.1.doc},
  creationdate = {2008/11/05},
  keywords     = {geomorphometry},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{UlmW05,
  author       = {K. Ulm and X. Wang},
  booktitle    = {Proceedings of the 1st {I}nternational {W}orkshop on {N}ext {G}eneration 3{D} {C}ity {M}odels},
  title        = {Efficient reality-based 3{D} City Modeling with {C}yber{C}ity {M}odeler -- Management in {A}rc{GIS} (ESRI) and Visualization with {T}errain{V}iew},
  editor       = {Gr\''{o}ger and Kolbe},
  url          = {file:///L:/Izzy/presentations/NextGen3D/NextGen3Dreport.html},
  comment      = {Ulm (Ulm and Wang, 2005) gave an overview of CC-Modeler which also seemed quite promising. CC-Modeler can be used independently of the capture system, for example SOCET SET could be used to capture the roofs (much as has already been achieved in the Building Objects Database research). Thus CC-Modeler can be used as a 3D edit tool. It allows for extrusion of ground plans up to eave height - under previously captured roofs - enabling modelling of eaves. The software can be used to create true-orthoimages and its possible that textures can be cut from aerial or terrestrial images to 'texture' 3D objects. An interesting point was that CC-Modeler is currently setting up a partnership with ESRI.},
  creationdate = {2005/01/01},
  keywords     = {3D},
  owner        = {izzy},
  year         = {2005},
}

@Unpublished{unknown99,
  author       = {unknown},
  title        = {Change detection in rural areas - project completion report},
  note         = {Internal OS report},
  comment      = {Overview: A brief overview of a project looking at how change detection may be achieved in rural areas. A very brief list of techniques is given and a short list of 3 software packages. The information was derived from an internet-based investigation as well as some trialling of 2 of the software packages. This report follows on from a change detection report written in 1997 and a feature extraction report written in 1998. Comments: This report is too brief, does not reference any of its sources or describe in enough detail how the investigation was undertaken. This makes it very difficult of follow up. It seems rather confused when describing different change detection methods. Several of these methods do not detect change, rather they are ways of processing the data so that change may be highlighted. That the methods are very manual is expressed to in the conclusion, however. The report doesn't have a clear structure. For example, a short section 6 called Feature Extraction describes how edge detection is used to produce features to be (unsuccessfully) compared to Land Line data, which should surely be part of the potential algorithms section. The first sentence of the conclusion that ``the project has shown that change detection between images can be achieved'' does not seem strongly backed up by the rest of the report, rather the project has shown that differences between images (including illumination, viewing, atmospheric and other natural variations) have been identified. The research seemed to have been undertaken with a clear idea of the requirements of change detection in rural areas. Its a shame that these requirements were not stated in the report or the relevant document referenced. How could report be updated: This report requires a more comprehensive literature review that covers change detection using a variety of raster (including SAR) and vector (including laser scanning) data sources. Relevance to/of current or proposed activities: Because the change detection methods are a little unclear and the software has moved on since the writing of this report, it has little relevance to current or proposed activities. Reviewer: Izzy Date: March 2005},
  creationdate = {2005/01/01},
  owner        = {izzy},
  year         = {1999},
}

@Misc{UthusHHXX,
  author       = {L. Uthus and I. Hoff and I. Horvli},
  title        = {Evaluation of grain shape characterization methods for unbound aggregates},
  howpublished = {Internet},
  url          = {http://www.sintef.no/upload/154.pdf},
  comment      = {''The flatness ratio (p) is the ratio of the short length (thickness) to the intermediate length (width). The elongation ratio (q) is the ratio of the intermediate length to the longest length (length). By combining the flatness- and the elongation ratio, the shape of the aggregates can be described by a shape factor (F) and the sphericity (?). The shape factor is the ratio of the elongation ratio and the flatness ratio. F=p/q A round or cubical particle will have a shape factor equal to 1. If the shape factor is less than 1, the particle is more elongated and thin. A blade shaped particle will have a shape factor greater than 1. The sphericity is defined as the ratio of the surface area of a sphere having the same volume as the aggregate particle. The sphericity can also be expressed by the flatness- and elongation ratios ?=(12.8(cubedroot(p^2q)))/(1+p(1+q)+6(sqrt(1+p^2(1+q^2)))). The sphericity varies from values near 0 to values near 1.0 for perfect spheres.},
  creationdate = {2008/02/13},
  owner        = {izzy},
}

@Unpublished{Utteridge02,
  Title                    = {Feature {E}xtraction},
  Author                   = {Mark Utteridge},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {The aim of the presentation will be to give a flavour of the various methods of feature extraction carried out in the {I}nfoterra {L}td production environment. {F}eature extraction is routinely employed in the production of {O}rtho/{T}rue {O}rthophotographs, {C}lutter data, {T}errain elevation data and photogrammetrically derived vectors. {T}he range of customers supplied by {I}nfoterra {L}td means that data is rarely required in the same format and therefore production techniques vary not only by product but also by client. {F}urther more the source data used to derive the various products is widely varied in type, resolution and complexity. {E}xamples of current developments and employed techniques will be given with particular reference to the derivation of building outlines, 3{D} models, roadways, breaklines and wooded areas from laser scanner elevation and intensity data.},
  Organisation             = {Infoterra},
  Owner                    = {Izzy},
  creationdate                = {2005/01/01}
}

@InProceedings{ValletT05,
  author    = {Bruno Vallet and Franck Taillandier},
  title     = {Fitting {C}onstrained 3{D} {M}odels in {M}ultiple {A}erial {I}mages},
  booktitle = {British {M}achine {V}ision {C}onference},
  year      = {2005},
  editor    = {William Clocksin and Andrew Fitzgibbon and Philip Torr},
  month     = {September},
  url       = {http://www.bmva.ac.uk/bmvc/2005/papers/176/Vallet_Taillandier_BMVC2005.pdf},
  address   = {Oxford Brookes University, Oxford},
  comment   = {I can't really tell where the initial 3D model comes from, but this is matched to multiple images using any set of contraints. Maybe worth a proper read later.},
  keywords  = {3D, buildings},
  owner     = {izzy},
  creationdate = {2006/09/27},
}

@Book{Vapnik98,
  author    = {V. N. Vapnik},
  title     = {Statistical learning theory},
  year      = {1998},
  publisher = {New York: Wiley},
  comment   = {See pages 339-371 about transductive learning},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@InProceedings{VestriD00,
  author    = {C Vestri and F Devernay},
  title     = {Improving correlation-based {DEM}s by {I}mage {W}arping and {F}acade {C}orrelation},
  booktitle = {Proceedings {IEEE} {C}omputer {V}ision and {P}attern {R}ecognition},
  year      = {2000},
  volume    = {1},
  comment   = {Dont have a copy. Kim01 said this is research into increating the quality of DEMs using 10 or more images.},
  keywords  = {height, quality, toread},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Article{Virzi92,
  author       = {Virzi, Robert A},
  journaltitle = {Human {F}actors},
  title        = {Refining the test phase of usability evaluation: how many subjects is enough?},
  number       = {4},
  pages        = {457-468},
  volume       = {34},
  comment      = {In TRIM. Clare says:''Basically he did 3 experiments in which he got a panel of expert judges to assess the severity of usability problems of a system (actually a voicemail system but let's assume we can generalise), as compared to how many users it took in user trials (run by separate evaluators) for those problems to appear. In effect he showed that the more severe a problem is for users, the fewer people you need to find it... as you'd expect! With 6 users, as you're planning to have, around 85\% of the problems were found (and 60-70\% even of the ``least severe'' ones). He also points out that you can use his results to ask ``what \% of this user population would experience this problem?'' and ``what statistical confidence level can we have about that?'' Recalculating that way, he says that to have 80\% confidence that you'd found all the problems that would be experienced by 10\% or more of the user population, you'd need 15 users. But less (I haven't calculated how much less)if you only care about problems experienced by say 50\% of users, or if you can accept a lower confidence level. Final thing to note is that he does also say this [p. 467]: ``For the practitioner with only one chance to evaluate a user interface, the results suggest that the size of the evaluation should not be fixed prior to the test. Subjects should be run until the number of new problems uncovered drops to an acceptable level.'' I think that's good advice if we were doing the final evaluation before actually implementing a final, customised, system. But not for the case where you're comparing different early prototypes to get some approximate relative comparisons.'' From Lewis94: ``...three claims...(1) observing four of five participants will allow a usability practioner to sicover 80\% of a product's usability problems, (2) observating additional participants will reveal fewer and fewer new usability problems and (3) more severe usability problems are easier to detect with the first few participants'' Lewis94 says that the second claim is support by independant tests, the first claim is partially support but the third is not supported.},
  creationdate = {2006/01/26},
  keywords     = {usability, RapidDC},
  owner        = {izzy},
  year         = {1992},
}

@InProceedings{Vosselman02,
  Title                    = {Fusion of {L}aser {S}canning {D}ata, {M}aps, and {A}erial {P}hotographs for {B}uilding {R}econstruction},
  Author                   = {Vosselman, George},
  Booktitle                = {I{EEE} {I}nternational {G}eoscience and {R}emote {S}ensing, {S}ymposium and the 24th {C}anadian {S}ymposium on {R}emote {S}ensing, {IGARSS}'02},
  Year                     = {2002},

  Address                  = {Toronto, Canada},

  Owner                    = {izzy},
  creationdate                = {2005/01/01},
  Url                      = {http://www.itc.nl/personal/vosselman/papers/vosselman2002.igarss.pdf}
}

@Unpublished{Vosselman02a,
  Title                    = {{CAD}-based object reconstruction},
  Author                   = {George Vosselman},
  Note                     = {Loughborough Feature Extraction Workshop: commercial in confidence},
  Year                     = {2002},

  Abstract                 = {Man-made objects are often characterised by simple geometrical shapes. In particular factory installations, as seen e.g. in the petrochemical industries, can be modelled by compositions of primitive shapes using the CAD modelling technique CSG (constructive solid geometry). The presentation at the workshop will start with a review of an interactive photogrammetric measurement technique using a library of CAD models. While exemplified with close-range imagery of a gas drying installation, the same object modelling principles can also be applied to buildings in aerial photography. The second part of the presentation deals with the more automated 3D modelling of buildings using maps without height information in addition to the library of CAD models. It will discuss the advantages and disadvantages of top-down and bottom-up generation of building model hypotheses and strategies for the evaluation of these hypotheses. In a future project these strategies will be extended to incorporate cues from data acquired by other sensors like airborne laser scanners and 3-line cameras.},
  Organisation             = {Delft University of Technology},
  Owner                    = {Izzy},
  creationdate                = {2005/01/01}
}

@Article{Vosselman00,
  author       = {George Vosselman},
  journaltitle = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  title        = {Slope Based Filtering of Laser Altimetry Data},
  number       = {B3},
  pages        = {935-942},
  url          = {http://www.itc.nl/personal/vosselman/papers/vosselman2000.adam.pdf},
  volume       = {XXXIII},
  comment      = {Use the slope between two points to filter out non-terrain points. ``In this paper points were classified solely by comparing height differences between two points. Better classifications can be expected if other features, like height textures derived from multiple points are also used [Maas, 1999, Oude Elberink and Maas, 2000]. In that case it should become easier to make a distinction between a ground point on a sloped surface and a vegetation point on a horizontal surface, even though the maximum height differences between these points and their surrounding points are the same.''},
  creationdate = {2005/01/01},
  keywords     = {DTM, DEM},
  owner        = {izzy},
  year         = {2000},
}

@Article{VosselmanD01,
  author       = {Vosselman, George and Dijkman, Sander},
  title        = {3{D} building model reconstruction from point clouds and ground plans},
  journaltitle = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  year         = {2001},
  volume       = {XXXIV-3/W4},
  pages        = {37--43},
  url          = {http://www.isprs.org/proceedings/XXXIV/3-W4/pdf/Vosselman.pdf},
  abstract     = {Airborne laser altimetry has become a very popular technique for the acquisition of digital elevation models. {T}he high point density that can be achieved with this technique enables applications of laser data for many other purposes. {T}his paper deals with the construction of 3{D} models of the urban environment. {A} three-dimensional version of the well-known {H}ough transform is used for the extraction of planar faces from the irregularly distributed point clouds. {T}o support the 3{D} reconstruction usage is made of available ground plans of the buildings. {T}wo different strategies are explored to reconstruct building models from the detected planar faces and segmented ground plans. {W}hereas the first strategy tries to detect intersection lines and height jump edges, the second one assumes that all detected planar faces should model some part of the building. {E}xperiments show that the second strategy is able to reconstruct more buildings and more details of this buildings, but that it sometimes leads to additional parts of the model that do not exist. {W}hen restricted to buildings with rectangular segments of the ground plan, the second strategy was able to reconstruct 83 buildings out of a dataset with 94 buildings.},
  comment      = {Use ground plans to limit the search area. Fit plans to DEMs.},
  keyword      = {Building reconstruction, laser altimetry, Hough transform},
  keywords     = {toread, 3D},
  owner        = {Izzy},
  creationdate    = {2005/01/01},
  wherefind    = {SLSmith},
}

@InProceedings{Vozikis04,
  author    = {Vozikis, G},
  title     = {Automated {G}eneration {A}nd {U}pdating {O}f {D}igital {C}ity {M}odels {U}sing {H}igh-{R}esolution {L}ine {S}canning {S}ystems},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  url       = {http://www.ISPRS.org/istanbul2004/comm7/papers/198.pdf},
  comment   = {Use height information to detect buildings and then Hough transform to determine the roof outline. 2D model only extracted (and this is roof not footprint).},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@PhdThesis{Vranic04,
  author       = {Dejan V Vrani\'{c}},
  title        = {3D Model Retrieval},
  url          = {file://///os2k17/Research%20Labs/Lammergeier/Common/Library/ExternalPapers\Vranic04.pdf},
  abstract     = {''... The main objective of this thesis is construction, analysis, and testing of new techniques for describing 3D-shape of polygonal mesh models. Since a solid formal framework that could be used for defining optimal 3D-shape descriptors does not exist, we develop a variety of descriptors capturing different features of 3D-objects and using different representation methods. We consider a variety of features for characterizing 3D-shape such as extents of a model in certain directions, contours of 2D projections of a model, depth buffer images of a model, artificially defined volumes associated to triangles of a mesh, voxel grids attributed by fractions of the total surface area of a mesh, rendered perspective projections of a model on an enclosing sphere, and layered depth spheres. The used representation techniques include the 1D, 2D, and 3D discrete Fourier transforms, the Fourier transform on a sphere (spherical harmonics), and moments for representing the extent function. We also introduce two approaches for merging appropriate feature vectors, by defining a complex function on a sphere, and by crossbreeding (hybrid descriptors). We present a variety of original feature extraction algorithms and give complete specifications for forming feature vector components for each of presented approaches. A Webbased 3D model retrieval system is implemented as serves as a proof-of-concept. We compare two techniques for achieving invariance of descriptors with respect to rotation of the polygonal mesh, the Principal Component Analysis (PCA) vs. a property of spherical harmonics. Several tests show that the first approach (PCA) is better method for attaining rotation invariance of descriptors. ...''},
  creationdate = {2008/03/10},
  keywords     = {morphology},
  owner        = {izzy},
  school       = {Fakult\''{a}t f\''{u}r Mathematik und Informatik, Universit\''{a}t Leizig},
  year         = {2004},
}

@InProceedings{Vranic05,
  author    = {Vranic, D V},
  title     = {{DESIRE}: a composite 3D-shape descriptor},
  booktitle = {Multimedia and Expo, 2005. ICME 2005. IEEE International Conference},
  year      = {2005},
  abstract  = {The topic of this communication is shape-similarity search for 3D-mesh models. We present and evaluate a composite 3D-shape feature vector (DESIRE), which is formed using depth buffer images, silhouettes, and ray-extents of a polygonal mesh. We contrast our method with the approach that is declared the best in the recent study. Our experiments suggest that the composite feature vector, which is extracted in a canonical coordinate frame, generally outperforms the competing method, which relies upon pairwise alignment of models. We also provide a Web-based retrieval system as well as publicly available executables for verifying the results.},
  comment   = {get a copy?
Review:
Based on his PhD work I assume. Supervisor was Saupe.},
  keywords  = {morphology},
  owner     = {izzy},
  creationdate = {2008/02/21},
}

@InProceedings{WagstaffCRS01,
  author    = {Kiri Wagstaff and Claire Cardie and Seth Rogers and Stefan Schroedl},
  title     = {Constrained {K}-means {C}lustering with {B}ackground {K}nowledge},
  booktitle = {Proceedings of the {E}ighteenth {I}nternational {C}onference on {M}achine {L}earning},
  year      = {2001},
  pages     = {577-584},
  url       = {http://www.litech.org/~wkiri/Papers/wagstaff-kmeans-01.pdf},
  comment   = {referenced by HeilerKS05 as constraned k-means},
  owner     = {izzy},
  creationdate = {2005/09/13},
}

@InProceedings{WahlH05,
  author    = {Eric Wahl and Gerd Hirzinger},
  title     = {Cluster-based point cloud analysis for rapid scene interpretation},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {This is about chosing a sensor depending on the object in question. This sensor weems to have everything - laser range scanner, laser stripe profiler and stereo imager. close range phtogrammetry.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@MastersThesis{Walker10,
  author       = {Lucy Walker},
  title        = {Roof Classification from Aerial Photography},
  comment      = {I have only skimmed this. The document reads very well and has a comprehensive literature review. ENVI is used for the classification and some detail is given on the use of this software. The work attempts to classify building objects (as defined by OS MasterMap Topography Layer polygons) first using unsupervised algorithms (ISODATA and k-means) as then in 5 roof material classes using several supervised techniques (multi-layer perceptron, support vector machines, maximum likelihood and parallelpiped). The input features are the average values for each of the 4 bands for each object. SVM did not work because of the size of the data set. Training and testing data were used produced using various sources (Google Earth, Architectural consultation). The MLP gave the highest accuracy results (~85%) and other measures of accuracy are also calculated. The work concludes with identifying improvements: using the DSM in the classification, addressing the differences in illumation between and within roofs, extending roof material types classes, addressing the offset between the vectors and the building roofs, identifying suiltable site for green roofs. A good basic study for a MSc project.},
  creationdate = {2010.07.01},
  owner        = {Izzy},
  school       = {Faculty of Development and Society, Sheffield Hallam University},
  year         = {2010},
}

@Article{WallaceHLPM02,
  author       = {Wallace, S.J and Hatcher, M.J and Ley, R.G and Priestnall, G and Morton, R. D},
  journaltitle = {\''{O}sterreichische Zeitschrift f\''{u}r Vermessung und Geoinformation},
  title        = {Automatic differentiation of linear features extracted from remotely sensed imagery},
  pages        = {17-29},
  volume       = {3+4},
  comment      = {In TRIM},
  creationdate = {2008/02/04},
  owner        = {izzy},
  year         = {2002},
}

@Unpublished{WallacePMD02,
  author       = {Wallace, S J and .Priestnall, G and Morton, R D and Dowman, I},
  title        = {Automatic differentiation of linear features extracted from remotely sensed imagery},
  note         = {Loughborough Feature Extraction Workshop: commercial in confidence},
  abstract     = {An approach to automated feature extraction is presented which uses an object-oriented geodata model as the framework to store contextual knowledge and to use this both to control feature extraction routines and to automatically differentiate between linear feature classes (roads, railways, rivers etc.). {T}he problem of geographic extraction has proved complex and ideally requires the incorporation of contextual clues similar to those used by human interpreters of imagery. {O}ften the feature recognition algorithms work at local levels and in a bottom-up fashion and lack the higher level control that would allow a more global understanding of parts of the image. {A} proof of principle system has been developed under {UK} {M}inistry of {D}efence {C}orporate {R}esearch funding. {T}he project is named ``{A}utomatic {L}inear {F}eature {I}dentification and {E}xtraction'' ({ALFIE}). {T}he geodata model comprises a class hierarchy representing the features under study and their likely relationships. {E}ach class of object within this model contains criteria that need to be satisfied in order to strengthen the belief that an instance of that object type has been recognised. {T}he criteria cannot be rigid and the system must be able to control partial recognition of objects and identify conflicts. {T}he system described has at its core a spatially enabled object oriented database. {T}his enables the extraction of linears to be divorced from the classification process which gives the system the flexibility to build up evidence of class membership from a variety of sources. {I}n this way individual linears can be tagged with initial probabilities of class membership and refined following further processing, such as network building stages, where classification conflicts are identified and resolved to provide more probable class memberships. {T}he classification algorithm which provides the initial probabilities utilises a {B}ayesian graphical modelling approach (the {C}luster {W}eighted {M}odel). {T}he evidence used in the cluster weighted model uses both geometric and photometric values. {E}ighteen discriminants were initially identified. {A}nalysis showed five to be key - width, variation in width, sinuosity, dominant spectral value and variation in spectral value. {R}esults are available which provide summarise the classification accuracy obtained from the initial classification process and the final output of the system in terms of classification accuracy and network completeness. {A} follow-on project is currently underway to integrate 3-{D} feature extraction into the {ALFIE} framework.},
  comment      = {In filing cabinet},
  creationdate = {2008/02/04},
  organisation = {Wallace: QinetiQ Ltd, UK; Priestnall: School of Geography, University of Nottingham; Morton: Laser-Scan Ltd, Cambridge, UK; Dowman: University College London, UK},
  owner        = {izzy},
  year         = {2002},
}

@Article{WangM08,
  Title                    = {A statistical approach to volume data quality assessment},
  Author                   = {Wang, Chaoli and Ma, Kwan-Liu},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {590-602},
  Volume                   = {14},

  Abstract                 = {Quality assessment plays a crucial role in data analysis. In this paper, we present a reduced-reference approach to volume data quality assessment. Our algorithm extracts important statistical information from the original data in the wavelet domain. Using the extracted information as feature and predefined distance functions, we are able to identify and quantify the quality loss in the reduced or distorted version of data, eliminating the need to access the original data. Our feature representation is naturally organized in the form of multiple scales, which facilitates quality evaluation of data with different resolutions. The feature can be effectively compressed in size. We have experimented with our algorithm on scientific and medical data sets of various sizes and characteristics. Our results show that the size of the feature does not increase in proportion to the size of original data. This ensures the scalability of our algorithm and makes it very applicable for quality assessment of large-scale data sets. Additionally, the feature could be used to repair the reduced or distorted data for quality improvement. Finally, our approach can be treated as a new way to evaluate the uncertainty introduced by different versions of data.},
  Comment                  = {Ordered on ILL 14/10/08},
  Journaltitle             = {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
  Keywords                 = {3D, quality},
  Owner                    = {izzy},
  creationdate                = {2008/10/14},
  Url                      = {http://www.cs.mtu.edu/~chaoliw/research/tvcg08-vdqa.pdf}
}

@Article{WangT02,
  author       = {Sendo Wang and Yi-Hsing Tseng},
  title        = {Least-squares model-image fitting for building extraction from aerial images},
  journaltitle = {Asian {J}ournal of {G}eoinformatics},
  year         = {2002},
  volume       = {4},
  number       = {4},
  pages        = {3-12},
  comment      = {Fit primitive CSG models to multiple images. Do this by finding lines in images to fit models to. Horizontal accuracy good but verticle accuracy not so good. Say improvements would be made with more images and better constraints.},
  owner        = {izzy},
  creationdate    = {2005/01/01},
}

@Article{WangB01,
  author       = {Zhon Wang and Alan Conrad Bovik},
  journaltitle = ieip,
  title        = {Embedded foveation image coding},
  number       = {10},
  pages        = {1397--1410},
  volume       = {10},
  comment      = {Have predefined foveation points and regions in the images (iz: can define these at point of interest such as roads, buildings etc). These are used to compute an error sensitivity-based importance mask, which weights wavelet coefficients. They then use a modification of the ``Said and Pearlman's set partitioning in hierarchical trees'' (SPIHT) algorithm, which itself is a modification of Shapiro's ``embedded zerotree wavelet'' (EZW) algorithm. These try to order the output bitstream such that those bits with greater contribution to the MSE between the original the the compressed images are encoded and transmitted first. Having been encoded and transmitted the reverse precess is applied to reconstruct the image. The receiver can specify bit-rate and foveation points and also the decoder can truncate the received bitstream to obtain any bit rate image below the encoder bit-rate.},
  creationdate = {2005/01/01},
  haveiread    = {Y},
  year         = {2001},
}

@InProceedings{WaSc00,
  Title                    = {Building extraction and reconstruction from {L}i{DAR} data},
  Author                   = {Z Wang and T Schenk},
  Booktitle                = {International {A}rchives of {P}hotogrammetry and {R}emote {S}ensing},
  Year                     = {2000},

  Address                  = {Amsterdam},
  Number                   = {Part B3},
  Volume                   = {XXXIII},

  Groups                   = {lidar},
  Owner                    = {slsmith},
  creationdate                = {2005/01/01}
}

@Article{WatanabeSS02,
  author       = {Toshinori Watanabe and Ken Sugawara and Hiroshi Sugihara},
  title        = {A new pattern representation scheme using data compression},
  journaltitle = iepami,
  year         = {2002},
  volume       = {24},
  number       = {5},
  pages        = {579--590},
  comment      = {Data are translated into a 'text' which is a finite sequence of character from an 'alphabet'. Substrings of the text define a 'dectionary' of words with a maximum length (defined by the user). A compression retio can be fefined for any text, given a dictionary, as the length of the longest word in the text that is found in that dictionary divided by the length of the text (I think - they seem to wrote this awkwardly). With a number of dictionaries, a compression ratio vector can be defined for a text. It is this n-D vector that can be used to compress and represent the data. Use technique for classifying colour photos - gives reasonable results.},
  haveiread    = {Y},
  creationdate    = {2005/01/01},
}

@Unpublished{Weidner02,
  author       = {Uwe Weidner},
  title        = {On {Q}uality {E}valuation of 3{D}-{B}uilding {M}odels},
  note         = {Loughborough Feature Extraction Workshop: commercial in confidence},
  abstract     = {In contrast to the huge amount of references dealing with semi-automatic or automatic approaches for building reconstruction from aerial images or laser scanner data (c.f. {B}altasavias 2001 and previous proceedings of the {A}scona-{W}orkshop), there are only a few references focussing on quality evaluation of the extracted building models (e.g. {M}c{G}lone/{S}hufelt 1994, {W}eidner 1997, {M}c{K}eown et al. 2000 and {R}agia 2001). {Q}uality evaluation is important due to several reasons. {F}irst, it may give important information about deficiencies of an approach and may thereby help to focus further research activities. {S}econd, quality evaluation is needed in order to compare the results of the different approaches and to convince a user, that an approach can be used in an operational workflow. {B}esides these reasons, the most important reason arise from the practical requirement, that a contractor should check his measurements and that a customer has to check the quality of the delivered data with respect to the specifications of the contract. {F}or this purpose, quality evaluation should not only be based on visual and thereby subjective control, but on quantitative quality measures. {T}herefore, a recent project in cooperation with the {S}urveying {O}ffice of {N}orthrhine-{W}estfalia investigates this topic with the aim to indentify useful quality measures which can be used for contract specifications and to implement an approach for automated quality control based on a comparision between measurement and reference data. {R}eferences:\\ - {B}altsavias, {E}.{P}.; {G}r\''un, {A}.; {V}an {G}ool, {L}. ({H}rsg.) (2001): {A}utomatic {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages {III}. {A}.{A}. {B}alkema {P}ublishers, 2001\\ - {H}enricsson, {O}.; {B}altsavias, {E}.{P}. (1997): 3-{D} {B}uilding {R}econstruction with {ARUBA}: {A} {Q}ualitative and {Q}uantitative {E}valuation. {I}n: {G}r\''un, {A}.; {B}altsavias, {E}.{P}.; {H}enricsson, {O}. ({H}rsg.)(1997): {A}utomatic {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages. {B}irkh\''auser, {B}asel, 1997\\ - {M}c{G}lone, {J}.{C}.; {S}hufelt, {J}.{A}. (1994): {P}rojective and {O}bject {S}pace {G}eometry for {M}onocular {B}uilding {E}xtraction. {I}n: {P}roceedings {C}omputer {V}ision and {P}attern {R}ecognition, {S}eiten 54 - 61, 1994\\ - {M}c{K}eown, {D}.{M}.; {B}ulwinkle, {T}.; {C}ochran, {S}.; {H}arvey, {W}.; {M}c{G}lone, {C}.; {S}hufelt, {J}.{A}. (2000): {P}erformance {E}valuation for {A}utomatic {F}eature {E}xtraction. {I}n: {IAPRS}, {V}ol. 33, {P}art {B}2, 379 - 394, 2000\\ - {R}agia, {L}. (2001): {E}in {M}odell f\''ur die {Q}ualit\''at r\''aumlicher {D}aten zur {B}ewertung der photogrammetrischen {G}eb\''audeerfassung. {T}echnischer {B}ericht 14, {G}esellschaft f\''ur mathematische {D}atenverarbeitung - {F}orschungszentrum {I}nformationstechnik {G}mb{H}, 2001\\ - {W}eidner, {U}. (1997): {G}eb\''audeerfassung aus {D}igitalen {O}berfl\''achenmodellen, {B}and 474 der {R}eihe {C}, {D}eutsche {G}eod\''atische {K}ommission, {M}\''unchen, 1997},
  creationdate = {2005/01/01},
  keywords     = {3D, quality},
  organisation = {Institute for Photogrammetry, University Bonn},
  owner        = {Izzy},
  year         = {2002},
}

@TechReport{Weidner97,
  author       = {Weidner, Uwe},
  institution  = {Deutsche Geod\''{a}tische Kommission},
  title        = {Geb\''{a}udeerfassung aus {{D}igitalen} {{O}berfl\''{a}chenmodellen}.},
  number       = {Volume 474},
  type         = {C},
  address      = {M\''{u}nchen},
  comment      = {According to SchusterW03 do quality assessment using type-2 error (ommission, I think), quality rate, weighted quality rate, and RMS/distance},
  creationdate = {2005/11/18},
  keywords     = {quality},
  owner        = {izzy},
  year         = {1997},
}

@Article{WiebeB01,
  Title                    = {Improving {I}mage and {V}ideo {T}ransmission {Q}uality over {ATM} with {F}oveal {P}rioritization and {P}riority {D}ithering},
  Author                   = {Wiebe, Kevin James and Basu, Anup},
  Year                     = {2001},
  Number                   = {8},
  Pages                    = {905--915},
  Volume                   = {22},

  Anstract                 = {Several characteristics of the Asynchronous Transfer Mode (ATM) protocol are making it increasingly popular with designers of networked multimedia systems. However, the main draw-back to ATM-based switching is the possibility of information loss with congestion. In this paper, we address this issue; we demonstrate that with intelligent, fovea driven priority assignment of image data, we can reduce the negative impact of information loss over ATM networks. ATM standards allow a single bit to indicate high or low packet priority. To reduce the effect of this restriction we introduce the concept of priority dithering. Network multimedia multicast scenarios over heterogeneous link capacities where foveal prioritization would be of benefit are described. Net- work simulation results of this method are included which demonstrate the advantages of priority dithered foveal prioritization over traditional methods.},
  Haveiread                = {no},
  Infile                   = {foveal},
  Journaltitle             = {Pattern {R}ecognition {L}etters},
  creationdate                = {2005/01/01},
  Url                      = {http://citeseer.nj.nec.com/473014.html}
}

@InProceedings{WillertECK05,
  author       = {Volker Willert and Julian Eggert and Sebastian Clever and Edgar K\''{o}rner},
  booktitle    = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  title        = {Probabilistic color optical flow},
  editor       = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note         = {see also log book},
  address      = {Vienna, Austria},
  comment      = {Optical flow is motion tracking and usually uses only luminance. This paper inclusdes colour. Seems to give better flow estimation.},
  creationdate = {2005/09/03},
  owner        = {izzy},
  year         = {2005},
}

@Article{Wilson04,
  Title                    = {C{MOS} single-chip sensor captures 3-{D} images},
  Author                   = {Wilson, Andrew},
  Year                     = {2004},

  Month                    = {July},
  Pages                    = {7-8},

  Comments                 = {A summary of new technology from Canesta. My notes, having read press releases and part of a technical paper:Rather than using stereo imaging or laser scanning, this patent pending technology from Canesta can capture 3-D information from one image frame. This is achieved by emitting light for which the phase has been modulated. When this light is reflected back to the sensor, there is a measureable delay in the phase which is directly related to the distance of the reflecting surface from the light source. The technology is cheap is intended to capture 3-D information in real-time. The principal use for such imaging devices seems to be for robotic vision and the range of the sensor is not far (a few metres?). Its will probably be a while before such technology can be used for data capture, but worth keeping an eye on - so to speak. Press release: www.canesta.com/news/20040504.htm. A technical paper: metrology.eng.sunysb.edu/realtime3D.htm},
  Journaltitle             = {Vision {S}ystems {D}esign},
  Keywords                 = {3D},
  creationdate                = {2005/01/01}
}

@Article{Wilson04b,
  Title                    = {I{C} vendors tailor imagers to meet demands},
  Author                   = {Andrew Wilson},
  Year                     = {2004},

  Month                    = {June},
  Pages                    = {47--52},

  Comments                 = {Useful article for learning about CCD and CMOS differences as well as the variations therein and what uses these imagers are put to.},
  Journaltitle             = {Vision {S}ystems {D}esign},
  creationdate                = {2005/01/01}
}

@TechReport{WongR90,
  author      = {Gee-Kay Wong and Ralph Rengger},
  title       = {The validity of questionnaires designed to measure user-satisfaction of computer systems},
  institution = {National Physical Laboratory},
  year        = {1990},
  number      = {NPL Report DITC 169/90},
  month       = {October},
  comment     = {Clare has hardcopy. Compares several different user-satisfaction questionnaires: CUSI, SUS (Brooke96) and QUIS. It may be worth reading this more carefull before undertaking any questionnairre analysis.},
  keywords    = {usability, RapidDC},
  owner       = {izzy},
  creationdate   = {2006/02/01},
}

@Misc{Wood05,
  author       = {Lucy Wood},
  title        = {I{DENTIFYING} {KEY} {USERS} {OF} 3{D} {GEOGRAPHICAL} {INFORMATION} {REPORT}},
  howpublished = {Internal R\&I document},
  note         = {\url{file://///os2k05/Research/Projects/GeoUsers/Goal%202+3+Orch%20work%20(Squish,%20inc%20BOD)/BOD_Users/Internal%203D%20knowledge/Strategic%20Users%20Research%20Report_Final.doc}},
  creationdate = {2005/10/03},
  keywords     = {3D},
  month        = {February},
  owner        = {izzy},
  year         = {2005},
}

@Article{XiongS04,
  author       = {Demin Xiong and Jonathan Sperling},
  journaltitle = ijprs,
  title        = {Semiautomated matching for network database integration},
  pages        = {35-46},
  volume       = {59},
  comment      = {''The automated algorithm establishes robust correspondences for nodes, edges and segments between two networks using a cluster-based matching mechanism''. Could be useful for comparing derived vectors with already existing vectors - change detection?},
  creationdate = {2005/01/01},
  owner        = {izzy},
  wherefind    = {library},
  year         = {2004},
}

@InProceedings{YangKK01,
  Title                    = {View-dependent progressive mesh coding for graphic streaming},
  Author                   = {Sheng Yang and Chang-Su Kim and C.-C. Jay Kuo},
  Booktitle                = {Conference on multimedia systems and applications IV. SPIE International symposium on the convergence of information technologies and communications.},
  Year                     = {2001},

  Address                  = {Denver, Colorado},
  Month                    = {August},
  Organization             = {SPIE},
  Publisher                = {SPIE},

  Keywords                 = {TIN compression},
  Owner                    = {izzy},
  creationdate                = {2008/02/04}
}

@Article{YangLZ07,
  author       = {Yang, Y B and Lin, H and Zhang, Y},
  journaltitle = {IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART C-APPLICATIONS AND REVIEWS},
  title        = {Content-based 3-D model retrieval: A survey},
  number       = {6},
  pages        = {1081-1098},
  volume       = {37},
  abstract     = {As the number of available 3-D models grows, there is an increasing need to index and retrieve them according to their contents. This paper provides a survey of the up-to-date methods for content-based 3-D model retrieval. First, the new challenges encountered in 3-D model retrieval are discussed. Then, the system framework and some key techniques of content-based 3-D model retrieval are identified and explained, including canonical coordinate normalization and preprocessing, feature extraction, similarity match, query representation and user interface, and performance evaluation. In particular, similarity measures using semantic clues and machine learning methods, as well as retrieval approaches using nonshape features, are given adequate recognition as improvements and complements for traditional shapematching techniques. Typical 3-D model retrieval systems and search engines are also listed and compared. Finally, future research directions are indicated, and an extensive bibliography is provided.},
  comment      = {Hard copy in filing cabinet
Review:
Typically a content-based 3D model retrieval system comprises 1) canonical coordinate normalisation and model preprocessing; 2) feature extraction; 3) similarity matching and 4) query interface. I am interested in 1) and 2) and maybe a little of 3). Normalisation is required to make featres extracted inveriant to scale, psition and orientation. Often normalisation uses principal component analysis, especially for rotation. This works reasonably except when models have two or more PCs of similar variance (eigenvalues) ``which usually happens to different models within the same category (Funkhouser03, Kazhdan04). Divide feature extraction into shape features and appearance features. Global geometrical analysis methods: align the model using PCA-like methods and Vranic propose produce a feature that is the maximum distance along a equally-spaced rays from the origin of the co-ordinate system to triangles that define the object. Suzuki divided the model into a a set of grid cells and computed the number of vetices in each grid cell. Also Heczko et al and Vranic used octrees. Other methods are briefly but not very clearly described. The section on function mapping methods includes spherical mapping and 2D planar mapping. The latter is quite interesting - various methods of mapping the 3D model onto 2D in a binary form or including some indication of depth. Zernike models and Fourier descriptors are used. Statistical properties methods includes moments, which I still don't really understand and no-one seems to explain, and histograms such as Osada's 5 shape functions. Topology methods include how to generate graphs (mainly medial axis transforms). Similarity matching can be divided into distance metrics, graph matching, machine learning and semantic measurements. The latter include 'subjective measures' and could perhaps be relevant to meaningful roof features such as dormers, ridge, etc.},
  creationdate = {2008/02/21},
  keywords     = {morphology},
  owner        = {izzy},
  year         = {2007},
}

@InProceedings{ZahediKDN05,
  author    = {Morteza Zehedi and Daniel Keysers and Thomas Deselars and Hermann Ney},
  title     = {Combination of tangent distance and an image distortion model for appearance-based sign language recognition},
  booktitle = {Pattern {R}ecogition. {P}roceedings of the 27th {DAGM} {S}ymposium.},
  year      = {2005},
  editor    = {Kropatsch, Walter G and Sablatnig, Robert and Hanbury, Allan},
  note      = {see also log book},
  address   = {Vienna, Austria},
  comment   = {Trying to automatically understand sign language (why??) which is a considerably more complex problem that modelling than RosenhahnKSGBK05? However, seem to massively reduce resultion of image (movie) data so that fingers can no longer be distibuished and this may be why the signs for toy and car were no distinguiable.},
  owner     = {izzy},
  creationdate = {2005/09/03},
}

@Article{ZhangYC06,
  author       = {Zhang, Keqi and Yan, Jianhua and Chen, Shu-Ching},
  journaltitle = {IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING},
  title        = {Automatic construction of building footprint's from airborne LIDAR data},
  number       = {9},
  pages        = {2523-2533},
  volume       = {44},
  abstract     = {This paper presents a framework that applies a series of algorithms to automatically extract building footprints from airborne light detection and ranging (LIDAR) measurements. In the proposed framework, the ground and nonground LIDAR measurements are first separated using a progressive morphological filter. Then, building measurements are identified from nonground measurements using a region-growing algorithm based on the plane-fitting technique. Finally, raw footprints for segmented building measurements are derived by connecting boundary points, and the raw footprints are further simplified and adjusted to remove noise caused by irregularly spaced LIDAR measurements. Data sets from urbanized areas including large institutional, commercial, and small residential buildings were employed to test the proposed framework. A quantitative analysis showed that the total of omission and commission errors for extracted footprints for both institutional and residential areas was about 12%. The results demonstrated that the proposed framework identified building footprints well.},
  creationdate = {2008/05/28},
  keywords     = {lidar},
  owner        = {izzy},
  year         = {2006},
}

@InProceedings{ZhangZ04,
  Title                    = {Applications of 3{D} city models based spatial analysis to urban design},
  Author                   = {Zhang, Xiaa and Zhu, Qing},
  Booktitle                = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  Year                     = {2004},
  Editor                   = {M Orhan {ALTAN}},
  Volume                   = {XXXV},

  Keywords                 = {3D},
  Owner                    = {Izzy},
  creationdate                = {2005/01/01}
}

@InProceedings{ZhengaZZ04,
  author    = {Zhenga, Shunyi and Zhana, Zongqian and Zhang, Zuxun},
  title     = {A flexible and automatic 3{D} reconstruction method},
  booktitle = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  year      = {2004},
  editor    = {M Orhan {ALTAN}},
  volume    = {XXXV},
  comment   = {handheld camera},
  keywords  = {3D},
  owner     = {Izzy},
  creationdate = {2005/01/01},
}

@Article{ZhouSSC04,
  Title                    = {Urban 3D GIS From {LiDAR} and digital aerial images},
  Author                   = {Guoqing Zhou and C Song and J Simmers and P Cheng},
  Year                     = {2004},
  Number                   = {4},
  Pages                    = {345-353},
  Volume                   = {30},

  Abstract                 = {This paper presents a method, which integrates image knowledge and Light Detection And Ranging (LiDAR) point cloud data for urban digital terrain model (DTM) and digital building model (DBM) generation. The DBM is an Object-Oriented data structure, in which each building is considered as a building object, i.e., an entity of the building class. The attributes of each building include roof types, polygons of the roof surfaces, height, parameters describing the roof surfaces, and the LiDAR point array within the roof surfaces. Each polygon represents a roof surface of building. This type of data structure is flexible for adding other building attributes in future, such as texture information and wall information. Using image knowledge extracted, we developed a new method of interpolating LiDAR raw data into grid digital surface model (DSM) with considering the steep discontinuities of buildings. In this interpolation method, the LiDAR data points, which are located in the polygon of roof surfaces, first are determined, and then interpolation via planar equation is employed for grid DSM generation. The basic steps of our research are: (1) edge detection by digital image processing algorithms; (2) complete extraction of the building roof edges by digital image processing and human-computer interactive operation; (3) establishment of DBM; (4) generation of DTM by removing surface objects. Finally, we implement the above functions by MS VC++ programming. The outcome of urban 3D DSM, DTM and DBM is exported into urban database for urban 3D GIs, (C) 2004 Elsevier Ltd. All rights},
  Journaltitle             = {Computers \& Geosciences},
  Keywords                 = {3D},
  Owner                    = {Izzy},
  creationdate                = {2007/11/16}
}

@InProceedings{ZhouBC05,
  author       = {Zhou, J and Bischof, W F and Caelli, T},
  title        = {Robust and efficient road tracking in aerial images},
  booktitle    = {International archives of photogrammetry, remote sensing and spatial information sciences. ({O}bject extraction for 3{D} city models, road databases and traffic monitoring - concepts, algorithms and evaluation)},
  year         = {2005},
  editor       = {U Stilla and F Rottensteiner and S Hinz},
  volume       = {XXXVI},
  organization = {Joint workshop of ISPRS and DAGM},
  comment      = {Improve the speed of map update by reducing human involvement. But keep the human in the loop because computer vision algorithms can be weak.Study and model human performance. Identify key actions and difficulties. Interface that tracks user action. Human starts tracking and computer takes over. If computer struggles it hands back to human. The evaluation criteria are a) saving of inputs b) saving of time c) percentage of tracking and d) RMSE. no solution yet for intersections.},
  keywords     = {quality},
  owner        = {izzy},
  creationdate    = {2005/09/05},
}

@Article{ZhuLZZH02,
  Title                    = {CyberCity GIS (CCGIS): Integration of DEMs, images, and 3D models},
  Author                   = {Zhu, Q and Li, D and Zhang, YT and Zhong, Z and Huang, D},
  Year                     = {2002},
  Number                   = {4},
  Pages                    = {361-367},
  Volume                   = {68},

  Abstract                 = {A CyberCity is a virtual representation of a city that enables a person to explore and interact, in cyberspace, with the vast amount of environmental and cultural information gathered about the city. A GIS software for CyberCity called CCGIS, has been developed, and this paper reports its technical characteristics, including the three-dimensional hierarchical modeling technique, the integrated database structure, and the interactive method of visualization of the three-dimensional data of urban environments. The effective integrated data organization strategy for dynamical loading and progressive rendering, which enables CCGIS to support the development, design, and presentation of a large CyberCity, is stressed. Finally, a pilot project for CCGIS software application is also demonstrated.},
  Journaltitle             = {PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING},
  Keywords                 = {3D},
  Owner                    = {izzy},
  creationdate                = {2008/05/28}
}

@Proceedings{ISPRS04,
  Title                    = {The international archives of the photogrammetry, remote sensing and spatial information sciences},
  Year                     = {2004},
  Editor                   = {M Orhan {ALTAN}},
  Volume                   = {XXXV},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Book{Ascona01,
  title        = {Automatic {E}xtraction of {M}an-{M}ade {O}bjects from {A}erial and {S}pace {I}mages ({III})},
  editor       = {E P Baltsavias and A Gr\''un and van Gool, L},
  publisher    = {A.A. Balkema Publishers},
  address      = {Centro Stafano Franscini, Monte Verit\`{a}, Ascona},
  booktitle    = {Automatic extraction of man-made objects from aerial and space images {III}},
  comment      = {Quote from booknew.co.uk: ``These are the papers from the workshop at the conference held in Switzerland in June 2001 and, as such, provide an almost-complete account of the current state-of-the-art in man-made object extraction. Most of the papers deal with different levels of automation for building and road extraction from aerial film and digital images and from airborne laser and SAR, and satellite images. Other topics included 3D city models, vegetation extraction, revisiting based sequences and visualisation.''},
  creationdate = {2005/01/01},
  organization = {Swiss Federal Institute of Technology ({ETH}), Zurich, Switzerland},
  year         = {2001},
}

@Misc{buildingrecognition,
  url       = {http://homepages.inf.ed.ac.uk/cgi/rbf/CVONLINE/entries.pl?TAG930},
  comment   = {some interestings building recognition papers},
  owner     = {izzy},
  creationdate = {2005/01/01},
}

@Manual{ISO19113,
  title     = {I{SO} 19113:2002 {G}eographic information -- {Q}uality principles},
  comment   = {in library},
  keywords  = {quality toread},
  owner     = {izzy},
  creationdate = {2005/11/17},
}

@Manual{ISO19114,
  title     = {I{SO} 19114:2003 {G}eographic information -- {Q}uality evaluation procedures},
  comment   = {Look for ISO19114_draft in share_library},
  keywords  = {quality toread},
  owner     = {izzy},
  creationdate = {2005/11/17},
}

@Unpublished{3DPatentAppln05,
  title     = {Application papers for three-dimensional mapping system and method},
  year      = {2005},
  note      = {Application for patent?},
  month     = {March},
  comment   = {In filing cabinet.},
  keywords  = {3D},
  owner     = {izzy},
  creationdate = {2008/02/04},
}

@Proceedings{ASPRS04,
  Title                    = {Proceedings of {ASPRS} 2004 {C}onference},
  Year                     = {2004},

  Address                  = {Denver, Colorado},
  Month                    = {May},
  Organization             = {ASPRS},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Proceedings{IGARSS2002,
  Title                    = {Remote {S}ensing: {I}ntegrating {O}ur {V}iew of the {P}lanet},
  Year                     = {2002},
  Organization             = {IEEE},
  Publisher                = {IEEE},

  Booktitle                = {Remote {S}ensing: {I}ntegrating {O}ur {V}iew of the {P}lanet},
  creationdate                = {2005/01/01}
}

@Proceedings{ISPRS02,
  Title                    = {Integrated {S}ystem for {S}patial {D}ata {P}roduction, {C}ustodian and {D}ecision {S}upport, {ISPRS} {C}ommission {II} {S}ymposium},
  Year                     = {2002},

  Address                  = {Xi'an, P.R.China},
  Month                    = {August 20-23},

  Owner                    = {izzy},
  Text                     = {Olsen, B P, Knudsen, T and Frederiksen, P, 2002. Digital Change Detection For Map Database Update. Integrated System for Spatial Data Production, Custodian and Decision Support, {ISPRS} Commission II Symposium. Xi'an, P.R.China},
  creationdate                = {2005/01/01},
  Url                      = {http://www.ISPRS.org/commission2/proceedings/contents.html}
}

@Proceedings{PCV02,
  Title                    = {Proceedings of the {P}hotogrammetric {C}omputer {V}ision},
  Year                     = {2002},

  Address                  = {Graz, Austria},
  Month                    = {September},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Proceedings{ISPRS00,
  Title                    = {X{IX}th {C}ongress of {ISPRS}: {G}eoinformation for {A}ll},
  Year                     = {2000},

  Address                  = {Amsterdam, The Netherlands},
  Month                    = {July},
  Volume                   = {XXXIII},

  Owner                    = {izzy},
  creationdate                = {2005/01/01}
}

@Proceedings{ISCAS99,
  Title                    = {I{SCAS} '99: {PROCEEDINGS} {OF} {THE} 1999 {IEEE} {INTERNATIONAL} {SYMPOSIUM} {ON} {CIRCUITS} {AND} {SYSTEMS}},
  Year                     = {1999},
  Organization             = {IEEE},

  Booktitle                = {I{SCAS} '99: {PROCEEDINGS} {OF} {THE} 1999 {IEEE} {INTERNATIONAL} {SYMPOSIUM} {ON} {CIRCUITS} {AND} {SYSTEMS}},
  creationdate                = {2005/01/01}
}

@Proceedings{CVPR85,
  Title                    = {I{EEE} {CVPR} {C}onference, {S}an {F}rancisco.},
  Year                     = {1985},
  Organization             = {IEEE},

  Booktitle                = {I{EEE} {CVPR} {C}onference, {S}an {F}rancisco.},
  creationdate                = {2005/01/01}
}

@Proceedings{ieeecvpr85,
  Title                    = {I{EEE} {CVPR} {C}onference},
  Year                     = {1985},
  Organization             = {IEEE},

  Booktitle                = {I{EEE} {CVPR} {C}onference},
  creationdate                = {2005/01/01}
}

@Comment{jabref-meta: databaseType:bibtex;}
